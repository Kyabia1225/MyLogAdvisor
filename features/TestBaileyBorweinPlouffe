[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "testMod",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testMod()\n{\r\n    final BigInteger TWO = BigInteger.ONE.add(BigInteger.ONE);\r\n    for (long n = 3; n < 100; n++) {\r\n        for (long e = 1; e < 100; e++) {\r\n            final long r = TWO.modPow(BigInteger.valueOf(e), BigInteger.valueOf(n)).longValue();\r\n            Assert.assertEquals(\"e=\" + e + \", n=\" + n, r, BaileyBorweinPlouffe.mod(e, n));\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "testHexDigit",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testHexDigit()\n{\r\n    final long[] answers = { 0x43F6, 0xA308, 0x29B7, 0x49F1, 0x8AC8, 0x35EA };\r\n    long d = 1;\r\n    for (int i = 0; i < answers.length; i++) {\r\n        Assert.assertEquals(\"d=\" + d, answers[i], BaileyBorweinPlouffe.hexDigits(d));\r\n        d *= 10;\r\n    }\r\n    Assert.assertEquals(0x243FL, BaileyBorweinPlouffe.hexDigits(0));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "nextPositiveLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long nextPositiveLong()\n{\r\n    return RAN.nextLong() & MASK;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "verifyMultiplication",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void verifyMultiplication(long a, long b)\n{\r\n    final LongLong ll = LongLong.multiplication(new LongLong(), a, b);\r\n    final BigInteger bi = BigInteger.valueOf(a).multiply(BigInteger.valueOf(b));\r\n    final String s = String.format(\"\\na = %x\\nb = %x\\nll= \" + ll + \"\\nbi= \" + bi.toString(16) + \"\\n\", a, b);\r\n    Assert.assertEquals(s, bi, ll.toBigInteger());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "testMultiplication",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testMultiplication()\n{\r\n    for (int i = 0; i < 100; i++) {\r\n        final long a = nextPositiveLong();\r\n        final long b = nextPositiveLong();\r\n        verifyMultiplication(a, b);\r\n    }\r\n    final long max = Long.MAX_VALUE & MASK;\r\n    verifyMultiplication(max, max);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "testRightShift",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRightShift()\n{\r\n    for (int i = 0; i < 1000; i++) {\r\n        final long a = nextPositiveLong();\r\n        final long b = nextPositiveLong();\r\n        verifyRightShift(a, b);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "verifyRightShift",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void verifyRightShift(long a, long b)\n{\r\n    final LongLong ll = new LongLong().set(a, b);\r\n    final BigInteger bi = ll.toBigInteger();\r\n    final String s = String.format(\"\\na = %x\\nb = %x\\nll= \" + ll + \"\\nbi= \" + bi.toString(16) + \"\\n\", a, b);\r\n    Assert.assertEquals(s, bi, ll.toBigInteger());\r\n    for (int i = 0; i < LongLong.SIZE >> 1; i++) {\r\n        final long result = ll.shiftRight(i) & MASK;\r\n        final long expected = bi.shiftRight(i).longValue() & MASK;\r\n        Assert.assertEquals(s, expected, result);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\mapreduce\\lib\\db",
  "methodName" : "testRun",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRun() throws Exception\n{\r\n    DBCountPageView testDriver = new DBCountPageView();\r\n    ToolRunner.run(createJobConf(), testDriver, new String[0]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "deleteDir",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean deleteDir(File dir)\n{\r\n    if (dir.isDirectory()) {\r\n        String[] children = dir.list();\r\n        for (int i = 0; i < children.length; i++) {\r\n            boolean success = deleteDir(new File(dir, children[i]));\r\n            if (!success) {\r\n                System.out.println(\"Could not delete directory after test!\");\r\n                return false;\r\n            }\r\n        }\r\n    }\r\n    return dir.delete();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    deleteDir(new File(MEAN_OUTPUT));\r\n    deleteDir(new File(MEDIAN_OUTPUT));\r\n    deleteDir(new File(STDDEV_OUTPUT));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "testGetTheMean",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetTheMean() throws Exception\n{\r\n    String[] args = new String[2];\r\n    args[0] = INPUT;\r\n    args[1] = MEAN_OUTPUT;\r\n    WordMean wm = new WordMean();\r\n    ToolRunner.run(new Configuration(), wm, args);\r\n    double mean = wm.getMean();\r\n    WordMeanReader wr = new WordMeanReader();\r\n    assertEquals(mean, wr.read(INPUT), 0.0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "testGetTheMedian",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetTheMedian() throws Exception\n{\r\n    String[] args = new String[2];\r\n    args[0] = INPUT;\r\n    args[1] = MEDIAN_OUTPUT;\r\n    WordMedian wm = new WordMedian();\r\n    ToolRunner.run(new Configuration(), wm, args);\r\n    double median = wm.getMedian();\r\n    WordMedianReader wr = new WordMedianReader();\r\n    assertEquals(median, wr.read(INPUT), 0.0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "testGetTheStandardDeviation",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetTheStandardDeviation() throws Exception\n{\r\n    String[] args = new String[2];\r\n    args[0] = INPUT;\r\n    args[1] = STDDEV_OUTPUT;\r\n    WordStandardDeviation wsd = new WordStandardDeviation();\r\n    ToolRunner.run(new Configuration(), wsd, args);\r\n    double stddev = wsd.getStandardDeviation();\r\n    WordStdDevReader wr = new WordStdDevReader();\r\n    assertEquals(stddev, wr.read(INPUT), 0.0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples",
  "methodName" : "cleanup",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void cleanup() throws Exception\n{\r\n    deleteDir(new File(MEAN_OUTPUT));\r\n    deleteDir(new File(MEDIAN_OUTPUT));\r\n    deleteDir(new File(STDDEV_OUTPUT));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\terasort",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void tearDown() throws Exception\n{\r\n    getFileSystem().delete(TEST_DIR, true);\r\n    super.tearDown();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\terasort",
  "methodName" : "runTeraGen",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void runTeraGen(Configuration conf, Path sortInput) throws Exception\n{\r\n    String[] genArgs = { NUM_ROWS, sortInput.toString() };\r\n    assertEquals(0, ToolRunner.run(conf, new TeraGen(), genArgs));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\terasort",
  "methodName" : "runTeraSort",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void runTeraSort(Configuration conf, Path sortInput, Path sortOutput) throws Exception\n{\r\n    String[] sortArgs = { sortInput.toString(), sortOutput.toString() };\r\n    assertEquals(0, ToolRunner.run(conf, new TeraSort(), sortArgs));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\terasort",
  "methodName" : "runTeraValidator",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void runTeraValidator(Configuration job, Path sortOutput, Path valOutput) throws Exception\n{\r\n    String[] svArgs = { sortOutput.toString(), valOutput.toString() };\r\n    assertEquals(0, ToolRunner.run(job, new TeraValidate(), svArgs));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\terasort",
  "methodName" : "testTeraSort",
  "errType" : [ "FileAlreadyExistsException", "FileAlreadyExistsException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testTeraSort() throws Exception\n{\r\n    runTeraGen(createJobConf(), SORT_INPUT_PATH);\r\n    try {\r\n        runTeraGen(createJobConf(), SORT_INPUT_PATH);\r\n        fail(\"Teragen output overwritten!\");\r\n    } catch (FileAlreadyExistsException fae) {\r\n        LOG.info(\"Expected exception: \", fae);\r\n    }\r\n    runTeraSort(createJobConf(), SORT_INPUT_PATH, SORT_OUTPUT_PATH);\r\n    try {\r\n        runTeraSort(createJobConf(), SORT_INPUT_PATH, SORT_OUTPUT_PATH);\r\n        fail(\"Terasort output overwritten!\");\r\n    } catch (FileAlreadyExistsException fae) {\r\n        LOG.info(\"Expected exception: \", fae);\r\n    }\r\n    runTeraValidator(createJobConf(), SORT_OUTPUT_PATH, TERA_OUTPUT_PATH);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\terasort",
  "methodName" : "testTeraSortWithLessThanTwoArgs",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testTeraSortWithLessThanTwoArgs() throws Exception\n{\r\n    String[] args = new String[1];\r\n    assertThat(new TeraSort().run(args)).isEqualTo(2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "newSummation",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Summation2 newSummation(final long base, final long range, final long delta)\n{\r\n    final ArithmeticProgression N = new ArithmeticProgression('n', base + 3, delta, base + 3 + range);\r\n    final ArithmeticProgression E = new ArithmeticProgression('e', base + range, -delta, base);\r\n    return new Summation2(N, E);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "runTestSubtract",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void runTestSubtract(Summation sigma, List<Summation> diff)\n{\r\n    List<Container<Summation>> tmp = new ArrayList<Container<Summation>>(diff.size());\r\n    for (Summation s : diff) tmp.add(s);\r\n    final List<Summation> a = sigma.remainingTerms(tmp);\r\n    a.addAll(diff);\r\n    for (Summation s : a) s.compute();\r\n    final List<Summation> combined = Util.combine(a);\r\n    Assert.assertEquals(1, combined.size());\r\n    Assert.assertEquals(sigma, combined.get(0));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "testSubtract",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testSubtract()\n{\r\n    final Summation sigma = newSummation(3, 10000, 20);\r\n    final int size = 10;\r\n    final List<Summation> parts = Arrays.asList(sigma.partition(size));\r\n    Collections.sort(parts);\r\n    runTestSubtract(sigma, new ArrayList<Summation>());\r\n    runTestSubtract(sigma, parts);\r\n    for (int n = 1; n < size; n++) {\r\n        for (int j = 0; j < 10; j++) {\r\n            final List<Summation> diff = new ArrayList<Summation>(parts);\r\n            for (int i = 0; i < n; i++) diff.remove(RANDOM.nextInt(diff.size()));\r\n            runTestSubtract(sigma, diff);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "computeBenchmarks",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void computeBenchmarks(final Summation2 sigma)\n{\r\n    final Timer t = new Timer(false);\r\n    t.tick(\"sigma=\" + sigma);\r\n    final double value = sigma.compute();\r\n    t.tick(\"compute=\" + value);\r\n    Assert.assertEquals(value, sigma.compute_modular(), DOUBLE_DELTA);\r\n    t.tick(\"compute_modular\");\r\n    Assert.assertEquals(value, sigma.compute_montgomery(), DOUBLE_DELTA);\r\n    t.tick(\"compute_montgomery\");\r\n    Assert.assertEquals(value, sigma.compute_montgomery2(), DOUBLE_DELTA);\r\n    t.tick(\"compute_montgomery2\");\r\n    Assert.assertEquals(value, sigma.compute_modBigInteger(), DOUBLE_DELTA);\r\n    t.tick(\"compute_modBigInteger\");\r\n    Assert.assertEquals(value, sigma.compute_modPow(), DOUBLE_DELTA);\r\n    t.tick(\"compute_modPow\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    final long delta = 1L << 4;\r\n    final long range = 1L << 20;\r\n    for (int i = 20; i < 40; i += 2) computeBenchmarks(newSummation(1L << i, range, delta));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "div",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long div(long sum, long r, long n)\n{\r\n    long q = 0;\r\n    int i = DIV_VALID_BIT - 1;\r\n    for (r <<= 1; r < n; r <<= 1) i--;\r\n    for (; i >= 0; ) {\r\n        r -= n;\r\n        q |= (1L << i);\r\n        if (r <= 0)\r\n            break;\r\n        for (; r < n; r <<= 1) i--;\r\n    }\r\n    sum += q;\r\n    return sum < DIV_LIMIT ? sum : sum - DIV_LIMIT;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "testDiv",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testDiv()\n{\r\n    for (long n = 2; n < 100; n++) for (long r = 1; r < n; r++) {\r\n        final long a = div(0, r, n);\r\n        final long b = (long) ((r * 1.0 / n) * (1L << DIV_VALID_BIT));\r\n        final String s = String.format(\"r=%d, n=%d, a=%X, b=%X\", r, n, a, b);\r\n        Assert.assertEquals(s, b, a);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "generateRN",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "long[][][] generateRN(int nsize, int rsize)\n{\r\n    final long[][][] rn = new long[nsize][][];\r\n    for (int i = 0; i < rn.length; i++) {\r\n        rn[i] = new long[rsize + 1][];\r\n        long n = RANDOM.nextLong() & 0xFFFFFFFFFFFFFFFL;\r\n        if (n <= 1)\r\n            n = 0xFFFFFFFFFFFFFFFL - n;\r\n        rn[i][0] = new long[] { n };\r\n        final BigInteger N = BigInteger.valueOf(n);\r\n        for (int j = 1; j < rn[i].length; j++) {\r\n            long r = RANDOM.nextLong();\r\n            if (r < 0)\r\n                r = -r;\r\n            if (r >= n)\r\n                r %= n;\r\n            final BigInteger R = BigInteger.valueOf(r);\r\n            rn[i][j] = new long[] { r, R.multiply(R).mod(N).longValue() };\r\n        }\r\n    }\r\n    return rn;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "square_slow",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long square_slow(long z, final long n)\n{\r\n    long r = 0;\r\n    for (long s = z; z > 0; z >>= 1) {\r\n        if ((((int) z) & 1) == 1) {\r\n            r += s;\r\n            if (r >= n)\r\n                r -= n;\r\n        }\r\n        s <<= 1;\r\n        if (s >= n)\r\n            s -= n;\r\n    }\r\n    return r;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "square",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long square(long r, final long n, long r2p64)\n{\r\n    if (r <= Modular.MAX_SQRT_LONG) {\r\n        r *= r;\r\n        if (r >= n)\r\n            r %= n;\r\n    } else {\r\n        final int HALF = (63 - Long.numberOfLeadingZeros(n)) >> 1;\r\n        final int FULL = HALF << 1;\r\n        final long ONES = (1 << HALF) - 1;\r\n        final long high = r >>> HALF;\r\n        final long low = r &= ONES;\r\n        r *= r;\r\n        if (r >= n)\r\n            r %= n;\r\n        if (high != 0) {\r\n            long s = high * high;\r\n            if (s >= n)\r\n                s %= n;\r\n            for (int i = 0; i < FULL; i++) if ((s <<= 1) >= n)\r\n                s -= n;\r\n            if (low == 0)\r\n                r = s;\r\n            else {\r\n                long t = high * low;\r\n                if (t >= n)\r\n                    t %= n;\r\n                for (int i = -1; i < HALF; i++) if ((t <<= 1) >= n)\r\n                    t -= n;\r\n                r += s;\r\n                if (r >= n)\r\n                    r -= n;\r\n                r += t;\r\n                if (r >= n)\r\n                    r -= n;\r\n            }\r\n        }\r\n    }\r\n    return r;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "squareBenchmarks",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void squareBenchmarks()\n{\r\n    final Timer t = new Timer(false);\r\n    t.tick(\"squareBenchmarks(), MAX_SQRT=\" + Modular.MAX_SQRT_LONG);\r\n    final long[][][] rn = generateRN(1000, 1000);\r\n    t.tick(\"generateRN\");\r\n    for (int i = 0; i < rn.length; i++) {\r\n        final long n = rn[i][0][0];\r\n        for (int j = 1; j < rn[i].length; j++) {\r\n            final long r = rn[i][j][0];\r\n            final long answer = rn[i][j][1];\r\n            final long s = square_slow(r, n);\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"r=\" + r + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"square_slow\");\r\n    for (int i = 0; i < rn.length; i++) {\r\n        final long n = rn[i][0][0];\r\n        long r2p64 = (0x4000000000000000L % n) << 1;\r\n        if (r2p64 >= n)\r\n            r2p64 -= n;\r\n        for (int j = 1; j < rn[i].length; j++) {\r\n            final long r = rn[i][j][0];\r\n            final long answer = rn[i][j][1];\r\n            final long s = square(r, n, r2p64);\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"r=\" + r + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"square\");\r\n    for (int i = 0; i < rn.length; i++) {\r\n        final long n = rn[i][0][0];\r\n        final BigInteger N = BigInteger.valueOf(n);\r\n        for (int j = 1; j < rn[i].length; j++) {\r\n            final long r = rn[i][j][0];\r\n            final long answer = rn[i][j][1];\r\n            final BigInteger R = BigInteger.valueOf(r);\r\n            final long s = R.multiply(R).mod(N).longValue();\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"r=\" + r + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"R.multiply(R).mod(N)\");\r\n    for (int i = 0; i < rn.length; i++) {\r\n        final long n = rn[i][0][0];\r\n        final BigInteger N = BigInteger.valueOf(n);\r\n        for (int j = 1; j < rn[i].length; j++) {\r\n            final long r = rn[i][j][0];\r\n            final long answer = rn[i][j][1];\r\n            final BigInteger R = BigInteger.valueOf(r);\r\n            final long s = R.modPow(TWO, N).longValue();\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"r=\" + r + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"R.modPow(TWO, N)\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "generateEN",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "long[][][] generateEN(int nsize, int esize)\n{\r\n    final long[][][] en = new long[nsize][][];\r\n    for (int i = 0; i < en.length; i++) {\r\n        en[i] = new long[esize + 1][];\r\n        long n = (RANDOM.nextLong() & 0xFFFFFFFFFFFFFFFL) | 1L;\r\n        if (n == 1)\r\n            n = 3;\r\n        en[i][0] = new long[] { n };\r\n        final BigInteger N = BigInteger.valueOf(n);\r\n        for (int j = 1; j < en[i].length; j++) {\r\n            long e = RANDOM.nextLong();\r\n            if (e < 0)\r\n                e = -e;\r\n            final BigInteger E = BigInteger.valueOf(e);\r\n            en[i][j] = new long[] { e, TWO.modPow(E, N).longValue() };\r\n        }\r\n    }\r\n    return en;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "modBigInteger",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long modBigInteger(final long e, final long n)\n{\r\n    long mask = (e & 0xFFFFFFFF00000000L) == 0 ? 0x00000000FFFFFFFFL : 0xFFFFFFFF00000000L;\r\n    mask &= (e & 0xFFFF0000FFFF0000L & mask) == 0 ? 0x0000FFFF0000FFFFL : 0xFFFF0000FFFF0000L;\r\n    mask &= (e & 0xFF00FF00FF00FF00L & mask) == 0 ? 0x00FF00FF00FF00FFL : 0xFF00FF00FF00FF00L;\r\n    mask &= (e & 0xF0F0F0F0F0F0F0F0L & mask) == 0 ? 0x0F0F0F0F0F0F0F0FL : 0xF0F0F0F0F0F0F0F0L;\r\n    mask &= (e & 0xCCCCCCCCCCCCCCCCL & mask) == 0 ? 0x3333333333333333L : 0xCCCCCCCCCCCCCCCCL;\r\n    mask &= (e & 0xAAAAAAAAAAAAAAAAL & mask) == 0 ? 0x5555555555555555L : 0xAAAAAAAAAAAAAAAAL;\r\n    final BigInteger N = BigInteger.valueOf(n);\r\n    long r = 2;\r\n    for (mask >>= 1; mask > 0; mask >>= 1) {\r\n        if (r <= Modular.MAX_SQRT_LONG) {\r\n            r *= r;\r\n            if (r >= n)\r\n                r %= n;\r\n        } else {\r\n            final BigInteger R = BigInteger.valueOf(r);\r\n            r = R.multiply(R).mod(N).longValue();\r\n        }\r\n        if ((e & mask) != 0) {\r\n            r <<= 1;\r\n            if (r >= n)\r\n                r -= n;\r\n        }\r\n    }\r\n    return r;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "modBenchmarks",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void modBenchmarks()\n{\r\n    final Timer t = new Timer(false);\r\n    t.tick(\"modBenchmarks()\");\r\n    final long[][][] en = generateEN(10000, 10);\r\n    t.tick(\"generateEN\");\r\n    for (int i = 0; i < en.length; i++) {\r\n        final long n = en[i][0][0];\r\n        for (int j = 1; j < en[i].length; j++) {\r\n            final long e = en[i][j][0];\r\n            final long answer = en[i][j][1];\r\n            final long s = Modular.mod(e, n);\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"e=\" + e + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"Modular.mod\");\r\n    final Montgomery2 m2 = new Montgomery2();\r\n    for (int i = 0; i < en.length; i++) {\r\n        final long n = en[i][0][0];\r\n        m2.set(n);\r\n        for (int j = 1; j < en[i].length; j++) {\r\n            final long e = en[i][j][0];\r\n            final long answer = en[i][j][1];\r\n            final long s = m2.mod(e);\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"e=\" + e + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"montgomery.mod\");\r\n    for (int i = 0; i < en.length; i++) {\r\n        final long n = en[i][0][0];\r\n        m2.set(n);\r\n        for (int j = 1; j < en[i].length; j++) {\r\n            final long e = en[i][j][0];\r\n            final long answer = en[i][j][1];\r\n            final long s = m2.mod2(e);\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"e=\" + e + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"montgomery.mod2\");\r\n    for (int i = 0; i < en.length; i++) {\r\n        final long n = en[i][0][0];\r\n        final BigInteger N = BigInteger.valueOf(n);\r\n        for (int j = 1; j < en[i].length; j++) {\r\n            final long e = en[i][j][0];\r\n            final long answer = en[i][j][1];\r\n            final long s = TWO.modPow(BigInteger.valueOf(e), N).longValue();\r\n            if (s != answer) {\r\n                Assert.assertEquals(\"e=\" + e + \", n=\" + n + \", answer=\" + answer + \" but s=\" + s, answer, s);\r\n            }\r\n        }\r\n    }\r\n    t.tick(\"BigInteger.modPow(e, n)\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-examples\\src\\test\\java\\org\\apache\\hadoop\\examples\\pi\\math",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    squareBenchmarks();\r\n    modBenchmarks();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]