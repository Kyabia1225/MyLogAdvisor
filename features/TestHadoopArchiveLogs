[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testCheckFilesAndSeedApps",
  "errType" : null,
  "containingMethodsNum" : 29,
  "sourceCodeText" : "void testCheckFilesAndSeedApps() throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    HadoopArchiveLogs hal = new HadoopArchiveLogs(conf);\r\n    FileSystem fs = FileSystem.getLocal(conf);\r\n    Path rootLogDir = new Path(\"target\", \"logs\");\r\n    String suffix = \"logs\";\r\n    Path logDir = new Path(rootLogDir, new Path(USER, suffix));\r\n    fs.delete(logDir, true);\r\n    Assert.assertFalse(fs.exists(logDir));\r\n    fs.mkdirs(logDir);\r\n    ApplicationId appId1 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 1);\r\n    Path app1Path = new Path(logDir, appId1.toString());\r\n    fs.mkdirs(app1Path);\r\n    ApplicationId appId2 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 2);\r\n    Path app2Path = new Path(logDir, appId2.toString());\r\n    fs.mkdirs(app2Path);\r\n    createFile(fs, new Path(app2Path, \"file1\"), 1);\r\n    hal.minNumLogFiles = 2;\r\n    ApplicationId appId3 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 3);\r\n    Path app3Path = new Path(logDir, appId3.toString());\r\n    fs.mkdirs(app3Path);\r\n    createFile(fs, new Path(app3Path, \"file1\"), 2);\r\n    createFile(fs, new Path(app3Path, \"file2\"), 5);\r\n    hal.maxTotalLogsSize = FILE_SIZE_INCREMENT * 6;\r\n    ApplicationId appId4 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 4);\r\n    Path app4Path = new Path(logDir, appId4.toString());\r\n    fs.mkdirs(app4Path);\r\n    createFile(fs, new Path(app4Path, appId4 + \".har\"), 1);\r\n    ApplicationId appId5 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 5);\r\n    Path app5Path = new Path(logDir, appId5.toString());\r\n    fs.mkdirs(app5Path);\r\n    createFile(fs, new Path(app5Path, \"file1\"), 2);\r\n    createFile(fs, new Path(app5Path, \"file2\"), 3);\r\n    Assert.assertEquals(0, hal.eligibleApplications.size());\r\n    hal.checkFilesAndSeedApps(fs, rootLogDir, suffix, new Path(rootLogDir, \"archive-logs-work\"));\r\n    Assert.assertEquals(1, hal.eligibleApplications.size());\r\n    Assert.assertEquals(appId5.toString(), hal.eligibleApplications.iterator().next().getAppId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testCheckMaxEligible",
  "errType" : null,
  "containingMethodsNum" : 42,
  "sourceCodeText" : "void testCheckMaxEligible() throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    HadoopArchiveLogs.AppInfo app1 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 1).toString(), USER);\r\n    app1.setFinishTime(CLUSTER_TIMESTAMP - 5);\r\n    HadoopArchiveLogs.AppInfo app2 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 2).toString(), USER);\r\n    app2.setFinishTime(CLUSTER_TIMESTAMP - 10);\r\n    HadoopArchiveLogs.AppInfo app3 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 3).toString(), USER);\r\n    HadoopArchiveLogs.AppInfo app4 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 4).toString(), USER);\r\n    app4.setFinishTime(CLUSTER_TIMESTAMP + 5);\r\n    HadoopArchiveLogs.AppInfo app5 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 5).toString(), USER);\r\n    app5.setFinishTime(CLUSTER_TIMESTAMP + 10);\r\n    HadoopArchiveLogs.AppInfo app6 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 6).toString(), USER);\r\n    HadoopArchiveLogs.AppInfo app7 = new HadoopArchiveLogs.AppInfo(ApplicationId.newInstance(CLUSTER_TIMESTAMP, 7).toString(), USER);\r\n    app7.setFinishTime(CLUSTER_TIMESTAMP);\r\n    HadoopArchiveLogs hal = new HadoopArchiveLogs(conf);\r\n    Assert.assertEquals(0, hal.eligibleApplications.size());\r\n    hal.eligibleApplications.add(app1);\r\n    hal.eligibleApplications.add(app2);\r\n    hal.eligibleApplications.add(app3);\r\n    hal.eligibleApplications.add(app4);\r\n    hal.eligibleApplications.add(app5);\r\n    hal.eligibleApplications.add(app6);\r\n    hal.eligibleApplications.add(app7);\r\n    Assert.assertEquals(7, hal.eligibleApplications.size());\r\n    hal.maxEligible = -1;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(7, hal.eligibleApplications.size());\r\n    hal.maxEligible = 6;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(6, hal.eligibleApplications.size());\r\n    Assert.assertFalse(hal.eligibleApplications.contains(app5));\r\n    hal.maxEligible = 5;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(5, hal.eligibleApplications.size());\r\n    Assert.assertFalse(hal.eligibleApplications.contains(app4));\r\n    hal.maxEligible = 4;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(4, hal.eligibleApplications.size());\r\n    Assert.assertFalse(hal.eligibleApplications.contains(app7));\r\n    hal.maxEligible = 3;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(3, hal.eligibleApplications.size());\r\n    Assert.assertFalse(hal.eligibleApplications.contains(app1));\r\n    hal.maxEligible = 2;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(2, hal.eligibleApplications.size());\r\n    Assert.assertFalse(hal.eligibleApplications.contains(app2));\r\n    hal.maxEligible = 1;\r\n    hal.checkMaxEligible();\r\n    Assert.assertEquals(1, hal.eligibleApplications.size());\r\n    Assert.assertFalse(hal.eligibleApplications.contains(app6));\r\n    Assert.assertTrue(hal.eligibleApplications.contains(app3));\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testFilterAppsByAggregatedStatus",
  "errType" : null,
  "containingMethodsNum" : 39,
  "sourceCodeText" : "void testFilterAppsByAggregatedStatus() throws Exception\n{\r\n    try (MiniYARNCluster yarnCluster = new MiniYARNCluster(TestHadoopArchiveLogs.class.getSimpleName(), 1, 1, 1, 1)) {\r\n        Configuration conf = new Configuration();\r\n        conf.setBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED, true);\r\n        yarnCluster.init(conf);\r\n        yarnCluster.start();\r\n        conf = yarnCluster.getConfig();\r\n        RMContext rmContext = yarnCluster.getResourceManager().getRMContext();\r\n        RMAppImpl appImpl1 = (RMAppImpl) createRMApp(1, conf, rmContext, LogAggregationStatus.DISABLED);\r\n        RMAppImpl appImpl2 = (RMAppImpl) createRMApp(2, conf, rmContext, LogAggregationStatus.FAILED);\r\n        RMAppImpl appImpl3 = (RMAppImpl) createRMApp(3, conf, rmContext, LogAggregationStatus.NOT_START);\r\n        RMAppImpl appImpl4 = (RMAppImpl) createRMApp(4, conf, rmContext, LogAggregationStatus.SUCCEEDED);\r\n        RMAppImpl appImpl5 = (RMAppImpl) createRMApp(5, conf, rmContext, LogAggregationStatus.RUNNING);\r\n        RMAppImpl appImpl6 = (RMAppImpl) createRMApp(6, conf, rmContext, LogAggregationStatus.RUNNING_WITH_FAILURE);\r\n        RMAppImpl appImpl7 = (RMAppImpl) createRMApp(7, conf, rmContext, LogAggregationStatus.TIME_OUT);\r\n        RMAppImpl appImpl8 = (RMAppImpl) createRMApp(8, conf, rmContext, LogAggregationStatus.SUCCEEDED);\r\n        rmContext.getRMApps().put(appImpl1.getApplicationId(), appImpl1);\r\n        rmContext.getRMApps().put(appImpl2.getApplicationId(), appImpl2);\r\n        rmContext.getRMApps().put(appImpl3.getApplicationId(), appImpl3);\r\n        rmContext.getRMApps().put(appImpl4.getApplicationId(), appImpl4);\r\n        rmContext.getRMApps().put(appImpl5.getApplicationId(), appImpl5);\r\n        rmContext.getRMApps().put(appImpl6.getApplicationId(), appImpl6);\r\n        rmContext.getRMApps().put(appImpl7.getApplicationId(), appImpl7);\r\n        HadoopArchiveLogs hal = new HadoopArchiveLogs(conf);\r\n        Assert.assertEquals(0, hal.eligibleApplications.size());\r\n        hal.eligibleApplications.add(new HadoopArchiveLogs.AppInfo(appImpl1.getApplicationId().toString(), USER));\r\n        hal.eligibleApplications.add(new HadoopArchiveLogs.AppInfo(appImpl2.getApplicationId().toString(), USER));\r\n        hal.eligibleApplications.add(new HadoopArchiveLogs.AppInfo(appImpl3.getApplicationId().toString(), USER));\r\n        HadoopArchiveLogs.AppInfo app4 = new HadoopArchiveLogs.AppInfo(appImpl4.getApplicationId().toString(), USER);\r\n        hal.eligibleApplications.add(app4);\r\n        hal.eligibleApplications.add(new HadoopArchiveLogs.AppInfo(appImpl5.getApplicationId().toString(), USER));\r\n        hal.eligibleApplications.add(new HadoopArchiveLogs.AppInfo(appImpl6.getApplicationId().toString(), USER));\r\n        HadoopArchiveLogs.AppInfo app7 = new HadoopArchiveLogs.AppInfo(appImpl7.getApplicationId().toString(), USER);\r\n        hal.eligibleApplications.add(app7);\r\n        HadoopArchiveLogs.AppInfo app8 = new HadoopArchiveLogs.AppInfo(appImpl8.getApplicationId().toString(), USER);\r\n        hal.eligibleApplications.add(app8);\r\n        Assert.assertEquals(8, hal.eligibleApplications.size());\r\n        hal.filterAppsByAggregatedStatus();\r\n        Assert.assertEquals(3, hal.eligibleApplications.size());\r\n        Assert.assertTrue(hal.eligibleApplications.contains(app4));\r\n        Assert.assertTrue(hal.eligibleApplications.contains(app7));\r\n        Assert.assertTrue(hal.eligibleApplications.contains(app8));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testGenerateScript",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testGenerateScript() throws Exception\n{\r\n    _testGenerateScript(false);\r\n    _testGenerateScript(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "_testGenerateScript",
  "errType" : null,
  "containingMethodsNum" : 45,
  "sourceCodeText" : "void _testGenerateScript(boolean proxy) throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    HadoopArchiveLogs hal = new HadoopArchiveLogs(conf);\r\n    Path workingDir = new Path(\"/tmp\", \"working\");\r\n    Path remoteRootLogDir = new Path(\"/tmp\", \"logs\");\r\n    String suffix = \"logs\";\r\n    ApplicationId app1 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 1);\r\n    HadoopArchiveLogs.AppInfo appInfo1 = new HadoopArchiveLogs.AppInfo(app1.toString(), USER);\r\n    appInfo1.setSuffix(suffix);\r\n    appInfo1.setRemoteRootLogDir(remoteRootLogDir);\r\n    appInfo1.setWorkingDir(workingDir);\r\n    hal.eligibleApplications.add(appInfo1);\r\n    ApplicationId app2 = ApplicationId.newInstance(CLUSTER_TIMESTAMP, 2);\r\n    Path workingDir2 = new Path(\"/tmp\", \"working2\");\r\n    Path remoteRootLogDir2 = new Path(\"/tmp\", \"logs2\");\r\n    String suffix2 = \"logs2\";\r\n    HadoopArchiveLogs.AppInfo appInfo2 = new HadoopArchiveLogs.AppInfo(app2.toString(), USER);\r\n    appInfo2.setSuffix(suffix2);\r\n    appInfo2.setRemoteRootLogDir(remoteRootLogDir2);\r\n    appInfo2.setWorkingDir(workingDir2);\r\n    hal.eligibleApplications.add(appInfo2);\r\n    hal.proxy = proxy;\r\n    File localScript = new File(\"target\", \"script.sh\");\r\n    localScript.delete();\r\n    Assert.assertFalse(localScript.exists());\r\n    hal.generateScript(localScript);\r\n    Assert.assertTrue(localScript.exists());\r\n    String script = IOUtils.toString(localScript.toURI(), StandardCharsets.UTF_8);\r\n    String[] lines = script.split(\"\\n\");\r\n    Assert.assertEquals(22, lines.length);\r\n    Assert.assertEquals(\"#!/bin/bash\", lines[0]);\r\n    Assert.assertEquals(\"set -e\", lines[1]);\r\n    Assert.assertEquals(\"set -x\", lines[2]);\r\n    Assert.assertEquals(\"if [ \\\"$YARN_SHELL_ID\\\" == \\\"1\\\" ]; then\", lines[3]);\r\n    boolean oneBefore = true;\r\n    if (lines[4].contains(app1.toString())) {\r\n        Assert.assertEquals(\"\\tappId=\\\"\" + app1.toString() + \"\\\"\", lines[4]);\r\n        Assert.assertEquals(\"\\tappId=\\\"\" + app2.toString() + \"\\\"\", lines[10]);\r\n    } else {\r\n        oneBefore = false;\r\n        Assert.assertEquals(\"\\tappId=\\\"\" + app2.toString() + \"\\\"\", lines[4]);\r\n        Assert.assertEquals(\"\\tappId=\\\"\" + app1.toString() + \"\\\"\", lines[10]);\r\n    }\r\n    Assert.assertEquals(\"\\tuser=\\\"\" + USER + \"\\\"\", lines[5]);\r\n    Assert.assertEquals(\"\\tworkingDir=\\\"\" + (oneBefore ? workingDir.toString() : workingDir2.toString()) + \"\\\"\", lines[6]);\r\n    Assert.assertEquals(\"\\tremoteRootLogDir=\\\"\" + (oneBefore ? remoteRootLogDir.toString() : remoteRootLogDir2.toString()) + \"\\\"\", lines[7]);\r\n    Assert.assertEquals(\"\\tsuffix=\\\"\" + (oneBefore ? suffix : suffix2) + \"\\\"\", lines[8]);\r\n    Assert.assertEquals(\"elif [ \\\"$YARN_SHELL_ID\\\" == \\\"2\\\" ]; then\", lines[9]);\r\n    Assert.assertEquals(\"\\tuser=\\\"\" + USER + \"\\\"\", lines[11]);\r\n    Assert.assertEquals(\"\\tworkingDir=\\\"\" + (oneBefore ? workingDir2.toString() : workingDir.toString()) + \"\\\"\", lines[12]);\r\n    Assert.assertEquals(\"\\tremoteRootLogDir=\\\"\" + (oneBefore ? remoteRootLogDir2.toString() : remoteRootLogDir.toString()) + \"\\\"\", lines[13]);\r\n    Assert.assertEquals(\"\\tsuffix=\\\"\" + (oneBefore ? suffix2 : suffix) + \"\\\"\", lines[14]);\r\n    Assert.assertEquals(\"else\", lines[15]);\r\n    Assert.assertEquals(\"\\techo \\\"Unknown Mapping!\\\"\", lines[16]);\r\n    Assert.assertEquals(\"\\texit 1\", lines[17]);\r\n    Assert.assertEquals(\"fi\", lines[18]);\r\n    Assert.assertEquals(\"export HADOOP_CLIENT_OPTS=\\\"-Xmx1024m\\\"\", lines[19]);\r\n    Assert.assertTrue(lines[20].startsWith(\"export HADOOP_CLASSPATH=\"));\r\n    if (proxy) {\r\n        Assert.assertEquals(\"\\\"$HADOOP_HOME\\\"/bin/hadoop org.apache.hadoop.tools.\" + \"HadoopArchiveLogsRunner -appId \\\"$appId\\\" -user \\\"$user\\\" \" + \"-workingDir \\\"$workingDir\\\" -remoteRootLogDir \" + \"\\\"$remoteRootLogDir\\\" -suffix \\\"$suffix\\\"\", lines[21]);\r\n    } else {\r\n        Assert.assertEquals(\"\\\"$HADOOP_HOME\\\"/bin/hadoop org.apache.hadoop.tools.\" + \"HadoopArchiveLogsRunner -appId \\\"$appId\\\" -user \\\"$user\\\" \" + \"-workingDir \\\"$workingDir\\\" -remoteRootLogDir \" + \"\\\"$remoteRootLogDir\\\" -suffix \\\"$suffix\\\" -noProxy\", lines[21]);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testStatuses",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStatuses() throws Exception\n{\r\n    LogAggregationStatus[] statuses = new LogAggregationStatus[7];\r\n    statuses[0] = LogAggregationStatus.DISABLED;\r\n    statuses[1] = LogAggregationStatus.NOT_START;\r\n    statuses[2] = LogAggregationStatus.RUNNING;\r\n    statuses[3] = LogAggregationStatus.RUNNING_WITH_FAILURE;\r\n    statuses[4] = LogAggregationStatus.SUCCEEDED;\r\n    statuses[5] = LogAggregationStatus.FAILED;\r\n    statuses[6] = LogAggregationStatus.TIME_OUT;\r\n    Assert.assertArrayEquals(statuses, LogAggregationStatus.values());\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testPrepareWorkingDir",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testPrepareWorkingDir() throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    HadoopArchiveLogs hal = new HadoopArchiveLogs(conf);\r\n    FileSystem fs = FileSystem.getLocal(conf);\r\n    Path workingDir = new Path(\"target\", \"testPrepareWorkingDir\");\r\n    fs.delete(workingDir, true);\r\n    Assert.assertFalse(fs.exists(workingDir));\r\n    hal.force = false;\r\n    boolean dirPrepared = hal.prepareWorkingDir(fs, workingDir);\r\n    Assert.assertTrue(dirPrepared);\r\n    Assert.assertTrue(fs.exists(workingDir));\r\n    Assert.assertEquals(new FsPermission(FsAction.ALL, FsAction.ALL, FsAction.ALL, !Shell.WINDOWS), fs.getFileStatus(workingDir).getPermission());\r\n    Path dummyFile = new Path(workingDir, \"dummy.txt\");\r\n    fs.createNewFile(dummyFile);\r\n    Assert.assertTrue(fs.exists(dummyFile));\r\n    dirPrepared = hal.prepareWorkingDir(fs, workingDir);\r\n    Assert.assertFalse(dirPrepared);\r\n    Assert.assertTrue(fs.exists(workingDir));\r\n    Assert.assertTrue(fs.exists(dummyFile));\r\n    Assert.assertEquals(new FsPermission(FsAction.ALL, FsAction.ALL, FsAction.ALL, !Shell.WINDOWS), fs.getFileStatus(workingDir).getPermission());\r\n    hal.force = true;\r\n    dirPrepared = hal.prepareWorkingDir(fs, workingDir);\r\n    Assert.assertTrue(dirPrepared);\r\n    Assert.assertTrue(fs.exists(workingDir));\r\n    Assert.assertEquals(new FsPermission(FsAction.ALL, FsAction.ALL, FsAction.ALL, !Shell.WINDOWS), fs.getFileStatus(workingDir).getPermission());\r\n    Assert.assertFalse(fs.exists(dummyFile));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "createFile",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void createFile(FileSystem fs, Path p, long sizeMultiple) throws IOException\n{\r\n    FSDataOutputStream out = null;\r\n    try {\r\n        out = fs.create(p);\r\n        for (int i = 0; i < sizeMultiple; i++) {\r\n            out.write(DUMMY_DATA);\r\n        }\r\n    } finally {\r\n        if (out != null) {\r\n            out.close();\r\n        }\r\n    }\r\n    Assert.assertTrue(fs.exists(p));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "createRMApp",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "RMApp createRMApp(int id, Configuration conf, RMContext rmContext, final LogAggregationStatus aggStatus)\n{\r\n    ApplicationId appId = ApplicationId.newInstance(CLUSTER_TIMESTAMP, id);\r\n    ApplicationSubmissionContext submissionContext = ApplicationSubmissionContext.newInstance(appId, \"test\", \"default\", Priority.newInstance(0), null, true, true, 2, Resource.newInstance(10, 2), \"test\");\r\n    return new RMAppImpl(appId, rmContext, conf, \"test\", USER, \"default\", submissionContext, rmContext.getScheduler(), rmContext.getApplicationMasterService(), System.currentTimeMillis(), \"test\", null, null) {\r\n\r\n        @Override\r\n        public ApplicationReport createAndGetApplicationReport(String clientUserName, boolean allowAccess) {\r\n            ApplicationReport report = super.createAndGetApplicationReport(clientUserName, allowAccess);\r\n            report.setLogAggregationStatus(aggStatus);\r\n            return report;\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    yarnCluster = new MiniYARNCluster(TestHadoopArchiveLogsRunner.class.getSimpleName(), 1, 2, 1, 1);\r\n    conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED, true);\r\n    conf.setBoolean(YarnConfiguration.YARN_MINICLUSTER_FIXED_PORTS, true);\r\n    yarnCluster.init(conf);\r\n    yarnCluster.start();\r\n    conf = yarnCluster.getConfig();\r\n    dfsCluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();\r\n    conf = new JobConf(conf);\r\n    app1 = ApplicationId.newInstance(System.currentTimeMillis(), 1);\r\n    fs = FileSystem.get(conf);\r\n    remoteRootLogDir = new Path(conf.get(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, YarnConfiguration.DEFAULT_NM_REMOTE_APP_LOG_DIR));\r\n    workingDir = new Path(remoteRootLogDir, \"archive-logs-work\");\r\n    suffix = \"logs\";\r\n    Path logDir = new Path(remoteRootLogDir, new Path(System.getProperty(\"user.name\"), suffix));\r\n    fs.mkdirs(logDir);\r\n    app1Path = new Path(logDir, app1.toString());\r\n    fs.mkdirs(app1Path);\r\n    for (int i = 0; i < FILE_COUNT; i++) {\r\n        createFile(fs, new Path(app1Path, \"log\" + (i + 1)), FILE_SIZES[i]);\r\n    }\r\n    FileStatus[] app1Files = fs.listStatus(app1Path);\r\n    Assert.assertEquals(FILE_COUNT, app1Files.length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "teardown",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void teardown() throws IOException\n{\r\n    if (fs != null) {\r\n        fs.close();\r\n    }\r\n    if (yarnCluster != null) {\r\n        yarnCluster.close();\r\n    }\r\n    if (dfsCluster != null) {\r\n        dfsCluster.shutdown();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testHadoopArchiveLogs",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testHadoopArchiveLogs() throws Exception\n{\r\n    String[] args = getArgs();\r\n    final HadoopArchiveLogsRunner halr = new HadoopArchiveLogsRunner(conf);\r\n    assertEquals(0, ToolRunner.run(halr, args));\r\n    fs = FileSystem.get(conf);\r\n    FileStatus[] app1Files = fs.listStatus(app1Path);\r\n    Assert.assertEquals(1, app1Files.length);\r\n    FileStatus harFile = app1Files[0];\r\n    Assert.assertEquals(app1.toString() + \".har\", harFile.getPath().getName());\r\n    Path harPath = new Path(\"har:///\" + harFile.getPath().toUri().getRawPath());\r\n    FileStatus[] harLogs = HarFs.get(harPath.toUri(), conf).listStatus(harPath);\r\n    Assert.assertEquals(FILE_COUNT, harLogs.length);\r\n    Arrays.sort(harLogs, new Comparator<FileStatus>() {\r\n\r\n        @Override\r\n        public int compare(FileStatus o1, FileStatus o2) {\r\n            return o1.getPath().getName().compareTo(o2.getPath().getName());\r\n        }\r\n    });\r\n    for (int i = 0; i < FILE_COUNT; i++) {\r\n        FileStatus harLog = harLogs[i];\r\n        Assert.assertEquals(\"log\" + (i + 1), harLog.getPath().getName());\r\n        Assert.assertEquals(FILE_SIZES[i] * FILE_SIZE_INCREMENT, harLog.getLen());\r\n        Assert.assertEquals(new FsPermission(FsAction.READ_WRITE, FsAction.READ, FsAction.NONE), harLog.getPermission());\r\n        Assert.assertEquals(System.getProperty(\"user.name\"), harLog.getOwner());\r\n    }\r\n    Assert.assertEquals(0, fs.listStatus(workingDir).length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "testHadoopArchiveLogsWithArchiveError",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testHadoopArchiveLogsWithArchiveError() throws Exception\n{\r\n    String[] args = getArgs();\r\n    final HadoopArchiveLogsRunner halr = new HadoopArchiveLogsRunner(conf);\r\n    HadoopArchives mockHadoopArchives = mock(HadoopArchives.class);\r\n    when(mockHadoopArchives.run(Mockito.<String[]>any())).thenReturn(-1);\r\n    halr.hadoopArchives = mockHadoopArchives;\r\n    assertNotEquals(0, ToolRunner.run(halr, args));\r\n    FileStatus[] app1Files = fs.listStatus(app1Path);\r\n    assertEquals(FILE_COUNT, app1Files.length);\r\n    for (int i = 0; i < FILE_COUNT; i++) {\r\n        Assert.assertEquals(FILE_SIZES[i] * FILE_SIZE_INCREMENT, app1Files[i].getLen());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "getArgs",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String[] getArgs()\n{\r\n    return new String[] { \"-appId\", app1.toString(), \"-user\", System.getProperty(\"user.name\"), \"-workingDir\", workingDir.toString(), \"-remoteRootLogDir\", remoteRootLogDir.toString(), \"-suffix\", suffix };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-archive-logs\\src\\test\\java\\org\\apache\\hadoop\\tools",
  "methodName" : "createFile",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void createFile(FileSystem fs, Path p, long sizeMultiple) throws IOException\n{\r\n    FSDataOutputStream out = null;\r\n    try {\r\n        out = fs.create(p);\r\n        for (int i = 0; i < sizeMultiple; i++) {\r\n            out.write(DUMMY_DATA);\r\n        }\r\n    } finally {\r\n        if (out != null) {\r\n            out.close();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
} ]