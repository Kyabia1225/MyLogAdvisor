[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getUriDefaultPort",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getUriDefaultPort()\n{\r\n    return Constants.OSS_DEFAULT_PORT;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "append",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FSDataOutputStream append(Path path, int bufferSize, Progressable progress) throws IOException\n{\r\n    throw new IOException(\"Append is not supported!\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    try {\r\n        store.close();\r\n        boundedThreadPool.shutdown();\r\n        boundedCopyThreadPool.shutdown();\r\n    } finally {\r\n        super.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "create",
  "errType" : [ "FileNotFoundException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "FSDataOutputStream create(Path path, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException\n{\r\n    String key = pathToKey(path);\r\n    FileStatus status = null;\r\n    try {\r\n        status = getFileStatus(path);\r\n        if (status.isDirectory()) {\r\n            throw new FileAlreadyExistsException(path + \" is a directory\");\r\n        }\r\n        if (!overwrite) {\r\n            throw new FileAlreadyExistsException(path + \" already exists\");\r\n        }\r\n        LOG.debug(\"Overwriting file {}\", path);\r\n    } catch (FileNotFoundException e) {\r\n    }\r\n    long uploadPartSize = AliyunOSSUtils.getMultipartSizeProperty(getConf(), MULTIPART_UPLOAD_PART_SIZE_KEY, MULTIPART_UPLOAD_PART_SIZE_DEFAULT);\r\n    return new FSDataOutputStream(new AliyunOSSBlockOutputStream(getConf(), store, key, uploadPartSize, new SemaphoredDelegatingExecutor(boundedThreadPool, blockOutputActiveBlocks, true)), statistics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "createNonRecursive",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FSDataOutputStream createNonRecursive(Path path, FsPermission permission, EnumSet<CreateFlag> flags, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException\n{\r\n    Path parent = path.getParent();\r\n    if (parent != null) {\r\n        if (!getFileStatus(parent).isDirectory()) {\r\n            throw new FileAlreadyExistsException(\"Not a directory: \" + parent);\r\n        }\r\n    }\r\n    return create(path, permission, flags.contains(CreateFlag.OVERWRITE), bufferSize, replication, blockSize, progress);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "delete",
  "errType" : [ "FileNotFoundException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean delete(Path path, boolean recursive) throws IOException\n{\r\n    try {\r\n        return innerDelete(getFileStatus(path), recursive);\r\n    } catch (FileNotFoundException e) {\r\n        LOG.debug(\"Couldn't delete {} - does not exist\", path);\r\n        return false;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "innerDelete",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "boolean innerDelete(FileStatus status, boolean recursive) throws IOException\n{\r\n    Path f = status.getPath();\r\n    String p = f.toUri().getPath();\r\n    FileStatus[] statuses;\r\n    if (p.equals(\"/\")) {\r\n        statuses = listStatus(status.getPath());\r\n        boolean isEmptyDir = statuses.length <= 0;\r\n        return rejectRootDirectoryDelete(isEmptyDir, recursive);\r\n    }\r\n    String key = pathToKey(f);\r\n    if (status.isDirectory()) {\r\n        if (!recursive) {\r\n            statuses = listStatus(status.getPath());\r\n            if (statuses.length > 0) {\r\n                throw new IOException(\"Cannot remove directory \" + f + \": It is not empty!\");\r\n            } else {\r\n                key = AliyunOSSUtils.maybeAddTrailingSlash(key);\r\n                store.deleteObject(key);\r\n            }\r\n        } else {\r\n            store.deleteDirs(key);\r\n        }\r\n    } else {\r\n        store.deleteObject(key);\r\n    }\r\n    createFakeDirectoryIfNecessary(f);\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "rejectRootDirectoryDelete",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean rejectRootDirectoryDelete(boolean isEmptyDir, boolean recursive) throws IOException\n{\r\n    LOG.info(\"oss delete the {} root directory of {}\", bucket, recursive);\r\n    if (isEmptyDir) {\r\n        return true;\r\n    }\r\n    if (recursive) {\r\n        return false;\r\n    } else {\r\n        throw new PathIOException(bucket, \"Cannot delete root path\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "createFakeDirectoryIfNecessary",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void createFakeDirectoryIfNecessary(Path f) throws IOException\n{\r\n    String key = pathToKey(f);\r\n    if (StringUtils.isNotEmpty(key) && !exists(f)) {\r\n        LOG.debug(\"Creating new fake directory at {}\", f);\r\n        mkdir(pathToKey(f.getParent()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getFileStatus",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "FileStatus getFileStatus(Path path) throws IOException\n{\r\n    Path qualifiedPath = path.makeQualified(uri, workingDir);\r\n    String key = pathToKey(qualifiedPath);\r\n    if (key.length() == 0) {\r\n        return new OSSFileStatus(0, true, 1, 0, 0, qualifiedPath, username);\r\n    }\r\n    ObjectMetadata meta = store.getObjectMetadata(key);\r\n    if (meta == null && !key.endsWith(\"/\")) {\r\n        key += \"/\";\r\n        meta = store.getObjectMetadata(key);\r\n    }\r\n    if (meta == null) {\r\n        OSSListRequest listRequest = store.createListObjectsRequest(key, maxKeys, null, null, false);\r\n        OSSListResult listing = store.listObjects(listRequest);\r\n        do {\r\n            if (CollectionUtils.isNotEmpty(listing.getObjectSummaries()) || CollectionUtils.isNotEmpty(listing.getCommonPrefixes())) {\r\n                return new OSSFileStatus(0, true, 1, 0, 0, qualifiedPath, username);\r\n            } else if (listing.isTruncated()) {\r\n                listing = store.continueListObjects(listRequest, listing);\r\n            } else {\r\n                throw new FileNotFoundException(path + \": No such file or directory!\");\r\n            }\r\n        } while (true);\r\n    } else if (objectRepresentsDirectory(key, meta.getContentLength())) {\r\n        return new OSSFileStatus(0, true, 1, 0, meta.getLastModified().getTime(), qualifiedPath, username);\r\n    } else {\r\n        return new OSSFileStatus(meta.getContentLength(), false, 1, getDefaultBlockSize(path), meta.getLastModified().getTime(), qualifiedPath, username);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getScheme",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getScheme()\n{\r\n    return \"oss\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getUri",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "URI getUri()\n{\r\n    return uri;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getDefaultPort",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getDefaultPort()\n{\r\n    return Constants.OSS_DEFAULT_PORT;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getWorkingDirectory()\n{\r\n    return workingDir;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getDefaultBlockSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getDefaultBlockSize()\n{\r\n    return getConf().getLong(FS_OSS_BLOCK_SIZE_KEY, FS_OSS_BLOCK_SIZE_DEFAULT);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getCanonicalServiceName",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getCanonicalServiceName()\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void initialize(URI name, Configuration conf) throws IOException\n{\r\n    super.initialize(name, conf);\r\n    bucket = name.getHost();\r\n    uri = java.net.URI.create(name.getScheme() + \"://\" + name.getAuthority());\r\n    username = UserGroupInformation.getCurrentUser().getShortUserName();\r\n    workingDir = new Path(\"/user\", username).makeQualified(uri, null);\r\n    long keepAliveTime = longOption(conf, KEEPALIVE_TIME_KEY, KEEPALIVE_TIME_DEFAULT, 0);\r\n    blockOutputActiveBlocks = intOption(conf, UPLOAD_ACTIVE_BLOCKS_KEY, UPLOAD_ACTIVE_BLOCKS_DEFAULT, 1);\r\n    store = new AliyunOSSFileSystemStore();\r\n    store.initialize(name, conf, username, statistics);\r\n    maxKeys = conf.getInt(MAX_PAGING_KEYS_KEY, MAX_PAGING_KEYS_DEFAULT);\r\n    int threadNum = AliyunOSSUtils.intPositiveOption(conf, Constants.MULTIPART_DOWNLOAD_THREAD_NUMBER_KEY, Constants.MULTIPART_DOWNLOAD_THREAD_NUMBER_DEFAULT);\r\n    int totalTasks = AliyunOSSUtils.intPositiveOption(conf, Constants.MAX_TOTAL_TASKS_KEY, Constants.MAX_TOTAL_TASKS_DEFAULT);\r\n    maxReadAheadPartNumber = AliyunOSSUtils.intPositiveOption(conf, Constants.MULTIPART_DOWNLOAD_AHEAD_PART_MAX_NUM_KEY, Constants.MULTIPART_DOWNLOAD_AHEAD_PART_MAX_NUM_DEFAULT);\r\n    this.boundedThreadPool = BlockingThreadPoolExecutorService.newInstance(threadNum, totalTasks, keepAliveTime, TimeUnit.SECONDS, \"oss-transfer-shared\");\r\n    maxConcurrentCopyTasksPerDir = AliyunOSSUtils.intPositiveOption(conf, Constants.MAX_CONCURRENT_COPY_TASKS_PER_DIR_KEY, Constants.MAX_CONCURRENT_COPY_TASKS_PER_DIR_DEFAULT);\r\n    int maxCopyThreads = AliyunOSSUtils.intPositiveOption(conf, Constants.MAX_COPY_THREADS_NUM_KEY, Constants.MAX_COPY_THREADS_DEFAULT);\r\n    int maxCopyTasks = AliyunOSSUtils.intPositiveOption(conf, Constants.MAX_COPY_TASKS_KEY, Constants.MAX_COPY_TASKS_DEFAULT);\r\n    this.boundedCopyThreadPool = BlockingThreadPoolExecutorService.newInstance(maxCopyThreads, maxCopyTasks, 60L, TimeUnit.SECONDS, \"oss-copy-unbounded\");\r\n    setConf(conf);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "pathToKey",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String pathToKey(Path path)\n{\r\n    if (!path.isAbsolute()) {\r\n        path = new Path(workingDir, path);\r\n    }\r\n    return path.toUri().getPath().substring(1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "keyToPath",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path keyToPath(String key)\n{\r\n    return new Path(\"/\" + key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "listStatus",
  "errType" : null,
  "containingMethodsNum" : 34,
  "sourceCodeText" : "FileStatus[] listStatus(Path path) throws IOException\n{\r\n    String key = pathToKey(path);\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"List status for path: \" + path);\r\n    }\r\n    final List<FileStatus> result = new ArrayList<FileStatus>();\r\n    final FileStatus fileStatus = getFileStatus(path);\r\n    if (fileStatus.isDirectory()) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\"listStatus: doing listObjects for directory \" + key);\r\n        }\r\n        OSSListRequest listRequest = store.createListObjectsRequest(key, maxKeys, null, null, false);\r\n        OSSListResult objects = store.listObjects(listRequest);\r\n        while (true) {\r\n            for (OSSObjectSummary objectSummary : objects.getObjectSummaries()) {\r\n                String objKey = objectSummary.getKey();\r\n                if (objKey.equals(key + \"/\")) {\r\n                    if (LOG.isDebugEnabled()) {\r\n                        LOG.debug(\"Ignoring: \" + objKey);\r\n                    }\r\n                    continue;\r\n                } else {\r\n                    Path keyPath = keyToPath(objectSummary.getKey()).makeQualified(uri, workingDir);\r\n                    if (LOG.isDebugEnabled()) {\r\n                        LOG.debug(\"Adding: fi: \" + keyPath);\r\n                    }\r\n                    result.add(new OSSFileStatus(objectSummary.getSize(), false, 1, getDefaultBlockSize(keyPath), objectSummary.getLastModified().getTime(), keyPath, username));\r\n                }\r\n            }\r\n            for (String prefix : objects.getCommonPrefixes()) {\r\n                if (prefix.equals(key + \"/\")) {\r\n                    if (LOG.isDebugEnabled()) {\r\n                        LOG.debug(\"Ignoring: \" + prefix);\r\n                    }\r\n                    continue;\r\n                } else {\r\n                    Path keyPath = keyToPath(prefix).makeQualified(uri, workingDir);\r\n                    if (LOG.isDebugEnabled()) {\r\n                        LOG.debug(\"Adding: rd: \" + keyPath);\r\n                    }\r\n                    result.add(getFileStatus(keyPath));\r\n                }\r\n            }\r\n            if (objects.isTruncated()) {\r\n                if (LOG.isDebugEnabled()) {\r\n                    LOG.debug(\"listStatus: list truncated - getting next batch\");\r\n                }\r\n                objects = store.continueListObjects(listRequest, objects);\r\n            } else {\r\n                break;\r\n            }\r\n        }\r\n    } else {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\"Adding: rd (not a dir): \" + path);\r\n        }\r\n        result.add(fileStatus);\r\n    }\r\n    return result.toArray(new FileStatus[result.size()]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "listFiles",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "RemoteIterator<LocatedFileStatus> listFiles(final Path f, final boolean recursive) throws IOException\n{\r\n    Path qualifiedPath = f.makeQualified(uri, workingDir);\r\n    final FileStatus status = getFileStatus(qualifiedPath);\r\n    PathFilter filter = new PathFilter() {\r\n\r\n        @Override\r\n        public boolean accept(Path path) {\r\n            return status.isFile() || !path.equals(f);\r\n        }\r\n    };\r\n    FileStatusAcceptor acceptor = new FileStatusAcceptor.AcceptFilesOnly(qualifiedPath);\r\n    return innerList(f, status, filter, acceptor, recursive);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "listLocatedStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "RemoteIterator<LocatedFileStatus> listLocatedStatus(Path f) throws IOException\n{\r\n    return listLocatedStatus(f, DEFAULT_FILTER);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "listLocatedStatus",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "RemoteIterator<LocatedFileStatus> listLocatedStatus(final Path f, final PathFilter filter) throws IOException\n{\r\n    Path qualifiedPath = f.makeQualified(uri, workingDir);\r\n    final FileStatus status = getFileStatus(qualifiedPath);\r\n    FileStatusAcceptor acceptor = new FileStatusAcceptor.AcceptAllButSelf(qualifiedPath);\r\n    return innerList(f, status, filter, acceptor, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "innerList",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "RemoteIterator<LocatedFileStatus> innerList(final Path f, final FileStatus status, final PathFilter filter, final FileStatusAcceptor acceptor, final boolean recursive) throws IOException\n{\r\n    Path qualifiedPath = f.makeQualified(uri, workingDir);\r\n    String key = pathToKey(qualifiedPath);\r\n    if (status.isFile()) {\r\n        LOG.debug(\"{} is a File\", qualifiedPath);\r\n        final BlockLocation[] locations = getFileBlockLocations(status, 0, status.getLen());\r\n        return store.singleStatusRemoteIterator(filter.accept(f) ? status : null, locations);\r\n    } else {\r\n        return store.createLocatedFileStatusIterator(key, maxKeys, this, filter, acceptor, recursive);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "mkdir",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean mkdir(final String key) throws IOException\n{\r\n    String dirName = key;\r\n    if (StringUtils.isNotEmpty(key)) {\r\n        if (!key.endsWith(\"/\")) {\r\n            dirName += \"/\";\r\n        }\r\n        store.storeEmptyFile(dirName);\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "mkdirs",
  "errType" : [ "FileNotFoundException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean mkdirs(Path path, FsPermission permission) throws IOException\n{\r\n    try {\r\n        FileStatus fileStatus = getFileStatus(path);\r\n        if (fileStatus.isDirectory()) {\r\n            return true;\r\n        } else {\r\n            throw new FileAlreadyExistsException(\"Path is a file: \" + path);\r\n        }\r\n    } catch (FileNotFoundException e) {\r\n        validatePath(path);\r\n        String key = pathToKey(path);\r\n        return mkdir(key);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "validatePath",
  "errType" : [ "FileNotFoundException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void validatePath(Path path) throws IOException\n{\r\n    Path fPart = path.getParent();\r\n    do {\r\n        try {\r\n            FileStatus fileStatus = getFileStatus(fPart);\r\n            if (fileStatus.isDirectory()) {\r\n                break;\r\n            } else {\r\n                throw new FileAlreadyExistsException(String.format(\"Can't make directory for path '%s', it is a file.\", fPart));\r\n            }\r\n        } catch (FileNotFoundException fnfe) {\r\n        }\r\n        fPart = fPart.getParent();\r\n    } while (fPart != null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "open",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "FSDataInputStream open(Path path, int bufferSize) throws IOException\n{\r\n    final FileStatus fileStatus = getFileStatus(path);\r\n    if (fileStatus.isDirectory()) {\r\n        throw new FileNotFoundException(\"Can't open \" + path + \" because it is a directory\");\r\n    }\r\n    return new FSDataInputStream(new AliyunOSSInputStream(getConf(), new SemaphoredDelegatingExecutor(boundedThreadPool, maxReadAheadPartNumber, true), maxReadAheadPartNumber, store, pathToKey(path), fileStatus.getLen(), statistics));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "rename",
  "errType" : [ "FileNotFoundException", "FileNotFoundException" ],
  "containingMethodsNum" : 23,
  "sourceCodeText" : "boolean rename(Path srcPath, Path dstPath) throws IOException\n{\r\n    if (srcPath.isRoot()) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\"Cannot rename the root of a filesystem\");\r\n        }\r\n        return false;\r\n    }\r\n    Path parent = dstPath.getParent();\r\n    while (parent != null && !srcPath.equals(parent)) {\r\n        parent = parent.getParent();\r\n    }\r\n    if (parent != null) {\r\n        return false;\r\n    }\r\n    FileStatus srcStatus = getFileStatus(srcPath);\r\n    FileStatus dstStatus;\r\n    try {\r\n        dstStatus = getFileStatus(dstPath);\r\n    } catch (FileNotFoundException fnde) {\r\n        dstStatus = null;\r\n    }\r\n    if (dstStatus == null) {\r\n        dstStatus = getFileStatus(dstPath.getParent());\r\n        if (!dstStatus.isDirectory()) {\r\n            throw new IOException(String.format(\"Failed to rename %s to %s, %s is a file\", srcPath, dstPath, dstPath.getParent()));\r\n        }\r\n    } else {\r\n        if (srcStatus.getPath().equals(dstStatus.getPath())) {\r\n            return !srcStatus.isDirectory();\r\n        } else if (dstStatus.isDirectory()) {\r\n            dstPath = new Path(dstPath, srcPath.getName());\r\n            FileStatus[] statuses;\r\n            try {\r\n                statuses = listStatus(dstPath);\r\n            } catch (FileNotFoundException fnde) {\r\n                statuses = null;\r\n            }\r\n            if (statuses != null && statuses.length > 0) {\r\n                throw new FileAlreadyExistsException(String.format(\"Failed to rename %s to %s, file already exists or not empty!\", srcPath, dstPath));\r\n            }\r\n        } else {\r\n            throw new FileAlreadyExistsException(String.format(\"Failed to rename %s to %s, file already exists!\", srcPath, dstPath));\r\n        }\r\n    }\r\n    boolean succeed;\r\n    if (srcStatus.isDirectory()) {\r\n        succeed = copyDirectory(srcPath, dstPath);\r\n    } else {\r\n        succeed = copyFile(srcPath, srcStatus.getLen(), dstPath);\r\n    }\r\n    return srcPath.equals(dstPath) || (succeed && delete(srcPath, true));\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "copyFile",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean copyFile(Path srcPath, long srcLen, Path dstPath)\n{\r\n    String srcKey = pathToKey(srcPath);\r\n    String dstKey = pathToKey(dstPath);\r\n    return store.copyFile(srcKey, srcLen, dstKey);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "copyDirectory",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 20,
  "sourceCodeText" : "boolean copyDirectory(Path srcPath, Path dstPath) throws IOException\n{\r\n    String srcKey = AliyunOSSUtils.maybeAddTrailingSlash(pathToKey(srcPath));\r\n    String dstKey = AliyunOSSUtils.maybeAddTrailingSlash(pathToKey(dstPath));\r\n    if (dstKey.startsWith(srcKey)) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\"Cannot rename a directory to a subdirectory of self\");\r\n        }\r\n        return false;\r\n    }\r\n    store.storeEmptyFile(dstKey);\r\n    AliyunOSSCopyFileContext copyFileContext = new AliyunOSSCopyFileContext();\r\n    ExecutorService executorService = MoreExecutors.listeningDecorator(new SemaphoredDelegatingExecutor(boundedCopyThreadPool, maxConcurrentCopyTasksPerDir, true));\r\n    OSSListRequest listRequest = store.createListObjectsRequest(srcKey, maxKeys, null, null, true);\r\n    OSSListResult objects = store.listObjects(listRequest);\r\n    int copiesToFinish = 0;\r\n    while (true) {\r\n        for (OSSObjectSummary objectSummary : objects.getObjectSummaries()) {\r\n            String newKey = dstKey.concat(objectSummary.getKey().substring(srcKey.length()));\r\n            executorService.execute(new AliyunOSSCopyFileTask(store, objectSummary.getKey(), objectSummary.getSize(), newKey, copyFileContext));\r\n            copiesToFinish++;\r\n            if (copyFileContext.isCopyFailure()) {\r\n                break;\r\n            }\r\n        }\r\n        if (objects.isTruncated()) {\r\n            objects = store.continueListObjects(listRequest, objects);\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n    copyFileContext.lock();\r\n    try {\r\n        copyFileContext.awaitAllFinish(copiesToFinish);\r\n    } catch (InterruptedException e) {\r\n        LOG.warn(\"interrupted when wait copies to finish\");\r\n    } finally {\r\n        copyFileContext.unlock();\r\n    }\r\n    return !copyFileContext.isCopyFailure();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "setWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setWorkingDirectory(Path dir)\n{\r\n    this.workingDir = dir;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getStore",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AliyunOSSFileSystemStore getStore()\n{\r\n    return store;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "reopen",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void reopen(long pos) throws IOException\n{\r\n    long partSize;\r\n    if (pos < 0) {\r\n        throw new EOFException(\"Cannot seek at negative position:\" + pos);\r\n    } else if (pos > contentLength) {\r\n        throw new EOFException(\"Cannot seek after EOF, contentLength:\" + contentLength + \" position:\" + pos);\r\n    } else if (pos + downloadPartSize > contentLength) {\r\n        partSize = contentLength - pos;\r\n    } else {\r\n        partSize = downloadPartSize;\r\n    }\r\n    if (this.buffer != null) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\"Aborting old stream to open at pos \" + pos);\r\n        }\r\n        this.buffer = null;\r\n    }\r\n    boolean isRandomIO = true;\r\n    if (pos == this.expectNextPos) {\r\n        isRandomIO = false;\r\n    } else {\r\n        while (readBufferQueue.size() != 0) {\r\n            if (readBufferQueue.element().getByteStart() != pos) {\r\n                readBufferQueue.poll();\r\n            } else {\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    this.expectNextPos = pos + partSize;\r\n    int currentSize = readBufferQueue.size();\r\n    if (currentSize == 0) {\r\n        lastByteStart = pos - partSize;\r\n    } else {\r\n        ReadBuffer[] readBuffers = readBufferQueue.toArray(new ReadBuffer[currentSize]);\r\n        lastByteStart = readBuffers[currentSize - 1].getByteStart();\r\n    }\r\n    int maxLen = this.maxReadAheadPartNumber - currentSize;\r\n    for (int i = 0; i < maxLen && i < (currentSize + 1) * 2; i++) {\r\n        if (lastByteStart + partSize * (i + 1) > contentLength) {\r\n            break;\r\n        }\r\n        long byteStart = lastByteStart + partSize * (i + 1);\r\n        long byteEnd = byteStart + partSize - 1;\r\n        if (byteEnd >= contentLength) {\r\n            byteEnd = contentLength - 1;\r\n        }\r\n        ReadBuffer readBuffer = new ReadBuffer(byteStart, byteEnd);\r\n        if (readBuffer.getBuffer().length == 0) {\r\n            readBuffer.setStatus(ReadBuffer.STATUS.SUCCESS);\r\n        } else {\r\n            this.readAheadExecutorService.execute(new AliyunOSSFileReaderTask(key, store, readBuffer));\r\n        }\r\n        readBufferQueue.add(readBuffer);\r\n        if (isRandomIO) {\r\n            break;\r\n        }\r\n    }\r\n    ReadBuffer readBuffer = readBufferQueue.poll();\r\n    readBuffer.lock();\r\n    try {\r\n        readBuffer.await(ReadBuffer.STATUS.INIT);\r\n        if (readBuffer.getStatus() == ReadBuffer.STATUS.ERROR) {\r\n            this.buffer = null;\r\n        } else {\r\n            this.buffer = readBuffer.getBuffer();\r\n        }\r\n    } catch (InterruptedException e) {\r\n        LOG.warn(\"interrupted when wait a read buffer\");\r\n    } finally {\r\n        readBuffer.unlock();\r\n    }\r\n    if (this.buffer == null) {\r\n        throw new IOException(\"Null IO stream\");\r\n    }\r\n    position = pos;\r\n    partRemaining = partSize;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int read() throws IOException\n{\r\n    checkNotClosed();\r\n    if (partRemaining <= 0 && position < contentLength) {\r\n        reopen(position);\r\n    }\r\n    int byteRead = -1;\r\n    if (partRemaining != 0) {\r\n        byteRead = this.buffer[this.buffer.length - (int) partRemaining] & 0xFF;\r\n    }\r\n    if (byteRead >= 0) {\r\n        position++;\r\n        partRemaining--;\r\n    }\r\n    if (statistics != null && byteRead >= 0) {\r\n        statistics.incrementBytesRead(byteRead);\r\n    }\r\n    return byteRead;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "checkNotClosed",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void checkNotClosed() throws IOException\n{\r\n    if (closed) {\r\n        throw new IOException(FSExceptionMessages.STREAM_IS_CLOSED);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int read(byte[] buf, int off, int len) throws IOException\n{\r\n    checkNotClosed();\r\n    if (buf == null) {\r\n        throw new NullPointerException();\r\n    } else if (off < 0 || len < 0 || len > buf.length - off) {\r\n        throw new IndexOutOfBoundsException();\r\n    } else if (len == 0) {\r\n        return 0;\r\n    }\r\n    int bytesRead = 0;\r\n    while (position < contentLength && bytesRead < len) {\r\n        if (partRemaining == 0) {\r\n            reopen(position);\r\n        }\r\n        int bytes = 0;\r\n        for (int i = this.buffer.length - (int) partRemaining; i < this.buffer.length; i++) {\r\n            buf[off + bytesRead] = this.buffer[i];\r\n            bytes++;\r\n            bytesRead++;\r\n            if (off + bytesRead >= len) {\r\n                break;\r\n            }\r\n        }\r\n        if (bytes > 0) {\r\n            position += bytes;\r\n            partRemaining -= bytes;\r\n        } else if (partRemaining != 0) {\r\n            throw new IOException(\"Failed to read from stream. Remaining:\" + partRemaining);\r\n        }\r\n    }\r\n    if (statistics != null && bytesRead > 0) {\r\n        statistics.incrementBytesRead(bytesRead);\r\n    }\r\n    if (bytesRead == 0 && len > 0) {\r\n        return -1;\r\n    } else {\r\n        return bytesRead;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (closed) {\r\n        return;\r\n    }\r\n    closed = true;\r\n    this.buffer = null;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "available",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int available() throws IOException\n{\r\n    checkNotClosed();\r\n    long remaining = contentLength - position;\r\n    if (remaining > Integer.MAX_VALUE) {\r\n        return Integer.MAX_VALUE;\r\n    }\r\n    return (int) remaining;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "seek",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void seek(long pos) throws IOException\n{\r\n    checkNotClosed();\r\n    if (position == pos) {\r\n        return;\r\n    } else if (pos > position && pos < position + partRemaining) {\r\n        long len = pos - position;\r\n        position = pos;\r\n        partRemaining -= len;\r\n    } else {\r\n        reopen(pos);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getPos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getPos() throws IOException\n{\r\n    checkNotClosed();\r\n    return position;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "seekToNewSource",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean seekToNewSource(long targetPos) throws IOException\n{\r\n    checkNotClosed();\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getExpectNextPos",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getExpectNextPos()\n{\r\n    return this.expectNextPos;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "v1",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "OSSListRequest v1(ListObjectsRequest request)\n{\r\n    return new OSSListRequest(request, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "v2",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "OSSListRequest v2(ListObjectsV2Request request)\n{\r\n    return new OSSListRequest(null, request);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "isV1",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isV1()\n{\r\n    return v1Request != null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getV1",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ListObjectsRequest getV1()\n{\r\n    return v1Request;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getV2",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ListObjectsV2Request getV2()\n{\r\n    return v2Request;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String toString()\n{\r\n    if (isV1()) {\r\n        return String.format(DESCRIPTION, v1Request.getBucketName(), v1Request.getPrefix(), v1Request.getDelimiter(), v1Request.getMaxKeys());\r\n    } else {\r\n        return String.format(DESCRIPTION, v2Request.getBucketName(), v2Request.getPrefix(), v2Request.getDelimiter(), v2Request.getMaxKeys());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "run",
  "errType" : [ "Exception", "Exception" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void run()\n{\r\n    int retries = 0;\r\n    readBuffer.lock();\r\n    try {\r\n        while (true) {\r\n            try (InputStream in = store.retrieve(key, readBuffer.getByteStart(), readBuffer.getByteEnd())) {\r\n                IOUtils.readFully(in, readBuffer.getBuffer(), 0, readBuffer.getBuffer().length);\r\n                readBuffer.setStatus(ReadBuffer.STATUS.SUCCESS);\r\n                break;\r\n            } catch (Exception e) {\r\n                LOG.warn(\"Exception thrown when retrieve key: \" + this.key + \", exception: \" + e);\r\n                try {\r\n                    RetryPolicy.RetryAction rc = retryPolicy.shouldRetry(e, retries++, 0, true);\r\n                    if (rc.action == RetryPolicy.RetryAction.RetryDecision.RETRY) {\r\n                        Thread.sleep(rc.delayMillis);\r\n                    } else {\r\n                        break;\r\n                    }\r\n                } catch (Exception ex) {\r\n                    LOG.warn(\"Exception thrown when call shouldRetry, exception \" + ex);\r\n                    break;\r\n                }\r\n            }\r\n        }\r\n        if (readBuffer.getStatus() != ReadBuffer.STATUS.SUCCESS) {\r\n            readBuffer.setStatus(ReadBuffer.STATUS.ERROR);\r\n        }\r\n        readBuffer.signalAll();\r\n    } finally {\r\n        readBuffer.unlock();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "lock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void lock()\n{\r\n    lock.lock();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "unlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void unlock()\n{\r\n    lock.unlock();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "awaitAllFinish",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void awaitAllFinish(int copiesToFinish) throws InterruptedException\n{\r\n    while (this.copiesFinish != copiesToFinish) {\r\n        readyCondition.await();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "signalAll",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void signalAll()\n{\r\n    readyCondition.signalAll();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "isCopyFailure",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isCopyFailure()\n{\r\n    return copyFailure;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "setCopyFailure",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setCopyFailure(boolean copyFailure)\n{\r\n    this.copyFailure = copyFailure;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "incCopiesFinish",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void incCopiesFinish()\n{\r\n    ++copiesFinish;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "setCredentials",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setCredentials(Credentials creds)\n{\r\n    if (creds == null) {\r\n        throw new InvalidCredentialsException(\"Credentials should not be null.\");\r\n    }\r\n    credentials = creds;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getCredentials",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Credentials getCredentials()\n{\r\n    if (credentials == null) {\r\n        throw new InvalidCredentialsException(\"Invalid credentials\");\r\n    }\r\n    return credentials;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "intPositiveOption",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int intPositiveOption(Configuration conf, String key, int defVal)\n{\r\n    int v = conf.getInt(key, defVal);\r\n    if (v <= 0) {\r\n        LOG.warn(key + \" is configured to \" + v + \", will use default value: \" + defVal);\r\n        v = defVal;\r\n    }\r\n    return v;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getValueWithKey",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getValueWithKey(Configuration conf, String key) throws IOException\n{\r\n    try {\r\n        final char[] pass = conf.getPassword(key);\r\n        if (pass != null) {\r\n            return (new String(pass)).trim();\r\n        } else {\r\n            return \"\";\r\n        }\r\n    } catch (IOException ioe) {\r\n        throw new IOException(\"Cannot find password option \" + key, ioe);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "calculatePartSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long calculatePartSize(long contentLength, long minPartSize)\n{\r\n    long tmpPartSize = contentLength / MULTIPART_UPLOAD_PART_NUM_LIMIT + 1;\r\n    return Math.max(minPartSize, tmpPartSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getCredentialsProvider",
  "errType" : [ "ClassNotFoundException", "NoSuchMethodException|SecurityException", "ReflectiveOperationException|IllegalArgumentException", "NoSuchMethodException|SecurityException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "CredentialsProvider getCredentialsProvider(URI uri, Configuration conf) throws IOException\n{\r\n    CredentialsProvider credentials;\r\n    String className = conf.getTrimmed(CREDENTIALS_PROVIDER_KEY);\r\n    if (StringUtils.isEmpty(className)) {\r\n        Configuration newConf = ProviderUtils.excludeIncompatibleCredentialProviders(conf, AliyunOSSFileSystem.class);\r\n        credentials = new AliyunCredentialsProvider(newConf);\r\n    } else {\r\n        try {\r\n            LOG.debug(\"Credential provider class is:\" + className);\r\n            Class<?> credClass = Class.forName(className);\r\n            try {\r\n                credentials = (CredentialsProvider) credClass.getDeclaredConstructor(URI.class, Configuration.class).newInstance(uri, conf);\r\n            } catch (NoSuchMethodException | SecurityException e) {\r\n                credentials = (CredentialsProvider) credClass.getDeclaredConstructor().newInstance();\r\n            }\r\n        } catch (ClassNotFoundException e) {\r\n            throw new IOException(className + \" not found.\", e);\r\n        } catch (NoSuchMethodException | SecurityException e) {\r\n            throw new IOException(String.format(\"%s constructor exception.  A \" + \"class specified in %s must provide an accessible constructor \" + \"accepting URI and Configuration, or an accessible default \" + \"constructor.\", className, CREDENTIALS_PROVIDER_KEY), e);\r\n        } catch (ReflectiveOperationException | IllegalArgumentException e) {\r\n            throw new IOException(className + \" instantiation exception.\", e);\r\n        }\r\n    }\r\n    return credentials;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "maybeAddTrailingSlash",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String maybeAddTrailingSlash(String key)\n{\r\n    if (StringUtils.isNotEmpty(key) && !key.endsWith(\"/\")) {\r\n        return key + '/';\r\n    } else {\r\n        return key;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "objectRepresentsDirectory",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean objectRepresentsDirectory(final String name, final long size)\n{\r\n    return StringUtils.isNotEmpty(name) && name.endsWith(\"/\") && size == 0L;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "createTmpFileForWrite",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "File createTmpFileForWrite(String path, long size, Configuration conf) throws IOException\n{\r\n    if (conf.get(BUFFER_DIR_KEY) == null) {\r\n        conf.set(BUFFER_DIR_KEY, conf.get(\"hadoop.tmp.dir\") + \"/oss\");\r\n    }\r\n    if (directoryAllocator == null) {\r\n        directoryAllocator = new LocalDirAllocator(BUFFER_DIR_KEY);\r\n    }\r\n    return directoryAllocator.createTmpFileForWrite(path, size, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "intOption",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int intOption(Configuration conf, String key, int defVal, int min)\n{\r\n    int v = conf.getInt(key, defVal);\r\n    Preconditions.checkArgument(v >= min, String.format(\"Value of %s: %d is below the minimum value %d\", key, v, min));\r\n    LOG.debug(\"Value of {} is {}\", key, v);\r\n    return v;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "longOption",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long longOption(Configuration conf, String key, long defVal, long min)\n{\r\n    long v = conf.getLong(key, defVal);\r\n    Preconditions.checkArgument(v >= min, String.format(\"Value of %s: %d is below the minimum value %d\", key, v, min));\r\n    LOG.debug(\"Value of {} is {}\", key, v);\r\n    return v;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getMultipartSizeProperty",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long getMultipartSizeProperty(Configuration conf, String property, long defVal)\n{\r\n    long partSize = conf.getLong(property, defVal);\r\n    if (partSize < MULTIPART_MIN_SIZE) {\r\n        LOG.warn(\"{} must be at least 100 KB; configured value is {}\", property, partSize);\r\n        partSize = MULTIPART_MIN_SIZE;\r\n    } else if (partSize > Integer.MAX_VALUE) {\r\n        LOG.warn(\"oss: {} capped to ~2.14GB(maximum allowed size with \" + \"current output mechanism)\", MULTIPART_UPLOAD_PART_SIZE_KEY);\r\n        partSize = Integer.MAX_VALUE;\r\n    }\r\n    return partSize;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "v1",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "OSSListResult v1(ObjectListing result)\n{\r\n    return new OSSListResult(result, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "v2",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "OSSListResult v2(ListObjectsV2Result result)\n{\r\n    return new OSSListResult(null, result);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "isV1",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isV1()\n{\r\n    return v1Result != null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getV1",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ObjectListing getV1()\n{\r\n    return v1Result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getV2",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ListObjectsV2Result getV2()\n{\r\n    return v2Result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getObjectSummaries",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "List<OSSObjectSummary> getObjectSummaries()\n{\r\n    if (isV1()) {\r\n        return v1Result.getObjectSummaries();\r\n    } else {\r\n        return v2Result.getObjectSummaries();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "isTruncated",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean isTruncated()\n{\r\n    if (isV1()) {\r\n        return v1Result.isTruncated();\r\n    } else {\r\n        return v2Result.isTruncated();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getCommonPrefixes",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "List<String> getCommonPrefixes()\n{\r\n    if (isV1()) {\r\n        return v1Result.getCommonPrefixes();\r\n    } else {\r\n        return v2Result.getCommonPrefixes();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "logAtDebug",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void logAtDebug(Logger log)\n{\r\n    Collection<String> prefixes = getCommonPrefixes();\r\n    Collection<OSSObjectSummary> summaries = getObjectSummaries();\r\n    log.debug(\"Prefix count = {}; object count={}\", prefixes.size(), summaries.size());\r\n    for (OSSObjectSummary summary : summaries) {\r\n        log.debug(\"Summary: {} {}\", summary.getKey(), summary.getSize());\r\n    }\r\n    for (String prefix : prefixes) {\r\n        log.debug(\"Prefix: {}\", prefix);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 38,
  "sourceCodeText" : "void initialize(URI uri, Configuration conf, String user, FileSystem.Statistics stat) throws IOException\n{\r\n    this.username = user;\r\n    statistics = stat;\r\n    ClientConfiguration clientConf = new ClientConfiguration();\r\n    clientConf.setMaxConnections(conf.getInt(MAXIMUM_CONNECTIONS_KEY, MAXIMUM_CONNECTIONS_DEFAULT));\r\n    boolean secureConnections = conf.getBoolean(SECURE_CONNECTIONS_KEY, SECURE_CONNECTIONS_DEFAULT);\r\n    clientConf.setProtocol(secureConnections ? Protocol.HTTPS : Protocol.HTTP);\r\n    clientConf.setMaxErrorRetry(conf.getInt(MAX_ERROR_RETRIES_KEY, MAX_ERROR_RETRIES_DEFAULT));\r\n    clientConf.setConnectionTimeout(conf.getInt(ESTABLISH_TIMEOUT_KEY, ESTABLISH_TIMEOUT_DEFAULT));\r\n    clientConf.setSocketTimeout(conf.getInt(SOCKET_TIMEOUT_KEY, SOCKET_TIMEOUT_DEFAULT));\r\n    clientConf.setUserAgent(conf.get(USER_AGENT_PREFIX, USER_AGENT_PREFIX_DEFAULT) + \", Hadoop/\" + VersionInfo.getVersion());\r\n    String proxyHost = conf.getTrimmed(PROXY_HOST_KEY, \"\");\r\n    int proxyPort = conf.getInt(PROXY_PORT_KEY, -1);\r\n    if (StringUtils.isNotEmpty(proxyHost)) {\r\n        clientConf.setProxyHost(proxyHost);\r\n        if (proxyPort >= 0) {\r\n            clientConf.setProxyPort(proxyPort);\r\n        } else {\r\n            if (secureConnections) {\r\n                LOG.warn(\"Proxy host set without port. Using HTTPS default 443\");\r\n                clientConf.setProxyPort(443);\r\n            } else {\r\n                LOG.warn(\"Proxy host set without port. Using HTTP default 80\");\r\n                clientConf.setProxyPort(80);\r\n            }\r\n        }\r\n        String proxyUsername = conf.getTrimmed(PROXY_USERNAME_KEY);\r\n        String proxyPassword = conf.getTrimmed(PROXY_PASSWORD_KEY);\r\n        if ((proxyUsername == null) != (proxyPassword == null)) {\r\n            String msg = \"Proxy error: \" + PROXY_USERNAME_KEY + \" or \" + PROXY_PASSWORD_KEY + \" set without the other.\";\r\n            LOG.error(msg);\r\n            throw new IllegalArgumentException(msg);\r\n        }\r\n        clientConf.setProxyUsername(proxyUsername);\r\n        clientConf.setProxyPassword(proxyPassword);\r\n        clientConf.setProxyDomain(conf.getTrimmed(PROXY_DOMAIN_KEY));\r\n        clientConf.setProxyWorkstation(conf.getTrimmed(PROXY_WORKSTATION_KEY));\r\n    } else if (proxyPort >= 0) {\r\n        String msg = \"Proxy error: \" + PROXY_PORT_KEY + \" set without \" + PROXY_HOST_KEY;\r\n        LOG.error(msg);\r\n        throw new IllegalArgumentException(msg);\r\n    }\r\n    String endPoint = conf.getTrimmed(ENDPOINT_KEY, \"\");\r\n    if (StringUtils.isEmpty(endPoint)) {\r\n        throw new IllegalArgumentException(\"Aliyun OSS endpoint should not be \" + \"null or empty. Please set proper endpoint with 'fs.oss.endpoint'.\");\r\n    }\r\n    CredentialsProvider provider = AliyunOSSUtils.getCredentialsProvider(uri, conf);\r\n    ossClient = new OSSClient(endPoint, provider, clientConf);\r\n    uploadPartSize = AliyunOSSUtils.getMultipartSizeProperty(conf, MULTIPART_UPLOAD_PART_SIZE_KEY, MULTIPART_UPLOAD_PART_SIZE_DEFAULT);\r\n    serverSideEncryptionAlgorithm = conf.get(SERVER_SIDE_ENCRYPTION_ALGORITHM_KEY, \"\");\r\n    bucketName = uri.getHost();\r\n    String cannedACLName = conf.get(CANNED_ACL_KEY, CANNED_ACL_DEFAULT);\r\n    if (StringUtils.isNotEmpty(cannedACLName)) {\r\n        CannedAccessControlList cannedACL = CannedAccessControlList.valueOf(cannedACLName);\r\n        ossClient.setBucketAcl(bucketName, cannedACL);\r\n        statistics.incrementWriteOps(1);\r\n    }\r\n    maxKeys = conf.getInt(MAX_PAGING_KEYS_KEY, MAX_PAGING_KEYS_DEFAULT);\r\n    int listVersion = conf.getInt(LIST_VERSION, DEFAULT_LIST_VERSION);\r\n    if (listVersion < 1 || listVersion > 2) {\r\n        LOG.warn(\"Configured fs.oss.list.version {} is invalid, forcing \" + \"version 2\", listVersion);\r\n    }\r\n    useListV1 = (listVersion == 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "deleteObject",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void deleteObject(String key)\n{\r\n    ossClient.deleteObject(bucketName, key);\r\n    statistics.incrementWriteOps(1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "deleteObjects",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void deleteObjects(List<String> keysToDelete) throws IOException\n{\r\n    if (CollectionUtils.isEmpty(keysToDelete)) {\r\n        LOG.warn(\"Keys to delete is empty.\");\r\n        return;\r\n    }\r\n    int retry = 10;\r\n    int tries = 0;\r\n    List<String> deleteFailed = keysToDelete;\r\n    while (CollectionUtils.isNotEmpty(deleteFailed)) {\r\n        DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucketName);\r\n        deleteRequest.setKeys(deleteFailed);\r\n        deleteRequest.setQuiet(true);\r\n        DeleteObjectsResult result = ossClient.deleteObjects(deleteRequest);\r\n        statistics.incrementWriteOps(1);\r\n        deleteFailed = result.getDeletedObjects();\r\n        tries++;\r\n        if (tries == retry) {\r\n            break;\r\n        }\r\n    }\r\n    if (tries == retry && CollectionUtils.isNotEmpty(deleteFailed)) {\r\n        throw new IOException(\"Failed to delete Aliyun OSS objects for \" + tries + \" times.\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "deleteDirs",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void deleteDirs(String key) throws IOException\n{\r\n    OSSListRequest listRequest = createListObjectsRequest(key, maxKeys, null, null, true);\r\n    while (true) {\r\n        OSSListResult objects = listObjects(listRequest);\r\n        statistics.incrementReadOps(1);\r\n        List<String> keysToDelete = new ArrayList<String>();\r\n        for (OSSObjectSummary objectSummary : objects.getObjectSummaries()) {\r\n            keysToDelete.add(objectSummary.getKey());\r\n        }\r\n        deleteObjects(keysToDelete);\r\n        if (objects.isTruncated()) {\r\n            if (objects.isV1()) {\r\n                listRequest.getV1().setMarker(objects.getV1().getNextMarker());\r\n            } else {\r\n                listRequest.getV2().setContinuationToken(objects.getV2().getNextContinuationToken());\r\n            }\r\n        } else {\r\n            break;\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getObjectMetadata",
  "errType" : [ "OSSException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "ObjectMetadata getObjectMetadata(String key)\n{\r\n    try {\r\n        GenericRequest request = new GenericRequest(bucketName, key);\r\n        request.setLogEnabled(false);\r\n        ObjectMetadata objectMeta = ossClient.getObjectMetadata(request);\r\n        statistics.incrementReadOps(1);\r\n        return objectMeta;\r\n    } catch (OSSException osse) {\r\n        LOG.debug(\"Exception thrown when get object meta: \" + key + \", exception: \" + osse);\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "storeEmptyFile",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void storeEmptyFile(String key) throws IOException\n{\r\n    ObjectMetadata dirMeta = new ObjectMetadata();\r\n    byte[] buffer = new byte[0];\r\n    ByteArrayInputStream in = new ByteArrayInputStream(buffer);\r\n    dirMeta.setContentLength(0);\r\n    try {\r\n        ossClient.putObject(bucketName, key, in, dirMeta);\r\n        statistics.incrementWriteOps(1);\r\n    } finally {\r\n        in.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "copyFile",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean copyFile(String srcKey, long srcLen, String dstKey)\n{\r\n    try {\r\n        return singleCopy(srcKey, dstKey);\r\n    } catch (Exception e) {\r\n        LOG.debug(\"Exception thrown when copy file: \" + srcKey + \", exception: \" + e + \", use multipartCopy instead\");\r\n        return multipartCopy(srcKey, srcLen, dstKey);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "singleCopy",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean singleCopy(String srcKey, String dstKey)\n{\r\n    CopyObjectResult copyResult = ossClient.copyObject(bucketName, srcKey, bucketName, dstKey);\r\n    statistics.incrementWriteOps(1);\r\n    LOG.debug(copyResult.getETag());\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "multipartCopy",
  "errType" : [ "OSSException|ClientException" ],
  "containingMethodsNum" : 21,
  "sourceCodeText" : "boolean multipartCopy(String srcKey, long contentLength, String dstKey)\n{\r\n    long realPartSize = AliyunOSSUtils.calculatePartSize(contentLength, uploadPartSize);\r\n    int partNum = (int) (contentLength / realPartSize);\r\n    if (contentLength % realPartSize != 0) {\r\n        partNum++;\r\n    }\r\n    InitiateMultipartUploadRequest initiateMultipartUploadRequest = new InitiateMultipartUploadRequest(bucketName, dstKey);\r\n    ObjectMetadata meta = new ObjectMetadata();\r\n    if (StringUtils.isNotEmpty(serverSideEncryptionAlgorithm)) {\r\n        meta.setServerSideEncryption(serverSideEncryptionAlgorithm);\r\n    }\r\n    initiateMultipartUploadRequest.setObjectMetadata(meta);\r\n    InitiateMultipartUploadResult initiateMultipartUploadResult = ossClient.initiateMultipartUpload(initiateMultipartUploadRequest);\r\n    String uploadId = initiateMultipartUploadResult.getUploadId();\r\n    List<PartETag> partETags = new ArrayList<PartETag>();\r\n    try {\r\n        for (int i = 0; i < partNum; i++) {\r\n            long skipBytes = realPartSize * i;\r\n            long size = (realPartSize < contentLength - skipBytes) ? realPartSize : contentLength - skipBytes;\r\n            UploadPartCopyRequest partCopyRequest = new UploadPartCopyRequest();\r\n            partCopyRequest.setSourceBucketName(bucketName);\r\n            partCopyRequest.setSourceKey(srcKey);\r\n            partCopyRequest.setBucketName(bucketName);\r\n            partCopyRequest.setKey(dstKey);\r\n            partCopyRequest.setUploadId(uploadId);\r\n            partCopyRequest.setPartSize(size);\r\n            partCopyRequest.setBeginIndex(skipBytes);\r\n            partCopyRequest.setPartNumber(i + 1);\r\n            UploadPartCopyResult partCopyResult = ossClient.uploadPartCopy(partCopyRequest);\r\n            statistics.incrementWriteOps(1);\r\n            statistics.incrementBytesWritten(size);\r\n            partETags.add(partCopyResult.getPartETag());\r\n        }\r\n        CompleteMultipartUploadRequest completeMultipartUploadRequest = new CompleteMultipartUploadRequest(bucketName, dstKey, uploadId, partETags);\r\n        CompleteMultipartUploadResult completeMultipartUploadResult = ossClient.completeMultipartUpload(completeMultipartUploadRequest);\r\n        LOG.debug(completeMultipartUploadResult.getETag());\r\n        return true;\r\n    } catch (OSSException | ClientException e) {\r\n        AbortMultipartUploadRequest abortMultipartUploadRequest = new AbortMultipartUploadRequest(bucketName, dstKey, uploadId);\r\n        ossClient.abortMultipartUpload(abortMultipartUploadRequest);\r\n        return false;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "uploadObject",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void uploadObject(String key, File file) throws IOException\n{\r\n    File object = file.getAbsoluteFile();\r\n    FileInputStream fis = new FileInputStream(object);\r\n    ObjectMetadata meta = new ObjectMetadata();\r\n    meta.setContentLength(object.length());\r\n    if (StringUtils.isNotEmpty(serverSideEncryptionAlgorithm)) {\r\n        meta.setServerSideEncryption(serverSideEncryptionAlgorithm);\r\n    }\r\n    try {\r\n        PutObjectResult result = ossClient.putObject(bucketName, key, fis, meta);\r\n        LOG.debug(result.getETag());\r\n        statistics.incrementWriteOps(1);\r\n    } finally {\r\n        fis.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "listObjects",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "OSSListResult listObjects(OSSListRequest listRequest)\n{\r\n    OSSListResult listResult;\r\n    if (listRequest.isV1()) {\r\n        listResult = OSSListResult.v1(ossClient.listObjects(listRequest.getV1()));\r\n    } else {\r\n        listResult = OSSListResult.v2(ossClient.listObjectsV2(listRequest.getV2()));\r\n    }\r\n    statistics.incrementReadOps(1);\r\n    return listResult;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "continueListObjects",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "OSSListResult continueListObjects(OSSListRequest listRequest, OSSListResult preListResult)\n{\r\n    OSSListResult listResult;\r\n    if (listRequest.isV1()) {\r\n        listRequest.getV1().setMarker(preListResult.getV1().getNextMarker());\r\n        listResult = OSSListResult.v1(ossClient.listObjects(listRequest.getV1()));\r\n    } else {\r\n        listRequest.getV2().setContinuationToken(preListResult.getV2().getNextContinuationToken());\r\n        listResult = OSSListResult.v2(ossClient.listObjectsV2(listRequest.getV2()));\r\n    }\r\n    statistics.incrementReadOps(1);\r\n    return listResult;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "createListObjectsRequest",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "OSSListRequest createListObjectsRequest(String prefix, int maxListingLength, String marker, String continuationToken, boolean recursive)\n{\r\n    String delimiter = recursive ? null : \"/\";\r\n    prefix = AliyunOSSUtils.maybeAddTrailingSlash(prefix);\r\n    if (useListV1) {\r\n        ListObjectsRequest listRequest = new ListObjectsRequest(bucketName);\r\n        listRequest.setPrefix(prefix);\r\n        listRequest.setDelimiter(delimiter);\r\n        listRequest.setMaxKeys(maxListingLength);\r\n        listRequest.setMarker(marker);\r\n        return OSSListRequest.v1(listRequest);\r\n    } else {\r\n        ListObjectsV2Request listV2Request = new ListObjectsV2Request(bucketName);\r\n        listV2Request.setPrefix(prefix);\r\n        listV2Request.setDelimiter(delimiter);\r\n        listV2Request.setMaxKeys(maxListingLength);\r\n        listV2Request.setContinuationToken(continuationToken);\r\n        return OSSListRequest.v2(listV2Request);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "retrieve",
  "errType" : [ "OSSException|ClientException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "InputStream retrieve(String key, long byteStart, long byteEnd)\n{\r\n    try {\r\n        GetObjectRequest request = new GetObjectRequest(bucketName, key);\r\n        request.setRange(byteStart, byteEnd);\r\n        InputStream in = ossClient.getObject(request).getObjectContent();\r\n        statistics.incrementReadOps(1);\r\n        return in;\r\n    } catch (OSSException | ClientException e) {\r\n        LOG.error(\"Exception thrown when store retrieves key: \" + key + \", exception: \" + e);\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close()\n{\r\n    if (ossClient != null) {\r\n        ossClient.shutdown();\r\n        ossClient = null;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "purge",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void purge(String prefix) throws IOException\n{\r\n    deleteDirs(prefix);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "singleStatusRemoteIterator",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "RemoteIterator<LocatedFileStatus> singleStatusRemoteIterator(final FileStatus fileStatus, final BlockLocation[] locations)\n{\r\n    return new RemoteIterator<LocatedFileStatus>() {\r\n\r\n        private boolean hasNext = true;\r\n\r\n        @Override\r\n        public boolean hasNext() throws IOException {\r\n            return fileStatus != null && hasNext;\r\n        }\r\n\r\n        @Override\r\n        public LocatedFileStatus next() throws IOException {\r\n            if (hasNext()) {\r\n                LocatedFileStatus s = new LocatedFileStatus(fileStatus, fileStatus.isFile() ? locations : null);\r\n                hasNext = false;\r\n                return s;\r\n            } else {\r\n                throw new NoSuchElementException();\r\n            }\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "createLocatedFileStatusIterator",
  "errType" : null,
  "containingMethodsNum" : 34,
  "sourceCodeText" : "RemoteIterator<LocatedFileStatus> createLocatedFileStatusIterator(final String prefix, final int maxListingLength, FileSystem fs, PathFilter filter, FileStatusAcceptor acceptor, boolean recursive)\n{\r\n    return new RemoteIterator<LocatedFileStatus>() {\r\n\r\n        private boolean firstListing = true;\r\n\r\n        private boolean meetEnd = false;\r\n\r\n        private ListIterator<FileStatus> batchIterator;\r\n\r\n        private OSSListRequest listRequest = null;\r\n\r\n        @Override\r\n        public boolean hasNext() throws IOException {\r\n            if (firstListing) {\r\n                requestNextBatch();\r\n                firstListing = false;\r\n            }\r\n            return batchIterator.hasNext() || requestNextBatch();\r\n        }\r\n\r\n        @Override\r\n        public LocatedFileStatus next() throws IOException {\r\n            if (hasNext()) {\r\n                FileStatus status = batchIterator.next();\r\n                BlockLocation[] locations = fs.getFileBlockLocations(status, 0, status.getLen());\r\n                return new LocatedFileStatus(status, status.isFile() ? locations : null);\r\n            } else {\r\n                throw new NoSuchElementException();\r\n            }\r\n        }\r\n\r\n        private boolean requestNextBatch() {\r\n            while (!meetEnd) {\r\n                if (continueListStatus()) {\r\n                    return true;\r\n                }\r\n            }\r\n            return false;\r\n        }\r\n\r\n        private boolean continueListStatus() {\r\n            if (meetEnd) {\r\n                return false;\r\n            }\r\n            if (listRequest == null) {\r\n                listRequest = createListObjectsRequest(prefix, maxListingLength, null, null, recursive);\r\n            }\r\n            OSSListResult listing = listObjects(listRequest);\r\n            List<FileStatus> stats = new ArrayList<>(listing.getObjectSummaries().size() + listing.getCommonPrefixes().size());\r\n            for (OSSObjectSummary summary : listing.getObjectSummaries()) {\r\n                String key = summary.getKey();\r\n                Path path = fs.makeQualified(new Path(\"/\" + key));\r\n                if (filter.accept(path) && acceptor.accept(path, summary)) {\r\n                    FileStatus status = new OSSFileStatus(summary.getSize(), key.endsWith(\"/\"), 1, fs.getDefaultBlockSize(path), summary.getLastModified().getTime(), path, username);\r\n                    stats.add(status);\r\n                }\r\n            }\r\n            for (String commonPrefix : listing.getCommonPrefixes()) {\r\n                Path path = fs.makeQualified(new Path(\"/\" + commonPrefix));\r\n                if (filter.accept(path) && acceptor.accept(path, commonPrefix)) {\r\n                    FileStatus status = new OSSFileStatus(0, true, 1, 0, 0, path, username);\r\n                    stats.add(status);\r\n                }\r\n            }\r\n            batchIterator = stats.listIterator();\r\n            if (listing.isTruncated()) {\r\n                if (listing.isV1()) {\r\n                    listRequest.getV1().setMarker(listing.getV1().getNextMarker());\r\n                } else {\r\n                    listRequest.getV2().setContinuationToken(listing.getV2().getNextContinuationToken());\r\n                }\r\n            } else {\r\n                meetEnd = true;\r\n            }\r\n            statistics.incrementReadOps(1);\r\n            return batchIterator.hasNext();\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "uploadPart",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "PartETag uploadPart(File file, String key, String uploadId, int idx) throws IOException\n{\r\n    InputStream instream = null;\r\n    Exception caught = null;\r\n    int tries = 3;\r\n    while (tries > 0) {\r\n        try {\r\n            instream = new FileInputStream(file);\r\n            UploadPartRequest uploadRequest = new UploadPartRequest();\r\n            uploadRequest.setBucketName(bucketName);\r\n            uploadRequest.setKey(key);\r\n            uploadRequest.setUploadId(uploadId);\r\n            uploadRequest.setInputStream(instream);\r\n            uploadRequest.setPartSize(file.length());\r\n            uploadRequest.setPartNumber(idx);\r\n            UploadPartResult uploadResult = ossClient.uploadPart(uploadRequest);\r\n            statistics.incrementWriteOps(1);\r\n            return uploadResult.getPartETag();\r\n        } catch (Exception e) {\r\n            LOG.debug(\"Failed to upload \" + file.getPath() + \", \" + \"try again.\", e);\r\n            caught = e;\r\n        } finally {\r\n            if (instream != null) {\r\n                instream.close();\r\n                instream = null;\r\n            }\r\n        }\r\n        tries--;\r\n    }\r\n    assert (caught != null);\r\n    throw new IOException(\"Failed to upload \" + file.getPath() + \" for 3 times.\", caught);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getUploadId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getUploadId(String key)\n{\r\n    InitiateMultipartUploadRequest initiateMultipartUploadRequest = new InitiateMultipartUploadRequest(bucketName, key);\r\n    InitiateMultipartUploadResult initiateMultipartUploadResult = ossClient.initiateMultipartUpload(initiateMultipartUploadRequest);\r\n    return initiateMultipartUploadResult.getUploadId();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "completeMultipartUpload",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "CompleteMultipartUploadResult completeMultipartUpload(String key, String uploadId, List<PartETag> partETags)\n{\r\n    Collections.sort(partETags, new PartNumberAscendComparator());\r\n    CompleteMultipartUploadRequest completeMultipartUploadRequest = new CompleteMultipartUploadRequest(bucketName, key, uploadId, partETags);\r\n    return ossClient.completeMultipartUpload(completeMultipartUploadRequest);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "abortMultipartUpload",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void abortMultipartUpload(String key, String uploadId)\n{\r\n    AbortMultipartUploadRequest request = new AbortMultipartUploadRequest(bucketName, key, uploadId);\r\n    ossClient.abortMultipartUpload(request);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "run",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void run()\n{\r\n    boolean fail = false;\r\n    try {\r\n        fail = !store.copyFile(srcKey, srcLen, dstKey);\r\n    } catch (Exception e) {\r\n        LOG.warn(\"Exception thrown when copy from \" + srcKey + \" to \" + dstKey + \", exception: \" + e);\r\n        fail = true;\r\n    } finally {\r\n        copyFileContext.lock();\r\n        if (fail) {\r\n            copyFileContext.setCopyFailure(fail);\r\n        }\r\n        copyFileContext.incCopiesFinish();\r\n        copyFileContext.signalAll();\r\n        copyFileContext.unlock();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "newBlockFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "File newBlockFile() throws IOException\n{\r\n    return AliyunOSSUtils.createTmpFileForWrite(String.format(\"oss-block-%04d-\", blockId), blockSize, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "flush",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void flush() throws IOException\n{\r\n    blockStream.flush();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (closed) {\r\n        return;\r\n    }\r\n    blockStream.flush();\r\n    blockStream.close();\r\n    if (!blockFiles.values().contains(blockFile)) {\r\n        blockId++;\r\n        blockFiles.put(blockId, blockFile);\r\n    }\r\n    try {\r\n        if (blockFiles.size() == 1) {\r\n            store.uploadObject(key, blockFile);\r\n        } else {\r\n            if (blockWritten > 0) {\r\n                ListenableFuture<PartETag> partETagFuture = executorService.submit(() -> {\r\n                    PartETag partETag = store.uploadPart(blockFile, key, uploadId, blockId);\r\n                    return partETag;\r\n                });\r\n                partETagsFutures.add(partETagFuture);\r\n            }\r\n            final List<PartETag> partETags = waitForAllPartUploads();\r\n            if (null == partETags) {\r\n                throw new IOException(\"Failed to multipart upload to oss, abort it.\");\r\n            }\r\n            store.completeMultipartUpload(key, uploadId, new ArrayList<>(partETags));\r\n        }\r\n    } finally {\r\n        removeTemporaryFiles();\r\n        closed = true;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void write(int b) throws IOException\n{\r\n    singleByte[0] = (byte) b;\r\n    write(singleByte, 0, 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void write(byte[] b, int off, int len) throws IOException\n{\r\n    if (closed) {\r\n        throw new IOException(\"Stream closed.\");\r\n    }\r\n    blockStream.write(b, off, len);\r\n    blockWritten += len;\r\n    if (blockWritten >= blockSize) {\r\n        uploadCurrentPart();\r\n        blockWritten = 0L;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "removeTemporaryFiles",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void removeTemporaryFiles()\n{\r\n    for (File file : blockFiles.values()) {\r\n        if (file != null && file.exists() && !file.delete()) {\r\n            LOG.warn(\"Failed to delete temporary file {}\", file);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "removePartFiles",
  "errType" : [ "InterruptedException|ExecutionException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void removePartFiles() throws IOException\n{\r\n    for (ListenableFuture<PartETag> partETagFuture : partETagsFutures) {\r\n        if (!partETagFuture.isDone()) {\r\n            continue;\r\n        }\r\n        try {\r\n            File blockFile = blockFiles.get(partETagFuture.get().getPartNumber());\r\n            if (blockFile != null && blockFile.exists() && !blockFile.delete()) {\r\n                LOG.warn(\"Failed to delete temporary file {}\", blockFile);\r\n            }\r\n        } catch (InterruptedException | ExecutionException e) {\r\n            throw new IOException(e);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "uploadCurrentPart",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void uploadCurrentPart() throws IOException\n{\r\n    blockStream.flush();\r\n    blockStream.close();\r\n    if (blockId == 0) {\r\n        uploadId = store.getUploadId(key);\r\n    }\r\n    blockId++;\r\n    blockFiles.put(blockId, blockFile);\r\n    File currentFile = blockFile;\r\n    int currentBlockId = blockId;\r\n    ListenableFuture<PartETag> partETagFuture = executorService.submit(() -> {\r\n        PartETag partETag = store.uploadPart(currentFile, key, uploadId, currentBlockId);\r\n        return partETag;\r\n    });\r\n    partETagsFutures.add(partETagFuture);\r\n    removePartFiles();\r\n    blockFile = newBlockFile();\r\n    blockStream = new BufferedOutputStream(new FileOutputStream(blockFile));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "waitForAllPartUploads",
  "errType" : [ "InterruptedException", "ExecutionException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "List<PartETag> waitForAllPartUploads() throws IOException\n{\r\n    LOG.debug(\"Waiting for {} uploads to complete\", partETagsFutures.size());\r\n    try {\r\n        return Futures.allAsList(partETagsFutures).get();\r\n    } catch (InterruptedException ie) {\r\n        LOG.warn(\"Interrupted partUpload\", ie);\r\n        Thread.currentThread().interrupt();\r\n        return null;\r\n    } catch (ExecutionException ee) {\r\n        LOG.debug(\"While waiting for upload completion\", ee);\r\n        LOG.debug(\"Cancelling futures\");\r\n        for (ListenableFuture<PartETag> future : partETagsFutures) {\r\n            future.cancel(true);\r\n        }\r\n        store.abortMultipartUpload(key, uploadId);\r\n        throw new IOException(\"Multi-part upload with id '\" + uploadId + \"' to \" + key, ee);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "lock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void lock()\n{\r\n    lock.lock();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "unlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void unlock()\n{\r\n    lock.unlock();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "await",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void await(STATUS waitStatus) throws InterruptedException\n{\r\n    while (this.status == waitStatus) {\r\n        readyCondition.await();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "signalAll",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void signalAll()\n{\r\n    readyCondition.signalAll();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getBuffer",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getBuffer()\n{\r\n    return buffer;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "STATUS getStatus()\n{\r\n    return status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "setStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setStatus(STATUS status)\n{\r\n    this.status = status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getByteStart",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getByteStart()\n{\r\n    return byteStart;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-aliyun\\src\\main\\java\\org\\apache\\hadoop\\fs\\aliyun\\oss",
  "methodName" : "getByteEnd",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getByteEnd()\n{\r\n    return byteEnd;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]