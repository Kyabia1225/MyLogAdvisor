[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "transferTo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long transferTo(WritableByteChannel target, long position) throws IOException\n{\r\n    if (readaheadPool != null && readaheadLength > 0) {\r\n        readaheadRequest = readaheadPool.readaheadStream(identifier, fd, getPosition() + position, readaheadLength, getPosition() + getCount(), readaheadRequest);\r\n    }\r\n    if (this.shuffleTransferToAllowed) {\r\n        return super.transferTo(target, position);\r\n    } else {\r\n        return customShuffleTransfer(target, position);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "customShuffleTransfer",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "long customShuffleTransfer(WritableByteChannel target, long position) throws IOException\n{\r\n    long actualCount = this.count - position;\r\n    if (actualCount < 0 || position < 0) {\r\n        throw new IllegalArgumentException(\"position out of range: \" + position + \" (expected: 0 - \" + (this.count - 1) + ')');\r\n    }\r\n    if (actualCount == 0) {\r\n        return 0L;\r\n    }\r\n    long trans = actualCount;\r\n    int readSize;\r\n    ByteBuffer byteBuffer = ByteBuffer.allocate(Math.min(this.shuffleBufferSize, trans > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) trans));\r\n    while (trans > 0L && (readSize = fileChannel.read(byteBuffer, this.position + position)) > 0) {\r\n        if (readSize < trans) {\r\n            trans -= readSize;\r\n            position += readSize;\r\n            byteBuffer.flip();\r\n        } else {\r\n            byteBuffer.limit((int) trans);\r\n            byteBuffer.position(0);\r\n            position += trans;\r\n            trans = 0;\r\n        }\r\n        while (byteBuffer.hasRemaining()) {\r\n            target.write(byteBuffer);\r\n        }\r\n        byteBuffer.clear();\r\n    }\r\n    return actualCount - trans;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "releaseExternalResources",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void releaseExternalResources()\n{\r\n    if (readaheadRequest != null) {\r\n        readaheadRequest.cancel();\r\n    }\r\n    super.releaseExternalResources();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "transferSuccessful",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void transferSuccessful()\n{\r\n    if (manageOsCache && getCount() > 0) {\r\n        try {\r\n            NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(identifier, fd, getPosition(), getCount(), POSIX_FADV_DONTNEED);\r\n        } catch (Throwable t) {\r\n            LOG.warn(\"Failed to manage OS cache for \" + identifier, t);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serializeMetaData",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ByteBuffer serializeMetaData(int port) throws IOException\n{\r\n    DataOutputBuffer port_dob = new DataOutputBuffer();\r\n    port_dob.writeInt(port);\r\n    return ByteBuffer.wrap(port_dob.getData(), 0, port_dob.getLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "deserializeMetaData",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int deserializeMetaData(ByteBuffer meta) throws IOException\n{\r\n    DataInputByteBuffer in = new DataInputByteBuffer();\r\n    in.reset(meta);\r\n    int port = in.readInt();\r\n    return port;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serializeServiceData",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ByteBuffer serializeServiceData(Token<JobTokenIdentifier> jobToken) throws IOException\n{\r\n    DataOutputBuffer jobToken_dob = new DataOutputBuffer();\r\n    jobToken.write(jobToken_dob);\r\n    return ByteBuffer.wrap(jobToken_dob.getData(), 0, jobToken_dob.getLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "deserializeServiceData",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Token<JobTokenIdentifier> deserializeServiceData(ByteBuffer secret) throws IOException\n{\r\n    DataInputByteBuffer in = new DataInputByteBuffer();\r\n    in.reset(secret);\r\n    Token<JobTokenIdentifier> jt = new Token<JobTokenIdentifier>();\r\n    jt.readFields(in);\r\n    return jt;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "initializeApplication",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void initializeApplication(ApplicationInitializationContext context)\n{\r\n    String user = context.getUser();\r\n    ApplicationId appId = context.getApplicationId();\r\n    ByteBuffer secret = context.getApplicationDataForService();\r\n    try {\r\n        Token<JobTokenIdentifier> jt = deserializeServiceData(secret);\r\n        JobID jobId = new JobID(Long.toString(appId.getClusterTimestamp()), appId.getId());\r\n        recordJobShuffleInfo(jobId, user, jt);\r\n    } catch (IOException e) {\r\n        LOG.error(\"Error during initApp\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "stopApplication",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void stopApplication(ApplicationTerminationContext context)\n{\r\n    ApplicationId appId = context.getApplicationId();\r\n    JobID jobId = new JobID(Long.toString(appId.getClusterTimestamp()), appId.getId());\r\n    try {\r\n        removeJobShuffleInfo(jobId);\r\n    } catch (IOException e) {\r\n        LOG.error(\"Error during stopApp\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serviceInit",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void serviceInit(Configuration conf) throws Exception\n{\r\n    manageOsCache = conf.getBoolean(SHUFFLE_MANAGE_OS_CACHE, DEFAULT_SHUFFLE_MANAGE_OS_CACHE);\r\n    readaheadLength = conf.getInt(SHUFFLE_READAHEAD_BYTES, DEFAULT_SHUFFLE_READAHEAD_BYTES);\r\n    maxShuffleConnections = conf.getInt(MAX_SHUFFLE_CONNECTIONS, DEFAULT_MAX_SHUFFLE_CONNECTIONS);\r\n    int maxShuffleThreads = conf.getInt(MAX_SHUFFLE_THREADS, DEFAULT_MAX_SHUFFLE_THREADS);\r\n    if (maxShuffleThreads == 0) {\r\n        maxShuffleThreads = 2 * Runtime.getRuntime().availableProcessors();\r\n    }\r\n    shuffleBufferSize = conf.getInt(SHUFFLE_BUFFER_SIZE, DEFAULT_SHUFFLE_BUFFER_SIZE);\r\n    shuffleTransferToAllowed = conf.getBoolean(SHUFFLE_TRANSFERTO_ALLOWED, (Shell.WINDOWS) ? WINDOWS_DEFAULT_SHUFFLE_TRANSFERTO_ALLOWED : DEFAULT_SHUFFLE_TRANSFERTO_ALLOWED);\r\n    maxSessionOpenFiles = conf.getInt(SHUFFLE_MAX_SESSION_OPEN_FILES, DEFAULT_SHUFFLE_MAX_SESSION_OPEN_FILES);\r\n    ThreadFactory bossFactory = new ThreadFactoryBuilder().setNameFormat(\"ShuffleHandler Netty Boss #%d\").build();\r\n    ThreadFactory workerFactory = new ThreadFactoryBuilder().setNameFormat(\"ShuffleHandler Netty Worker #%d\").build();\r\n    selector = new NioServerSocketChannelFactory(HadoopExecutors.newCachedThreadPool(bossFactory), HadoopExecutors.newCachedThreadPool(workerFactory), maxShuffleThreads);\r\n    super.serviceInit(new Configuration(conf));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serviceStart",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void serviceStart() throws Exception\n{\r\n    Configuration conf = getConfig();\r\n    userRsrc = new ConcurrentHashMap<String, String>();\r\n    secretManager = new JobTokenSecretManager();\r\n    recoverState(conf);\r\n    ServerBootstrap bootstrap = new ServerBootstrap(selector);\r\n    timer = new HashedWheelTimer();\r\n    try {\r\n        pipelineFact = new HttpPipelineFactory(conf, timer);\r\n    } catch (Exception ex) {\r\n        throw new RuntimeException(ex);\r\n    }\r\n    bootstrap.setOption(\"backlog\", conf.getInt(SHUFFLE_LISTEN_QUEUE_SIZE, DEFAULT_SHUFFLE_LISTEN_QUEUE_SIZE));\r\n    bootstrap.setOption(\"child.keepAlive\", true);\r\n    bootstrap.setPipelineFactory(pipelineFact);\r\n    port = conf.getInt(SHUFFLE_PORT_CONFIG_KEY, DEFAULT_SHUFFLE_PORT);\r\n    Channel ch = bootstrap.bind(new InetSocketAddress(port));\r\n    accepted.add(ch);\r\n    port = ((InetSocketAddress) ch.getLocalAddress()).getPort();\r\n    conf.set(SHUFFLE_PORT_CONFIG_KEY, Integer.toString(port));\r\n    pipelineFact.SHUFFLE.setPort(port);\r\n    LOG.info(getName() + \" listening on port \" + port);\r\n    super.serviceStart();\r\n    sslFileBufferSize = conf.getInt(SUFFLE_SSL_FILE_BUFFER_SIZE_KEY, DEFAULT_SUFFLE_SSL_FILE_BUFFER_SIZE);\r\n    connectionKeepAliveEnabled = conf.getBoolean(SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED, DEFAULT_SHUFFLE_CONNECTION_KEEP_ALIVE_ENABLED);\r\n    connectionKeepAliveTimeOut = Math.max(1, conf.getInt(SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT, DEFAULT_SHUFFLE_CONNECTION_KEEP_ALIVE_TIME_OUT));\r\n    mapOutputMetaInfoCacheSize = Math.max(1, conf.getInt(SHUFFLE_MAPOUTPUT_META_INFO_CACHE_SIZE, DEFAULT_SHUFFLE_MAPOUTPUT_META_INFO_CACHE_SIZE));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serviceStop",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void serviceStop() throws Exception\n{\r\n    accepted.close().awaitUninterruptibly(10, TimeUnit.SECONDS);\r\n    if (selector != null) {\r\n        ServerBootstrap bootstrap = new ServerBootstrap(selector);\r\n        bootstrap.releaseExternalResources();\r\n    }\r\n    if (pipelineFact != null) {\r\n        pipelineFact.destroy();\r\n    }\r\n    if (timer != null) {\r\n        timer.stop();\r\n    }\r\n    if (stateDb != null) {\r\n        stateDb.close();\r\n    }\r\n    ms.unregisterSource(ShuffleMetrics.class.getSimpleName());\r\n    super.serviceStop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getMetaData",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ByteBuffer getMetaData()\n{\r\n    try {\r\n        return serializeMetaData(port);\r\n    } catch (IOException e) {\r\n        LOG.error(\"Error during getMeta\", e);\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getShuffle",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Shuffle getShuffle(Configuration conf)\n{\r\n    return new Shuffle(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "recoverState",
  "errType" : [ "DBException" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void recoverState(Configuration conf) throws IOException\n{\r\n    Path recoveryRoot = getRecoveryPath();\r\n    if (recoveryRoot != null) {\r\n        startStore(recoveryRoot);\r\n        Pattern jobPattern = Pattern.compile(JobID.JOBID_REGEX);\r\n        LeveldbIterator iter = null;\r\n        try {\r\n            iter = new LeveldbIterator(stateDb);\r\n            iter.seek(bytes(JobID.JOB));\r\n            while (iter.hasNext()) {\r\n                Map.Entry<byte[], byte[]> entry = iter.next();\r\n                String key = asString(entry.getKey());\r\n                if (!jobPattern.matcher(key).matches()) {\r\n                    break;\r\n                }\r\n                recoverJobShuffleInfo(key, entry.getValue());\r\n            }\r\n        } catch (DBException e) {\r\n            throw new IOException(\"Database error during recovery\", e);\r\n        } finally {\r\n            if (iter != null) {\r\n                iter.close();\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "startStore",
  "errType" : [ "NativeDB.DBException", "DBException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void startStore(Path recoveryRoot) throws IOException\n{\r\n    Options options = new Options();\r\n    options.createIfMissing(false);\r\n    Path dbPath = new Path(recoveryRoot, STATE_DB_NAME);\r\n    LOG.info(\"Using state database at \" + dbPath + \" for recovery\");\r\n    File dbfile = new File(dbPath.toString());\r\n    try {\r\n        stateDb = JniDBFactory.factory.open(dbfile, options);\r\n    } catch (NativeDB.DBException e) {\r\n        if (e.isNotFound() || e.getMessage().contains(\" does not exist \")) {\r\n            LOG.info(\"Creating state database at \" + dbfile);\r\n            options.createIfMissing(true);\r\n            try {\r\n                stateDb = JniDBFactory.factory.open(dbfile, options);\r\n                storeVersion();\r\n            } catch (DBException dbExc) {\r\n                throw new IOException(\"Unable to create state store\", dbExc);\r\n            }\r\n        } else {\r\n            throw e;\r\n        }\r\n    }\r\n    checkVersion();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "loadVersion",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Version loadVersion() throws IOException\n{\r\n    byte[] data = stateDb.get(bytes(STATE_DB_SCHEMA_VERSION_KEY));\r\n    if (data == null || data.length == 0) {\r\n        return getCurrentVersion();\r\n    }\r\n    Version version = new VersionPBImpl(VersionProto.parseFrom(data));\r\n    return version;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "storeSchemaVersion",
  "errType" : [ "DBException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void storeSchemaVersion(Version version) throws IOException\n{\r\n    String key = STATE_DB_SCHEMA_VERSION_KEY;\r\n    byte[] data = ((VersionPBImpl) version).getProto().toByteArray();\r\n    try {\r\n        stateDb.put(bytes(key), data);\r\n    } catch (DBException e) {\r\n        throw new IOException(e.getMessage(), e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "storeVersion",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void storeVersion() throws IOException\n{\r\n    storeSchemaVersion(CURRENT_VERSION_INFO);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "storeVersion",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void storeVersion(Version version) throws IOException\n{\r\n    storeSchemaVersion(version);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getCurrentVersion",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Version getCurrentVersion()\n{\r\n    return CURRENT_VERSION_INFO;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "checkVersion",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void checkVersion() throws IOException\n{\r\n    Version loadedVersion = loadVersion();\r\n    LOG.info(\"Loaded state DB schema version info \" + loadedVersion);\r\n    if (loadedVersion.equals(getCurrentVersion())) {\r\n        return;\r\n    }\r\n    if (loadedVersion.isCompatibleTo(getCurrentVersion())) {\r\n        LOG.info(\"Storing state DB schema version info \" + getCurrentVersion());\r\n        storeVersion();\r\n    } else {\r\n        throw new IOException(\"Incompatible version for state DB schema: expecting DB schema version \" + getCurrentVersion() + \", but loading version \" + loadedVersion);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "addJobToken",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addJobToken(JobID jobId, String user, Token<JobTokenIdentifier> jobToken)\n{\r\n    userRsrc.put(jobId.toString(), user);\r\n    secretManager.addTokenForJob(jobId.toString(), jobToken);\r\n    LOG.info(\"Added token for \" + jobId.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "recoverJobShuffleInfo",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void recoverJobShuffleInfo(String jobIdStr, byte[] data) throws IOException\n{\r\n    JobID jobId;\r\n    try {\r\n        jobId = JobID.forName(jobIdStr);\r\n    } catch (IllegalArgumentException e) {\r\n        throw new IOException(\"Bad job ID \" + jobIdStr + \" in state store\", e);\r\n    }\r\n    JobShuffleInfoProto proto = JobShuffleInfoProto.parseFrom(data);\r\n    String user = proto.getUser();\r\n    TokenProto tokenProto = proto.getJobToken();\r\n    Token<JobTokenIdentifier> jobToken = new Token<JobTokenIdentifier>(tokenProto.getIdentifier().toByteArray(), tokenProto.getPassword().toByteArray(), new Text(tokenProto.getKind()), new Text(tokenProto.getService()));\r\n    addJobToken(jobId, user, jobToken);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "recordJobShuffleInfo",
  "errType" : [ "DBException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void recordJobShuffleInfo(JobID jobId, String user, Token<JobTokenIdentifier> jobToken) throws IOException\n{\r\n    if (stateDb != null) {\r\n        TokenProto tokenProto = TokenProto.newBuilder().setIdentifier(ByteString.copyFrom(jobToken.getIdentifier())).setPassword(ByteString.copyFrom(jobToken.getPassword())).setKind(jobToken.getKind().toString()).setService(jobToken.getService().toString()).build();\r\n        JobShuffleInfoProto proto = JobShuffleInfoProto.newBuilder().setUser(user).setJobToken(tokenProto).build();\r\n        try {\r\n            stateDb.put(bytes(jobId.toString()), proto.toByteArray());\r\n        } catch (DBException e) {\r\n            throw new IOException(\"Error storing \" + jobId, e);\r\n        }\r\n    }\r\n    addJobToken(jobId, user, jobToken);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "removeJobShuffleInfo",
  "errType" : [ "DBException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void removeJobShuffleInfo(JobID jobId) throws IOException\n{\r\n    String jobIdStr = jobId.toString();\r\n    secretManager.removeTokenForJob(jobIdStr);\r\n    userRsrc.remove(jobIdStr);\r\n    if (stateDb != null) {\r\n        try {\r\n            stateDb.delete(bytes(jobIdStr));\r\n        } catch (DBException e) {\r\n            throw new IOException(\"Unable to remove \" + jobId + \" from state store\", e);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getFd",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FileDescriptor getFd()\n{\r\n    return fd;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "nextChunk",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Object nextChunk() throws Exception\n{\r\n    synchronized (closeLock) {\r\n        if (fd.valid()) {\r\n            if (manageOsCache && readaheadPool != null) {\r\n                readaheadRequest = readaheadPool.readaheadStream(identifier, fd, getCurrentOffset(), readaheadLength, getEndOffset(), readaheadRequest);\r\n            }\r\n            return super.nextChunk();\r\n        } else {\r\n            return null;\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-shuffle\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void close() throws Exception\n{\r\n    synchronized (closeLock) {\r\n        if (readaheadRequest != null) {\r\n            readaheadRequest.cancel();\r\n            readaheadRequest = null;\r\n        }\r\n        if (fd.valid() && manageOsCache && getEndOffset() - getStartOffset() > 0) {\r\n            try {\r\n                NativeIO.POSIX.getCacheManipulator().posixFadviseIfPossible(identifier, fd, getStartOffset(), getEndOffset() - getStartOffset(), POSIX_FADV_DONTNEED);\r\n            } catch (Throwable t) {\r\n                LOG.warn(\"Failed to manage OS cache for \" + identifier + \" fd \" + fd.toString(), t);\r\n            }\r\n        }\r\n        super.close();\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
} ]