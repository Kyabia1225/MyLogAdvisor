[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addUser",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addUser(String name)\n{\r\n    if (!usernames.contains(name)) {\r\n        addUser(name, id);\r\n        id++;\r\n        usernames.add(name);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addGroup",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addGroup(String name)\n{\r\n    if (!groupnames.contains(name)) {\r\n        addGroup(name, id);\r\n        id++;\r\n        groupnames.add(name);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getChildren",
  "errType" : [ "FileNotFoundException", "IOException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Iterable<TreePath> getChildren(TreePath path, long id, TreeIterator i)\n{\r\n    if (!path.getFileStatus().isDirectory()) {\r\n        return Collections.emptyList();\r\n    }\r\n    try {\r\n        ArrayList<TreePath> ret = new ArrayList<>();\r\n        for (FileStatus s : fs.listStatus(path.getFileStatus().getPath())) {\r\n            AclStatus aclStatus = getAclStatus(fs, s.getPath());\r\n            ret.add(new TreePath(s, id, i, fs, aclStatus));\r\n        }\r\n        return ret;\r\n    } catch (FileNotFoundException e) {\r\n        throw new ConcurrentModificationException(\"FS modified\");\r\n    } catch (IOException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getAclStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "AclStatus getAclStatus(FileSystem fileSystem, Path path) throws IOException\n{\r\n    return enableACLs ? fileSystem.getAclStatus(path) : null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "iterator",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TreeIterator iterator()\n{\r\n    try {\r\n        FileStatus s = fs.getFileStatus(root);\r\n        return new FSTreeIterator(s, -1L);\r\n    } catch (IOException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.conf = conf;\r\n    blocksize = conf.getLong(BLOCKSIZE, BLOCKSIZE_DEFAULT);\r\n    blockIds.set(conf.getLong(START_BLOCK, (1L << 30)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "blockLengths",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "List<Long> blockLengths(FileStatus s)\n{\r\n    ArrayList<Long> ret = new ArrayList<>();\r\n    if (!s.isFile()) {\r\n        return ret;\r\n    }\r\n    if (0 == s.getLen()) {\r\n        ret.add(0L);\r\n        return ret;\r\n    }\r\n    int nblocks = (int) ((s.getLen() - 1) / blocksize) + 1;\r\n    for (int i = 0; i < nblocks - 1; ++i) {\r\n        ret.add(blocksize);\r\n    }\r\n    long rem = s.getLen() % blocksize;\r\n    ret.add(0 == (rem % blocksize) ? blocksize : rem);\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "nextId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long nextId()\n{\r\n    return blockIds.incrementAndGet();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "lastId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long lastId()\n{\r\n    return blockIds.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "preferredBlockSize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long preferredBlockSize(FileStatus s)\n{\r\n    return blocksize;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getReplication",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getReplication(FileStatus s)\n{\r\n    return 1;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.conf = conf;\r\n    FileSystem.setDefaultUri(conf, new File(\".\").toURI().toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void printUsage()\n{\r\n    HelpFormatter formatter = new HelpFormatter();\r\n    formatter.printHelp(\"fs2img [OPTIONS] URI\", new Options());\r\n    formatter.setSyntaxPrefix(\"\");\r\n    formatter.printHelp(\"Options\", options());\r\n    ToolRunner.printGenericCommandUsage(System.out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "options",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "Options options()\n{\r\n    Options options = new Options();\r\n    options.addOption(\"o\", \"outdir\", true, \"Output directory\");\r\n    options.addOption(\"u\", \"ugiclass\", true, \"UGI resolver class\");\r\n    options.addOption(\"b\", \"blockclass\", true, \"Block output class\");\r\n    options.addOption(\"i\", \"blockidclass\", true, \"Block resolver class\");\r\n    options.addOption(\"c\", \"cachedirs\", true, \"Max active dirents\");\r\n    options.addOption(\"cid\", \"clusterID\", true, \"Cluster ID\");\r\n    options.addOption(\"bpid\", \"blockPoolID\", true, \"Block Pool ID\");\r\n    options.addOption(\"h\", \"help\", false, \"Print usage\");\r\n    return options;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "run",
  "errType" : [ "ParseException" ],
  "containingMethodsNum" : 21,
  "sourceCodeText" : "int run(String[] argv) throws Exception\n{\r\n    Options options = options();\r\n    CommandLineParser parser = new PosixParser();\r\n    CommandLine cmd;\r\n    try {\r\n        cmd = parser.parse(options, argv);\r\n    } catch (ParseException e) {\r\n        System.out.println(\"Error parsing command-line options: \" + e.getMessage());\r\n        printUsage();\r\n        return -1;\r\n    }\r\n    if (cmd.hasOption(\"h\")) {\r\n        printUsage();\r\n        return -1;\r\n    }\r\n    ImageWriter.Options opts = ReflectionUtils.newInstance(ImageWriter.Options.class, getConf());\r\n    for (Option o : cmd.getOptions()) {\r\n        switch(o.getOpt()) {\r\n            case \"o\":\r\n                opts.output(o.getValue());\r\n                break;\r\n            case \"u\":\r\n                opts.ugi(Class.forName(o.getValue()).asSubclass(UGIResolver.class));\r\n                break;\r\n            case \"b\":\r\n                opts.blocks(Class.forName(o.getValue()).asSubclass(BlockAliasMap.class));\r\n                break;\r\n            case \"i\":\r\n                opts.blockIds(Class.forName(o.getValue()).asSubclass(BlockResolver.class));\r\n                break;\r\n            case \"c\":\r\n                opts.cache(Integer.parseInt(o.getValue()));\r\n                break;\r\n            case \"cid\":\r\n                opts.clusterID(o.getValue());\r\n                break;\r\n            case \"bpid\":\r\n                opts.blockPoolID(o.getValue());\r\n                break;\r\n            default:\r\n                throw new UnsupportedOperationException(\"Unknown option: \" + o.getOpt());\r\n        }\r\n    }\r\n    String[] rem = cmd.getArgs();\r\n    if (rem.length != 1) {\r\n        printUsage();\r\n        return -1;\r\n    }\r\n    try (ImageWriter w = new ImageWriter(opts)) {\r\n        for (TreePath e : new FSTreeWalk(new Path(rem[0]), getConf())) {\r\n            w.accept(e);\r\n        }\r\n    }\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void main(String[] argv) throws Exception\n{\r\n    int ret = ToolRunner.run(new FileSystemImage(), argv);\r\n    System.exit(ret);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "buildPermissionStatus",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "long buildPermissionStatus(String owner, String group, short permission)\n{\r\n    long userId = users.get(owner);\r\n    if (0L != ((~USER_GROUP_STRID_MASK) & userId)) {\r\n        throw new IllegalArgumentException(\"UID must fit in 24 bits\");\r\n    }\r\n    long groupId = groups.get(group);\r\n    if (0L != ((~USER_GROUP_STRID_MASK) & groupId)) {\r\n        throw new IllegalArgumentException(\"GID must fit in 24 bits\");\r\n    }\r\n    return ((userId & USER_GROUP_STRID_MASK) << USER_STRID_OFFSET) | ((groupId & USER_GROUP_STRID_MASK) << GROUP_STRID_OFFSET) | permission;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "ugiMap",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Map<Integer, String> ugiMap()\n{\r\n    Map<Integer, String> ret = new HashMap<>();\r\n    for (Map<String, Integer> m : Arrays.asList(users, groups)) {\r\n        for (Map.Entry<String, Integer> e : m.entrySet()) {\r\n            String s = ret.put(e.getValue(), e.getKey());\r\n            if (s != null) {\r\n                throw new IllegalStateException(\"Duplicate mapping: \" + e.getValue() + \" \" + s + \" \" + e.getKey());\r\n            }\r\n        }\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addUser",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void addUser(String name)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addUser",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void addUser(String name, int id)\n{\r\n    Integer uid = users.put(name, id);\r\n    if (uid != null) {\r\n        throw new IllegalArgumentException(\"Duplicate mapping: \" + name + \" \" + uid + \" \" + id);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addGroup",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void addGroup(String name)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addGroup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void addGroup(String name, int id)\n{\r\n    Integer gid = groups.put(name, id);\r\n    if (gid != null) {\r\n        throw new IllegalArgumentException(\"Duplicate mapping: \" + name + \" \" + gid + \" \" + id);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "resetUGInfo",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void resetUGInfo()\n{\r\n    users.clear();\r\n    groups.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "resolve",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "long resolve(FileStatus s)\n{\r\n    String resolvedGroup = group(s.getGroup());\r\n    String resolvedOwner = user(s.getOwner());\r\n    FsPermission resolvedPermission = permission(s.getPermission());\r\n    return buildPermissionStatus(resolvedOwner, resolvedGroup, resolvedPermission.toShort());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "resolve",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "long resolve(AclStatus aclStatus)\n{\r\n    String resolvedOwner = user(aclStatus.getOwner());\r\n    String resolvedGroup = group(aclStatus.getGroup());\r\n    FsPermission resolvedPermision = permission(aclStatus.getPermission());\r\n    return buildPermissionStatus(resolvedOwner, resolvedGroup, resolvedPermision.toShort());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "user",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String user(String s)\n{\r\n    return s;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "group",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String group(String s)\n{\r\n    return s;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "permission",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FsPermission permission(FsPermission s)\n{\r\n    return s;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getPermissionsProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long getPermissionsProto(FileStatus remoteStatus, AclStatus remoteAcl)\n{\r\n    addUGI(remoteStatus, remoteAcl);\r\n    if (remoteAcl == null) {\r\n        return resolve(remoteStatus);\r\n    } else {\r\n        return resolve(remoteAcl);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addUGI",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void addUGI(FileStatus remoteStatus, AclStatus remoteAcl)\n{\r\n    if (remoteAcl != null) {\r\n        addUser(remoteAcl.getOwner());\r\n        addGroup(remoteAcl.getGroup());\r\n        for (AclEntry entry : remoteAcl.getEntries()) {\r\n            String name = entry.getName();\r\n            if (name != null) {\r\n                if (entry.getType() == AclEntryType.USER) {\r\n                    addUser(name);\r\n                } else if (entry.getType() == AclEntryType.GROUP) {\r\n                    addGroup(name);\r\n                }\r\n            }\r\n        }\r\n    } else {\r\n        addUser(remoteStatus.getOwner());\r\n        addGroup(remoteStatus.getGroup());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getFileStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FileStatus getFileStatus()\n{\r\n    return stat;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getAclStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AclStatus getAclStatus()\n{\r\n    return acls;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getParentId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getParentId()\n{\r\n    return parentId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getIterator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TreeWalk.TreeIterator getIterator()\n{\r\n    return i;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getId()\n{\r\n    if (id < 0) {\r\n        throw new IllegalStateException();\r\n    }\r\n    return id;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "accept",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void accept(long pathId)\n{\r\n    this.id = pathId;\r\n    i.onAccept(this, id);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "toINode",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "INode toINode(UGIResolver ugi, BlockResolver blk, BlockAliasMap.Writer<FileRegion> out) throws IOException\n{\r\n    if (stat.isFile()) {\r\n        return toFile(ugi, blk, out);\r\n    } else if (stat.isDirectory()) {\r\n        return toDirectory(ugi);\r\n    } else if (stat.isSymlink()) {\r\n        throw new UnsupportedOperationException(\"symlinks not supported\");\r\n    } else {\r\n        throw new UnsupportedOperationException(\"Unknown type: \" + stat);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean equals(Object other)\n{\r\n    if (!(other instanceof TreePath)) {\r\n        return false;\r\n    }\r\n    TreePath o = (TreePath) other;\r\n    return getParentId() == o.getParentId() && getFileStatus().equals(o.getFileStatus());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int hashCode()\n{\r\n    long pId = getParentId() * getFileStatus().hashCode();\r\n    return (int) (pId ^ (pId >>> 32));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeBlock",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeBlock(long blockId, long offset, long length, long genStamp, PathHandle pathHandle, BlockAliasMap.Writer<FileRegion> out) throws IOException\n{\r\n    FileStatus s = getFileStatus();\r\n    out.store(new FileRegion(blockId, s.getPath(), offset, length, genStamp, (pathHandle != null ? pathHandle.toByteArray() : new byte[0])));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "toFile",
  "errType" : [ "UnsupportedOperationException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "INode toFile(UGIResolver ugi, BlockResolver blk, BlockAliasMap.Writer<FileRegion> out) throws IOException\n{\r\n    final FileStatus s = getFileStatus();\r\n    final AclStatus aclStatus = getAclStatus();\r\n    long permissions = ugi.getPermissionsProto(s, aclStatus);\r\n    INodeFile.Builder b = INodeFile.newBuilder().setReplication(blk.getReplication(s)).setModificationTime(s.getModificationTime()).setAccessTime(s.getAccessTime()).setPreferredBlockSize(blk.preferredBlockSize(s)).setPermission(permissions).setStoragePolicyID(HdfsConstants.PROVIDED_STORAGE_POLICY_ID);\r\n    PathHandle pathHandle = null;\r\n    if (fs != null) {\r\n        try {\r\n            pathHandle = fs.getPathHandle(s, Options.HandleOpt.exact());\r\n        } catch (UnsupportedOperationException e) {\r\n            LOG.warn(\"Exact path handle not supported by filesystem \" + fs.toString());\r\n        }\r\n    }\r\n    if (aclStatus != null) {\r\n        throw new UnsupportedOperationException(\"ACLs not supported by ImageWriter\");\r\n    }\r\n    long off = 0L;\r\n    for (BlockProto block : blk.resolve(s)) {\r\n        b.addBlocks(block);\r\n        writeBlock(block.getBlockId(), off, block.getNumBytes(), block.getGenStamp(), pathHandle, out);\r\n        off += block.getNumBytes();\r\n    }\r\n    INode.Builder ib = INode.newBuilder().setType(INode.Type.FILE).setId(id).setName(ByteString.copyFrom(string2Bytes(s.getPath().getName()))).setFile(b);\r\n    return ib.build();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "toDirectory",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "INode toDirectory(UGIResolver ugi)\n{\r\n    final FileStatus s = getFileStatus();\r\n    final AclStatus aclStatus = getAclStatus();\r\n    long permissions = ugi.getPermissionsProto(s, aclStatus);\r\n    INodeDirectory.Builder b = INodeDirectory.newBuilder().setModificationTime(s.getModificationTime()).setNsQuota(DEFAULT_NAMESPACE_QUOTA).setDsQuota(DEFAULT_STORAGE_SPACE_QUOTA).setPermission(permissions);\r\n    if (aclStatus != null) {\r\n        throw new UnsupportedOperationException(\"ACLs not supported by ImageWriter\");\r\n    }\r\n    INode.Builder ib = INode.newBuilder().setType(INode.Type.DIRECTORY).setId(id).setName(ByteString.copyFrom(string2Bytes(s.getPath().getName()))).setDirectory(b);\r\n    return ib.build();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder sb = new StringBuilder();\r\n    sb.append(\"{ stat=\\\"\").append(getFileStatus()).append(\"\\\"\");\r\n    sb.append(\", id=\").append(getId());\r\n    sb.append(\", parentId=\").append(getParentId());\r\n    sb.append(\", iterObjId=\").append(System.identityHashCode(i));\r\n    sb.append(\" }\");\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getReader",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Reader<FileRegion> getReader(Reader.Options opts, String blockPoolID) throws IOException\n{\r\n    return new Reader<FileRegion>() {\r\n\r\n        @Override\r\n        public Iterator<FileRegion> iterator() {\r\n            return new Iterator<FileRegion>() {\r\n\r\n                @Override\r\n                public boolean hasNext() {\r\n                    return false;\r\n                }\r\n\r\n                @Override\r\n                public FileRegion next() {\r\n                    throw new NoSuchElementException();\r\n                }\r\n\r\n                @Override\r\n                public void remove() {\r\n                    throw new UnsupportedOperationException();\r\n                }\r\n            };\r\n        }\r\n\r\n        @Override\r\n        public void close() throws IOException {\r\n        }\r\n\r\n        @Override\r\n        public Optional<FileRegion> resolve(Block ident) throws IOException {\r\n            throw new UnsupportedOperationException();\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getWriter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Writer getWriter(Writer.Options opts, String blockPoolID) throws IOException\n{\r\n    return new Writer<FileRegion>() {\r\n\r\n        @Override\r\n        public void store(FileRegion token) throws IOException {\r\n        }\r\n\r\n        @Override\r\n        public void close() throws IOException {\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "refresh",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void refresh() throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void close() throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "setConf",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.conf = conf;\r\n    uid = conf.getInt(UID, 0);\r\n    user = conf.get(USER);\r\n    if (null == user) {\r\n        try {\r\n            user = UserGroupInformation.getCurrentUser().getShortUserName();\r\n        } catch (IOException e) {\r\n            user = \"hadoop\";\r\n        }\r\n    }\r\n    gid = conf.getInt(GID, 1);\r\n    group = conf.get(GROUP);\r\n    if (null == group) {\r\n        group = user;\r\n    }\r\n    resetUGInfo();\r\n    addUser(user, uid);\r\n    addGroup(group, gid);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "user",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String user(String s)\n{\r\n    return user;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "group",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String group(String s)\n{\r\n    return group;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addUser",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void addUser(String name)\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "addGroup",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void addGroup(String name)\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getChildren",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Iterable<TreePath> getChildren(TreePath path, long id, TreeWalk.TreeIterator iterator)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "iterator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TreeIterator iterator()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    super.setConf(conf);\r\n    replication = conf.getInt(REPLICATION, 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getReplication",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getReplication(FileStatus s)\n{\r\n    return replication;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "defaults",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Options defaults()\n{\r\n    return new Options();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "accept",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void accept(TreePath e) throws IOException\n{\r\n    assert e.getParentId() < curInode.get();\r\n    long id = curInode.getAndIncrement();\r\n    e.accept(id);\r\n    assert e.getId() < curInode.get();\r\n    INode n = e.toINode(ugis, blockIds, blocks);\r\n    writeInode(n);\r\n    if (e.getParentId() > 0) {\r\n        DirEntry.Builder de = DirEntry.newBuilder().setParent(e.getParentId()).addChildren(e.getId());\r\n        dircache.put(e.getParentId(), de);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeInode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeInode(INode n) throws IOException\n{\r\n    n.writeDelimitedTo(inodes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeDirEntry",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeDirEntry(DirEntry e) throws IOException\n{\r\n    e.writeDelimitedTo(dirs);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getOndiskSize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getOndiskSize(GeneratedMessageV3 s)\n{\r\n    return CodedOutputStream.computeUInt32SizeNoTag(s.getSerializedSize()) + s.getSerializedSize();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (closed) {\r\n        return;\r\n    }\r\n    for (DirEntry.Builder b : dircache.values()) {\r\n        DirEntry e = b.build();\r\n        writeDirEntry(e);\r\n    }\r\n    dircache.clear();\r\n    IOUtils.cleanupWithLogger(null, dirs, inodes, blocks);\r\n    if (null == dirs || null == inodes) {\r\n        if (raw != null) {\r\n            raw.close();\r\n        }\r\n        return;\r\n    }\r\n    try {\r\n        writeNameSystemSection();\r\n        writeINodeSection();\r\n        writeDirSection();\r\n        writeStringTableSection();\r\n        FileSummary s = summary.build();\r\n        s.writeDelimitedTo(raw);\r\n        int length = getOndiskSize(s);\r\n        byte[] lengthBytes = new byte[4];\r\n        ByteBuffer.wrap(lengthBytes).asIntBuffer().put(length);\r\n        raw.write(lengthBytes);\r\n    } finally {\r\n        raw.close();\r\n    }\r\n    writeMD5(\"fsimage_0000000000000000000\");\r\n    closed = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeMD5",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void writeMD5(String imagename) throws IOException\n{\r\n    if (null == outdir) {\r\n        return;\r\n    }\r\n    MD5Hash md5 = new MD5Hash(digest.digest());\r\n    String digestString = StringUtils.byteToHexString(md5.getDigest());\r\n    Path chk = new Path(outdir, imagename + \".md5\");\r\n    try (OutputStream out = outfs.create(chk)) {\r\n        String md5Line = digestString + \" *\" + imagename + \"\\n\";\r\n        out.write(md5Line.getBytes(Charsets.UTF_8));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "beginSection",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "OutputStream beginSection(OutputStream out) throws IOException\n{\r\n    CompressionCodec codec = compress.getImageCodec();\r\n    if (null == codec) {\r\n        return out;\r\n    }\r\n    return codec.createOutputStream(out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "endSection",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void endSection(OutputStream out, SectionName name) throws IOException\n{\r\n    CompressionCodec codec = compress.getImageCodec();\r\n    if (codec != null) {\r\n        ((CompressorStream) out).finish();\r\n    }\r\n    out.flush();\r\n    long length = raw.pos - curSec;\r\n    summary.addSections(FileSummary.Section.newBuilder().setName(name.toString()).setOffset(curSec).setLength(length));\r\n    curSec += length;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeNameSystemSection",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeNameSystemSection() throws IOException\n{\r\n    NameSystemSection.Builder b = NameSystemSection.newBuilder().setGenstampV1(1000).setGenstampV1Limit(0).setGenstampV2(1001).setLastAllocatedBlockId(blockIds.lastId()).setTransactionId(0);\r\n    NameSystemSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    endSection(sec, SectionName.NS_INFO);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeINodeSection",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void writeINodeSection() throws IOException\n{\r\n    INodeSection.Builder b = INodeSection.newBuilder().setNumInodes(curInode.get() - startInode).setLastInodeId(curInode.get());\r\n    INodeSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    try (FileInputStream in = new FileInputStream(inodesTmp)) {\r\n        IOUtils.copyBytes(in, sec, 4096, false);\r\n    }\r\n    endSection(sec, SectionName.INODE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeDirSection",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeDirSection() throws IOException\n{\r\n    OutputStream sec = raw;\r\n    try (FileInputStream in = new FileInputStream(dirsTmp)) {\r\n        IOUtils.copyBytes(in, sec, 4096, false);\r\n    }\r\n    endSection(sec, SectionName.INODE_DIR);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeFilesUCSection",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeFilesUCSection() throws IOException\n{\r\n    FilesUnderConstructionSection.Builder b = FilesUnderConstructionSection.newBuilder();\r\n    FilesUnderConstructionSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    endSection(sec, SectionName.FILES_UNDERCONSTRUCTION);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeSnapshotDiffSection",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeSnapshotDiffSection() throws IOException\n{\r\n    SnapshotDiffSection.Builder b = SnapshotDiffSection.newBuilder();\r\n    SnapshotDiffSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    endSection(sec, SectionName.SNAPSHOT_DIFF);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeSecretManagerSection",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeSecretManagerSection() throws IOException\n{\r\n    SecretManagerSection.Builder b = SecretManagerSection.newBuilder().setCurrentId(0).setTokenSequenceNumber(0);\r\n    SecretManagerSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    endSection(sec, SectionName.SECRET_MANAGER);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeCacheManagerSection",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeCacheManagerSection() throws IOException\n{\r\n    CacheManagerSection.Builder b = CacheManagerSection.newBuilder().setNumPools(0).setNumDirectives(0).setNextDirectiveId(1);\r\n    CacheManagerSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    endSection(sec, SectionName.CACHE_MANAGER);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "writeStringTableSection",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void writeStringTableSection() throws IOException\n{\r\n    StringTableSection.Builder b = StringTableSection.newBuilder();\r\n    Map<Integer, String> u = ugis.ugiMap();\r\n    b.setNumEntry(u.size());\r\n    StringTableSection s = b.build();\r\n    OutputStream sec = beginSection(raw);\r\n    s.writeDelimitedTo(sec);\r\n    for (Map.Entry<Integer, String> e : u.entrySet()) {\r\n        StringTableSection.Entry.Builder x = StringTableSection.Entry.newBuilder().setId(e.getKey()).setStr(e.getValue());\r\n        x.build().writeDelimitedTo(sec);\r\n    }\r\n    endSection(sec, SectionName.STRING_TABLE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder sb = new StringBuilder();\r\n    sb.append(\"{ codec=\\\"\").append(compress.getImageCodec());\r\n    sb.append(\"\\\", startBlock=\").append(startBlock);\r\n    sb.append(\", curBlock=\").append(curBlock);\r\n    sb.append(\", startInode=\").append(startInode);\r\n    sb.append(\", curInode=\").append(curInode);\r\n    sb.append(\", ugi=\").append(ugis);\r\n    sb.append(\", blockIds=\").append(blockIds);\r\n    sb.append(\", offset=\").append(raw.pos);\r\n    sb.append(\" }\");\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "buildBlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "BlockProto buildBlock(long blockId, long bytes)\n{\r\n    return buildBlock(blockId, bytes, 1001);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "buildBlock",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "BlockProto buildBlock(long blockId, long bytes, long genstamp)\n{\r\n    BlockProto.Builder b = BlockProto.newBuilder().setBlockId(blockId).setNumBytes(bytes).setGenStamp(genstamp);\r\n    return b.build();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "resolve",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Iterable<BlockProto> resolve(FileStatus s)\n{\r\n    List<Long> lengths = blockLengths(s);\r\n    ArrayList<BlockProto> ret = new ArrayList<>(lengths.size());\r\n    long tot = 0;\r\n    for (long l : lengths) {\r\n        tot += l;\r\n        ret.add(buildBlock(nextId(), l));\r\n    }\r\n    if (tot != s.getLen()) {\r\n        throw new IllegalStateException(\"Expected \" + s.getLen() + \" found \" + tot);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "nextId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long nextId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "lastId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long lastId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "blockLengths",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "List<Long> blockLengths(FileStatus status)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "preferredBlockSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long preferredBlockSize(FileStatus status)\n{\r\n    return status.getBlockSize();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-fs2img\\src\\main\\java\\org\\apache\\hadoop\\hdfs\\server\\namenode",
  "methodName" : "getReplication",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getReplication(FileStatus status)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]