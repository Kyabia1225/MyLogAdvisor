[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "publishDataStatistics",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "DataStatistics publishDataStatistics(Path inputDir, long genBytes, Configuration conf) throws IOException\n{\r\n    if (CompressionEmulationUtil.isCompressionEmulationEnabled(conf)) {\r\n        return CompressionEmulationUtil.publishCompressedDataStatistics(inputDir, conf, genBytes);\r\n    } else {\r\n        return publishPlainDataStatistics(conf, inputDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "publishPlainDataStatistics",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "DataStatistics publishPlainDataStatistics(Configuration conf, Path inputDir) throws IOException\n{\r\n    FileSystem fs = inputDir.getFileSystem(conf);\r\n    long dataSize = 0;\r\n    long fileCount = 0;\r\n    RemoteIterator<LocatedFileStatus> iter = fs.listFiles(inputDir, true);\r\n    PathFilter filter = new Utils.OutputFileUtils.OutputFilesFilter();\r\n    while (iter.hasNext()) {\r\n        LocatedFileStatus lStatus = iter.next();\r\n        if (filter.accept(lStatus.getPath())) {\r\n            dataSize += lStatus.getLen();\r\n            ++fileCount;\r\n        }\r\n    }\r\n    LOG.info(\"Total size of input data : \" + StringUtils.humanReadableInt(dataSize));\r\n    LOG.info(\"Total number of input data files : \" + fileCount);\r\n    return new DataStatistics(dataSize, fileCount, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "call",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Job call() throws IOException, InterruptedException, ClassNotFoundException\n{\r\n    UserGroupInformation ugi = UserGroupInformation.getLoginUser();\r\n    ugi.doAs(new PrivilegedExceptionAction<Job>() {\r\n\r\n        public Job run() throws IOException, ClassNotFoundException, InterruptedException {\r\n            if (CompressionEmulationUtil.isCompressionEmulationEnabled(job.getConfiguration())) {\r\n                CompressionEmulationUtil.configure(job);\r\n            } else {\r\n                configureRandomBytesDataGenerator();\r\n            }\r\n            job.submit();\r\n            return job;\r\n        }\r\n\r\n        private void configureRandomBytesDataGenerator() {\r\n            job.setMapperClass(GenDataMapper.class);\r\n            job.setNumReduceTasks(0);\r\n            job.setMapOutputKeyClass(NullWritable.class);\r\n            job.setMapOutputValueClass(BytesWritable.class);\r\n            job.setInputFormatClass(GenDataFormat.class);\r\n            job.setOutputFormatClass(RawBytesOutputFormat.class);\r\n            job.setJarByClass(GenerateData.class);\r\n            try {\r\n                FileInputFormat.addInputPath(job, new Path(\"ignored\"));\r\n            } catch (IOException e) {\r\n                LOG.error(\"Error while adding input path \", e);\r\n            }\r\n        }\r\n    });\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "canEmulateCompression",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean canEmulateCompression()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "call",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Job call() throws IOException, InterruptedException, ClassNotFoundException\n{\r\n    ugi.doAs(new PrivilegedExceptionAction<Job>() {\r\n\r\n        public Job run() throws IOException, ClassNotFoundException, InterruptedException {\r\n            job.setMapperClass(LoadMapper.class);\r\n            job.setReducerClass(LoadReducer.class);\r\n            job.setNumReduceTasks(jobdesc.getNumberReduces());\r\n            job.setMapOutputKeyClass(GridmixKey.class);\r\n            job.setMapOutputValueClass(GridmixRecord.class);\r\n            job.setSortComparatorClass(LoadSortComparator.class);\r\n            job.setGroupingComparatorClass(SpecGroupingComparator.class);\r\n            job.setInputFormatClass(LoadInputFormat.class);\r\n            job.setOutputFormatClass(RawBytesOutputFormat.class);\r\n            job.setPartitionerClass(DraftPartitioner.class);\r\n            job.setJarByClass(LoadJob.class);\r\n            job.getConfiguration().setBoolean(Job.USED_GENERIC_PARSER, true);\r\n            FileOutputFormat.setOutputPath(job, outdir);\r\n            job.submit();\r\n            return job;\r\n        }\r\n    });\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "canEmulateCompression",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean canEmulateCompression()\n{\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "buildSplits",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void buildSplits(FilePool inputDir) throws IOException\n{\r\n    long mapInputBytesTotal = 0L;\r\n    long mapOutputBytesTotal = 0L;\r\n    long mapOutputRecordsTotal = 0L;\r\n    final JobStory jobdesc = getJobDesc();\r\n    if (null == jobdesc) {\r\n        return;\r\n    }\r\n    final int maps = jobdesc.getNumberMaps();\r\n    final int reds = jobdesc.getNumberReduces();\r\n    for (int i = 0; i < maps; ++i) {\r\n        final TaskInfo info = jobdesc.getTaskInfo(TaskType.MAP, i);\r\n        mapInputBytesTotal += info.getInputBytes();\r\n        mapOutputBytesTotal += info.getOutputBytes();\r\n        mapOutputRecordsTotal += info.getOutputRecords();\r\n    }\r\n    final double[] reduceRecordRatio = new double[reds];\r\n    final double[] reduceByteRatio = new double[reds];\r\n    for (int i = 0; i < reds; ++i) {\r\n        final TaskInfo info = jobdesc.getTaskInfo(TaskType.REDUCE, i);\r\n        reduceByteRatio[i] = info.getInputBytes() / (1.0 * mapOutputBytesTotal);\r\n        reduceRecordRatio[i] = info.getInputRecords() / (1.0 * mapOutputRecordsTotal);\r\n    }\r\n    final InputStriper striper = new InputStriper(inputDir, mapInputBytesTotal);\r\n    final List<InputSplit> splits = new ArrayList<InputSplit>();\r\n    for (int i = 0; i < maps; ++i) {\r\n        final int nSpec = reds / maps + ((reds % maps) > i ? 1 : 0);\r\n        final long[] specBytes = new long[nSpec];\r\n        final long[] specRecords = new long[nSpec];\r\n        final ResourceUsageMetrics[] metrics = new ResourceUsageMetrics[nSpec];\r\n        for (int j = 0; j < nSpec; ++j) {\r\n            final TaskInfo info = jobdesc.getTaskInfo(TaskType.REDUCE, i + j * maps);\r\n            specBytes[j] = info.getOutputBytes();\r\n            specRecords[j] = info.getOutputRecords();\r\n            metrics[j] = info.getResourceUsageMetrics();\r\n            if (LOG.isDebugEnabled()) {\r\n                LOG.debug(String.format(\"SPEC(%d) %d -> %d %d %d %d %d %d %d\", id(), i, i + j * maps, info.getOutputRecords(), info.getOutputBytes(), info.getResourceUsageMetrics().getCumulativeCpuUsage(), info.getResourceUsageMetrics().getPhysicalMemoryUsage(), info.getResourceUsageMetrics().getVirtualMemoryUsage(), info.getResourceUsageMetrics().getHeapUsage()));\r\n            }\r\n        }\r\n        final TaskInfo info = jobdesc.getTaskInfo(TaskType.MAP, i);\r\n        long possiblyCompressedInputBytes = info.getInputBytes();\r\n        Configuration conf = job.getConfiguration();\r\n        long uncompressedInputBytes = CompressionEmulationUtil.getUncompressedInputBytes(possiblyCompressedInputBytes, conf);\r\n        splits.add(new LoadSplit(striper.splitFor(inputDir, uncompressedInputBytes, 3), maps, i, uncompressedInputBytes, info.getInputRecords(), info.getOutputBytes(), info.getOutputRecords(), reduceByteRatio, reduceRecordRatio, specBytes, specRecords, info.getResourceUsageMetrics(), metrics));\r\n    }\r\n    pushDescription(id(), splits);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createReaderThread",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Thread createReaderThread()\n{\r\n    return new SerialReaderThread(\"SerialJobFactory\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "update",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void update(Statistics.JobStats item)\n{\r\n    lock.lock();\r\n    try {\r\n        jobCompleted.signalAll();\r\n    } finally {\r\n        lock.unlock();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void start()\n{\r\n    LOG.info(\" Starting Serial submission \");\r\n    this.rThread.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setDistCacheEmulator",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setDistCacheEmulator(DistributedCacheEmulator e)\n{\r\n    jobCreator.setDistCacheEmulator(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "nextSource",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void nextSource() throws IOException\n{\r\n    if (0 == paths.length) {\r\n        return;\r\n    }\r\n    if (input != null) {\r\n        input.close();\r\n    }\r\n    idx = (idx + 1) % paths.length;\r\n    curlen = lengths[idx];\r\n    final Path file = paths[idx];\r\n    input = CompressionEmulationUtil.getPossiblyDecompressedInputStream(file, conf, startoffset[idx]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int read() throws IOException\n{\r\n    final int tmp = read(z);\r\n    return tmp == -1 ? -1 : (0xFF & z[0]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int read(byte[] b) throws IOException\n{\r\n    return read(b, 0, b.length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int read(byte[] b, int off, int len) throws IOException\n{\r\n    int kvread = 0;\r\n    while (kvread < len) {\r\n        if (curlen <= 0) {\r\n            nextSource();\r\n            continue;\r\n        }\r\n        final int srcRead = (int) Math.min(len - kvread, curlen);\r\n        IOUtils.readFully(input, b, kvread, srcRead);\r\n        curlen -= srcRead;\r\n        kvread += srcRead;\r\n    }\r\n    return kvread;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    input.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "boolean next(GridmixKey key, GridmixRecord val) throws IOException\n{\r\n    assert key != null;\r\n    final boolean rslt = factory.next(key, val);\r\n    ++accRecords;\r\n    if (rslt) {\r\n        if (accRecords < targetRecords) {\r\n            key.setType(GridmixKey.DATA);\r\n        } else {\r\n            final int orig = key.getSize();\r\n            key.setType(GridmixKey.REDUCE_SPEC);\r\n            spec.rec_in = accRecords;\r\n            key.setSpec(spec);\r\n            val.setSize(val.getSize() - (key.getSize() - orig));\r\n            accRecords = 0L;\r\n            spec.bytes_out = 0L;\r\n            spec.rec_out = 0L;\r\n            done = true;\r\n        }\r\n    } else if (!done) {\r\n        key.setType(GridmixKey.REDUCE_SPEC);\r\n        key.setPartition(partition);\r\n        key.setSize(0);\r\n        val.setSize(0);\r\n        spec.rec_in = 0L;\r\n        key.setSpec(spec);\r\n        done = true;\r\n        return true;\r\n    }\r\n    key.setPartition(partition);\r\n    return rslt;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress() throws IOException\n{\r\n    return factory.getProgress();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    factory.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "select",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int[] select(int m, int n, Random rand)\n{\r\n    if (m >= n) {\r\n        int[] ret = new int[n];\r\n        for (int i = 0; i < n; ++i) {\r\n            ret[i] = i;\r\n        }\r\n        return ret;\r\n    }\r\n    Selector selector = new Selector(n, (float) m / n, rand);\r\n    int[] selected = new int[m];\r\n    for (int i = 0; i < m; ++i) {\r\n        selected[i] = selector.next();\r\n    }\r\n    return selected;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createReaderThread",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Thread createReaderThread()\n{\r\n    return new ReplayReaderThread(\"ReplayJobFactory\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "update",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void update(Statistics.ClusterStats item)\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void start()\n{\r\n    this.rThread.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "canEmulateCompression",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean canEmulateCompression()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "call",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Job call() throws IOException, InterruptedException, ClassNotFoundException\n{\r\n    ugi.doAs(new PrivilegedExceptionAction<Job>() {\r\n\r\n        public Job run() throws IOException, ClassNotFoundException, InterruptedException {\r\n            job.setMapperClass(SleepMapper.class);\r\n            job.setReducerClass(SleepReducer.class);\r\n            job.setNumReduceTasks((mapTasksOnly) ? 0 : jobdesc.getNumberReduces());\r\n            job.setMapOutputKeyClass(GridmixKey.class);\r\n            job.setMapOutputValueClass(NullWritable.class);\r\n            job.setSortComparatorClass(GridmixKey.Comparator.class);\r\n            job.setGroupingComparatorClass(SpecGroupingComparator.class);\r\n            job.setInputFormatClass(SleepInputFormat.class);\r\n            job.setOutputFormatClass(NullOutputFormat.class);\r\n            job.setPartitionerClass(DraftPartitioner.class);\r\n            job.setJarByClass(SleepJob.class);\r\n            job.getConfiguration().setBoolean(Job.USED_GENERIC_PARSER, true);\r\n            job.submit();\r\n            return job;\r\n        }\r\n    });\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSuccessfulAttemptInfo",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TaskAttemptInfo getSuccessfulAttemptInfo(TaskType type, int task)\n{\r\n    TaskAttemptInfo ret;\r\n    for (int i = 0; true; ++i) {\r\n        ret = jobdesc.getTaskAttemptInfo(type, task, i);\r\n        if (ret.getRunState() == TaskStatus.State.SUCCEEDED) {\r\n            break;\r\n        }\r\n    }\r\n    if (ret.getRunState() != TaskStatus.State.SUCCEEDED) {\r\n        LOG.warn(\"No sucessful attempts tasktype \" + type + \" task \" + task);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "buildSplits",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void buildSplits(FilePool inputDir) throws IOException\n{\r\n    final List<InputSplit> splits = new ArrayList<InputSplit>();\r\n    final int reds = (mapTasksOnly) ? 0 : jobdesc.getNumberReduces();\r\n    final int maps = jobdesc.getNumberMaps();\r\n    for (int i = 0; i < maps; ++i) {\r\n        final int nSpec = reds / maps + ((reds % maps) > i ? 1 : 0);\r\n        final long[] redDurations = new long[nSpec];\r\n        for (int j = 0; j < nSpec; ++j) {\r\n            final ReduceTaskAttemptInfo info = (ReduceTaskAttemptInfo) getSuccessfulAttemptInfo(TaskType.REDUCE, i + j * maps);\r\n            redDurations[j] = Math.min(reduceMaxSleepTime, info.getMergeRuntime() + info.getReduceRuntime());\r\n            if (LOG.isDebugEnabled()) {\r\n                LOG.debug(String.format(\"SPEC(%d) %d -> %d %d/%d\", id(), i, i + j * maps, redDurations[j], info.getRuntime()));\r\n            }\r\n        }\r\n        final TaskAttemptInfo info = getSuccessfulAttemptInfo(TaskType.MAP, i);\r\n        ArrayList<String> locations = new ArrayList<String>(fakeLocations);\r\n        if (fakeLocations > 0) {\r\n            selector.reset();\r\n        }\r\n        for (int k = 0; k < fakeLocations; ++k) {\r\n            int index = selector.next();\r\n            if (index < 0)\r\n                break;\r\n            locations.add(hosts[index]);\r\n        }\r\n        splits.add(new SleepSplit(i, Math.min(info.getRuntime(), mapMaxSleepTime), redDurations, maps, locations.toArray(new String[locations.size()])));\r\n    }\r\n    pushDescription(id(), splits);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "call",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Job call() throws IOException, InterruptedException, ClassNotFoundException\n{\r\n    UserGroupInformation ugi = UserGroupInformation.getLoginUser();\r\n    ugi.doAs(new PrivilegedExceptionAction<Job>() {\r\n\r\n        public Job run() throws IOException, ClassNotFoundException, InterruptedException {\r\n            job.setMapperClass(GenDCDataMapper.class);\r\n            job.setNumReduceTasks(0);\r\n            job.setMapOutputKeyClass(NullWritable.class);\r\n            job.setMapOutputValueClass(BytesWritable.class);\r\n            job.setInputFormatClass(GenDCDataFormat.class);\r\n            job.setOutputFormatClass(NullOutputFormat.class);\r\n            job.setJarByClass(GenerateDistCacheData.class);\r\n            try {\r\n                FileInputFormat.addInputPath(job, new Path(\"ignored\"));\r\n            } catch (IOException e) {\r\n                LOG.error(\"Error while adding input path \", e);\r\n            }\r\n            job.submit();\r\n            return job;\r\n        }\r\n    });\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "canEmulateCompression",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean canEmulateCompression()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getId()\n{\r\n    return id;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMapCount",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getMapCount()\n{\r\n    return maps;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInputRecords",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getInputRecords()\n{\r\n    return inputRecords;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getOutputBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long[] getOutputBytes()\n{\r\n    if (0 == reduces) {\r\n        return new long[] { outputBytes };\r\n    }\r\n    final long[] ret = new long[reduces];\r\n    for (int i = 0; i < reduces; ++i) {\r\n        ret[i] = Math.round(outputBytes * reduceBytes[i]);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getOutputRecords",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long[] getOutputRecords()\n{\r\n    if (0 == reduces) {\r\n        return new long[] { outputRecords };\r\n    }\r\n    final long[] ret = new long[reduces];\r\n    for (int i = 0; i < reduces; ++i) {\r\n        ret[i] = Math.round(outputRecords * reduceRecords[i]);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceBytes",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getReduceBytes(int i)\n{\r\n    return reduceOutputBytes[i];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceRecords",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getReduceRecords(int i)\n{\r\n    return reduceOutputRecords[i];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n    super.write(out);\r\n    WritableUtils.writeVInt(out, id);\r\n    WritableUtils.writeVInt(out, maps);\r\n    WritableUtils.writeVLong(out, inputRecords);\r\n    WritableUtils.writeVLong(out, outputBytes);\r\n    WritableUtils.writeVLong(out, outputRecords);\r\n    WritableUtils.writeVLong(out, maxMemory);\r\n    WritableUtils.writeVInt(out, reduces);\r\n    for (int i = 0; i < reduces; ++i) {\r\n        out.writeDouble(reduceBytes[i]);\r\n        out.writeDouble(reduceRecords[i]);\r\n    }\r\n    WritableUtils.writeVInt(out, nSpec);\r\n    for (int i = 0; i < nSpec; ++i) {\r\n        WritableUtils.writeVLong(out, reduceOutputBytes[i]);\r\n        WritableUtils.writeVLong(out, reduceOutputRecords[i]);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n    super.readFields(in);\r\n    id = WritableUtils.readVInt(in);\r\n    maps = WritableUtils.readVInt(in);\r\n    inputRecords = WritableUtils.readVLong(in);\r\n    outputBytes = WritableUtils.readVLong(in);\r\n    outputRecords = WritableUtils.readVLong(in);\r\n    maxMemory = WritableUtils.readVLong(in);\r\n    reduces = WritableUtils.readVInt(in);\r\n    if (reduceBytes.length < reduces) {\r\n        reduceBytes = new double[reduces];\r\n        reduceRecords = new double[reduces];\r\n    }\r\n    for (int i = 0; i < reduces; ++i) {\r\n        reduceBytes[i] = in.readDouble();\r\n        reduceRecords[i] = in.readDouble();\r\n    }\r\n    nSpec = WritableUtils.readVInt(in);\r\n    if (reduceOutputBytes.length < nSpec) {\r\n        reduceOutputBytes = new long[nSpec];\r\n        reduceOutputRecords = new long[nSpec];\r\n    }\r\n    for (int i = 0; i < nSpec; ++i) {\r\n        reduceOutputBytes[i] = WritableUtils.readVLong(in);\r\n        reduceOutputRecords[i] = WritableUtils.readVLong(in);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void start(Configuration conf)\n{\r\n    simulationStartTime = System.currentTimeMillis();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "processJobState",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void processJobState(JobStats stats)\n{\r\n    Job job = stats.getJob();\r\n    try {\r\n        if (job.isSuccessful()) {\r\n            ++totalSuccessfulJobs;\r\n        } else {\r\n            ++totalFailedJobs;\r\n        }\r\n    } catch (Exception e) {\r\n        ++totalLostJobs;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "processJobTasks",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void processJobTasks(JobStats stats)\n{\r\n    totalMapTasksLaunched += stats.getNoOfMaps();\r\n    totalReduceTasksLaunched += stats.getNoOfReds();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "process",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void process(JobStats stats)\n{\r\n    processJobState(stats);\r\n    processJobTasks(stats);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "update",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void update(JobStats item)\n{\r\n    if (simulationStartTime > 0) {\r\n        process(item);\r\n        totalSimulationTime = System.currentTimeMillis() - getSimulationStartTime();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getTraceSignature",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "String getTraceSignature(String input) throws IOException\n{\r\n    Path inputPath = new Path(input);\r\n    FileSystem fs = inputPath.getFileSystem(new Configuration());\r\n    FileStatus status = fs.getFileStatus(inputPath);\r\n    Path qPath = fs.makeQualified(status.getPath());\r\n    String traceID = status.getModificationTime() + qPath.toString() + status.getOwner() + status.getLen();\r\n    return MD5Hash.digest(traceID).toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "finalize",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void finalize(JobFactory factory, String inputPath, long dataSize, UserResolver userResolver, DataStatistics stats, Configuration conf) throws IOException\n{\r\n    numJobsInInputTrace = factory.numJobsInTrace;\r\n    endTime = System.currentTimeMillis();\r\n    if (\"-\".equals(inputPath)) {\r\n        inputTraceLocation = Summarizer.NA;\r\n        inputTraceSignature = Summarizer.NA;\r\n    } else {\r\n        Path inputTracePath = new Path(inputPath);\r\n        FileSystem fs = inputTracePath.getFileSystem(conf);\r\n        inputTraceLocation = fs.makeQualified(inputTracePath).toString();\r\n        inputTraceSignature = getTraceSignature(inputPath);\r\n    }\r\n    jobSubmissionPolicy = Gridmix.getJobSubmissionPolicy(conf).name();\r\n    resolver = userResolver.getClass().getName();\r\n    if (dataSize > 0) {\r\n        expectedDataSize = StringUtils.humanReadableInt(dataSize);\r\n    } else {\r\n        expectedDataSize = Summarizer.NA;\r\n    }\r\n    dataStats = stats;\r\n    totalRuntime = System.currentTimeMillis() - getStartTime();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 23,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder builder = new StringBuilder();\r\n    builder.append(\"Execution Summary:-\");\r\n    builder.append(\"\\nInput trace: \").append(getInputTraceLocation());\r\n    builder.append(\"\\nInput trace signature: \").append(getInputTraceSignature());\r\n    builder.append(\"\\nTotal number of jobs in trace: \").append(getNumJobsInTrace());\r\n    builder.append(\"\\nExpected input data size: \").append(getExpectedDataSize());\r\n    builder.append(\"\\nInput data statistics: \").append(getInputDataStatistics());\r\n    builder.append(\"\\nTotal number of jobs processed: \").append(getNumSubmittedJobs());\r\n    builder.append(\"\\nTotal number of successful jobs: \").append(getNumSuccessfulJobs());\r\n    builder.append(\"\\nTotal number of failed jobs: \").append(getNumFailedJobs());\r\n    builder.append(\"\\nTotal number of lost jobs: \").append(getNumLostJobs());\r\n    builder.append(\"\\nTotal number of map tasks launched: \").append(getNumMapTasksLaunched());\r\n    builder.append(\"\\nTotal number of reduce task launched: \").append(getNumReduceTasksLaunched());\r\n    builder.append(\"\\nGridmix start time: \").append(UTIL.format(getStartTime()));\r\n    builder.append(\"\\nGridmix end time: \").append(UTIL.format(getEndTime()));\r\n    builder.append(\"\\nGridmix simulation start time: \").append(UTIL.format(getStartTime()));\r\n    builder.append(\"\\nGridmix runtime: \").append(StringUtils.formatTime(getRuntime()));\r\n    builder.append(\"\\nTime spent in initialization (data-gen etc): \").append(StringUtils.formatTime(getInitTime()));\r\n    builder.append(\"\\nTime spent in simulation: \").append(StringUtils.formatTime(getSimulationTime()));\r\n    builder.append(\"\\nGridmix configuration parameters: \").append(getCommandLineArgsString());\r\n    builder.append(\"\\nGridmix job submission policy: \").append(getJobSubmissionPolicy());\r\n    builder.append(\"\\nGridmix resolver: \").append(getUserResolver());\r\n    builder.append(\"\\n\\n\");\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "stringifyDataStatistics",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "String stringifyDataStatistics(DataStatistics stats)\n{\r\n    if (stats != null) {\r\n        StringBuffer buffer = new StringBuffer();\r\n        String compressionStatus = stats.isDataCompressed() ? \"Compressed\" : \"Uncompressed\";\r\n        buffer.append(compressionStatus).append(\" input data size: \");\r\n        buffer.append(StringUtils.humanReadableInt(stats.getDataSize()));\r\n        buffer.append(\", \");\r\n        buffer.append(\"Number of files: \").append(stats.getNumFiles());\r\n        return buffer.toString();\r\n    } else {\r\n        return Summarizer.NA;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getExpectedDataSize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getExpectedDataSize()\n{\r\n    return expectedDataSize;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getUserResolver",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getUserResolver()\n{\r\n    return resolver;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInputDataStatistics",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getInputDataStatistics()\n{\r\n    return stringifyDataStatistics(dataStats);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInputTraceSignature",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getInputTraceSignature()\n{\r\n    return inputTraceSignature;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInputTraceLocation",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getInputTraceLocation()\n{\r\n    return inputTraceLocation;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumJobsInTrace",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumJobsInTrace()\n{\r\n    return numJobsInInputTrace;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumSuccessfulJobs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumSuccessfulJobs()\n{\r\n    return totalSuccessfulJobs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumFailedJobs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumFailedJobs()\n{\r\n    return totalFailedJobs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumLostJobs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumLostJobs()\n{\r\n    return totalLostJobs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumSubmittedJobs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumSubmittedJobs()\n{\r\n    return totalSuccessfulJobs + totalFailedJobs + totalLostJobs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumMapTasksLaunched",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumMapTasksLaunched()\n{\r\n    return totalMapTasksLaunched;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumReduceTasksLaunched",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumReduceTasksLaunched()\n{\r\n    return totalReduceTasksLaunched;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getStartTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getStartTime()\n{\r\n    return startTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getEndTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getEndTime()\n{\r\n    return endTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInitTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getInitTime()\n{\r\n    return simulationStartTime - startTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSimulationStartTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getSimulationStartTime()\n{\r\n    return simulationStartTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSimulationTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getSimulationTime()\n{\r\n    return totalSimulationTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRuntime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getRuntime()\n{\r\n    return totalRuntime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getCommandLineArgsString",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getCommandLineArgsString()\n{\r\n    return commandLineArgs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobSubmissionPolicy",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getJobSubmissionPolicy()\n{\r\n    return jobSubmissionPolicy;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean next(GridmixKey key, GridmixRecord val) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "float getProgress() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "update",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void update(ClusterStats item)\n{\r\n    try {\r\n        numBlacklistedTrackers = item.getStatus().getBlacklistedTrackers();\r\n        numActiveTrackers = item.getStatus().getTaskTrackers();\r\n        maxMapTasks = item.getStatus().getMaxMapTasks();\r\n        maxReduceTasks = item.getStatus().getMaxReduceTasks();\r\n    } catch (Exception e) {\r\n        long time = System.currentTimeMillis();\r\n        LOG.info(\"Error in processing cluster status at \" + FastDateFormat.getInstance().format(time));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder builder = new StringBuilder();\r\n    builder.append(\"Cluster Summary:-\");\r\n    builder.append(\"\\nJobTracker: \").append(getJobTrackerInfo());\r\n    builder.append(\"\\nFileSystem: \").append(getNamenodeInfo());\r\n    builder.append(\"\\nNumber of blacklisted trackers: \").append(getNumBlacklistedTrackers());\r\n    builder.append(\"\\nNumber of active trackers: \").append(getNumActiveTrackers());\r\n    builder.append(\"\\nMax map task capacity: \").append(getMaxMapTasks());\r\n    builder.append(\"\\nMax reduce task capacity: \").append(getMaxReduceTasks());\r\n    builder.append(\"\\n\\n\");\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void start(Configuration conf)\n{\r\n    jobTrackerInfo = conf.get(JTConfig.JT_IPC_ADDRESS);\r\n    namenodeInfo = conf.getTrimmed(CommonConfigurationKeys.FS_DEFAULT_NAME_KEY);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumBlacklistedTrackers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumBlacklistedTrackers()\n{\r\n    return numBlacklistedTrackers;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNumActiveTrackers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumActiveTrackers()\n{\r\n    return numActiveTrackers;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMaxMapTasks",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getMaxMapTasks()\n{\r\n    return maxMapTasks;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMaxReduceTasks",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getMaxReduceTasks()\n{\r\n    return maxReduceTasks;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobTrackerInfo",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getJobTrackerInfo()\n{\r\n    return jobTrackerInfo;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNamenodeInfo",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getNamenodeInfo()\n{\r\n    return namenodeInfo;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getSize()\n{\r\n    return size;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setSize(int size)\n{\r\n    setSizeInternal(size);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setCompressibility",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setCompressibility(boolean compressible, float ratio)\n{\r\n    this.compressible = compressible;\r\n    this.compressionRatio = ratio;\r\n    if (compressible) {\r\n        rtg = CompressionEmulationUtil.getRandomTextDataGenerator(ratio, RandomTextDataGenerator.DEFAULT_SEED);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setSizeInternal",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setSizeInternal(int size)\n{\r\n    this.size = Math.max(1, size);\r\n    try {\r\n        seed = maskSeed(seed, this.size);\r\n        dob.reset();\r\n        dob.writeLong(seed);\r\n    } catch (IOException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setSeed",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setSeed(long seed)\n{\r\n    this.seed = seed;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "nextRand",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long nextRand(long x)\n{\r\n    x ^= (x << 13);\r\n    x ^= (x >>> 7);\r\n    return (x ^= (x << 17));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "writeRandomText",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void writeRandomText(DataOutput out, final int size) throws IOException\n{\r\n    long tmp = seed;\r\n    out.writeLong(tmp);\r\n    int i = size - (Long.SIZE / Byte.SIZE);\r\n    String randomWord = rtg.getRandomWord();\r\n    byte[] bytes = randomWord.getBytes(\"UTF-8\");\r\n    long randomWordSize = bytes.length;\r\n    while (i >= randomWordSize) {\r\n        out.write(bytes);\r\n        i -= randomWordSize;\r\n        randomWord = rtg.getRandomWord();\r\n        bytes = randomWord.getBytes(\"UTF-8\");\r\n        randomWordSize = bytes.length;\r\n    }\r\n    if (i > 0) {\r\n        out.write(bytes, 0, i);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "writeRandom",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeRandom(DataOutput out, final int size) throws IOException\n{\r\n    long tmp = seed;\r\n    out.writeLong(tmp);\r\n    int i = size - (Long.SIZE / Byte.SIZE);\r\n    while (i > Long.SIZE / Byte.SIZE - 1) {\r\n        tmp = nextRand(tmp);\r\n        out.writeLong(tmp);\r\n        i -= Long.SIZE / Byte.SIZE;\r\n    }\r\n    for (tmp = nextRand(tmp); i > 0; --i) {\r\n        out.writeByte((int) (tmp & 0xFF));\r\n        tmp >>>= Byte.SIZE;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n    size = WritableUtils.readVInt(in);\r\n    int payload = size - WritableUtils.getVIntSize(size);\r\n    if (payload > Long.SIZE / Byte.SIZE) {\r\n        seed = in.readLong();\r\n        payload -= Long.SIZE / Byte.SIZE;\r\n    } else {\r\n        Arrays.fill(literal, (byte) 0);\r\n        in.readFully(literal, 0, payload);\r\n        dib.reset(literal, 0, literal.length);\r\n        seed = dib.readLong();\r\n        payload = 0;\r\n    }\r\n    final int vBytes = in.skipBytes(payload);\r\n    if (vBytes != payload) {\r\n        throw new EOFException(\"Expected \" + payload + \", read \" + vBytes);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n    WritableUtils.writeVInt(out, size);\r\n    final int payload = size - WritableUtils.getVIntSize(size);\r\n    if (payload > Long.SIZE / Byte.SIZE) {\r\n        if (compressible) {\r\n            writeRandomText(out, payload);\r\n        } else {\r\n            writeRandom(out, payload);\r\n        }\r\n    } else if (payload > 0) {\r\n        out.write(literal, 0, payload);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int compareTo(GridmixRecord other)\n{\r\n    return compareSeed(other.seed, Math.max(0, other.getSize() - other.fixedBytes()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "fixedBytes",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int fixedBytes()\n{\r\n    return FIXED_BYTES;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "maskSeed",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long maskSeed(long sd, int sz)\n{\r\n    if (sz <= FIXED_BYTES) {\r\n        sd = 0L;\r\n    } else if (sz < Long.SIZE / Byte.SIZE + FIXED_BYTES) {\r\n        final int tmp = sz - FIXED_BYTES;\r\n        final long mask = (1L << (Byte.SIZE * tmp)) - 1;\r\n        sd &= mask << (Byte.SIZE * (Long.SIZE / Byte.SIZE - tmp));\r\n    }\r\n    return sd;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "compareSeed",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "int compareSeed(long jSeed, int jSize)\n{\r\n    final int iSize = Math.max(0, getSize() - fixedBytes());\r\n    final int seedLen = Math.min(iSize, jSize) + FIXED_BYTES;\r\n    jSeed = maskSeed(jSeed, seedLen);\r\n    long iSeed = maskSeed(seed, seedLen);\r\n    final int cmplen = Math.min(iSize, jSize);\r\n    for (int i = 0; i < cmplen; i += Byte.SIZE) {\r\n        final int k = cmplen - i;\r\n        for (long j = Long.SIZE - Byte.SIZE; j >= Math.max(0, Long.SIZE / Byte.SIZE - k) * Byte.SIZE; j -= Byte.SIZE) {\r\n            final int xi = (int) ((iSeed >>> j) & 0xFFL);\r\n            final int xj = (int) ((jSeed >>> j) & 0xFFL);\r\n            if (xi != xj) {\r\n                return xi - xj;\r\n            }\r\n        }\r\n        iSeed = nextRand(iSeed);\r\n        jSeed = nextRand(jSeed);\r\n    }\r\n    return iSize - jSize;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean equals(Object other)\n{\r\n    if (this == other) {\r\n        return true;\r\n    }\r\n    if (other != null && other.getClass() == getClass()) {\r\n        final GridmixRecord o = ((GridmixRecord) other);\r\n        return getSize() == o.getSize() && seed == o.seed;\r\n    }\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    return (int) (seed * getSize());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setTargetUsers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean setTargetUsers(URI userdesc, Configuration conf) throws IOException\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getTargetUgi",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "UserGroupInformation getTargetUgi(UserGroupInformation ugi)\n{\r\n    return ugi;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "needsTargetUsersList",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean needsTargetUsersList()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInputFiles",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long getInputFiles(long minSize, Collection<FileStatus> files) throws IOException\n{\r\n    updateLock.readLock().lock();\r\n    try {\r\n        return root.selectFiles(minSize, files);\r\n    } finally {\r\n        updateLock.readLock().unlock();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "refresh",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void refresh() throws IOException\n{\r\n    updateLock.writeLock().lock();\r\n    try {\r\n        root = new InnerDesc(fs, fs.getFileStatus(path), new MinFileFilter(conf.getLong(GRIDMIX_MIN_FILE, 128 * 1024 * 1024), conf.getLong(GRIDMIX_MAX_TOTAL, 100L * (1L << 40))));\r\n        if (0 == root.getSize()) {\r\n            throw new IOException(\"Found no satisfactory file in \" + path);\r\n        }\r\n    } finally {\r\n        updateLock.writeLock().unlock();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "locationsFor",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "BlockLocation[] locationsFor(FileStatus stat, long start, long len) throws IOException\n{\r\n    return fs.getFileBlockLocations(stat, start, len);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getWeightForProgressInterval",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "float getWeightForProgressInterval(float progress)\n{\r\n    return progress * progress * progress * progress;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getCurrentCPUUsage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getCurrentCPUUsage()\n{\r\n    return monitor.getCumulativeCpuTime();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress()\n{\r\n    return enabled ? Math.min(1f, ((float) getCurrentCPUUsage()) / targetCpuUsage) : 1.0f;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "emulate",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void emulate() throws IOException, InterruptedException\n{\r\n    if (enabled) {\r\n        float currentProgress = progress.getProgress();\r\n        if (lastSeenProgress < currentProgress && ((currentProgress - lastSeenProgress) >= emulationInterval || currentProgress == 1)) {\r\n            long currentCpuUsage = getCurrentCPUUsage();\r\n            float rate = (currentCpuUsage - lastSeenCpuUsage) / (currentProgress - lastSeenProgress);\r\n            long projectedUsage = currentCpuUsage + (long) ((1 - currentProgress) * rate);\r\n            if (projectedUsage < targetCpuUsage) {\r\n                long currentWeighedTarget = (long) (targetCpuUsage * getWeightForProgressInterval(currentProgress));\r\n                while (getCurrentCPUUsage() < currentWeighedTarget) {\r\n                    emulatorCore.compute();\r\n                    try {\r\n                        Thread.sleep(100);\r\n                    } catch (InterruptedException ie) {\r\n                        String message = \"CumulativeCpuUsageEmulatorPlugin got interrupted. Exiting.\";\r\n                        throw new RuntimeException(message);\r\n                    }\r\n                }\r\n            }\r\n            lastSeenProgress = progress.getProgress();\r\n            lastSeenCpuUsage = getCurrentCPUUsage();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void initialize(Configuration conf, ResourceUsageMetrics metrics, ResourceCalculatorPlugin monitor, Progressive progress)\n{\r\n    this.monitor = monitor;\r\n    this.progress = progress;\r\n    targetCpuUsage = metrics.getCumulativeCpuUsage();\r\n    if (targetCpuUsage <= 0) {\r\n        enabled = false;\r\n        return;\r\n    } else {\r\n        enabled = true;\r\n    }\r\n    emulationInterval = conf.getFloat(CPU_EMULATION_PROGRESS_INTERVAL, DEFAULT_EMULATION_FREQUENCY);\r\n    emulatorCore.calibrate(monitor, targetCpuUsage);\r\n    lastSeenProgress = 0;\r\n    lastSeenCpuUsage = 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean next(GridmixKey key, GridmixRecord val) throws IOException\n{\r\n    if (!factory.next(key, val)) {\r\n        return false;\r\n    }\r\n    for (int len = (null == key ? 0 : key.getSize()) + val.getSize(); len > 0; len -= buf.length) {\r\n        IOUtils.readFully(src, buf, 0, Math.min(buf.length, len));\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress() throws IOException\n{\r\n    return factory.getProgress();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    IOUtils.cleanupWithLogger(null, src);\r\n    factory.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createReaderThread",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Thread createReaderThread()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNextJobFromTrace",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobStory getNextJobFromTrace() throws IOException\n{\r\n    JobStory story = jobProducer.getNextJob();\r\n    if (story != null) {\r\n        ++numJobsInTrace;\r\n    }\r\n    return story;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getNextJobFiltered",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "JobStory getNextJobFiltered() throws IOException\n{\r\n    JobStory job = getNextJobFromTrace();\r\n    while (job != null && (job.getOutcome() != Pre21JobHistoryConstants.Values.SUCCESS || job.getSubmissionTime() < 0 || job.getNumberMaps() == 0)) {\r\n        if (LOG.isDebugEnabled()) {\r\n            List<String> reason = new ArrayList<String>();\r\n            if (job.getOutcome() != Pre21JobHistoryConstants.Values.SUCCESS) {\r\n                reason.add(\"STATE (\" + job.getOutcome().name() + \")\");\r\n            }\r\n            if (job.getSubmissionTime() < 0) {\r\n                reason.add(\"SUBMISSION-TIME (\" + job.getSubmissionTime() + \")\");\r\n            }\r\n            if (job.getNumberMaps() == 0) {\r\n                reason.add(\"ZERO-MAPS-JOB\");\r\n            }\r\n            if (reason.size() == 0) {\r\n                reason.add(\"N/A\");\r\n            }\r\n            LOG.debug(\"Ignoring job \" + job.getJobID() + \" from the input trace.\" + \" Reason: \" + StringUtils.join(reason, \",\"));\r\n        }\r\n        job = getNextJobFromTrace();\r\n    }\r\n    return null == job ? null : new FilterJobStory(job) {\r\n\r\n        @Override\r\n        public TaskInfo getTaskInfo(TaskType taskType, int taskNumber) {\r\n            TaskInfo info = this.job.getTaskInfo(taskType, taskNumber);\r\n            if (info != null) {\r\n                info = new MinTaskInfo(info);\r\n            } else {\r\n                info = new MinTaskInfo(new TaskInfo(0, 0, 0, 0, 0));\r\n            }\r\n            return info;\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "error",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "IOException error()\n{\r\n    return error;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "add",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void add(Void ignored)\n{\r\n    throw new UnsupportedOperationException(getClass().getName() + \" is at the start of the pipeline and accepts no events\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void start()\n{\r\n    rThread.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "join",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void join(long millis) throws InterruptedException\n{\r\n    rThread.join(millis);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "shutdown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void shutdown()\n{\r\n    rThread.interrupt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "abort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void abort()\n{\r\n    rThread.interrupt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "init",
  "errType" : [ "URISyntaxException" ],
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void init(String traceIn, JobCreator jobCreator, boolean generate) throws IOException\n{\r\n    emulateDistributedCache = jobCreator.canEmulateDistCacheLoad() && conf.getBoolean(GRIDMIX_EMULATE_DISTRIBUTEDCACHE, true);\r\n    generateDistCacheData = generate;\r\n    if (generateDistCacheData || emulateDistributedCache) {\r\n        if (\"-\".equals(traceIn)) {\r\n            LOG.warn(\"Gridmix will not emulate Distributed Cache load because \" + \"the input trace source is a stream instead of file.\");\r\n            emulateDistributedCache = generateDistCacheData = false;\r\n        } else if (FileSystem.getLocal(conf).getUri().getScheme().equals(distCachePath.toUri().getScheme())) {\r\n            LOG.warn(\"Gridmix will not emulate Distributed Cache load because \" + \"<iopath> provided is on local file system.\");\r\n            emulateDistributedCache = generateDistCacheData = false;\r\n        } else {\r\n            FileSystem fs = FileSystem.get(conf);\r\n            Path cur = distCachePath.getParent();\r\n            while (cur != null) {\r\n                if (cur.toString().length() > 0) {\r\n                    FsPermission perm = fs.getFileStatus(cur).getPermission();\r\n                    if (!perm.getOtherAction().and(FsAction.EXECUTE).equals(FsAction.EXECUTE)) {\r\n                        LOG.warn(\"Gridmix will not emulate Distributed Cache load \" + \"because the ascendant directory (of distributed cache \" + \"directory) \" + cur + \" doesn't have execute permission \" + \"for others.\");\r\n                        emulateDistributedCache = generateDistCacheData = false;\r\n                        break;\r\n                    }\r\n                }\r\n                cur = cur.getParent();\r\n            }\r\n        }\r\n    }\r\n    try {\r\n        pseudoLocalFs = FileSystem.get(new URI(\"pseudo:///\"), conf);\r\n    } catch (URISyntaxException e) {\r\n        LOG.warn(\"Gridmix will not emulate Distributed Cache load because \" + \"creation of pseudo local file system failed.\");\r\n        e.printStackTrace();\r\n        emulateDistributedCache = generateDistCacheData = false;\r\n        return;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "shouldEmulateDistCacheLoad",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean shouldEmulateDistCacheLoad()\n{\r\n    return emulateDistributedCache;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "shouldGenerateDistCacheData",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean shouldGenerateDistCacheData()\n{\r\n    return generateDistCacheData;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getDistributedCacheDir",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getDistributedCacheDir()\n{\r\n    return distCachePath;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setupGenerateDistCacheData",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int setupGenerateDistCacheData(JobStoryProducer jsp) throws IOException\n{\r\n    createDistCacheDirectory();\r\n    return buildDistCacheFilesList(jsp);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createDistCacheDirectory",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void createDistCacheDirectory() throws IOException\n{\r\n    FileSystem fs = FileSystem.get(conf);\r\n    FileSystem.mkdirs(fs, distCachePath, new FsPermission((short) 0777));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "buildDistCacheFilesList",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "int buildDistCacheFilesList(JobStoryProducer jsp) throws IOException\n{\r\n    JobStory jobStory;\r\n    while ((jobStory = jsp.getNextJob()) != null) {\r\n        if (jobStory.getOutcome() == Pre21JobHistoryConstants.Values.SUCCESS && jobStory.getSubmissionTime() >= 0) {\r\n            updateHDFSDistCacheFilesList(jobStory);\r\n        }\r\n    }\r\n    jsp.close();\r\n    return writeDistCacheFilesList();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "updateHDFSDistCacheFilesList",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void updateHDFSDistCacheFilesList(JobStory jobdesc) throws IOException\n{\r\n    JobConf jobConf = jobdesc.getJobConf();\r\n    String[] files = jobConf.getStrings(MRJobConfig.CACHE_FILES);\r\n    if (files != null) {\r\n        String[] fileSizes = jobConf.getStrings(MRJobConfig.CACHE_FILES_SIZES);\r\n        String[] visibilities = jobConf.getStrings(MRJobConfig.CACHE_FILE_VISIBILITIES);\r\n        String[] timeStamps = jobConf.getStrings(MRJobConfig.CACHE_FILE_TIMESTAMPS);\r\n        FileSystem fs = FileSystem.get(conf);\r\n        String user = jobConf.getUser();\r\n        for (int i = 0; i < files.length; i++) {\r\n            boolean visibility = (visibilities == null) || Boolean.parseBoolean(visibilities[i]);\r\n            if (isLocalDistCacheFile(files[i], user, visibility)) {\r\n                continue;\r\n            }\r\n            String mappedPath = mapDistCacheFilePath(files[i], timeStamps[i], visibility, user);\r\n            if (distCacheFiles.containsKey(mappedPath) || fs.exists(new Path(mappedPath))) {\r\n                continue;\r\n            }\r\n            distCacheFiles.put(mappedPath, Long.valueOf(fileSizes[i]));\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "isLocalDistCacheFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isLocalDistCacheFile(String filePath, String user, boolean visibility)\n{\r\n    return (!visibility && filePath.contains(user + \"/.staging\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "mapDistCacheFilePath",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String mapDistCacheFilePath(String file, String timeStamp, boolean isPublic, String user)\n{\r\n    String id = file + timeStamp;\r\n    if (!isPublic) {\r\n        id = id.concat(user);\r\n    }\r\n    return new Path(distCachePath, MD5Hash.digest(id).toString()).toUri().getPath();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "writeDistCacheFilesList",
  "errType" : null,
  "containingMethodsNum" : 23,
  "sourceCodeText" : "int writeDistCacheFilesList() throws IOException\n{\r\n    List dcFiles = new ArrayList(distCacheFiles.entrySet());\r\n    Collections.sort(dcFiles, new Comparator() {\r\n\r\n        public int compare(Object dc1, Object dc2) {\r\n            return ((Comparable) ((Map.Entry) (dc2)).getValue()).compareTo(((Map.Entry) (dc1)).getValue());\r\n        }\r\n    });\r\n    FileSystem fs = FileSystem.get(conf);\r\n    Path distCacheFilesList = new Path(distCachePath, \"_distCacheFiles.txt\");\r\n    conf.set(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_LIST, distCacheFilesList.toString());\r\n    SequenceFile.Writer src_writer = SequenceFile.createWriter(fs, conf, distCacheFilesList, LongWritable.class, BytesWritable.class, SequenceFile.CompressionType.NONE);\r\n    int fileCount = dcFiles.size();\r\n    long byteCount = 0;\r\n    long bytesSync = 0;\r\n    for (Iterator it = dcFiles.iterator(); it.hasNext(); ) {\r\n        Map.Entry entry = (Map.Entry) it.next();\r\n        LongWritable fileSize = new LongWritable(Long.parseLong(entry.getValue().toString()));\r\n        BytesWritable filePath = new BytesWritable(entry.getKey().toString().getBytes(charsetUTF8));\r\n        byteCount += fileSize.get();\r\n        bytesSync += fileSize.get();\r\n        if (bytesSync > AVG_BYTES_PER_MAP) {\r\n            src_writer.sync();\r\n            bytesSync = fileSize.get();\r\n        }\r\n        src_writer.append(fileSize, filePath);\r\n    }\r\n    if (src_writer != null) {\r\n        src_writer.close();\r\n    }\r\n    fs.deleteOnExit(distCacheFilesList);\r\n    conf.setInt(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_COUNT, fileCount);\r\n    conf.setLong(GenerateDistCacheData.GRIDMIX_DISTCACHE_BYTE_COUNT, byteCount);\r\n    LOG.info(\"Number of HDFS based distributed cache files to be generated is \" + fileCount + \". Total size of HDFS based distributed cache files \" + \"to be generated is \" + byteCount);\r\n    if (!shouldGenerateDistCacheData() && fileCount > 0) {\r\n        LOG.error(\"Missing \" + fileCount + \" distributed cache files under the \" + \" directory\\n\" + distCachePath + \"\\nthat are needed for gridmix\" + \" to emulate distributed cache load. Either use -generate\\noption\" + \" to generate distributed cache data along with input data OR \" + \"disable\\ndistributed cache emulation by configuring '\" + DistributedCacheEmulator.GRIDMIX_EMULATE_DISTRIBUTEDCACHE + \"' to false.\");\r\n        return Gridmix.MISSING_DIST_CACHE_FILES_ERROR;\r\n    }\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "configureDistCacheFiles",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void configureDistCacheFiles(Configuration conf, JobConf jobConf) throws IOException\n{\r\n    if (shouldEmulateDistCacheLoad()) {\r\n        String[] files = jobConf.getStrings(MRJobConfig.CACHE_FILES);\r\n        if (files != null) {\r\n            List<String> cacheFiles = new ArrayList<String>();\r\n            List<String> localCacheFiles = new ArrayList<String>();\r\n            String[] visibilities = jobConf.getStrings(MRJobConfig.CACHE_FILE_VISIBILITIES);\r\n            String[] timeStamps = jobConf.getStrings(MRJobConfig.CACHE_FILE_TIMESTAMPS);\r\n            String[] fileSizes = jobConf.getStrings(MRJobConfig.CACHE_FILES_SIZES);\r\n            String user = jobConf.getUser();\r\n            for (int i = 0; i < files.length; i++) {\r\n                boolean visibility = (visibilities == null) || Boolean.parseBoolean(visibilities[i]);\r\n                if (isLocalDistCacheFile(files[i], user, visibility)) {\r\n                    String fileId = MD5Hash.digest(files[i] + timeStamps[i]).toString();\r\n                    long fileSize = Long.parseLong(fileSizes[i]);\r\n                    Path mappedLocalFilePath = PseudoLocalFs.generateFilePath(fileId, fileSize).makeQualified(pseudoLocalFs.getUri(), pseudoLocalFs.getWorkingDirectory());\r\n                    pseudoLocalFs.create(mappedLocalFilePath);\r\n                    localCacheFiles.add(mappedLocalFilePath.toUri().toString());\r\n                } else {\r\n                    String mappedPath = mapDistCacheFilePath(files[i], timeStamps[i], visibility, user);\r\n                    cacheFiles.add(mappedPath);\r\n                }\r\n            }\r\n            if (cacheFiles.size() > 0) {\r\n                conf.setStrings(MRJobConfig.CACHE_FILES, cacheFiles.toArray(new String[cacheFiles.size()]));\r\n            }\r\n            if (localCacheFiles.size() > 0) {\r\n                conf.setStrings(\"tmpfiles\", localCacheFiles.toArray(new String[localCacheFiles.size()]));\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getUri",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "URI getUri()\n{\r\n    return NAME;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getHomeDirectory",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getHomeDirectory()\n{\r\n    return home;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path getWorkingDirectory()\n{\r\n    return getHomeDirectory();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "generateFilePath",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path generateFilePath(String fileId, long fileSize)\n{\r\n    return new Path(fileId + \".\" + fileSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "create",
  "errType" : [ "FileNotFoundException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FSDataOutputStream create(Path path) throws IOException\n{\r\n    try {\r\n        validateFileNameFormat(path);\r\n    } catch (FileNotFoundException e) {\r\n        throw new IOException(\"File creation failed for \" + path);\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "validateFileNameFormat",
  "errType" : [ "NumberFormatException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "long validateFileNameFormat(Path path) throws FileNotFoundException\n{\r\n    path = this.makeQualified(path);\r\n    boolean valid = true;\r\n    long fileSize = 0;\r\n    if (!path.toUri().getScheme().equals(getUri().getScheme())) {\r\n        valid = false;\r\n    } else {\r\n        String[] parts = path.toUri().getPath().split(\"\\\\.\");\r\n        try {\r\n            fileSize = Long.parseLong(parts[parts.length - 1]);\r\n            valid = (fileSize >= 0);\r\n        } catch (NumberFormatException e) {\r\n            valid = false;\r\n        }\r\n    }\r\n    if (!valid) {\r\n        throw new FileNotFoundException(\"File \" + path + \" does not exist in pseudo local file system\");\r\n    }\r\n    return fileSize;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "open",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FSDataInputStream open(Path path, int bufferSize) throws IOException\n{\r\n    long fileSize = validateFileNameFormat(path);\r\n    InputStream in = new RandomInputStream(fileSize, bufferSize);\r\n    return new FSDataInputStream(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "open",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FSDataInputStream open(Path path) throws IOException\n{\r\n    return open(path, DEFAULT_BUFFER_SIZE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getFileStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FileStatus getFileStatus(Path path) throws IOException\n{\r\n    long fileSize = validateFileNameFormat(path);\r\n    return new FileStatus(fileSize, false, 1, BLOCK_SIZE, TIME, path);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "exists",
  "errType" : [ "FileNotFoundException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean exists(Path path)\n{\r\n    try {\r\n        validateFileNameFormat(path);\r\n    } catch (FileNotFoundException e) {\r\n        return false;\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FSDataOutputStream create(Path path, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException\n{\r\n    return create(path);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "listStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FileStatus[] listStatus(Path path) throws FileNotFoundException, IOException\n{\r\n    return new FileStatus[] { getFileStatus(path) };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "append",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FSDataOutputStream append(Path path, int bufferSize, Progressable progress) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"Append is not supported\" + \" in pseudo local file system.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "mkdirs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean mkdirs(Path f, FsPermission permission) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"Mkdirs is not supported\" + \" in pseudo local file system.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "rename",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean rename(Path src, Path dst) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"Rename is not supported\" + \" in pseudo local file system.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "delete",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean delete(Path path, boolean recursive)\n{\r\n    throw new UnsupportedOperationException(\"File deletion is not supported \" + \"in pseudo local file system.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setWorkingDirectory(Path newDir)\n{\r\n    throw new UnsupportedOperationException(\"SetWorkingDirectory \" + \"is not supported in pseudo local file system.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "makeQualified",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path makeQualified(Path path)\n{\r\n    return path.makeQualified(this.getUri(), this.getWorkingDirectory());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "boolean next(GridmixKey key, GridmixRecord val) throws IOException\n{\r\n    if (accBytes >= targetBytes) {\r\n        return false;\r\n    }\r\n    final int reclen = accRecords++ >= step ? avgrec - 1 : avgrec;\r\n    final int len = (int) Math.min(targetBytes - accBytes, reclen);\r\n    unspilledBytes += len;\r\n    if (key != null) {\r\n        if (unspilledBytes < minSpilledBytes && accRecords < targetRecords) {\r\n            key.setSize(1);\r\n            val.setSize(1);\r\n            accBytes += key.getSize() + val.getSize();\r\n            unspilledBytes -= (key.getSize() + val.getSize());\r\n        } else {\r\n            key.setSize(keyLen);\r\n            val.setSize(unspilledBytes - key.getSize());\r\n            accBytes += unspilledBytes;\r\n            unspilledBytes = 0;\r\n        }\r\n    } else {\r\n        if (unspilledBytes < minSpilledBytes && accRecords < targetRecords) {\r\n            val.setSize(1);\r\n            accBytes += val.getSize();\r\n            unspilledBytes -= val.getSize();\r\n        } else {\r\n            val.setSize(unspilledBytes);\r\n            accBytes += unspilledBytes;\r\n            unspilledBytes = 0;\r\n        }\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress() throws IOException\n{\r\n    return Math.min(1.0f, accBytes / ((float) targetBytes));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void close() throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRandomTextDataGeneratorListSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getRandomTextDataGeneratorListSize(Configuration conf)\n{\r\n    return conf.getInt(GRIDMIX_DATAGEN_RANDOMTEXT_LISTSIZE, DEFAULT_LIST_SIZE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setRandomTextDataGeneratorListSize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setRandomTextDataGeneratorListSize(Configuration conf, int listSize)\n{\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"Random text data generator is configured to use a dictionary \" + \" with \" + listSize + \" words\");\r\n    }\r\n    conf.setInt(GRIDMIX_DATAGEN_RANDOMTEXT_LISTSIZE, listSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRandomTextDataGeneratorWordSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getRandomTextDataGeneratorWordSize(Configuration conf)\n{\r\n    return conf.getInt(GRIDMIX_DATAGEN_RANDOMTEXT_WORDSIZE, DEFAULT_WORD_SIZE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setRandomTextDataGeneratorWordSize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setRandomTextDataGeneratorWordSize(Configuration conf, int wordSize)\n{\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"Random text data generator is configured to use a dictionary \" + \" with words of length \" + wordSize);\r\n    }\r\n    conf.setInt(GRIDMIX_DATAGEN_RANDOMTEXT_WORDSIZE, wordSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRandomWord",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getRandomWord()\n{\r\n    int index = random.nextInt(words.length);\r\n    return words[index];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRandomWords",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> getRandomWords()\n{\r\n    return Arrays.asList(words);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setTargetUsers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean setTargetUsers(URI userdesc, Configuration conf) throws IOException\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getTargetUgi",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "UserGroupInformation getTargetUgi(UserGroupInformation ugi)\n{\r\n    return this.ugi;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "needsTargetUsersList",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean needsTargetUsersList()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "add",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void add(JobStats job) throws InterruptedException\n{\r\n    runningJobs.put(job);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "submissionFailed",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void submissionFailed(JobStats job)\n{\r\n    String jobID = job.getJob().getConfiguration().get(Gridmix.ORIGINAL_JOB_ID);\r\n    LOG.info(\"Job submission failed notification for job \" + jobID);\r\n    synchronized (statistics) {\r\n        this.statistics.add(job);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "onSuccess",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void onSuccess(Job job)\n{\r\n    LOG.info(job.getJobName() + \" (\" + job.getJobID() + \")\" + \" success\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "onFailure",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void onFailure(Job job)\n{\r\n    LOG.info(job.getJobName() + \" (\" + job.getJobID() + \")\" + \" failure\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRemainingJobs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "List<JobStats> getRemainingJobs()\n{\r\n    synchronized (mJobs) {\r\n        return new ArrayList<JobStats>(mJobs);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void start()\n{\r\n    for (int i = 0; i < numPollingThreads; ++i) {\r\n        executor.execute(new MonitorThread(i));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "join",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void join(long millis) throws InterruptedException\n{\r\n    executor.awaitTermination(millis, TimeUnit.MILLISECONDS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "abort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void abort()\n{\r\n    synchronized (mJobs) {\r\n        graceful = false;\r\n        shutdown = true;\r\n    }\r\n    executor.shutdown();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "shutdown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void shutdown()\n{\r\n    synchronized (mJobs) {\r\n        graceful = true;\r\n        shutdown = true;\r\n    }\r\n    executor.shutdown();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createReaderThread",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Thread createReaderThread()\n{\r\n    return new StressReaderThread(\"StressJobFactory\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "update",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void update(Statistics.ClusterStats item)\n{\r\n    ClusterStatus clusterStatus = item.getStatus();\r\n    try {\r\n        loadStatus.updateMapCapacity(clusterStatus.getMaxMapTasks());\r\n        loadStatus.updateReduceCapacity(clusterStatus.getMaxReduceTasks());\r\n        int numTrackers = clusterStatus.getTaskTrackers();\r\n        int jobLoad = (int) (maxJobTrackerRatio * numTrackers) - item.getNumRunningJob();\r\n        loadStatus.updateJobLoad(jobLoad);\r\n    } catch (Exception e) {\r\n        LOG.error(\"Couldn't get the new Status\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "calcEffectiveIncompleteMapTasks",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "float calcEffectiveIncompleteMapTasks(int mapSlotCapacity, int numMaps, float mapProgress)\n{\r\n    float maxEffIncompleteMapTasks = Math.max(1.0f, mapSlotCapacity * maxMapSlotSharePerJob);\r\n    float mapProgressAdjusted = Math.max(Math.min(mapProgress, 1.0f), 0.0f);\r\n    return Math.min(maxEffIncompleteMapTasks, numMaps * (1.0f - mapProgressAdjusted));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "calcEffectiveIncompleteReduceTasks",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "float calcEffectiveIncompleteReduceTasks(int reduceSlotCapacity, int numReduces, float reduceProgress)\n{\r\n    float maxEffIncompleteReduceTasks = Math.max(1.0f, reduceSlotCapacity * maxReduceSlotSharePerJob);\r\n    float reduceProgressAdjusted = Math.max(Math.min(reduceProgress, 1.0f), 0.0f);\r\n    return Math.min(maxEffIncompleteReduceTasks, numReduces * (1.0f - reduceProgressAdjusted));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "checkLoadAndGetSlotsToBackfill",
  "errType" : null,
  "containingMethodsNum" : 47,
  "sourceCodeText" : "void checkLoadAndGetSlotsToBackfill() throws IOException, InterruptedException\n{\r\n    if (loadStatus.getJobLoad() <= 0) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(System.currentTimeMillis() + \" [JobLoad] Overloaded is \" + Boolean.TRUE.toString() + \" NumJobsBackfill is \" + loadStatus.getJobLoad());\r\n        }\r\n        return;\r\n    }\r\n    int mapCapacity = loadStatus.getMapCapacity();\r\n    int reduceCapacity = loadStatus.getReduceCapacity();\r\n    if (mapCapacity < 0 || reduceCapacity < 0) {\r\n        return;\r\n    }\r\n    int maxMapLoad = (int) (overloadMapTaskMapSlotRatio * mapCapacity);\r\n    int maxReduceLoad = (int) (overloadReduceTaskReduceSlotRatio * reduceCapacity);\r\n    int totalMapTasks = ClusterStats.getSubmittedMapTasks();\r\n    int totalReduceTasks = ClusterStats.getSubmittedReduceTasks();\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"Total submitted map tasks: \" + totalMapTasks);\r\n        LOG.debug(\"Total submitted reduce tasks: \" + totalReduceTasks);\r\n        LOG.debug(\"Max map load: \" + maxMapLoad);\r\n        LOG.debug(\"Max reduce load: \" + maxReduceLoad);\r\n    }\r\n    int mapSlotsBackFill = (int) (maxMapLoad - totalMapTasks);\r\n    int reduceSlotsBackFill = (int) (maxReduceLoad - totalReduceTasks);\r\n    Set<JobID> seenJobIDs = new HashSet<JobID>();\r\n    if (totalMapTasks > maxMapLoad || totalReduceTasks > maxReduceLoad) {\r\n        float incompleteMapTasks = 0;\r\n        float incompleteReduceTasks = 0;\r\n        for (JobStats job : ClusterStats.getRunningJobStats()) {\r\n            JobID id = job.getJob().getJobID();\r\n            seenJobIDs.add(id);\r\n            if (blacklistedJobs.contains(id)) {\r\n                LOG.warn(\"Ignoring blacklisted job: \" + id);\r\n                continue;\r\n            }\r\n            int noOfMaps = job.getNoOfMaps();\r\n            int noOfReduces = job.getNoOfReds();\r\n            if (noOfMaps > 0 || noOfReduces > 0) {\r\n                JobStatus status = job.getJobStatus();\r\n                if (status != null && status.isJobComplete()) {\r\n                    LOG.warn(\"Blacklisting completed job: \" + id);\r\n                    blacklistedJobs.add(id);\r\n                    continue;\r\n                }\r\n                float mapProgress = 0f;\r\n                float reduceProgress = 0f;\r\n                if (status != null) {\r\n                    mapProgress = status.getMapProgress();\r\n                    reduceProgress = status.getReduceProgress();\r\n                }\r\n                incompleteMapTasks += calcEffectiveIncompleteMapTasks(mapCapacity, noOfMaps, mapProgress);\r\n                int currentMapSlotsBackFill = (int) (maxMapLoad - incompleteMapTasks);\r\n                if (currentMapSlotsBackFill <= 0) {\r\n                    incompleteReduceTasks = totalReduceTasks;\r\n                    if (LOG.isDebugEnabled()) {\r\n                        LOG.debug(\"Terminating overload check due to high map load.\");\r\n                    }\r\n                    break;\r\n                }\r\n                if (noOfReduces > 0) {\r\n                    incompleteReduceTasks += calcEffectiveIncompleteReduceTasks(reduceCapacity, noOfReduces, reduceProgress);\r\n                }\r\n                int currentReduceSlotsBackFill = (int) (maxReduceLoad - incompleteReduceTasks);\r\n                if (currentReduceSlotsBackFill <= 0) {\r\n                    incompleteMapTasks = totalMapTasks;\r\n                    if (LOG.isDebugEnabled()) {\r\n                        LOG.debug(\"Terminating overload check due to high reduce load.\");\r\n                    }\r\n                    break;\r\n                }\r\n            } else {\r\n                LOG.warn(\"Blacklisting empty job: \" + id);\r\n                blacklistedJobs.add(id);\r\n            }\r\n        }\r\n        mapSlotsBackFill = (int) (maxMapLoad - incompleteMapTasks);\r\n        reduceSlotsBackFill = (int) (maxReduceLoad - incompleteReduceTasks);\r\n        blacklistedJobs.retainAll(seenJobIDs);\r\n        if (LOG.isDebugEnabled() && blacklistedJobs.size() > 0) {\r\n            LOG.debug(\"Blacklisted jobs count: \" + blacklistedJobs.size());\r\n        }\r\n    }\r\n    loadStatus.updateMapLoad(mapSlotsBackFill);\r\n    loadStatus.updateReduceLoad(reduceSlotsBackFill);\r\n    if (loadStatus.getMapLoad() <= 0) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(System.currentTimeMillis() + \" [MAP-LOAD] Overloaded is \" + Boolean.TRUE.toString() + \" MapSlotsBackfill is \" + loadStatus.getMapLoad());\r\n        }\r\n        return;\r\n    }\r\n    if (loadStatus.getReduceLoad() <= 0) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(System.currentTimeMillis() + \" [REDUCE-LOAD] Overloaded is \" + Boolean.TRUE.toString() + \" ReduceSlotsBackfill is \" + loadStatus.getReduceLoad());\r\n        }\r\n        return;\r\n    }\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(System.currentTimeMillis() + \" [OVERALL] Overloaded is \" + Boolean.FALSE.toString() + \"Current load Status is \" + loadStatus);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void start()\n{\r\n    LOG.info(\" Starting Stress submission \");\r\n    this.rThread.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getTotalHeapUsageInMB",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getTotalHeapUsageInMB()\n{\r\n    return Runtime.getRuntime().totalMemory() / ONE_MB;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getMaxHeapUsageInMB",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getMaxHeapUsageInMB()\n{\r\n    return Runtime.getRuntime().maxMemory() / ONE_MB;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress()\n{\r\n    return enabled ? Math.min(1f, ((float) getTotalHeapUsageInMB()) / targetHeapUsageInMB) : 1.0f;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "emulate",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void emulate() throws IOException, InterruptedException\n{\r\n    if (enabled) {\r\n        float currentProgress = progress.getProgress();\r\n        if (prevEmulationProgress < currentProgress && ((currentProgress - prevEmulationProgress) >= emulationInterval || currentProgress == 1)) {\r\n            long maxHeapSizeInMB = getMaxHeapUsageInMB();\r\n            long committedHeapSizeInMB = getTotalHeapUsageInMB();\r\n            long expectedHeapUsageInMB = Math.min(maxHeapSizeInMB, (long) (targetHeapUsageInMB * currentProgress));\r\n            if (expectedHeapUsageInMB < maxHeapSizeInMB && committedHeapSizeInMB < expectedHeapUsageInMB) {\r\n                long bufferInMB = (long) (minFreeHeapRatio * expectedHeapUsageInMB);\r\n                long currentDifferenceInMB = expectedHeapUsageInMB - committedHeapSizeInMB;\r\n                long currentIncrementLoadSizeInMB = (long) (currentDifferenceInMB * heapLoadRatio);\r\n                currentIncrementLoadSizeInMB = Math.max(1, currentIncrementLoadSizeInMB);\r\n                while (committedHeapSizeInMB + bufferInMB < expectedHeapUsageInMB) {\r\n                    emulatorCore.load(currentIncrementLoadSizeInMB);\r\n                    committedHeapSizeInMB = getTotalHeapUsageInMB();\r\n                }\r\n            }\r\n            prevEmulationProgress = currentProgress;\r\n        }\r\n        emulatorCore.reset();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void initialize(Configuration conf, ResourceUsageMetrics metrics, ResourceCalculatorPlugin monitor, Progressive progress)\n{\r\n    this.progress = progress;\r\n    targetHeapUsageInMB = metrics.getHeapUsage() / ONE_MB;\r\n    if (targetHeapUsageInMB <= 0) {\r\n        enabled = false;\r\n        return;\r\n    } else {\r\n        emulatorCore.initialize(monitor, targetHeapUsageInMB);\r\n        enabled = true;\r\n    }\r\n    emulationInterval = conf.getFloat(HEAP_EMULATION_PROGRESS_INTERVAL, DEFAULT_EMULATION_PROGRESS_INTERVAL);\r\n    minFreeHeapRatio = conf.getFloat(MIN_HEAP_FREE_RATIO, DEFAULT_MIN_FREE_HEAP_RATIO);\r\n    heapLoadRatio = conf.getFloat(HEAP_LOAD_RATIO, DEFAULT_HEAP_LOAD_RATIO);\r\n    prevEmulationProgress = 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "generateJobStats",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "JobStats generateJobStats(Job job, JobStory jobdesc)\n{\r\n    int seq = GridmixJob.getJobSeqId(job);\r\n    if (seq >= 0 && jobdesc == null) {\r\n        throw new IllegalArgumentException(\"JobStory not available for job \" + job.getJobID());\r\n    }\r\n    int maps = -1;\r\n    int reds = -1;\r\n    if (jobdesc != null) {\r\n        maps = jobdesc.getNumberMaps();\r\n        reds = jobdesc.getNumberReduces();\r\n    }\r\n    return new JobStats(maps, reds, job);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "addToNumMapsSubmitted",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void addToNumMapsSubmitted(int numMaps)\n{\r\n    numMapsSubmitted += numMaps;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "addToNumReducesSubmitted",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void addToNumReducesSubmitted(int numReduces)\n{\r\n    numReducesSubmitted += numReduces;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "subtractFromNumMapsSubmitted",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void subtractFromNumMapsSubmitted(int numMaps)\n{\r\n    numMapsSubmitted -= numMaps;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "subtractFromNumReducesSubmitted",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void subtractFromNumReducesSubmitted(int numReduces)\n{\r\n    numReducesSubmitted -= numReduces;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "addJobStats",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void addJobStats(JobStats stats)\n{\r\n    int seq = GridmixJob.getJobSeqId(stats.getJob());\r\n    if (seq < 0) {\r\n        LOG.info(\"Not tracking job \" + stats.getJob().getJobName() + \" as seq id is less than zero: \" + seq);\r\n        return;\r\n    }\r\n    submittedJobsMap.put(seq, stats);\r\n    addToNumMapsSubmitted(stats.getNoOfMaps());\r\n    addToNumReducesSubmitted(stats.getNoOfReds());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "add",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void add(Statistics.JobStats job)\n{\r\n    if (!statistics.isAlive()) {\r\n        return;\r\n    }\r\n    JobStats stat = submittedJobsMap.remove(GridmixJob.getJobSeqId(job.getJob()));\r\n    if (stat == null) {\r\n        LOG.error(\"[Statistics] Missing entry for job \" + job.getJob().getJobID());\r\n        return;\r\n    }\r\n    subtractFromNumMapsSubmitted(stat.getNoOfMaps());\r\n    subtractFromNumReducesSubmitted(stat.getNoOfReds());\r\n    completedJobsInCurrentInterval++;\r\n    if (completedJobsInCurrentInterval >= maxJobCompletedInInterval) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\" Reached maximum limit of jobs in a polling interval \" + completedJobsInCurrentInterval);\r\n        }\r\n        completedJobsInCurrentInterval = 0;\r\n        lock.lock();\r\n        try {\r\n            for (StatListener<JobStats> l : jobStatListeners) {\r\n                l.update(stat);\r\n            }\r\n            this.jobCompleted.signalAll();\r\n        } finally {\r\n            lock.unlock();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "addClusterStatsObservers",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void addClusterStatsObservers(StatListener<ClusterStats> listener)\n{\r\n    clusterStatlisteners.add(listener);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "addJobStatsListeners",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void addJobStatsListeners(StatListener<JobStats> listener)\n{\r\n    this.jobStatListeners.add(listener);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void start()\n{\r\n    statistics.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "join",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void join(long millis) throws InterruptedException\n{\r\n    statistics.join(millis);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "shutdown",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void shutdown()\n{\r\n    shutdown = true;\r\n    submittedJobsMap.clear();\r\n    clusterStatlisteners.clear();\r\n    jobStatListeners.clear();\r\n    statistics.interrupt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "abort",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void abort()\n{\r\n    shutdown = true;\r\n    submittedJobsMap.clear();\r\n    clusterStatlisteners.clear();\r\n    jobStatListeners.clear();\r\n    statistics.interrupt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getExecutionSummarizer",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ExecutionSummarizer getExecutionSummarizer()\n{\r\n    return executionSummarizer;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getClusterSummarizer",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ClusterSummarizer getClusterSummarizer()\n{\r\n    return clusterSummarizer;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void start(Configuration conf)\n{\r\n    executionSummarizer.start(conf);\r\n    clusterSummarizer.start(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "finalize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void finalize(JobFactory factory, String path, long size, UserResolver resolver, DataStatistics stats, Configuration conf) throws IOException\n{\r\n    executionSummarizer.finalize(factory, path, size, resolver, stats, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder builder = new StringBuilder();\r\n    builder.append(executionSummarizer.toString());\r\n    builder.append(clusterSummarizer.toString());\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getGridmixInputDataPath",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getGridmixInputDataPath(Path ioPath)\n{\r\n    return new Path(ioPath, \"input\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "writeInputData",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "int writeInputData(long genbytes, Path inputDir) throws IOException, InterruptedException\n{\r\n    if (genbytes > 0) {\r\n        final Configuration conf = getConf();\r\n        if (inputDir.getFileSystem(conf).exists(inputDir)) {\r\n            LOG.error(\"Gridmix input data directory {} already exists \" + \"when -generate option is used.\", inputDir);\r\n            return STARTUP_FAILED_ERROR;\r\n        }\r\n        CompressionEmulationUtil.setupDataGeneratorConfig(conf);\r\n        final GenerateData genData = new GenerateData(conf, inputDir, genbytes);\r\n        LOG.info(\"Generating {} of test data...\", StringUtils.TraditionalBinaryPrefix.long2String(genbytes, \"\", 1));\r\n        launchGridmixJob(genData);\r\n        FsShell shell = new FsShell(conf);\r\n        try {\r\n            LOG.info(\"Changing the permissions for inputPath {}\", inputDir);\r\n            shell.run(new String[] { \"-chmod\", \"-R\", \"777\", inputDir.toString() });\r\n        } catch (Exception e) {\r\n            LOG.error(\"Couldnt change the file permissions \", e);\r\n            throw new IOException(e);\r\n        }\r\n        LOG.info(\"Input data generation successful.\");\r\n    }\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "writeDistCacheData",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeDistCacheData(Configuration conf) throws IOException, InterruptedException\n{\r\n    int fileCount = conf.getInt(GenerateDistCacheData.GRIDMIX_DISTCACHE_FILE_COUNT, -1);\r\n    if (fileCount > 0) {\r\n        final GridmixJob genDistCacheData = new GenerateDistCacheData(conf);\r\n        LOG.info(\"Generating distributed cache data of size \" + conf.getLong(GenerateDistCacheData.GRIDMIX_DISTCACHE_BYTE_COUNT, -1));\r\n        launchGridmixJob(genDistCacheData);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "launchGridmixJob",
  "errType" : [ "ClassNotFoundException", "InterruptedException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void launchGridmixJob(GridmixJob job) throws IOException, InterruptedException\n{\r\n    submitter.add(job);\r\n    try {\r\n        while (!job.isSubmitted()) {\r\n            try {\r\n                Thread.sleep(100);\r\n            } catch (InterruptedException ie) {\r\n            }\r\n        }\r\n        job.getJob().waitForCompletion(false);\r\n    } catch (ClassNotFoundException e) {\r\n        throw new IOException(\"Internal error\", e);\r\n    }\r\n    if (!job.getJob().isSuccessful()) {\r\n        throw new IOException(job.getJob().getJobName() + \" job failed!\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createJobStoryProducer",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobStoryProducer createJobStoryProducer(String traceIn, Configuration conf) throws IOException\n{\r\n    if (\"-\".equals(traceIn)) {\r\n        return new ZombieJobProducer(System.in, null);\r\n    }\r\n    return new ZombieJobProducer(new Path(traceIn), null, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobSubmissionPolicy",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "GridmixJobSubmissionPolicy getJobSubmissionPolicy(Configuration conf)\n{\r\n    return GridmixJobSubmissionPolicy.getPolicy(conf, GridmixJobSubmissionPolicy.STRESS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "startThreads",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void startThreads(Configuration conf, String traceIn, Path ioPath, Path scratchDir, CountDownLatch startFlag, UserResolver userResolver) throws IOException\n{\r\n    try {\r\n        Path inputDir = getGridmixInputDataPath(ioPath);\r\n        GridmixJobSubmissionPolicy policy = getJobSubmissionPolicy(conf);\r\n        LOG.info(\" Submission policy is \" + policy.name());\r\n        statistics = new Statistics(conf, policy.getPollingInterval(), startFlag);\r\n        monitor = createJobMonitor(statistics, conf);\r\n        int noOfSubmitterThreads = (policy == GridmixJobSubmissionPolicy.SERIAL) ? 1 : Runtime.getRuntime().availableProcessors() + 1;\r\n        int numThreads = conf.getInt(GRIDMIX_SUB_THR, noOfSubmitterThreads);\r\n        int queueDep = conf.getInt(GRIDMIX_QUE_DEP, 5);\r\n        submitter = createJobSubmitter(monitor, numThreads, queueDep, new FilePool(conf, inputDir), userResolver, statistics);\r\n        distCacheEmulator = new DistributedCacheEmulator(conf, ioPath);\r\n        factory = createJobFactory(submitter, traceIn, scratchDir, conf, startFlag, userResolver);\r\n        factory.jobCreator.setDistCacheEmulator(distCacheEmulator);\r\n        if (policy == GridmixJobSubmissionPolicy.SERIAL) {\r\n            statistics.addJobStatsListeners(factory);\r\n        } else {\r\n            statistics.addClusterStatsObservers(factory);\r\n        }\r\n        statistics.addJobStatsListeners(summarizer.getExecutionSummarizer());\r\n        statistics.addClusterStatsObservers(summarizer.getClusterSummarizer());\r\n        monitor.start();\r\n        submitter.start();\r\n    } catch (Exception e) {\r\n        LOG.error(\" Exception at start \", e);\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createJobMonitor",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobMonitor createJobMonitor(Statistics stats, Configuration conf) throws IOException\n{\r\n    int delay = conf.getInt(GRIDMIX_JOBMONITOR_SLEEPTIME_MILLIS, GRIDMIX_JOBMONITOR_SLEEPTIME_MILLIS_DEFAULT);\r\n    int numThreads = conf.getInt(GRIDMIX_JOBMONITOR_THREADS, GRIDMIX_JOBMONITOR_THREADS_DEFAULT);\r\n    return new JobMonitor(delay, TimeUnit.MILLISECONDS, stats, numThreads);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createJobSubmitter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobSubmitter createJobSubmitter(JobMonitor monitor, int threads, int queueDepth, FilePool pool, UserResolver resolver, Statistics statistics) throws IOException\n{\r\n    return new JobSubmitter(monitor, threads, queueDepth, pool, statistics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "createJobFactory",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobFactory createJobFactory(JobSubmitter submitter, String traceIn, Path scratchDir, Configuration conf, CountDownLatch startFlag, UserResolver resolver) throws IOException\n{\r\n    return GridmixJobSubmissionPolicy.getPolicy(conf, GridmixJobSubmissionPolicy.STRESS).createJobFactory(submitter, createJobStoryProducer(traceIn, conf), scratchDir, conf, startFlag, resolver);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getCurrentUserResolver",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "UserResolver getCurrentUserResolver()\n{\r\n    return userResolver;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "run",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "int run(final String[] argv) throws IOException, InterruptedException\n{\r\n    int val = -1;\r\n    final Configuration conf = getConf();\r\n    UserGroupInformation.setConfiguration(conf);\r\n    UserGroupInformation ugi = UserGroupInformation.getLoginUser();\r\n    val = ugi.doAs(new PrivilegedExceptionAction<Integer>() {\r\n\r\n        public Integer run() throws Exception {\r\n            return runJob(conf, argv);\r\n        }\r\n    });\r\n    if (val == 0) {\r\n        System.out.print(\"\\n\\n\");\r\n        System.out.println(summarizer.toString());\r\n    }\r\n    return val;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "runJob",
  "errType" : [ "Exception", "IOException" ],
  "containingMethodsNum" : 24,
  "sourceCodeText" : "int runJob(Configuration conf, String[] argv) throws IOException, InterruptedException\n{\r\n    if (argv.length < 2) {\r\n        LOG.error(\"Too few arguments to Gridmix.\\n\");\r\n        printUsage(System.err);\r\n        return ARGS_ERROR;\r\n    }\r\n    long genbytes = -1L;\r\n    String traceIn = null;\r\n    Path ioPath = null;\r\n    URI userRsrc = null;\r\n    try {\r\n        userResolver = ReflectionUtils.newInstance(conf.getClass(GRIDMIX_USR_RSV, SubmitterUserResolver.class, UserResolver.class), conf);\r\n        for (int i = 0; i < argv.length - 2; ++i) {\r\n            if (\"-generate\".equals(argv[i])) {\r\n                genbytes = StringUtils.TraditionalBinaryPrefix.string2long(argv[++i]);\r\n                if (genbytes <= 0) {\r\n                    LOG.error(\"size of input data to be generated specified using \" + \"-generate option should be nonnegative.\\n\");\r\n                    return ARGS_ERROR;\r\n                }\r\n            } else if (\"-users\".equals(argv[i])) {\r\n                userRsrc = new URI(argv[++i]);\r\n            } else {\r\n                LOG.error(\"Unknown option \" + argv[i] + \" specified.\\n\");\r\n                printUsage(System.err);\r\n                return ARGS_ERROR;\r\n            }\r\n        }\r\n        if (userResolver.needsTargetUsersList()) {\r\n            if (userRsrc != null) {\r\n                if (!userResolver.setTargetUsers(userRsrc, conf)) {\r\n                    LOG.warn(\"Ignoring the user resource '\" + userRsrc + \"'.\");\r\n                }\r\n            } else {\r\n                LOG.error(userResolver.getClass() + \" needs target user list. Use -users option.\\n\");\r\n                printUsage(System.err);\r\n                return ARGS_ERROR;\r\n            }\r\n        } else if (userRsrc != null) {\r\n            LOG.warn(\"Ignoring the user resource '\" + userRsrc + \"'.\");\r\n        }\r\n        ioPath = new Path(argv[argv.length - 2]);\r\n        traceIn = argv[argv.length - 1];\r\n    } catch (Exception e) {\r\n        LOG.error(e.toString() + \"\\n\");\r\n        if (LOG.isDebugEnabled()) {\r\n            e.printStackTrace();\r\n        }\r\n        printUsage(System.err);\r\n        return ARGS_ERROR;\r\n    }\r\n    final FileSystem inputFs = ioPath.getFileSystem(conf);\r\n    ioPath = inputFs.makeQualified(ioPath);\r\n    boolean succeeded = false;\r\n    try {\r\n        succeeded = FileSystem.mkdirs(inputFs, ioPath, new FsPermission((short) 0777));\r\n    } catch (IOException e) {\r\n    } finally {\r\n        if (!succeeded) {\r\n            LOG.error(\"Failed creation of <ioPath> directory \" + ioPath + \"\\n\");\r\n            return STARTUP_FAILED_ERROR;\r\n        }\r\n    }\r\n    return start(conf, traceIn, ioPath, genbytes, userResolver);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 26,
  "sourceCodeText" : "int start(Configuration conf, String traceIn, Path ioPath, long genbytes, UserResolver userResolver) throws IOException, InterruptedException\n{\r\n    DataStatistics stats = null;\r\n    InputStream trace = null;\r\n    int exitCode = 0;\r\n    try {\r\n        Path scratchDir = new Path(ioPath, conf.get(GRIDMIX_OUT_DIR, \"gridmix\"));\r\n        Runtime.getRuntime().addShutdownHook(sdh);\r\n        CountDownLatch startFlag = new CountDownLatch(1);\r\n        try {\r\n            startThreads(conf, traceIn, ioPath, scratchDir, startFlag, userResolver);\r\n            Path inputDir = getGridmixInputDataPath(ioPath);\r\n            exitCode = writeInputData(genbytes, inputDir);\r\n            if (exitCode != 0) {\r\n                return exitCode;\r\n            }\r\n            stats = GenerateData.publishDataStatistics(inputDir, genbytes, conf);\r\n            submitter.refreshFilePool();\r\n            boolean shouldGenerate = (genbytes > 0);\r\n            exitCode = setupEmulation(conf, traceIn, scratchDir, ioPath, shouldGenerate);\r\n            if (exitCode != 0) {\r\n                return exitCode;\r\n            }\r\n            summarizer.start(conf);\r\n            factory.start();\r\n            statistics.start();\r\n        } catch (Throwable e) {\r\n            LOG.error(\"Startup failed. \" + e.toString() + \"\\n\");\r\n            LOG.debug(\"Startup failed\", e);\r\n            if (factory != null)\r\n                factory.abort();\r\n            exitCode = STARTUP_FAILED_ERROR;\r\n        } finally {\r\n            startFlag.countDown();\r\n        }\r\n        if (factory != null) {\r\n            factory.join(Long.MAX_VALUE);\r\n            final Throwable badTraceException = factory.error();\r\n            if (null != badTraceException) {\r\n                LOG.error(\"Error in trace\", badTraceException);\r\n                throw new IOException(\"Error in trace\", badTraceException);\r\n            }\r\n            submitter.shutdown();\r\n            submitter.join(Long.MAX_VALUE);\r\n            monitor.shutdown();\r\n            monitor.join(Long.MAX_VALUE);\r\n            statistics.shutdown();\r\n            statistics.join(Long.MAX_VALUE);\r\n        }\r\n    } finally {\r\n        if (factory != null) {\r\n            summarizer.finalize(factory, traceIn, genbytes, userResolver, stats, conf);\r\n        }\r\n        IOUtils.cleanupWithLogger(LOG, trace);\r\n    }\r\n    return exitCode;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setupEmulation",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int setupEmulation(Configuration conf, String traceIn, Path scratchDir, Path ioPath, boolean generate) throws IOException, InterruptedException\n{\r\n    final FileSystem scratchFs = scratchDir.getFileSystem(conf);\r\n    FileSystem.mkdirs(scratchFs, scratchDir, new FsPermission((short) 0777));\r\n    return setupDistCacheEmulation(conf, traceIn, ioPath, generate);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setupDistCacheEmulation",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "int setupDistCacheEmulation(Configuration conf, String traceIn, Path ioPath, boolean generate) throws IOException, InterruptedException\n{\r\n    distCacheEmulator.init(traceIn, factory.jobCreator, generate);\r\n    int exitCode = 0;\r\n    if (distCacheEmulator.shouldGenerateDistCacheData() || distCacheEmulator.shouldEmulateDistCacheLoad()) {\r\n        JobStoryProducer jsp = createJobStoryProducer(traceIn, conf);\r\n        exitCode = distCacheEmulator.setupGenerateDistCacheData(jsp);\r\n        if (exitCode == 0) {\r\n            writeDistCacheData(conf);\r\n        }\r\n    }\r\n    return exitCode;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void main(String[] argv) throws Exception\n{\r\n    int res = -1;\r\n    try {\r\n        res = ToolRunner.run(new Configuration(), new Gridmix(argv), argv);\r\n    } finally {\r\n        ExitUtil.terminate(res);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getEnumValues",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getEnumValues(Enum<?>[] e)\n{\r\n    StringBuilder sb = new StringBuilder();\r\n    String sep = \"\";\r\n    for (Enum<?> v : e) {\r\n        sb.append(sep);\r\n        sb.append(v.name());\r\n        sep = \"|\";\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobTypes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJobTypes()\n{\r\n    return getEnumValues(JobCreator.values());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSubmissionPolicies",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getSubmissionPolicies()\n{\r\n    return getEnumValues(GridmixJobSubmissionPolicy.values());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void printUsage(PrintStream out)\n{\r\n    ToolRunner.printGenericCommandUsage(out);\r\n    out.println(\"Usage: gridmix [-generate <MiB>] [-users URI] [-Dname=value ...] <iopath> <trace>\");\r\n    out.println(\"  e.g. gridmix -generate 100m foo -\");\r\n    out.println(\"Options:\");\r\n    out.println(\"   -generate <MiB> : Generate input data of size MiB under \" + \"<iopath>/input/ and generate\\n\\t\\t     distributed cache data under \" + \"<iopath>/distributedCache/.\");\r\n    out.println(\"   -users <usersResourceURI> : URI that contains the users list.\");\r\n    out.println(\"Configuration parameters:\");\r\n    out.println(\"   General parameters:\");\r\n    out.printf(\"       %-48s : Output directory%n\", GRIDMIX_OUT_DIR);\r\n    out.printf(\"       %-48s : Submitting threads%n\", GRIDMIX_SUB_THR);\r\n    out.printf(\"       %-48s : Queued job desc%n\", GRIDMIX_QUE_DEP);\r\n    out.printf(\"       %-48s : User resolution class%n\", GRIDMIX_USR_RSV);\r\n    out.printf(\"       %-48s : Job types (%s)%n\", JobCreator.GRIDMIX_JOB_TYPE, getJobTypes());\r\n    out.println(\"   Parameters related to job submission:\");\r\n    out.printf(\"       %-48s : Default queue%n\", GridmixJob.GRIDMIX_DEFAULT_QUEUE);\r\n    out.printf(\"       %-48s : Enable/disable using queues in trace%n\", GridmixJob.GRIDMIX_USE_QUEUE_IN_TRACE);\r\n    out.printf(\"       %-48s : Job submission policy (%s)%n\", GridmixJobSubmissionPolicy.JOB_SUBMISSION_POLICY, getSubmissionPolicies());\r\n    out.println(\"   Parameters specific for LOADJOB:\");\r\n    out.printf(\"       %-48s : Key fraction of rec%n\", AvgRecordFactory.GRIDMIX_KEY_FRC);\r\n    out.println(\"   Parameters specific for SLEEPJOB:\");\r\n    out.printf(\"       %-48s : Whether to ignore reduce tasks%n\", SleepJob.SLEEPJOB_MAPTASK_ONLY);\r\n    out.printf(\"       %-48s : Number of fake locations for map tasks%n\", JobCreator.SLEEPJOB_RANDOM_LOCATIONS);\r\n    out.printf(\"       %-48s : Maximum map task runtime in mili-sec%n\", SleepJob.GRIDMIX_SLEEP_MAX_MAP_TIME);\r\n    out.printf(\"       %-48s : Maximum reduce task runtime in mili-sec (merge+reduce)%n\", SleepJob.GRIDMIX_SLEEP_MAX_REDUCE_TIME);\r\n    out.println(\"   Parameters specific for STRESS submission throttling policy:\");\r\n    out.printf(\"       %-48s : jobs vs task-tracker ratio%n\", StressJobFactory.CONF_MAX_JOB_TRACKER_RATIO);\r\n    out.printf(\"       %-48s : maps vs map-slot ratio%n\", StressJobFactory.CONF_OVERLOAD_MAPTASK_MAPSLOT_RATIO);\r\n    out.printf(\"       %-48s : reduces vs reduce-slot ratio%n\", StressJobFactory.CONF_OVERLOAD_REDUCETASK_REDUCESLOT_RATIO);\r\n    out.printf(\"       %-48s : map-slot share per job%n\", StressJobFactory.CONF_MAX_MAPSLOT_SHARE_PER_JOB);\r\n    out.printf(\"       %-48s : reduce-slot share per job%n\", StressJobFactory.CONF_MAX_REDUCESLOT_SHARE_PER_JOB);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSummarizer",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Summarizer getSummarizer()\n{\r\n    return summarizer;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "configure",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void configure(final Job job) throws IOException, InterruptedException, ClassNotFoundException\n{\r\n    job.setMapperClass(RandomTextDataMapper.class);\r\n    job.setNumReduceTasks(0);\r\n    job.setMapOutputKeyClass(Text.class);\r\n    job.setMapOutputValueClass(Text.class);\r\n    job.setInputFormatClass(GenDataFormat.class);\r\n    job.setJarByClass(GenerateData.class);\r\n    FileOutputFormat.setCompressOutput(job, true);\r\n    try {\r\n        FileInputFormat.addInputPath(job, new Path(\"ignored\"));\r\n    } catch (IOException e) {\r\n        LOG.error(\"Error while adding input path \", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setupDataGeneratorConfig",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void setupDataGeneratorConfig(Configuration conf)\n{\r\n    boolean compress = isCompressionEmulationEnabled(conf);\r\n    if (compress) {\r\n        float ratio = getMapInputCompressionEmulationRatio(conf);\r\n        LOG.info(\"GridMix is configured to generate compressed input data with \" + \" a compression ratio of \" + ratio);\r\n        int wordSize = COMPRESSION_LOOKUP_TABLE.getWordSizeForRatio(ratio);\r\n        RandomTextDataGenerator.setRandomTextDataGeneratorWordSize(conf, wordSize);\r\n        RandomTextDataGenerator.setRandomTextDataGeneratorListSize(conf, RandomTextDataGenerator.DEFAULT_LIST_SIZE);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getRandomTextDataGenerator",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "RandomTextDataGenerator getRandomTextDataGenerator(float ratio, long seed)\n{\r\n    int wordSize = COMPRESSION_LOOKUP_TABLE.getWordSizeForRatio(ratio);\r\n    RandomTextDataGenerator rtg = new RandomTextDataGenerator(RandomTextDataGenerator.DEFAULT_LIST_SIZE, seed, wordSize);\r\n    return rtg;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "publishCompressedDataStatistics",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "DataStatistics publishCompressedDataStatistics(Path inputDir, Configuration conf, long uncompressedDataSize) throws IOException\n{\r\n    FileSystem fs = inputDir.getFileSystem(conf);\r\n    CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(conf);\r\n    long compressedDataSize = 0;\r\n    int numCompressedFiles = 0;\r\n    FileStatus[] outFileStatuses = fs.listStatus(inputDir, new Utils.OutputFileUtils.OutputFilesFilter());\r\n    for (FileStatus status : outFileStatuses) {\r\n        if (compressionCodecs != null) {\r\n            CompressionCodec codec = compressionCodecs.getCodec(status.getPath());\r\n            if (codec != null) {\r\n                ++numCompressedFiles;\r\n                compressedDataSize += status.getLen();\r\n            }\r\n        }\r\n    }\r\n    LOG.info(\"Gridmix is configured to use compressed input data.\");\r\n    LOG.info(\"Total size of compressed input data : \" + StringUtils.humanReadableInt(compressedDataSize));\r\n    LOG.info(\"Total number of compressed input data files : \" + numCompressedFiles);\r\n    if (numCompressedFiles == 0) {\r\n        throw new RuntimeException(\"No compressed file found in the input\" + \" directory : \" + inputDir.toString() + \". To enable compression\" + \" emulation, run Gridmix either with \" + \" an input directory containing compressed input file(s) or\" + \" use the -generate option to (re)generate it. If compression\" + \" emulation is not desired, disable it by setting '\" + COMPRESSION_EMULATION_ENABLE + \"' to 'false'.\");\r\n    }\r\n    if (uncompressedDataSize > 0) {\r\n        double ratio = ((double) compressedDataSize) / uncompressedDataSize;\r\n        LOG.info(\"Input Data Compression Ratio : \" + ratio);\r\n    }\r\n    return new DataStatistics(compressedDataSize, numCompressedFiles, true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setCompressionEmulationEnabled",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setCompressionEmulationEnabled(Configuration conf, boolean val)\n{\r\n    conf.setBoolean(COMPRESSION_EMULATION_ENABLE, val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "isCompressionEmulationEnabled",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isCompressionEmulationEnabled(Configuration conf)\n{\r\n    return conf.getBoolean(COMPRESSION_EMULATION_ENABLE, true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setInputCompressionEmulationEnabled",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setInputCompressionEmulationEnabled(Configuration conf, boolean val)\n{\r\n    conf.setBoolean(INPUT_DECOMPRESSION_EMULATION_ENABLE, val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "isInputCompressionEmulationEnabled",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isInputCompressionEmulationEnabled(Configuration conf)\n{\r\n    return conf.getBoolean(INPUT_DECOMPRESSION_EMULATION_ENABLE, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setMapInputCompressionEmulationRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMapInputCompressionEmulationRatio(Configuration conf, float ratio)\n{\r\n    conf.setFloat(GRIDMIX_MAP_INPUT_COMPRESSION_RATIO, ratio);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMapInputCompressionEmulationRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getMapInputCompressionEmulationRatio(Configuration conf)\n{\r\n    return conf.getFloat(GRIDMIX_MAP_INPUT_COMPRESSION_RATIO, DEFAULT_COMPRESSION_RATIO);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setMapOutputCompressionEmulationRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMapOutputCompressionEmulationRatio(Configuration conf, float ratio)\n{\r\n    conf.setFloat(GRIDMIX_MAP_OUTPUT_COMPRESSION_RATIO, ratio);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMapOutputCompressionEmulationRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getMapOutputCompressionEmulationRatio(Configuration conf)\n{\r\n    return conf.getFloat(GRIDMIX_MAP_OUTPUT_COMPRESSION_RATIO, DEFAULT_COMPRESSION_RATIO);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setJobOutputCompressionEmulationRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setJobOutputCompressionEmulationRatio(Configuration conf, float ratio)\n{\r\n    conf.setFloat(GRIDMIX_JOB_OUTPUT_COMPRESSION_RATIO, ratio);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobOutputCompressionEmulationRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getJobOutputCompressionEmulationRatio(Configuration conf)\n{\r\n    return conf.getFloat(GRIDMIX_JOB_OUTPUT_COMPRESSION_RATIO, DEFAULT_COMPRESSION_RATIO);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "standardizeCompressionRatio",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float standardizeCompressionRatio(float ratio)\n{\r\n    int significant = (int) Math.round(ratio * 100);\r\n    return ((float) significant) / 100;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getPossiblyDecompressedInputStream",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "InputStream getPossiblyDecompressedInputStream(Path file, Configuration conf, long offset) throws IOException\n{\r\n    FileSystem fs = file.getFileSystem(conf);\r\n    if (isCompressionEmulationEnabled(conf) && isInputCompressionEmulationEnabled(conf)) {\r\n        CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(conf);\r\n        CompressionCodec codec = compressionCodecs.getCodec(file);\r\n        if (codec != null) {\r\n            Decompressor decompressor = CodecPool.getDecompressor(codec);\r\n            if (decompressor != null) {\r\n                CompressionInputStream in = codec.createInputStream(fs.open(file), decompressor);\r\n                return (InputStream) in;\r\n            }\r\n        }\r\n    }\r\n    FSDataInputStream in = fs.open(file);\r\n    in.seek(offset);\r\n    return (InputStream) in;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getPossiblyCompressedOutputStream",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "OutputStream getPossiblyCompressedOutputStream(Path file, Configuration conf) throws IOException\n{\r\n    FileSystem fs = file.getFileSystem(conf);\r\n    JobConf jConf = new JobConf(conf);\r\n    if (org.apache.hadoop.mapred.FileOutputFormat.getCompressOutput(jConf)) {\r\n        Class<? extends CompressionCodec> codecClass = org.apache.hadoop.mapred.FileOutputFormat.getOutputCompressorClass(jConf, GzipCodec.class);\r\n        CompressionCodec codec = ReflectionUtils.newInstance(codecClass, conf);\r\n        file = file.suffix(codec.getDefaultExtension());\r\n        if (isCompressionEmulationEnabled(conf)) {\r\n            FSDataOutputStream fileOut = fs.create(file, false);\r\n            return new DataOutputStream(codec.createOutputStream(fileOut));\r\n        }\r\n    }\r\n    return fs.create(file, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "configureCompressionEmulation",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void configureCompressionEmulation(Configuration source, Configuration target)\n{\r\n    target.setBoolean(FileOutputFormat.COMPRESS, source.getBoolean(FileOutputFormat.COMPRESS, false));\r\n    String jobOutputCompressionCodec = source.get(FileOutputFormat.COMPRESS_CODEC);\r\n    if (jobOutputCompressionCodec != null) {\r\n        target.set(FileOutputFormat.COMPRESS_CODEC, jobOutputCompressionCodec);\r\n    }\r\n    String jobOutputCompressionType = source.get(FileOutputFormat.COMPRESS_TYPE);\r\n    if (jobOutputCompressionType != null) {\r\n        target.set(FileOutputFormat.COMPRESS_TYPE, jobOutputCompressionType);\r\n    }\r\n    target.setBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS, source.getBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS, false));\r\n    String mapOutputCompressionCodec = source.get(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC);\r\n    if (mapOutputCompressionCodec != null) {\r\n        target.set(MRJobConfig.MAP_OUTPUT_COMPRESS_CODEC, mapOutputCompressionCodec);\r\n    }\r\n    Path[] inputs = org.apache.hadoop.mapred.FileInputFormat.getInputPaths(new JobConf(source));\r\n    boolean needsCompressedInput = false;\r\n    CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(source);\r\n    for (Path input : inputs) {\r\n        CompressionCodec codec = compressionCodecs.getCodec(input);\r\n        if (codec != null) {\r\n            needsCompressedInput = true;\r\n        }\r\n    }\r\n    setInputCompressionEmulationEnabled(target, needsCompressedInput);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getUncompressedInputBytes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "long getUncompressedInputBytes(long possiblyCompressedInputBytes, Configuration conf)\n{\r\n    long uncompressedInputBytes = possiblyCompressedInputBytes;\r\n    if (CompressionEmulationUtil.isInputCompressionEmulationEnabled(conf)) {\r\n        float inputCompressionRatio = CompressionEmulationUtil.getMapInputCompressionEmulationRatio(conf);\r\n        uncompressedInputBytes /= inputCompressionRatio;\r\n    }\r\n    return uncompressedInputBytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setJobQueue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setJobQueue(Job job, String queue)\n{\r\n    if (queue != null) {\r\n        job.getConfiguration().set(MRJobConfig.QUEUE_NAME, queue);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "configureTaskJVMOptions",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void configureTaskJVMOptions(Configuration originalJobConf, Configuration simulatedJobConf)\n{\r\n    configureTaskJVMMaxHeapOptions(originalJobConf, simulatedJobConf, JobConf.MAPRED_TASK_JAVA_OPTS);\r\n    configureTaskJVMMaxHeapOptions(originalJobConf, simulatedJobConf, MRJobConfig.MAP_JAVA_OPTS);\r\n    configureTaskJVMMaxHeapOptions(originalJobConf, simulatedJobConf, MRJobConfig.REDUCE_JAVA_OPTS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "configureTaskJVMMaxHeapOptions",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void configureTaskJVMMaxHeapOptions(Configuration srcConf, Configuration destConf, String key)\n{\r\n    String srcHeapOpts = srcConf.get(key);\r\n    if (srcHeapOpts != null) {\r\n        List<String> srcMaxOptsList = new ArrayList<String>();\r\n        extractMaxHeapOpts(srcHeapOpts, srcMaxOptsList, new ArrayList<String>());\r\n        if (srcMaxOptsList.size() > 0) {\r\n            List<String> destOtherOptsList = new ArrayList<String>();\r\n            String destHeapOpts = destConf.get(key);\r\n            if (destHeapOpts != null) {\r\n                extractMaxHeapOpts(destHeapOpts, new ArrayList<String>(), destOtherOptsList);\r\n            }\r\n            StringBuilder newHeapOpts = new StringBuilder();\r\n            for (String otherOpt : destOtherOptsList) {\r\n                newHeapOpts.append(otherOpt).append(\" \");\r\n            }\r\n            for (String opts : srcMaxOptsList) {\r\n                newHeapOpts.append(opts).append(\" \");\r\n            }\r\n            destConf.set(key, newHeapOpts.toString().trim());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "scaleConfigParameter",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void scaleConfigParameter(Configuration sourceConf, Configuration destConf, String clusterValueKey, String jobValueKey, long defaultValue)\n{\r\n    long simulatedClusterDefaultValue = destConf.getLong(clusterValueKey, defaultValue);\r\n    long originalClusterDefaultValue = sourceConf.getLong(clusterValueKey, defaultValue);\r\n    long originalJobValue = sourceConf.getLong(jobValueKey, defaultValue);\r\n    double scaleFactor = (double) originalJobValue / originalClusterDefaultValue;\r\n    long simulatedJobValue = (long) (scaleFactor * simulatedClusterDefaultValue);\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"For the job configuration parameter '\" + jobValueKey + \"' and the cluster configuration parameter '\" + clusterValueKey + \"', the original job's configuration value\" + \" is scaled from '\" + originalJobValue + \"' to '\" + simulatedJobValue + \"' using the default (unit) value of \" + \"'\" + originalClusterDefaultValue + \"' for the original \" + \" cluster and '\" + simulatedClusterDefaultValue + \"' for the\" + \" simulated cluster.\");\r\n    }\r\n    destConf.setLong(jobValueKey, simulatedJobValue);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "checkMemoryUpperLimits",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean checkMemoryUpperLimits(String jobKey, String limitKey, Configuration conf, boolean convertLimitToMB)\n{\r\n    if (conf.get(limitKey) != null) {\r\n        long limit = conf.getLong(limitKey, JobConf.DISABLED_MEMORY_LIMIT);\r\n        if (limit >= 0) {\r\n            if (convertLimitToMB) {\r\n                limit /= (1024 * 1024);\r\n            }\r\n            long scaledConfigValue = conf.getLong(jobKey, JobConf.DISABLED_MEMORY_LIMIT);\r\n            if (scaledConfigValue > limit) {\r\n                throw new RuntimeException(\"Simulated job's configuration\" + \" parameter '\" + jobKey + \"' got scaled to a value '\" + scaledConfigValue + \"' which exceeds the upper limit of '\" + limit + \"' defined for the simulated cluster by the key '\" + limitKey + \"'. To disable High-Ram feature emulation, set '\" + GRIDMIX_HIGHRAM_EMULATION_ENABLE + \"' to 'false'.\");\r\n            }\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "validateTaskMemoryLimits",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void validateTaskMemoryLimits(Configuration conf, String jobKey, String clusterMaxKey)\n{\r\n    if (!checkMemoryUpperLimits(jobKey, JobConf.UPPER_LIMIT_ON_TASK_VMEM_PROPERTY, conf, true)) {\r\n        checkMemoryUpperLimits(jobKey, clusterMaxKey, conf, false);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "configureHighRamProperties",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void configureHighRamProperties(Configuration sourceConf, Configuration destConf)\n{\r\n    scaleConfigParameter(sourceConf, destConf, MRConfig.MAPMEMORY_MB, MRJobConfig.MAP_MEMORY_MB, MRJobConfig.DEFAULT_MAP_MEMORY_MB);\r\n    validateTaskMemoryLimits(destConf, MRJobConfig.MAP_MEMORY_MB, JTConfig.JT_MAX_MAPMEMORY_MB);\r\n    scaleConfigParameter(sourceConf, destConf, MRConfig.REDUCEMEMORY_MB, MRJobConfig.REDUCE_MEMORY_MB, MRJobConfig.DEFAULT_REDUCE_MEMORY_MB);\r\n    validateTaskMemoryLimits(destConf, MRJobConfig.REDUCE_MEMORY_MB, JTConfig.JT_MAX_REDUCEMEMORY_MB);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "canEmulateCompression",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean canEmulateCompression()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getUgi",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "UserGroupInformation getUgi()\n{\r\n    return ugi;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toString()\n{\r\n    return job.getJobName();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getDelay",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getDelay(TimeUnit unit)\n{\r\n    return unit.convert(submissionTimeNanos - System.nanoTime(), TimeUnit.NANOSECONDS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "int compareTo(Delayed other)\n{\r\n    if (this == other) {\r\n        return 0;\r\n    }\r\n    if (other instanceof GridmixJob) {\r\n        final long otherNanos = ((GridmixJob) other).submissionTimeNanos;\r\n        if (otherNanos < submissionTimeNanos) {\r\n            return 1;\r\n        }\r\n        if (otherNanos > submissionTimeNanos) {\r\n            return -1;\r\n        }\r\n        return id() - ((GridmixJob) other).id();\r\n    }\r\n    final long diff = getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS);\r\n    return 0 == diff ? 0 : (diff > 0 ? 1 : -1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean equals(Object other)\n{\r\n    if (this == other) {\r\n        return true;\r\n    }\r\n    return other instanceof GridmixJob && id() == ((GridmixJob) other).id();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    return id();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "id",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int id()\n{\r\n    return seq;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJob",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Job getJob()\n{\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobDesc",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobStory getJobDesc()\n{\r\n    return jobdesc;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setSubmitted",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setSubmitted()\n{\r\n    submitted = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "isSubmitted",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isSubmitted()\n{\r\n    return submitted;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "pushDescription",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void pushDescription(int seq, List<InputSplit> splits)\n{\r\n    if (null != descCache.putIfAbsent(seq, splits)) {\r\n        throw new IllegalArgumentException(\"Description exists for id \" + seq);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "pullDescription",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<InputSplit> pullDescription(JobContext jobCtxt)\n{\r\n    return pullDescription(GridmixJob.getJobSeqId(jobCtxt));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "pullDescription",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<InputSplit> pullDescription(int seq)\n{\r\n    return descCache.remove(seq);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "clearAll",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void clearAll()\n{\r\n    descCache.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "buildSplits",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void buildSplits(FilePool inputDir) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getJobSeqId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getJobSeqId(JobContext job)\n{\r\n    return job.getConfiguration().getInt(GRIDMIX_JOB_SEQ, -1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getSize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int getSize()\n{\r\n    switch(type) {\r\n        case REDUCE_SPEC:\r\n            return super.getSize() + spec.getSize() + META_BYTES;\r\n        case DATA:\r\n            return super.getSize() + META_BYTES;\r\n        default:\r\n            throw new IllegalStateException(\"Invalid type: \" + type);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setSize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setSize(int size)\n{\r\n    switch(type) {\r\n        case REDUCE_SPEC:\r\n            super.setSize(size - (META_BYTES + spec.getSize()));\r\n            break;\r\n        case DATA:\r\n            super.setSize(size - META_BYTES);\r\n            break;\r\n        default:\r\n            throw new IllegalStateException(\"Invalid type: \" + type);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getPartition",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getPartition()\n{\r\n    return partition;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setPartition",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setPartition(int partition)\n{\r\n    this.partition = partition;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceInputRecords",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getReduceInputRecords()\n{\r\n    assert REDUCE_SPEC == getType();\r\n    return spec.rec_in;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setReduceInputRecords",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setReduceInputRecords(long rec_in)\n{\r\n    assert REDUCE_SPEC == getType();\r\n    final int origSize = getSize();\r\n    spec.rec_in = rec_in;\r\n    setSize(origSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceOutputRecords",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getReduceOutputRecords()\n{\r\n    assert REDUCE_SPEC == getType();\r\n    return spec.rec_out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setReduceOutputRecords",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setReduceOutputRecords(long rec_out)\n{\r\n    assert REDUCE_SPEC == getType();\r\n    final int origSize = getSize();\r\n    spec.rec_out = rec_out;\r\n    setSize(origSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceOutputBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getReduceOutputBytes()\n{\r\n    assert REDUCE_SPEC == getType();\r\n    return spec.bytes_out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setReduceOutputBytes",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setReduceOutputBytes(long b_out)\n{\r\n    assert REDUCE_SPEC == getType();\r\n    final int origSize = getSize();\r\n    spec.bytes_out = b_out;\r\n    setSize(origSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceResourceUsageMetrics",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ResourceUsageMetrics getReduceResourceUsageMetrics()\n{\r\n    assert REDUCE_SPEC == getType();\r\n    return spec.metrics;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setReduceResourceUsageMetrics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setReduceResourceUsageMetrics(ResourceUsageMetrics metrics)\n{\r\n    assert REDUCE_SPEC == getType();\r\n    spec.setResourceUsageSpecification(metrics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getType",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte getType()\n{\r\n    return type;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setType",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setType(byte type) throws IOException\n{\r\n    final int origSize = getSize();\r\n    switch(type) {\r\n        case REDUCE_SPEC:\r\n        case DATA:\r\n            this.type = type;\r\n            break;\r\n        default:\r\n            throw new IOException(\"Invalid type: \" + type);\r\n    }\r\n    setSize(origSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setSpec",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setSpec(Spec spec)\n{\r\n    assert REDUCE_SPEC == getType();\r\n    final int origSize = getSize();\r\n    this.spec.set(spec);\r\n    setSize(origSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n    super.readFields(in);\r\n    setType(in.readByte());\r\n    if (REDUCE_SPEC == getType()) {\r\n        spec.readFields(in);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n    super.write(out);\r\n    final byte t = getType();\r\n    out.writeByte(t);\r\n    if (REDUCE_SPEC == t) {\r\n        spec.write(out);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "fixedBytes",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int fixedBytes()\n{\r\n    return super.fixedBytes() + (REDUCE_SPEC == getType() ? spec.getSize() : 0) + META_BYTES;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int compareTo(GridmixRecord other)\n{\r\n    final GridmixKey o = (GridmixKey) other;\r\n    final byte t1 = getType();\r\n    final byte t2 = o.getType();\r\n    if (t1 != t2) {\r\n        return t1 - t2;\r\n    }\r\n    return super.compareTo(other);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean equals(Object other)\n{\r\n    if (this == other) {\r\n        return true;\r\n    }\r\n    if (other != null && other.getClass() == getClass()) {\r\n        final GridmixKey o = ((GridmixKey) other);\r\n        return getType() == o.getType() && super.equals(o);\r\n    }\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int hashCode()\n{\r\n    return super.hashCode() ^ getType();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "splitFor",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "CombineFileSplit splitFor(FilePool inputDir, long bytes, int nLocs) throws IOException\n{\r\n    final ArrayList<Path> paths = new ArrayList<Path>();\r\n    final ArrayList<Long> start = new ArrayList<Long>();\r\n    final ArrayList<Long> length = new ArrayList<Long>();\r\n    final HashMap<String, Double> sb = new HashMap<String, Double>();\r\n    do {\r\n        paths.add(current.getPath());\r\n        start.add(currentStart);\r\n        final long fromFile = Math.min(bytes, current.getLen() - currentStart);\r\n        length.add(fromFile);\r\n        for (BlockLocation loc : inputDir.locationsFor(current, currentStart, fromFile)) {\r\n            final double tedium = loc.getLength() / (1.0 * bytes);\r\n            for (String l : loc.getHosts()) {\r\n                Double j = sb.get(l);\r\n                if (null == j) {\r\n                    sb.put(l, tedium);\r\n                } else {\r\n                    sb.put(l, j.doubleValue() + tedium);\r\n                }\r\n            }\r\n        }\r\n        currentStart += fromFile;\r\n        bytes -= fromFile;\r\n        CompressionCodecFactory compressionCodecs = new CompressionCodecFactory(conf);\r\n        CompressionCodec codec = compressionCodecs.getCodec(current.getPath());\r\n        if (current.getLen() - currentStart == 0 || codec != null) {\r\n            current = files.get(++idx % files.size());\r\n            currentStart = 0;\r\n        }\r\n    } while (bytes > 0);\r\n    final ArrayList<Entry<String, Double>> sort = new ArrayList<Entry<String, Double>>(sb.entrySet());\r\n    Collections.sort(sort, hostRank);\r\n    final String[] hosts = new String[Math.min(nLocs, sort.size())];\r\n    for (int i = 0; i < nLocs && i < sort.size(); ++i) {\r\n        hosts[i] = sort.get(i).getKey();\r\n    }\r\n    return new CombineFileSplit(paths.toArray(new Path[0]), toLongArray(start), toLongArray(length), hosts);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "toLongArray",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "long[] toLongArray(final ArrayList<Long> sigh)\n{\r\n    final long[] ret = new long[sigh.size()];\r\n    for (int i = 0; i < ret.length; ++i) {\r\n        ret[i] = sigh.get(i);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "configure",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void configure(Configuration conf, ResourceCalculatorPlugin monitor, ResourceUsageMetrics metrics, Progressive progress)\n{\r\n    Class[] plugins = conf.getClasses(RESOURCE_USAGE_EMULATION_PLUGINS);\r\n    if (plugins == null) {\r\n        System.out.println(\"No resource usage emulator plugins configured.\");\r\n    } else {\r\n        for (Class clazz : plugins) {\r\n            if (clazz != null) {\r\n                if (ResourceUsageEmulatorPlugin.class.isAssignableFrom(clazz)) {\r\n                    ResourceUsageEmulatorPlugin plugin = (ResourceUsageEmulatorPlugin) ReflectionUtils.newInstance(clazz, conf);\r\n                    emulationPlugins.add(plugin);\r\n                } else {\r\n                    throw new RuntimeException(\"Misconfigured resource usage plugins. \" + \"Class \" + clazz.getClass().getName() + \" is not a resource \" + \"usage plugin as it does not extend \" + ResourceUsageEmulatorPlugin.class.getName());\r\n                }\r\n            }\r\n        }\r\n    }\r\n    for (ResourceUsageEmulatorPlugin emulator : emulationPlugins) {\r\n        emulator.initialize(conf, metrics, monitor, progress);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "matchResourceUsage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void matchResourceUsage() throws IOException, InterruptedException\n{\r\n    for (ResourceUsageEmulatorPlugin emulator : emulationPlugins) {\r\n        emulator.emulate();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix\\emulators\\resourceusage",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "float getProgress()\n{\r\n    if (emulationPlugins.size() > 0) {\r\n        float progress = 0f;\r\n        for (ResourceUsageEmulatorPlugin emulator : emulationPlugins) {\r\n            progress += emulator.getProgress();\r\n        }\r\n        return progress / emulationPlugins.size();\r\n    }\r\n    return 1f;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "add",
  "errType" : [ "RejectedExecutionException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void add(final GridmixJob job) throws InterruptedException\n{\r\n    final boolean addToQueue = !shutdown;\r\n    if (addToQueue) {\r\n        final SubmitTask task = new SubmitTask(job);\r\n        LOG.info(\"Total number of queued jobs: \" + (queueDepth - sem.availablePermits()));\r\n        sem.acquire();\r\n        try {\r\n            sched.execute(task);\r\n        } catch (RejectedExecutionException e) {\r\n            sem.release();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "refreshFilePool",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void refreshFilePool() throws IOException\n{\r\n    inputDir.refresh();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void start()\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "join",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void join(long millis) throws InterruptedException\n{\r\n    if (!shutdown) {\r\n        throw new IllegalStateException(\"Cannot wait for active submit thread\");\r\n    }\r\n    sched.awaitTermination(millis, TimeUnit.MILLISECONDS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "shutdown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void shutdown()\n{\r\n    shutdown = true;\r\n    sched.shutdown();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "abort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void abort()\n{\r\n    shutdown = true;\r\n    sched.shutdownNow();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "parseUserList",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "List<UserGroupInformation> parseUserList(URI userUri, Configuration conf) throws IOException\n{\r\n    if (null == userUri) {\r\n        return Collections.emptyList();\r\n    }\r\n    final Path userloc = new Path(userUri.toString());\r\n    final Text rawUgi = new Text();\r\n    final FileSystem fs = userloc.getFileSystem(conf);\r\n    final ArrayList<UserGroupInformation> ugiList = new ArrayList<UserGroupInformation>();\r\n    LineReader in = null;\r\n    try {\r\n        in = new LineReader(fs.open(userloc));\r\n        while (in.readLine(rawUgi) > 0) {\r\n            if (rawUgi.toString().trim().equals(\"\")) {\r\n                continue;\r\n            }\r\n            int e = rawUgi.find(\",\");\r\n            if (e == 0) {\r\n                throw new IOException(\"Missing username: \" + rawUgi);\r\n            }\r\n            if (e == -1) {\r\n                e = rawUgi.getLength();\r\n            }\r\n            final String username = Text.decode(rawUgi.getBytes(), 0, e).trim();\r\n            UserGroupInformation ugi = null;\r\n            try {\r\n                ugi = UserGroupInformation.createProxyUser(username, UserGroupInformation.getLoginUser());\r\n            } catch (IOException ioe) {\r\n                LOG.error(\"Error while creating a proxy user \", ioe);\r\n            }\r\n            if (ugi != null) {\r\n                ugiList.add(ugi);\r\n            }\r\n        }\r\n    } finally {\r\n        if (in != null) {\r\n            in.close();\r\n        }\r\n    }\r\n    return ugiList;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "setTargetUsers",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean setTargetUsers(URI userloc, Configuration conf) throws IOException\n{\r\n    uidx = 0;\r\n    users = parseUserList(userloc, conf);\r\n    if (users.size() == 0) {\r\n        throw new IOException(buildEmptyUsersErrorMsg(userloc));\r\n    }\r\n    usercache.clear();\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "buildEmptyUsersErrorMsg",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String buildEmptyUsersErrorMsg(URI userloc)\n{\r\n    return \"Empty user list is not allowed for RoundRobinUserResolver. Provided\" + \" user resource URI '\" + userloc + \"' resulted in an empty user list.\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getTargetUgi",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "UserGroupInformation getTargetUgi(UserGroupInformation ugi)\n{\r\n    UserGroupInformation targetUGI = usercache.get(ugi.getUserName());\r\n    if (targetUGI == null) {\r\n        targetUGI = users.get(uidx++ % users.size());\r\n        usercache.put(ugi.getUserName(), targetUGI);\r\n    }\r\n    return targetUGI;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "needsTargetUsersList",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean needsTargetUsersList()\n{\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getId()\n{\r\n    return id;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMapCount",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getMapCount()\n{\r\n    return maps;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getInputRecords",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getInputRecords()\n{\r\n    return inputRecords;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getOutputBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long[] getOutputBytes()\n{\r\n    if (0 == reduces) {\r\n        return new long[] { outputBytes };\r\n    }\r\n    final long[] ret = new long[reduces];\r\n    for (int i = 0; i < reduces; ++i) {\r\n        ret[i] = Math.round(outputBytes * reduceBytes[i]);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getOutputRecords",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long[] getOutputRecords()\n{\r\n    if (0 == reduces) {\r\n        return new long[] { outputRecords };\r\n    }\r\n    final long[] ret = new long[reduces];\r\n    for (int i = 0; i < reduces; ++i) {\r\n        ret[i] = Math.round(outputRecords * reduceRecords[i]);\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceBytes",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getReduceBytes(int i)\n{\r\n    return reduceOutputBytes[i];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceRecords",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getReduceRecords(int i)\n{\r\n    return reduceOutputRecords[i];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getMapResourceUsageMetrics",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ResourceUsageMetrics getMapResourceUsageMetrics()\n{\r\n    return mapMetrics;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "getReduceResourceUsageMetrics",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ResourceUsageMetrics getReduceResourceUsageMetrics(int i)\n{\r\n    return reduceMetrics[i];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n    super.write(out);\r\n    WritableUtils.writeVInt(out, id);\r\n    WritableUtils.writeVInt(out, maps);\r\n    WritableUtils.writeVLong(out, inputRecords);\r\n    WritableUtils.writeVLong(out, outputBytes);\r\n    WritableUtils.writeVLong(out, outputRecords);\r\n    WritableUtils.writeVLong(out, maxMemory);\r\n    WritableUtils.writeVInt(out, reduces);\r\n    for (int i = 0; i < reduces; ++i) {\r\n        out.writeDouble(reduceBytes[i]);\r\n        out.writeDouble(reduceRecords[i]);\r\n    }\r\n    WritableUtils.writeVInt(out, nSpec);\r\n    for (int i = 0; i < nSpec; ++i) {\r\n        WritableUtils.writeVLong(out, reduceOutputBytes[i]);\r\n        WritableUtils.writeVLong(out, reduceOutputRecords[i]);\r\n    }\r\n    mapMetrics.write(out);\r\n    int numReduceMetrics = (reduceMetrics == null) ? 0 : reduceMetrics.length;\r\n    WritableUtils.writeVInt(out, numReduceMetrics);\r\n    for (int i = 0; i < numReduceMetrics; ++i) {\r\n        reduceMetrics[i].write(out);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-gridmix\\src\\main\\java\\org\\apache\\hadoop\\mapred\\gridmix",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n    super.readFields(in);\r\n    id = WritableUtils.readVInt(in);\r\n    maps = WritableUtils.readVInt(in);\r\n    inputRecords = WritableUtils.readVLong(in);\r\n    outputBytes = WritableUtils.readVLong(in);\r\n    outputRecords = WritableUtils.readVLong(in);\r\n    maxMemory = WritableUtils.readVLong(in);\r\n    reduces = WritableUtils.readVInt(in);\r\n    if (reduceBytes.length < reduces) {\r\n        reduceBytes = new double[reduces];\r\n        reduceRecords = new double[reduces];\r\n    }\r\n    for (int i = 0; i < reduces; ++i) {\r\n        reduceBytes[i] = in.readDouble();\r\n        reduceRecords[i] = in.readDouble();\r\n    }\r\n    nSpec = WritableUtils.readVInt(in);\r\n    if (reduceOutputBytes.length < nSpec) {\r\n        reduceOutputBytes = new long[nSpec];\r\n        reduceOutputRecords = new long[nSpec];\r\n    }\r\n    for (int i = 0; i < nSpec; ++i) {\r\n        reduceOutputBytes[i] = WritableUtils.readVLong(in);\r\n        reduceOutputRecords[i] = WritableUtils.readVLong(in);\r\n    }\r\n    mapMetrics = new ResourceUsageMetrics();\r\n    mapMetrics.readFields(in);\r\n    int numReduceMetrics = WritableUtils.readVInt(in);\r\n    reduceMetrics = new ResourceUsageMetrics[numReduceMetrics];\r\n    for (int i = 0; i < numReduceMetrics; ++i) {\r\n        reduceMetrics[i] = new ResourceUsageMetrics();\r\n        reduceMetrics[i].readFields(in);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]