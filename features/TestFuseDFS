[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "dumpInputStream",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void dumpInputStream(InputStream is) throws IOException\n{\r\n    int len;\r\n    do {\r\n        byte[] b = new byte[is.available()];\r\n        len = is.read(b);\r\n        System.out.println(\"Read \" + len + \" bytes\");\r\n        System.out.write(b, 0, b.length);\r\n    } while (len > 0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "checkProcessRet",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void checkProcessRet(Process p, boolean expectPass) throws IOException\n{\r\n    try {\r\n        int ret = p.waitFor();\r\n        if (ret != 0) {\r\n            dumpInputStream(p.getErrorStream());\r\n        }\r\n        if (expectPass) {\r\n            assertEquals(0, ret);\r\n        } else {\r\n            assertTrue(ret != 0);\r\n        }\r\n    } catch (InterruptedException ie) {\r\n        fail(\"Process interrupted: \" + ie.getMessage());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "execWaitRet",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void execWaitRet(String cmd) throws IOException\n{\r\n    LOG.debug(\"EXEC \" + cmd);\r\n    Process p = r.exec(cmd);\r\n    try {\r\n        p.waitFor();\r\n    } catch (InterruptedException ie) {\r\n        fail(\"Process interrupted: \" + ie.getMessage());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "execIgnoreRet",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void execIgnoreRet(String cmd) throws IOException\n{\r\n    LOG.debug(\"EXEC \" + cmd);\r\n    r.exec(cmd);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "execAssertSucceeds",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void execAssertSucceeds(String cmd) throws IOException\n{\r\n    LOG.debug(\"EXEC \" + cmd);\r\n    checkProcessRet(r.exec(cmd), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "execAssertFails",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void execAssertFails(String cmd) throws IOException\n{\r\n    LOG.debug(\"EXEC \" + cmd);\r\n    checkProcessRet(r.exec(cmd), false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "createFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void createFile(File f, String s) throws IOException\n{\r\n    InputStream is = new ByteArrayInputStream(s.getBytes());\r\n    FileOutputStream fos = new FileOutputStream(f);\r\n    IOUtils.copyBytes(is, fos, s.length(), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "checkFile",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void checkFile(File f, String expectedContents) throws IOException\n{\r\n    FileInputStream fi = new FileInputStream(f);\r\n    int len = expectedContents.length();\r\n    byte[] b = new byte[len];\r\n    try {\r\n        IOUtils.readFully(fi, b, 0, len);\r\n    } catch (IOException ie) {\r\n        fail(\"Reading \" + f.getName() + \" failed with \" + ie.getMessage());\r\n    } finally {\r\n        fi.close();\r\n    }\r\n    String s = new String(b, 0, len);\r\n    assertEquals(\"File content differs\", expectedContents, s);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "establishMount",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 19,
  "sourceCodeText" : "Process establishMount(URI uri) throws IOException\n{\r\n    Runtime r = Runtime.getRuntime();\r\n    String cp = System.getProperty(\"java.class.path\");\r\n    String buildTestDir = System.getProperty(\"build.test\");\r\n    String fuseCmd = buildTestDir + \"/../fuse_dfs\";\r\n    String libHdfs = buildTestDir + \"/../../../c++/lib\";\r\n    String arch = System.getProperty(\"os.arch\");\r\n    String jvm = System.getProperty(\"java.home\") + \"/lib/\" + arch + \"/server\";\r\n    String lp = System.getProperty(\"LD_LIBRARY_PATH\") + \":\" + libHdfs + \":\" + jvm;\r\n    LOG.debug(\"LD_LIBRARY_PATH=\" + lp);\r\n    String nameNode = \"dfs://\" + uri.getHost() + \":\" + String.valueOf(uri.getPort());\r\n    String[] mountCmd = { fuseCmd, nameNode, mountPoint, \"-obig_writes\", \"-oentry_timeout=0.1\", \"-oattribute_timeout=0.1\", \"-ononempty\", \"-f\", \"-ordbuffer=32768\", \"-omax_background=100\", \"rw\" };\r\n    String[] env = { \"CLASSPATH=\" + cp, \"LD_LIBRARY_PATH=\" + lp, \"PATH=/usr/bin:/bin\" };\r\n    execWaitRet(\"fusermount -u \" + mountPoint);\r\n    execAssertSucceeds(\"rm -rf \" + mountPoint);\r\n    execAssertSucceeds(\"mkdir -p \" + mountPoint);\r\n    String cmdStr = \"\";\r\n    for (String c : mountCmd) {\r\n        cmdStr += (\" \" + c);\r\n    }\r\n    LOG.info(\"now mounting with:\" + cmdStr);\r\n    Process fuseProcess = r.exec(mountCmd, env);\r\n    RedirectToStdoutThread stdoutThread = new RedirectToStdoutThread(fuseProcess.getInputStream());\r\n    RedirectToStdoutThread stderrThread = new RedirectToStdoutThread(fuseProcess.getErrorStream());\r\n    stdoutThread.start();\r\n    stderrThread.start();\r\n    try {\r\n        Thread.sleep(50000);\r\n    } catch (InterruptedException e) {\r\n    }\r\n    return fuseProcess;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "teardownMount",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void teardownMount() throws IOException\n{\r\n    execWaitRet(\"fusermount -u \" + mountPoint);\r\n    try {\r\n        assertEquals(0, fuseProcess.waitFor());\r\n    } catch (InterruptedException e) {\r\n        fail(\"interrupted while waiting for fuse_dfs process to exit.\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "startUp",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void startUp() throws IOException\n{\r\n    Configuration conf = new HdfsConfiguration();\r\n    r = Runtime.getRuntime();\r\n    mountPoint = System.getProperty(\"build.test\") + \"/mnt\";\r\n    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, false);\r\n    cluster = new MiniDFSCluster.Builder(conf).build();\r\n    cluster.waitClusterUp();\r\n    fs = cluster.getFileSystem();\r\n    fuseProcess = establishMount(fs.getUri());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void tearDown() throws IOException\n{\r\n    teardownMount();\r\n    if (fs != null) {\r\n        fs.close();\r\n    }\r\n    if (cluster != null) {\r\n        cluster.shutdown();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "testBasicDir",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testBasicDir() throws IOException\n{\r\n    File d = new File(mountPoint, \"dir1\");\r\n    execAssertSucceeds(\"mkdir \" + d.getAbsolutePath());\r\n    execAssertSucceeds(\"ls \" + d.getAbsolutePath());\r\n    execAssertSucceeds(\"rmdir \" + d.getAbsolutePath());\r\n    execAssertFails(\"ls \" + d.getAbsolutePath());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "testCreate",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testCreate() throws IOException\n{\r\n    final String contents = \"hello world\";\r\n    File f = new File(mountPoint, \"file1\");\r\n    createFile(f, contents);\r\n    try {\r\n        Thread.sleep(1000);\r\n    } catch (InterruptedException ie) {\r\n    }\r\n    checkFile(f, contents);\r\n    execAssertSucceeds(\"cat \" + f.getAbsolutePath());\r\n    execAssertSucceeds(\"stat \" + f.getAbsolutePath());\r\n    execAssertSucceeds(\"rm \" + f.getAbsolutePath());\r\n    execAssertFails(\"ls \" + f.getAbsolutePath());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "testTouch",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testTouch() throws IOException\n{\r\n    File f = new File(mountPoint, \"file1\");\r\n    execAssertSucceeds(\"touch \" + f.getAbsolutePath());\r\n    execAssertSucceeds(\"rm \" + f.getAbsolutePath());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "testRandomAccess",
  "errType" : [ "IOException", "IOException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testRandomAccess() throws IOException\n{\r\n    final String contents = \"hello world\";\r\n    File f = new File(mountPoint, \"file1\");\r\n    createFile(f, contents);\r\n    RandomAccessFile raf = new RandomAccessFile(f, \"rw\");\r\n    raf.seek(f.length());\r\n    try {\r\n        raf.write('b');\r\n    } catch (IOException e) {\r\n        assertEquals(\"Operation not supported\", e.getMessage());\r\n    } finally {\r\n        raf.close();\r\n    }\r\n    raf = new RandomAccessFile(f, \"rw\");\r\n    raf.seek(0);\r\n    try {\r\n        raf.write('b');\r\n        fail(\"Over-wrote existing bytes\");\r\n    } catch (IOException e) {\r\n        assertEquals(\"Invalid argument\", e.getMessage());\r\n    } finally {\r\n        raf.close();\r\n    }\r\n    execAssertSucceeds(\"rm \" + f.getAbsolutePath());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "testCopyFiles",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testCopyFiles() throws IOException\n{\r\n    final String contents = \"hello world\";\r\n    File d1 = new File(mountPoint, \"dir1\");\r\n    File d2 = new File(mountPoint, \"dir2\");\r\n    execAssertSucceeds(\"mkdir \" + d1.getAbsolutePath());\r\n    for (int i = 0; i < 5; i++) {\r\n        createFile(new File(d1, \"file\" + i), contents);\r\n    }\r\n    assertEquals(5, d1.listFiles().length);\r\n    execAssertSucceeds(\"cp -r \" + d1.getAbsolutePath() + \" \" + d2.getAbsolutePath());\r\n    assertEquals(5, d2.listFiles().length);\r\n    execAssertSucceeds(\"find \" + d1.getAbsolutePath());\r\n    execAssertSucceeds(\"find \" + d2.getAbsolutePath());\r\n    execAssertSucceeds(\"rm -r \" + d1.getAbsolutePath());\r\n    execAssertSucceeds(\"rm -r \" + d2.getAbsolutePath());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-hdfs-project\\hadoop-hdfs-native-client\\src\\main\\native\\fuse-dfs\\test",
  "methodName" : "testMultipleThreads",
  "errType" : [ "IOException", "InterruptedException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testMultipleThreads() throws IOException\n{\r\n    ArrayList<Thread> threads = new ArrayList<Thread>();\r\n    final AtomicReference<String> errorMessage = new AtomicReference<String>();\r\n    for (int i = 0; i < 10; i++) {\r\n        Thread t = new Thread() {\r\n\r\n            public void run() {\r\n                try {\r\n                    File d = new File(mountPoint, \"dir\" + getId());\r\n                    execWaitRet(\"mkdir \" + d.getAbsolutePath());\r\n                    for (int j = 0; j < 10; j++) {\r\n                        File f = new File(d, \"file\" + j);\r\n                        final String contents = \"thread \" + getId() + \" \" + j;\r\n                        createFile(f, contents);\r\n                    }\r\n                    for (int j = 0; j < 10; j++) {\r\n                        File f = new File(d, \"file\" + j);\r\n                        execWaitRet(\"cat \" + f.getAbsolutePath());\r\n                        execWaitRet(\"rm \" + f.getAbsolutePath());\r\n                    }\r\n                    execWaitRet(\"rmdir \" + d.getAbsolutePath());\r\n                } catch (IOException ie) {\r\n                    errorMessage.set(String.format(\"Exception %s\", StringUtils.stringifyException(ie)));\r\n                }\r\n            }\r\n        };\r\n        t.start();\r\n        threads.add(t);\r\n    }\r\n    for (Thread t : threads) {\r\n        try {\r\n            t.join();\r\n        } catch (InterruptedException ie) {\r\n            fail(\"Thread interrupted: \" + ie.getMessage());\r\n        }\r\n    }\r\n    assertNull(errorMessage.get(), errorMessage.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
} ]