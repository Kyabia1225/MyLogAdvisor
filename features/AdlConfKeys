[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "addDeprecatedKeys",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addDeprecatedKeys()\n{\r\n    Configuration.addDeprecations(new DeprecationDelta[] { new DeprecationDelta(\"dfs.adls.oauth2.access.token.provider.type\", AZURE_AD_TOKEN_PROVIDER_TYPE_KEY), new DeprecationDelta(\"dfs.adls.oauth2.client.id\", AZURE_AD_CLIENT_ID_KEY), new DeprecationDelta(\"dfs.adls.oauth2.refresh.token\", AZURE_AD_REFRESH_TOKEN_KEY), new DeprecationDelta(\"dfs.adls.oauth2.refresh.url\", AZURE_AD_REFRESH_URL_KEY), new DeprecationDelta(\"dfs.adls.oauth2.credential\", AZURE_AD_CLIENT_SECRET_KEY), new DeprecationDelta(\"dfs.adls.oauth2.access.token.provider\", AZURE_AD_TOKEN_PROVIDER_CLASS_KEY), new DeprecationDelta(\"adl.dfs.enable.client.latency.tracker\", LATENCY_TRACKER_KEY) });\r\n    Configuration.reloadExistingConfigurations();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "createDataLakeFileSystem",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "AdlFileSystem createDataLakeFileSystem(Configuration conf)\n{\r\n    AdlFileSystem fs = new AdlFileSystem();\r\n    fs.setConf(conf);\r\n    return fs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getUriDefaultPort",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getUriDefaultPort()\n{\r\n    return AdlFileSystem.DEFAULT_PORT;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl\\oauth2",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initialize(Configuration configuration) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl\\oauth2",
  "methodName" : "getAccessToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getAccessToken() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl\\oauth2",
  "methodName" : "getExpiryTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Date getExpiryTime()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getScheme",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getScheme()\n{\r\n    return SCHEME;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getUri",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "URI getUri()\n{\r\n    return uri;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getDefaultPort",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getDefaultPort()\n{\r\n    return DEFAULT_PORT;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "supportsSymlinks",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean supportsSymlinks()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "initialize",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 37,
  "sourceCodeText" : "void initialize(URI storeUri, Configuration originalConf) throws IOException\n{\r\n    String hostname = storeUri.getHost();\r\n    String accountName = getAccountNameFromFQDN(hostname);\r\n    Configuration conf = propagateAccountOptions(originalConf, accountName);\r\n    super.initialize(storeUri, conf);\r\n    this.setConf(conf);\r\n    this.uri = URI.create(storeUri.getScheme() + \"://\" + storeUri.getAuthority());\r\n    try {\r\n        userName = UserGroupInformation.getCurrentUser().getShortUserName();\r\n    } catch (IOException e) {\r\n        userName = \"hadoop\";\r\n        LOG.warn(\"Got exception when getting Hadoop user name.\" + \" Set the user name to '\" + userName + \"'.\", e);\r\n    }\r\n    this.setWorkingDirectory(getHomeDirectory());\r\n    overrideOwner = getConf().getBoolean(ADL_DEBUG_OVERRIDE_LOCAL_USER_AS_OWNER, ADL_DEBUG_SET_LOCAL_USER_AS_OWNER_DEFAULT);\r\n    aclBitStatus = conf.getBoolean(ADL_SUPPORT_ACL_BIT_IN_FSPERMISSION, ADL_SUPPORT_ACL_BIT_IN_FSPERMISSION_DEFAULT);\r\n    String accountFQDN = null;\r\n    String mountPoint = null;\r\n    if (!hostname.contains(\".\") && !hostname.equalsIgnoreCase(\"localhost\")) {\r\n        String hostNameProperty = \"dfs.adls.\" + hostname + \".hostname\";\r\n        String mountPointProperty = \"dfs.adls.\" + hostname + \".mountpoint\";\r\n        accountFQDN = getNonEmptyVal(conf, hostNameProperty);\r\n        mountPoint = getNonEmptyVal(conf, mountPointProperty);\r\n    } else {\r\n        accountFQDN = hostname;\r\n    }\r\n    if (storeUri.getPort() > 0) {\r\n        accountFQDN = accountFQDN + \":\" + storeUri.getPort();\r\n    }\r\n    adlClient = ADLStoreClient.createClient(accountFQDN, getAccessTokenProvider(conf));\r\n    ADLStoreOptions options = new ADLStoreOptions();\r\n    options.enableThrowingRemoteExceptions();\r\n    if (getTransportScheme().equalsIgnoreCase(INSECURE_TRANSPORT_SCHEME)) {\r\n        options.setInsecureTransport();\r\n    }\r\n    if (mountPoint != null) {\r\n        options.setFilePathPrefix(mountPoint);\r\n    }\r\n    String clusterName = conf.get(ADL_EVENTS_TRACKING_CLUSTERNAME, \"UNKNOWN\");\r\n    String clusterType = conf.get(ADL_EVENTS_TRACKING_CLUSTERTYPE, \"UNKNOWN\");\r\n    String clientVersion = ADL_HADOOP_CLIENT_NAME + (StringUtils.isEmpty(VersionInfo.getVersion().trim()) ? ADL_HADOOP_CLIENT_VERSION.trim() : VersionInfo.getVersion().trim());\r\n    options.setUserAgentSuffix(clientVersion + \"/\" + VersionInfo.getVersion().trim() + \"/\" + clusterName + \"/\" + clusterType);\r\n    int timeout = conf.getInt(ADL_HTTP_TIMEOUT, -1);\r\n    if (timeout > 0) {\r\n        options.setDefaultTimeout(timeout);\r\n    } else {\r\n        LOG.info(\"No valid ADL SDK timeout configured: using SDK default.\");\r\n    }\r\n    String sslChannelMode = conf.get(ADL_SSL_CHANNEL_MODE, \"Default\");\r\n    options.setSSLChannelMode(sslChannelMode);\r\n    adlClient.setOptions(options);\r\n    boolean trackLatency = conf.getBoolean(LATENCY_TRACKER_KEY, LATENCY_TRACKER_DEFAULT);\r\n    if (!trackLatency) {\r\n        LatencyTracker.disable();\r\n    }\r\n    boolean enableUPN = conf.getBoolean(ADL_ENABLEUPN_FOR_OWNERGROUP_KEY, ADL_ENABLEUPN_FOR_OWNERGROUP_DEFAULT);\r\n    oidOrUpn = enableUPN ? UserGroupRepresentation.UPN : UserGroupRepresentation.OID;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getCustomAccessTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "AzureADTokenProvider getCustomAccessTokenProvider(Configuration conf) throws IOException\n{\r\n    String className = getNonEmptyVal(conf, AZURE_AD_TOKEN_PROVIDER_CLASS_KEY);\r\n    Class<? extends AzureADTokenProvider> azureADTokenProviderClass = conf.getClass(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY, null, AzureADTokenProvider.class);\r\n    if (azureADTokenProviderClass == null) {\r\n        throw new IllegalArgumentException(\"Configuration  \" + className + \" \" + \"not defined/accessible.\");\r\n    }\r\n    azureTokenProvider = ReflectionUtils.newInstance(azureADTokenProviderClass, conf);\r\n    if (azureTokenProvider == null) {\r\n        throw new IllegalArgumentException(\"Failed to initialize \" + className);\r\n    }\r\n    azureTokenProvider.initialize(conf);\r\n    return azureTokenProvider;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAccessTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "AccessTokenProvider getAccessTokenProvider(Configuration config) throws IOException\n{\r\n    Configuration conf = ProviderUtils.excludeIncompatibleCredentialProviders(config, AdlFileSystem.class);\r\n    TokenProviderType type = conf.getEnum(AdlConfKeys.AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, AdlConfKeys.AZURE_AD_TOKEN_PROVIDER_TYPE_DEFAULT);\r\n    switch(type) {\r\n        case RefreshToken:\r\n            tokenProvider = getConfRefreshTokenBasedTokenProvider(conf);\r\n            break;\r\n        case ClientCredential:\r\n            tokenProvider = getConfCredentialBasedTokenProvider(conf);\r\n            break;\r\n        case MSI:\r\n            tokenProvider = getMsiBasedTokenProvider(conf);\r\n            break;\r\n        case DeviceCode:\r\n            tokenProvider = getDeviceCodeTokenProvider(conf);\r\n            break;\r\n        case Custom:\r\n        default:\r\n            AzureADTokenProvider azureADTokenProvider = getCustomAccessTokenProvider(conf);\r\n            tokenProvider = new SdkTokenProviderAdapter(azureADTokenProvider);\r\n            break;\r\n    }\r\n    return tokenProvider;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getConfCredentialBasedTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "AccessTokenProvider getConfCredentialBasedTokenProvider(Configuration conf) throws IOException\n{\r\n    String clientId = getPasswordString(conf, AZURE_AD_CLIENT_ID_KEY);\r\n    String refreshUrl = getPasswordString(conf, AZURE_AD_REFRESH_URL_KEY);\r\n    String clientSecret = getPasswordString(conf, AZURE_AD_CLIENT_SECRET_KEY);\r\n    return new ClientCredsTokenProvider(refreshUrl, clientId, clientSecret);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getConfRefreshTokenBasedTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "AccessTokenProvider getConfRefreshTokenBasedTokenProvider(Configuration conf) throws IOException\n{\r\n    String clientId = getPasswordString(conf, AZURE_AD_CLIENT_ID_KEY);\r\n    String refreshToken = getPasswordString(conf, AZURE_AD_REFRESH_TOKEN_KEY);\r\n    return new RefreshTokenBasedTokenProvider(clientId, refreshToken);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getMsiBasedTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "AccessTokenProvider getMsiBasedTokenProvider(Configuration conf) throws IOException\n{\r\n    return new MsiTokenProvider(conf.getInt(MSI_PORT, -1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getDeviceCodeTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "AccessTokenProvider getDeviceCodeTokenProvider(Configuration conf) throws IOException\n{\r\n    String clientAppId = getNonEmptyVal(conf, DEVICE_CODE_CLIENT_APP_ID);\r\n    return new DeviceCodeTokenProvider(clientAppId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AccessTokenProvider getTokenProvider()\n{\r\n    return tokenProvider;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAzureTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AzureADTokenProvider getAzureTokenProvider()\n{\r\n    return azureTokenProvider;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAdlClient",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ADLStoreClient getAdlClient()\n{\r\n    return adlClient;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getHomeDirectory",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path getHomeDirectory()\n{\r\n    return makeQualified(new Path(\"/user/\" + userName));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FSDataOutputStream create(Path f, FsPermission permission, boolean overwrite, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    IfExists overwriteRule = overwrite ? IfExists.OVERWRITE : IfExists.FAIL;\r\n    return new FSDataOutputStream(new AdlFsOutputStream(adlClient.createFile(toRelativeFilePath(f), overwriteRule, Integer.toOctalString(applyUMask(permission).toShort()), true), getConf()), this.statistics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "createNonRecursive",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FSDataOutputStream createNonRecursive(Path f, FsPermission permission, EnumSet<CreateFlag> flags, int bufferSize, short replication, long blockSize, Progressable progress) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    IfExists overwriteRule = IfExists.FAIL;\r\n    for (CreateFlag flag : flags) {\r\n        if (flag == CreateFlag.OVERWRITE) {\r\n            overwriteRule = IfExists.OVERWRITE;\r\n            break;\r\n        }\r\n    }\r\n    return new FSDataOutputStream(new AdlFsOutputStream(adlClient.createFile(toRelativeFilePath(f), overwriteRule, Integer.toOctalString(applyUMask(permission).toShort()), false), getConf()), this.statistics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "append",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FSDataOutputStream append(Path f, int bufferSize, Progressable progress) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    return new FSDataOutputStream(new AdlFsOutputStream(adlClient.getAppendStream(toRelativeFilePath(f)), getConf()), this.statistics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setReplication",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean setReplication(final Path p, final short replication) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "open",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FSDataInputStream open(final Path f, final int buffersize) throws IOException\n{\r\n    statistics.incrementReadOps(1);\r\n    return new FSDataInputStream(new AdlFsInputStream(adlClient.getReadStream(toRelativeFilePath(f)), statistics, getConf()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getFileStatus",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FileStatus getFileStatus(final Path f) throws IOException\n{\r\n    statistics.incrementReadOps(1);\r\n    DirectoryEntry entry = adlClient.getDirectoryEntry(toRelativeFilePath(f), oidOrUpn);\r\n    return toFileStatus(entry, f);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "listStatus",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FileStatus[] listStatus(final Path f) throws IOException\n{\r\n    statistics.incrementReadOps(1);\r\n    List<DirectoryEntry> entries = adlClient.enumerateDirectory(toRelativeFilePath(f), oidOrUpn);\r\n    return toFileStatuses(entries, f);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "rename",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean rename(final Path src, final Path dst) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    if (toRelativeFilePath(src).equals(\"/\")) {\r\n        return false;\r\n    }\r\n    return adlClient.rename(toRelativeFilePath(src), toRelativeFilePath(dst));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "rename",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void rename(final Path src, final Path dst, final Options.Rename... options) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    boolean overwrite = false;\r\n    for (Rename renameOption : options) {\r\n        if (renameOption == Rename.OVERWRITE) {\r\n            overwrite = true;\r\n            break;\r\n        }\r\n    }\r\n    adlClient.rename(toRelativeFilePath(src), toRelativeFilePath(dst), overwrite);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "concat",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void concat(final Path trg, final Path[] srcs) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    List<String> sourcesList = new ArrayList<String>();\r\n    for (Path entry : srcs) {\r\n        sourcesList.add(toRelativeFilePath(entry));\r\n    }\r\n    adlClient.concatenateFiles(toRelativeFilePath(trg), sourcesList);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "delete",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "boolean delete(final Path path, final boolean recursive) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    String relativePath = toRelativeFilePath(path);\r\n    if (relativePath.equals(\"/\")) {\r\n        if (!recursive && adlClient.enumerateDirectory(toRelativeFilePath(path), 1).size() > 0) {\r\n            throw new IOException(\"Delete on root is not supported.\");\r\n        }\r\n        return false;\r\n    }\r\n    return recursive ? adlClient.deleteRecursive(relativePath) : adlClient.delete(relativePath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "mkdirs",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean mkdirs(final Path path, final FsPermission permission) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    return adlClient.createDirectory(toRelativeFilePath(path), Integer.toOctalString(applyUMask(permission).toShort()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "toFileStatuses",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FileStatus[] toFileStatuses(final List<DirectoryEntry> entries, final Path parent)\n{\r\n    FileStatus[] fileStatuses = new FileStatus[entries.size()];\r\n    int index = 0;\r\n    for (DirectoryEntry entry : entries) {\r\n        FileStatus status = toFileStatus(entry, parent);\r\n        if (!(entry.name == null || entry.name == \"\")) {\r\n            status.setPath(new Path(parent.makeQualified(uri, workingDirectory), entry.name));\r\n        }\r\n        fileStatuses[index++] = status;\r\n    }\r\n    return fileStatuses;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "applyUMask",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "FsPermission applyUMask(FsPermission permission)\n{\r\n    if (permission == null) {\r\n        permission = FsPermission.getDefault();\r\n    }\r\n    return permission.applyUMask(FsPermission.getUMask(getConf()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "toFileStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FileStatus toFileStatus(final DirectoryEntry entry, final Path f)\n{\r\n    Path p = makeQualified(f);\r\n    boolean aclBit = aclBitStatus ? entry.aclBit : false;\r\n    if (overrideOwner) {\r\n        return new AdlFileStatus(entry, p, userName, \"hdfs\", aclBit);\r\n    }\r\n    return new AdlFileStatus(entry, p, aclBit);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setOwner",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setOwner(final Path path, final String owner, final String group) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    adlClient.setOwner(toRelativeFilePath(path), owner, group);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setPermission",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setPermission(final Path path, final FsPermission permission) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    adlClient.setPermission(toRelativeFilePath(path), Integer.toOctalString(permission.toShort()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "modifyAclEntries",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void modifyAclEntries(final Path path, final List<AclEntry> aclSpec) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    List<com.microsoft.azure.datalake.store.acl.AclEntry> msAclEntries = new ArrayList<com.microsoft.azure.datalake.store.acl.AclEntry>();\r\n    for (AclEntry aclEntry : aclSpec) {\r\n        msAclEntries.add(com.microsoft.azure.datalake.store.acl.AclEntry.parseAclEntry(aclEntry.toString()));\r\n    }\r\n    adlClient.modifyAclEntries(toRelativeFilePath(path), msAclEntries);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "removeAclEntries",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void removeAclEntries(final Path path, final List<AclEntry> aclSpec) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    List<com.microsoft.azure.datalake.store.acl.AclEntry> msAclEntries = new ArrayList<com.microsoft.azure.datalake.store.acl.AclEntry>();\r\n    for (AclEntry aclEntry : aclSpec) {\r\n        msAclEntries.add(com.microsoft.azure.datalake.store.acl.AclEntry.parseAclEntry(aclEntry.toString(), true));\r\n    }\r\n    adlClient.removeAclEntries(toRelativeFilePath(path), msAclEntries);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "removeDefaultAcl",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeDefaultAcl(final Path path) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    adlClient.removeDefaultAcls(toRelativeFilePath(path));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "removeAcl",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeAcl(final Path path) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    adlClient.removeAllAcls(toRelativeFilePath(path));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setAcl",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setAcl(final Path path, final List<AclEntry> aclSpec) throws IOException\n{\r\n    statistics.incrementWriteOps(1);\r\n    List<com.microsoft.azure.datalake.store.acl.AclEntry> msAclEntries = new ArrayList<com.microsoft.azure.datalake.store.acl.AclEntry>();\r\n    for (AclEntry aclEntry : aclSpec) {\r\n        msAclEntries.add(com.microsoft.azure.datalake.store.acl.AclEntry.parseAclEntry(aclEntry.toString()));\r\n    }\r\n    adlClient.setAcl(toRelativeFilePath(path), msAclEntries);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAclStatus",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "AclStatus getAclStatus(final Path path) throws IOException\n{\r\n    statistics.incrementReadOps(1);\r\n    com.microsoft.azure.datalake.store.acl.AclStatus adlStatus = adlClient.getAclStatus(toRelativeFilePath(path), oidOrUpn);\r\n    AclStatus.Builder aclStatusBuilder = new AclStatus.Builder();\r\n    aclStatusBuilder.owner(adlStatus.owner);\r\n    aclStatusBuilder.group(adlStatus.group);\r\n    aclStatusBuilder.setPermission(new FsPermission(Short.valueOf(adlStatus.octalPermissions, 8)));\r\n    aclStatusBuilder.stickyBit(adlStatus.stickyBit);\r\n    String aclListString = com.microsoft.azure.datalake.store.acl.AclEntry.aclListToString(adlStatus.aclSpec);\r\n    List<AclEntry> aclEntries = AclEntry.parseAclSpec(aclListString, true);\r\n    aclStatusBuilder.addEntries(aclEntries);\r\n    return aclStatusBuilder.build();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "access",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void access(final Path path, FsAction mode) throws IOException\n{\r\n    statistics.incrementReadOps(1);\r\n    if (!adlClient.checkAccess(toRelativeFilePath(path), mode.SYMBOL)) {\r\n        throw new AccessControlException(\"Access Denied : \" + path.toString());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getContentSummary",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "ContentSummary getContentSummary(Path f) throws IOException\n{\r\n    statistics.incrementReadOps(1);\r\n    com.microsoft.azure.datalake.store.ContentSummary msSummary = adlClient.getContentSummary(toRelativeFilePath(f));\r\n    return new Builder().length(msSummary.length).directoryCount(msSummary.directoryCount).fileCount(msSummary.fileCount).spaceConsumed(msSummary.spaceConsumed).build();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getTransportScheme",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getTransportScheme()\n{\r\n    return SECURE_TRANSPORT_SCHEME;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "toRelativeFilePath",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toRelativeFilePath(Path path)\n{\r\n    return path.makeQualified(uri, workingDirectory).toUri().getPath();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getWorkingDirectory()\n{\r\n    return workingDirectory;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setWorkingDirectory(final Path dir)\n{\r\n    if (dir == null) {\r\n        throw new InvalidPathException(\"Working directory cannot be set to NULL\");\r\n    }\r\n    this.workingDirectory = this.makeAbsolute(dir);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getDefaultBlockSize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getDefaultBlockSize()\n{\r\n    return ADL_BLOCK_SIZE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getDefaultBlockSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getDefaultBlockSize(Path f)\n{\r\n    return getDefaultBlockSize();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getBlockSize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getBlockSize(Path f) throws IOException\n{\r\n    return ADL_BLOCK_SIZE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getReplication",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "short getReplication(Path src)\n{\r\n    return ADL_REPLICATION_FACTOR;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "makeAbsolute",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path makeAbsolute(Path path)\n{\r\n    return path.isAbsolute() ? path : new Path(this.workingDirectory, path);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getNonEmptyVal",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getNonEmptyVal(Configuration conf, String key)\n{\r\n    String value = conf.get(key);\r\n    if (StringUtils.isEmpty(value)) {\r\n        throw new IllegalArgumentException(\"No value for \" + key + \" found in conf file.\");\r\n    }\r\n    return value;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getPasswordString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getPasswordString(Configuration conf, String key) throws IOException\n{\r\n    char[] passchars = conf.getPassword(key);\r\n    if (passchars == null) {\r\n        throw new IOException(\"Password \" + key + \" not found\");\r\n    }\r\n    return new String(passchars);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setUserGroupRepresentationAsUPN",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setUserGroupRepresentationAsUPN(boolean enableUPN)\n{\r\n    oidOrUpn = enableUPN ? UserGroupRepresentation.UPN : UserGroupRepresentation.OID;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAccountNameFromFQDN",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getAccountNameFromFQDN(String accountFQDN)\n{\r\n    return accountFQDN.contains(\".\") ? accountFQDN.substring(0, accountFQDN.indexOf(\".\")) : accountFQDN;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "propagateAccountOptions",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "Configuration propagateAccountOptions(Configuration source, String accountName)\n{\r\n    Preconditions.checkArgument(StringUtils.isNotEmpty(accountName), \"accountName\");\r\n    final String accountPrefix = AZURE_AD_ACCOUNT_PREFIX + accountName + '.';\r\n    LOG.debug(\"Propagating entries under {}\", accountPrefix);\r\n    final Configuration dest = new Configuration(source);\r\n    for (Map.Entry<String, String> entry : source) {\r\n        final String key = entry.getKey();\r\n        final String value = entry.getValue();\r\n        if (!key.startsWith(accountPrefix) || accountPrefix.equals(key)) {\r\n            continue;\r\n        }\r\n        final String stripped = key.substring(accountPrefix.length());\r\n        String origin = \"[\" + StringUtils.join(source.getPropertySources(key), \", \") + \"]\";\r\n        final String generic = AZURE_AD_PREFIX + stripped;\r\n        LOG.debug(\"Updating {} from {}\", generic, origin);\r\n        dest.set(generic, value, key + \" via \" + origin);\r\n    }\r\n    return dest;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hasPathCapability",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean hasPathCapability(final Path path, final String capability) throws IOException\n{\r\n    switch(validatePathCapabilityArgs(makeQualified(path), capability)) {\r\n        case CommonPathCapabilities.FS_ACLS:\r\n        case CommonPathCapabilities.FS_APPEND:\r\n        case CommonPathCapabilities.FS_CONCAT:\r\n        case CommonPathCapabilities.FS_PERMISSIONS:\r\n            return true;\r\n        default:\r\n            return super.hasPathCapability(path, capability);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hasAcl",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean hasAcl()\n{\r\n    return hasAcl;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean equals(Object o)\n{\r\n    return super.equals(o);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    return super.hashCode();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "seek",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void seek(long pos) throws IOException\n{\r\n    in.seek(pos);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getPos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getPos() throws IOException\n{\r\n    return in.getPos();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "seekToNewSource",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean seekToNewSource(long l) throws IOException\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int read() throws IOException\n{\r\n    int ch = in.read();\r\n    if (stat != null && ch != -1) {\r\n        stat.incrementBytesRead(1);\r\n    }\r\n    return ch;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int read(long position, byte[] buffer, int offset, int length) throws IOException\n{\r\n    int numberOfByteRead = 0;\r\n    if (enablePositionalReadExperiment) {\r\n        numberOfByteRead = in.read(position, buffer, offset, length);\r\n    } else {\r\n        numberOfByteRead = super.read(position, buffer, offset, length);\r\n    }\r\n    if (stat != null && numberOfByteRead > 0) {\r\n        stat.incrementBytesRead(numberOfByteRead);\r\n    }\r\n    return numberOfByteRead;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int read(byte[] buffer, int offset, int length) throws IOException\n{\r\n    int numberOfByteRead = in.read(buffer, offset, length);\r\n    if (stat != null && numberOfByteRead > 0) {\r\n        stat.incrementBytesRead(numberOfByteRead);\r\n    }\r\n    return numberOfByteRead;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "available",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int available() throws IOException\n{\r\n    return (int) Math.min(in.length() - in.getPos(), Integer.MAX_VALUE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    in.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "skip",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long skip(long pos) throws IOException\n{\r\n    return in.skip(pos);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "refreshToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "AzureADToken refreshToken() throws IOException\n{\r\n    AzureADToken azureADToken = new AzureADToken();\r\n    azureADToken.accessToken = tokenProvider.getAccessToken();\r\n    azureADToken.expiry = tokenProvider.getExpiryTime();\r\n    return azureADToken;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void write(int b) throws IOException\n{\r\n    out.write(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void write(byte[] b, int off, int len) throws IOException\n{\r\n    out.write(b, off, len);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    out.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "sync",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void sync() throws IOException\n{\r\n    out.flush();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hflush",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void hflush() throws IOException\n{\r\n    out.flush();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hsync",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void hsync() throws IOException\n{\r\n    out.flush();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hasCapability",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean hasCapability(String capability)\n{\r\n    return StoreImplementationUtils.isProbeForSyncable(capability);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAclBit",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean getAclBit()\n{\r\n    return aclBit;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "boolean equals(Object obj)\n{\r\n    if (obj instanceof FsPermission) {\r\n        FsPermission that = (FsPermission) obj;\r\n        return this.getUserAction() == that.getUserAction() && this.getGroupAction() == that.getGroupAction() && this.getOtherAction() == that.getOtherAction() && this.getStickyBit() == that.getStickyBit();\r\n    }\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\main\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    return toShort();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]