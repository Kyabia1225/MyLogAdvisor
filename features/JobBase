[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "setLongValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setLongValue(Object name, long value)\n{\r\n    this.longCounters.put(name, Long.valueOf(value));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "setDoubleValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setDoubleValue(Object name, double value)\n{\r\n    this.doubleCounters.put(name, new Double(value));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "getLongValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Long getLongValue(Object name)\n{\r\n    return this.longCounters.get(name);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "getDoubleValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Double getDoubleValue(Object name)\n{\r\n    return this.doubleCounters.get(name);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "addLongValue",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "Long addLongValue(Object name, long inc)\n{\r\n    Long val = this.longCounters.get(name);\r\n    Long retv = null;\r\n    if (val == null) {\r\n        retv = Long.valueOf(inc);\r\n    } else {\r\n        retv = Long.valueOf(val.longValue() + inc);\r\n    }\r\n    this.longCounters.put(name, retv);\r\n    return retv;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "addDoubleValue",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Double addDoubleValue(Object name, double inc)\n{\r\n    Double val = this.doubleCounters.get(name);\r\n    Double retv = null;\r\n    if (val == null) {\r\n        retv = new Double(inc);\r\n    } else {\r\n        retv = new Double(val.doubleValue() + inc);\r\n    }\r\n    this.doubleCounters.put(name, retv);\r\n    return retv;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "report",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void report()\n{\r\n    LOG.info(getReport());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "getReport",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "String getReport()\n{\r\n    StringBuffer sb = new StringBuffer();\r\n    Iterator iter = this.longCounters.entrySet().iterator();\r\n    while (iter.hasNext()) {\r\n        Entry e = (Entry) iter.next();\r\n        sb.append(e.getKey().toString()).append(\"\\t\").append(e.getValue()).append(\"\\n\");\r\n    }\r\n    iter = this.doubleCounters.entrySet().iterator();\r\n    while (iter.hasNext()) {\r\n        Entry e = (Entry) iter.next();\r\n        sb.append(e.getKey().toString()).append(\"\\t\").append(e.getValue()).append(\"\\n\");\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "configure",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    this.longCounters = new TreeMap<Object, Long>();\r\n    this.doubleCounters = new TreeMap<Object, Double>();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "getTag",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getTag()\n{\r\n    return tag;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "setTag",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTag(Text tag)\n{\r\n    this.tag = tag;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "getData",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Writable getData()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "clone",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaggedMapOutput clone(JobConf job)\n{\r\n    return (TaggedMapOutput) WritableUtils.clone(this, job);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "getClassByName",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Class getClassByName(String className)\n{\r\n    Class retv = null;\r\n    try {\r\n        ClassLoader classLoader = Thread.currentThread().getContextClassLoader();\r\n        retv = Class.forName(className, true, classLoader);\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n    return retv;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "createDataJoinJob",
  "errType" : null,
  "containingMethodsNum" : 29,
  "sourceCodeText" : "JobConf createDataJoinJob(String[] args) throws IOException\n{\r\n    String inputDir = args[0];\r\n    String outputDir = args[1];\r\n    Class inputFormat = SequenceFileInputFormat.class;\r\n    if (args[2].compareToIgnoreCase(\"text\") != 0) {\r\n        System.out.println(\"Using SequenceFileInputFormat: \" + args[2]);\r\n    } else {\r\n        System.out.println(\"Using TextInputFormat: \" + args[2]);\r\n        inputFormat = TextInputFormat.class;\r\n    }\r\n    int numOfReducers = Integer.parseInt(args[3]);\r\n    Class mapper = getClassByName(args[4]);\r\n    Class reducer = getClassByName(args[5]);\r\n    Class mapoutputValueClass = getClassByName(args[6]);\r\n    Class outputFormat = TextOutputFormat.class;\r\n    Class outputValueClass = Text.class;\r\n    if (args[7].compareToIgnoreCase(\"text\") != 0) {\r\n        System.out.println(\"Using SequenceFileOutputFormat: \" + args[7]);\r\n        outputFormat = SequenceFileOutputFormat.class;\r\n        outputValueClass = getClassByName(args[7]);\r\n    } else {\r\n        System.out.println(\"Using TextOutputFormat: \" + args[7]);\r\n    }\r\n    long maxNumOfValuesPerGroup = 100;\r\n    String jobName = \"\";\r\n    if (args.length > 8) {\r\n        maxNumOfValuesPerGroup = Long.parseLong(args[8]);\r\n    }\r\n    if (args.length > 9) {\r\n        jobName = args[9];\r\n    }\r\n    Configuration defaults = new Configuration();\r\n    JobConf job = new JobConf(defaults, DataJoinJob.class);\r\n    job.setJobName(\"DataJoinJob: \" + jobName);\r\n    FileSystem fs = FileSystem.get(defaults);\r\n    fs.delete(new Path(outputDir), true);\r\n    FileInputFormat.setInputPaths(job, inputDir);\r\n    job.setInputFormat(inputFormat);\r\n    job.setMapperClass(mapper);\r\n    FileOutputFormat.setOutputPath(job, new Path(outputDir));\r\n    job.setOutputFormat(outputFormat);\r\n    SequenceFileOutputFormat.setOutputCompressionType(job, SequenceFile.CompressionType.BLOCK);\r\n    job.setMapOutputKeyClass(Text.class);\r\n    job.setMapOutputValueClass(mapoutputValueClass);\r\n    job.setOutputKeyClass(Text.class);\r\n    job.setOutputValueClass(outputValueClass);\r\n    job.setReducerClass(reducer);\r\n    job.setNumMapTasks(1);\r\n    job.setNumReduceTasks(numOfReducers);\r\n    job.setLong(\"datajoin.maxNumOfValuesPerGroup\", maxNumOfValuesPerGroup);\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "runJob",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "boolean runJob(JobConf job) throws IOException\n{\r\n    JobClient jc = new JobClient(job);\r\n    boolean sucess = true;\r\n    RunningJob running = null;\r\n    try {\r\n        running = jc.submitJob(job);\r\n        JobID jobId = running.getID();\r\n        System.out.println(\"Job \" + jobId + \" is submitted\");\r\n        while (!running.isComplete()) {\r\n            System.out.println(\"Job \" + jobId + \" is still running.\");\r\n            try {\r\n                Thread.sleep(60000);\r\n            } catch (InterruptedException e) {\r\n            }\r\n            running = jc.getJob(jobId);\r\n        }\r\n        sucess = running.isSuccessful();\r\n    } finally {\r\n        if (!sucess && (running != null)) {\r\n            running.killJob();\r\n        }\r\n        jc.close();\r\n    }\r\n    return sucess;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "main",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    boolean success;\r\n    if (args.length < 8 || args.length > 10) {\r\n        System.out.println(\"usage: DataJoinJob \" + \"inputdirs outputdir map_input_file_format \" + \"numofParts \" + \"mapper_class \" + \"reducer_class \" + \"map_output_value_class \" + \"output_value_class [maxNumOfValuesPerGroup [descriptionOfJob]]]\");\r\n        System.exit(-1);\r\n    }\r\n    try {\r\n        JobConf job = DataJoinJob.createDataJoinJob(args);\r\n        success = DataJoinJob.runJob(job);\r\n        if (!success) {\r\n            System.out.println(\"Job failed\");\r\n        }\r\n    } catch (IOException ioe) {\r\n        ioe.printStackTrace();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "add",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void add(Object item)\n{\r\n    this.data.add(item);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "hasNext",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean hasNext()\n{\r\n    return this.iter.hasNext();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Object next()\n{\r\n    return this.iter.next();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "remove",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void remove()\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "reset",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void reset()\n{\r\n    this.iter = this.data.iterator();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    this.iter = null;\r\n    this.data = null;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "configure",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    super.configure(job);\r\n    this.job = job;\r\n    this.inputFile = job.get(MRJobConfig.MAP_INPUT_FILE);\r\n    this.inputTag = generateInputTag(this.inputFile);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "generateInputTag",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text generateInputTag(String inputFile)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "generateTaggedMapOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaggedMapOutput generateTaggedMapOutput(Object value)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "generateGroupKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text generateGroupKey(TaggedMapOutput aRecord)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "map",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void map(Object key, Object value, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    if (this.reporter == null) {\r\n        this.reporter = reporter;\r\n    }\r\n    addLongValue(\"totalCount\", 1);\r\n    TaggedMapOutput aRecord = generateTaggedMapOutput(value);\r\n    if (aRecord == null) {\r\n        addLongValue(\"discardedCount\", 1);\r\n        return;\r\n    }\r\n    Text groupKey = generateGroupKey(aRecord);\r\n    if (groupKey == null) {\r\n        addLongValue(\"nullGroupKeyCount\", 1);\r\n        return;\r\n    }\r\n    output.collect(groupKey, aRecord);\r\n    addLongValue(\"collectedCount\", 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (this.reporter != null) {\r\n        this.reporter.setStatus(super.getReport());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "reduce",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void reduce(Object arg0, Iterator arg1, OutputCollector arg2, Reporter arg3) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (this.reporter != null) {\r\n        this.reporter.setStatus(super.getReport());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "configure",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    super.configure(job);\r\n    this.job = job;\r\n    this.maxNumOfValuesPerGroup = job.getLong(\"datajoin.maxNumOfValuesPerGroup\", 100);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "createResetableIterator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ResetableIterator createResetableIterator()\n{\r\n    return new ArrayListBackedIterator();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "regroup",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "SortedMap<Object, ResetableIterator> regroup(Object key, Iterator arg1, Reporter reporter) throws IOException\n{\r\n    this.numOfValues = 0;\r\n    SortedMap<Object, ResetableIterator> retv = new TreeMap<Object, ResetableIterator>();\r\n    TaggedMapOutput aRecord = null;\r\n    while (arg1.hasNext()) {\r\n        this.numOfValues += 1;\r\n        if (this.numOfValues % 100 == 0) {\r\n            reporter.setStatus(\"key: \" + key.toString() + \" numOfValues: \" + this.numOfValues);\r\n        }\r\n        if (this.numOfValues > this.maxNumOfValuesPerGroup) {\r\n            continue;\r\n        }\r\n        aRecord = ((TaggedMapOutput) arg1.next()).clone(job);\r\n        Text tag = aRecord.getTag();\r\n        ResetableIterator data = retv.get(tag);\r\n        if (data == null) {\r\n            data = createResetableIterator();\r\n            retv.put(tag, data);\r\n        }\r\n        data.add(aRecord);\r\n    }\r\n    if (this.numOfValues > this.largestNumOfValues) {\r\n        this.largestNumOfValues = numOfValues;\r\n        LOG.info(\"key: \" + key.toString() + \" this.largestNumOfValues: \" + this.largestNumOfValues);\r\n    }\r\n    return retv;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "reduce",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void reduce(Object key, Iterator values, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    if (this.reporter == null) {\r\n        this.reporter = reporter;\r\n    }\r\n    SortedMap<Object, ResetableIterator> groups = regroup(key, values, reporter);\r\n    Object[] tags = groups.keySet().toArray();\r\n    ResetableIterator[] groupValues = new ResetableIterator[tags.length];\r\n    for (int i = 0; i < tags.length; i++) {\r\n        groupValues[i] = groups.get(tags[i]);\r\n    }\r\n    joinAndCollect(tags, groupValues, key, output, reporter);\r\n    addLongValue(\"groupCount\", 1);\r\n    for (int i = 0; i < tags.length; i++) {\r\n        groupValues[i].close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "collect",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void collect(Object key, TaggedMapOutput aRecord, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    this.collected += 1;\r\n    addLongValue(\"collectedCount\", 1);\r\n    if (aRecord != null) {\r\n        output.collect(key, aRecord.getData());\r\n        reporter.setStatus(\"key: \" + key.toString() + \" collected: \" + collected);\r\n        addLongValue(\"actuallyCollectedCount\", 1);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "joinAndCollect",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void joinAndCollect(Object[] tags, ResetableIterator[] values, Object key, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    if (values.length < 1) {\r\n        return;\r\n    }\r\n    Object[] partialList = new Object[values.length];\r\n    joinAndCollect(tags, values, 0, partialList, key, output, reporter);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "joinAndCollect",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void joinAndCollect(Object[] tags, ResetableIterator[] values, int pos, Object[] partialList, Object key, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    if (values.length == pos) {\r\n        TaggedMapOutput combined = combine(tags, partialList);\r\n        collect(key, combined, output, reporter);\r\n        return;\r\n    }\r\n    ResetableIterator nextValues = values[pos];\r\n    nextValues.reset();\r\n    while (nextValues.hasNext()) {\r\n        Object v = nextValues.next();\r\n        partialList[pos] = v;\r\n        joinAndCollect(tags, values, pos + 1, partialList, key, output, reporter);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "combine",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaggedMapOutput combine(Object[] tags, Object[] values)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-datajoin\\src\\main\\java\\org\\apache\\hadoop\\contrib\\utils\\join",
  "methodName" : "map",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void map(Object arg0, Object arg1, OutputCollector arg2, Reporter arg3) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]