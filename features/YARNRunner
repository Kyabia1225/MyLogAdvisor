[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setResourceMgrDelegate",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setResourceMgrDelegate(ResourceMgrDelegate resMgrDelegate)\n{\r\n    this.resMgrDelegate = resMgrDelegate;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "cancelDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void cancelDelegationToken(Token<DelegationTokenIdentifier> arg0) throws IOException, InterruptedException\n{\r\n    throw new UnsupportedOperationException(\"Use Token.renew instead\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getActiveTrackers",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTrackerInfo[] getActiveTrackers() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getActiveTrackers();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getAllJobs",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobStatus[] getAllJobs() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getAllJobs();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getBlacklistedTrackers",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTrackerInfo[] getBlacklistedTrackers() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getBlacklistedTrackers();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getClusterMetrics",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ClusterMetrics getClusterMetrics() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getClusterMetrics();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "addHistoryToken",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void addHistoryToken(Credentials ts) throws IOException, InterruptedException\n{\r\n    MRClientProtocol hsProxy = clientCache.getInitializedHSProxy();\r\n    if (UserGroupInformation.isSecurityEnabled() && (hsProxy != null)) {\r\n        RMDelegationTokenSelector tokenSelector = new RMDelegationTokenSelector();\r\n        Text service = resMgrDelegate.getRMDelegationTokenService();\r\n        if (tokenSelector.selectToken(service, ts.getAllTokens()) != null) {\r\n            Text hsService = SecurityUtil.buildTokenService(hsProxy.getConnectAddress());\r\n            if (ts.getToken(hsService) == null) {\r\n                ts.addToken(hsService, getDelegationTokenFromHS(hsProxy));\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getDelegationTokenFromHS",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "Token<?> getDelegationTokenFromHS(MRClientProtocol hsProxy) throws IOException, InterruptedException\n{\r\n    GetDelegationTokenRequest request = recordFactory.newRecordInstance(GetDelegationTokenRequest.class);\r\n    request.setRenewer(Master.getMasterPrincipal(conf));\r\n    org.apache.hadoop.yarn.api.records.Token mrDelegationToken;\r\n    mrDelegationToken = hsProxy.getDelegationToken(request).getDelegationToken();\r\n    return ConverterUtils.convertFromYarn(mrDelegationToken, hsProxy.getConnectAddress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Token<DelegationTokenIdentifier> getDelegationToken(Text renewer) throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getDelegationToken(renewer);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getFilesystemName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getFilesystemName() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getFilesystemName();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNewJobID",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobID getNewJobID() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getNewJobID();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo getQueue(String queueName) throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getQueue(queueName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueAclsForCurrentUser",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueAclsInfo[] getQueueAclsForCurrentUser() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getQueueAclsForCurrentUser();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueues",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo[] getQueues() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getQueues();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getRootQueues",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo[] getRootQueues() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getRootQueues();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getChildQueues",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo[] getChildQueues(String parent) throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getChildQueues(parent);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getStagingAreaDir",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getStagingAreaDir() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getStagingAreaDir();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getSystemDir",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getSystemDir() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getSystemDir();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskTrackerExpiryInterval",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getTaskTrackerExpiryInterval() throws IOException, InterruptedException\n{\r\n    return resMgrDelegate.getTaskTrackerExpiryInterval();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "submitJob",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "JobStatus submitJob(JobID jobId, String jobSubmitDir, Credentials ts) throws IOException, InterruptedException\n{\r\n    addHistoryToken(ts);\r\n    ApplicationSubmissionContext appContext = createApplicationSubmissionContext(conf, jobSubmitDir, ts);\r\n    try {\r\n        ApplicationId applicationId = resMgrDelegate.submitApplication(appContext);\r\n        ApplicationReport appMaster = resMgrDelegate.getApplicationReport(applicationId);\r\n        String diagnostics = (appMaster == null ? \"application report is null\" : appMaster.getDiagnostics());\r\n        if (appMaster == null || appMaster.getYarnApplicationState() == YarnApplicationState.FAILED || appMaster.getYarnApplicationState() == YarnApplicationState.KILLED) {\r\n            throw new IOException(\"Failed to run job : \" + diagnostics);\r\n        }\r\n        return clientCache.getClient(jobId).getJobStatus(jobId);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "createApplicationResource",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "LocalResource createApplicationResource(FileContext fs, Path p, LocalResourceType type) throws IOException\n{\r\n    return createApplicationResource(fs, p, null, type, LocalResourceVisibility.APPLICATION, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "createApplicationResource",
  "errType" : [ "URISyntaxException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "LocalResource createApplicationResource(FileContext fs, Path p, String fileSymlink, LocalResourceType type, LocalResourceVisibility viz, Boolean uploadToSharedCache) throws IOException\n{\r\n    LocalResource rsrc = recordFactory.newRecordInstance(LocalResource.class);\r\n    FileStatus rsrcStat = fs.getFileStatus(p);\r\n    Path qualifiedPath = fs.getDefaultFileSystem().resolvePath(rsrcStat.getPath());\r\n    URI uriWithFragment = null;\r\n    boolean useFragment = fileSymlink != null && !fileSymlink.equals(\"\");\r\n    try {\r\n        if (useFragment) {\r\n            uriWithFragment = new URI(qualifiedPath.toUri() + \"#\" + fileSymlink);\r\n        } else {\r\n            uriWithFragment = qualifiedPath.toUri();\r\n        }\r\n    } catch (URISyntaxException e) {\r\n        throw new IOException(\"Error parsing local resource path.\" + \" Path was not able to be converted to a URI: \" + qualifiedPath, e);\r\n    }\r\n    rsrc.setResource(URL.fromURI(uriWithFragment));\r\n    rsrc.setSize(rsrcStat.getLen());\r\n    rsrc.setTimestamp(rsrcStat.getModificationTime());\r\n    rsrc.setType(type);\r\n    rsrc.setVisibility(viz);\r\n    rsrc.setShouldBeUploadedToSharedCache(uploadToSharedCache);\r\n    return rsrc;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setupLocalResources",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "Map<String, LocalResource> setupLocalResources(Configuration jobConf, String jobSubmitDir) throws IOException\n{\r\n    Map<String, LocalResource> localResources = new HashMap<>();\r\n    Path jobConfPath = new Path(jobSubmitDir, MRJobConfig.JOB_CONF_FILE);\r\n    URL yarnUrlForJobSubmitDir = URL.fromPath(defaultFileContext.getDefaultFileSystem().resolvePath(defaultFileContext.makeQualified(new Path(jobSubmitDir))));\r\n    LOG.debug(\"Creating setup context, jobSubmitDir url is \" + yarnUrlForJobSubmitDir);\r\n    localResources.put(MRJobConfig.JOB_CONF_FILE, createApplicationResource(defaultFileContext, jobConfPath, LocalResourceType.FILE));\r\n    if (jobConf.get(MRJobConfig.JAR) != null) {\r\n        Path jobJarPath = new Path(jobConf.get(MRJobConfig.JAR));\r\n        FileContext fccc = FileContext.getFileContext(jobJarPath.toUri(), jobConf);\r\n        LocalResourceVisibility jobJarViz = jobConf.getBoolean(MRJobConfig.JOBJAR_VISIBILITY, MRJobConfig.JOBJAR_VISIBILITY_DEFAULT) ? LocalResourceVisibility.PUBLIC : LocalResourceVisibility.APPLICATION;\r\n        LocalResource rc = createApplicationResource(FileContext.getFileContext(jobJarPath.toUri(), jobConf), jobJarPath, MRJobConfig.JOB_JAR, LocalResourceType.PATTERN, jobJarViz, jobConf.getBoolean(MRJobConfig.JOBJAR_SHARED_CACHE_UPLOAD_POLICY, MRJobConfig.JOBJAR_SHARED_CACHE_UPLOAD_POLICY_DEFAULT));\r\n        String pattern = conf.getPattern(JobContext.JAR_UNPACK_PATTERN, JobConf.UNPACK_JAR_PATTERN_DEFAULT).pattern();\r\n        rc.setPattern(pattern);\r\n        localResources.put(MRJobConfig.JOB_JAR, rc);\r\n    } else {\r\n        LOG.info(\"Job jar is not present. \" + \"Not adding any jar to the list of resources.\");\r\n    }\r\n    for (String s : new String[] { MRJobConfig.JOB_SPLIT, MRJobConfig.JOB_SPLIT_METAINFO }) {\r\n        localResources.put(MRJobConfig.JOB_SUBMIT_DIR + \"/\" + s, createApplicationResource(defaultFileContext, new Path(jobSubmitDir, s), LocalResourceType.FILE));\r\n    }\r\n    return localResources;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setupAMCommand",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "List<String> setupAMCommand(Configuration jobConf)\n{\r\n    List<String> vargs = new ArrayList<>(8);\r\n    vargs.add(MRApps.crossPlatformifyMREnv(jobConf, Environment.JAVA_HOME) + \"/bin/java\");\r\n    Path amTmpDir = new Path(MRApps.crossPlatformifyMREnv(conf, Environment.PWD), YarnConfiguration.DEFAULT_CONTAINER_TEMP_DIR);\r\n    vargs.add(\"-Djava.io.tmpdir=\" + amTmpDir);\r\n    MRApps.addLog4jSystemProperties(null, vargs, conf);\r\n    warnForJavaLibPath(conf.get(MRJobConfig.MAP_JAVA_OPTS, \"\"), \"map\", MRJobConfig.MAP_JAVA_OPTS, MRJobConfig.MAP_ENV);\r\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, \"\"), \"map\", MRJobConfig.MAPRED_MAP_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\r\n    warnForJavaLibPath(conf.get(MRJobConfig.REDUCE_JAVA_OPTS, \"\"), \"reduce\", MRJobConfig.REDUCE_JAVA_OPTS, MRJobConfig.REDUCE_ENV);\r\n    warnForJavaLibPath(conf.get(MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, \"\"), \"reduce\", MRJobConfig.MAPRED_REDUCE_ADMIN_JAVA_OPTS, MRJobConfig.MAPRED_ADMIN_USER_ENV);\r\n    String mrAppMasterAdminOptions = conf.get(MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.DEFAULT_MR_AM_ADMIN_COMMAND_OPTS);\r\n    warnForJavaLibPath(mrAppMasterAdminOptions, \"app master\", MRJobConfig.MR_AM_ADMIN_COMMAND_OPTS, MRJobConfig.MR_AM_ADMIN_USER_ENV);\r\n    vargs.add(mrAppMasterAdminOptions);\r\n    String mrAppMasterUserOptions = conf.get(MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS);\r\n    warnForJavaLibPath(mrAppMasterUserOptions, \"app master\", MRJobConfig.MR_AM_COMMAND_OPTS, MRJobConfig.MR_AM_ENV);\r\n    vargs.add(mrAppMasterUserOptions);\r\n    if (jobConf.getBoolean(MRJobConfig.MR_AM_PROFILE, MRJobConfig.DEFAULT_MR_AM_PROFILE)) {\r\n        final String profileParams = jobConf.get(MRJobConfig.MR_AM_PROFILE_PARAMS, MRJobConfig.DEFAULT_TASK_PROFILE_PARAMS);\r\n        if (profileParams != null) {\r\n            vargs.add(String.format(profileParams, ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR + TaskLog.LogName.PROFILE));\r\n        }\r\n    }\r\n    vargs.add(MRJobConfig.APPLICATION_MASTER_CLASS);\r\n    vargs.add(\"1>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR + ApplicationConstants.STDOUT);\r\n    vargs.add(\"2>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + Path.SEPARATOR + ApplicationConstants.STDERR);\r\n    return vargs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setupContainerLaunchContextForAM",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "ContainerLaunchContext setupContainerLaunchContextForAM(Configuration jobConf, Map<String, LocalResource> localResources, ByteBuffer securityTokens, List<String> vargs) throws IOException\n{\r\n    Vector<String> vargsFinal = new Vector<>(8);\r\n    StringBuilder mergedCommand = new StringBuilder();\r\n    for (CharSequence str : vargs) {\r\n        mergedCommand.append(str).append(\" \");\r\n    }\r\n    vargsFinal.add(mergedCommand.toString());\r\n    LOG.debug(\"Command to launch container for ApplicationMaster is : \" + mergedCommand);\r\n    Map<String, String> environment = new HashMap<>();\r\n    MRApps.setClasspath(environment, conf);\r\n    environment.put(Environment.SHELL.name(), conf.get(MRJobConfig.MAPRED_ADMIN_USER_SHELL, MRJobConfig.DEFAULT_SHELL));\r\n    MRApps.addToEnvironment(environment, Environment.LD_LIBRARY_PATH.name(), MRApps.crossPlatformifyMREnv(conf, Environment.PWD), conf);\r\n    MRApps.setEnvFromInputProperty(environment, MRJobConfig.MR_AM_ADMIN_USER_ENV, MRJobConfig.DEFAULT_MR_AM_ADMIN_USER_ENV, conf);\r\n    MRApps.setEnvFromInputProperty(environment, MRJobConfig.MR_AM_ENV, null, conf);\r\n    MRApps.setupDistributedCache(jobConf, localResources);\r\n    Map<ApplicationAccessType, String> acls = new HashMap<>(2);\r\n    acls.put(ApplicationAccessType.VIEW_APP, jobConf.get(MRJobConfig.JOB_ACL_VIEW_JOB, MRJobConfig.DEFAULT_JOB_ACL_VIEW_JOB));\r\n    acls.put(ApplicationAccessType.MODIFY_APP, jobConf.get(MRJobConfig.JOB_ACL_MODIFY_JOB, MRJobConfig.DEFAULT_JOB_ACL_MODIFY_JOB));\r\n    return ContainerLaunchContext.newInstance(localResources, environment, vargsFinal, null, securityTokens, acls);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "createApplicationSubmissionContext",
  "errType" : [ "NumberFormatException", "IllegalArgumentException" ],
  "containingMethodsNum" : 35,
  "sourceCodeText" : "ApplicationSubmissionContext createApplicationSubmissionContext(Configuration jobConf, String jobSubmitDir, Credentials ts) throws IOException\n{\r\n    ApplicationId applicationId = resMgrDelegate.getApplicationId();\r\n    Map<String, LocalResource> localResources = setupLocalResources(jobConf, jobSubmitDir);\r\n    DataOutputBuffer dob = new DataOutputBuffer();\r\n    ts.writeTokenStorageToStream(dob);\r\n    ByteBuffer securityTokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\r\n    List<String> vargs = setupAMCommand(jobConf);\r\n    ContainerLaunchContext amContainer = setupContainerLaunchContextForAM(jobConf, localResources, securityTokens, vargs);\r\n    String regex = conf.get(MRJobConfig.MR_JOB_SEND_TOKEN_CONF);\r\n    if (regex != null && !regex.isEmpty()) {\r\n        setTokenRenewerConf(amContainer, conf, regex);\r\n    }\r\n    Collection<String> tagsFromConf = jobConf.getTrimmedStringCollection(MRJobConfig.JOB_TAGS);\r\n    ApplicationSubmissionContext appContext = recordFactory.newRecordInstance(ApplicationSubmissionContext.class);\r\n    appContext.setApplicationId(applicationId);\r\n    appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME, YarnConfiguration.DEFAULT_QUEUE_NAME));\r\n    ReservationId reservationID = null;\r\n    try {\r\n        reservationID = ReservationId.parseReservationId(jobConf.get(JobContext.RESERVATION_ID));\r\n    } catch (NumberFormatException e) {\r\n        String errMsg = \"Invalid reservationId: \" + jobConf.get(JobContext.RESERVATION_ID) + \" specified for the app: \" + applicationId;\r\n        LOG.warn(errMsg);\r\n        throw new IOException(errMsg);\r\n    }\r\n    if (reservationID != null) {\r\n        appContext.setReservationID(reservationID);\r\n        LOG.info(\"SUBMITTING ApplicationSubmissionContext app:\" + applicationId + \" to queue:\" + appContext.getQueue() + \" with reservationId:\" + appContext.getReservationID());\r\n    }\r\n    appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME, YarnConfiguration.DEFAULT_APPLICATION_NAME));\r\n    appContext.setCancelTokensWhenComplete(conf.getBoolean(MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN, true));\r\n    appContext.setAMContainerSpec(amContainer);\r\n    appContext.setMaxAppAttempts(conf.getInt(MRJobConfig.MR_AM_MAX_ATTEMPTS, MRJobConfig.DEFAULT_MR_AM_MAX_ATTEMPTS));\r\n    List<ResourceRequest> amResourceRequests = generateResourceRequests();\r\n    appContext.setAMContainerResourceRequests(amResourceRequests);\r\n    String amNodelabelExpression = conf.get(MRJobConfig.AM_NODE_LABEL_EXP);\r\n    if (null != amNodelabelExpression && amNodelabelExpression.trim().length() != 0) {\r\n        for (ResourceRequest amResourceRequest : amResourceRequests) {\r\n            amResourceRequest.setNodeLabelExpression(amNodelabelExpression.trim());\r\n        }\r\n    }\r\n    appContext.setNodeLabelExpression(jobConf.get(JobContext.JOB_NODE_LABEL_EXP));\r\n    appContext.setApplicationType(MRJobConfig.MR_APPLICATION_TYPE);\r\n    if (tagsFromConf != null && !tagsFromConf.isEmpty()) {\r\n        appContext.setApplicationTags(new HashSet<>(tagsFromConf));\r\n    }\r\n    String jobPriority = jobConf.get(MRJobConfig.PRIORITY);\r\n    if (jobPriority != null) {\r\n        int iPriority;\r\n        try {\r\n            iPriority = TypeConverter.toYarnApplicationPriority(jobPriority);\r\n        } catch (IllegalArgumentException e) {\r\n            iPriority = Integer.parseInt(jobPriority);\r\n        }\r\n        appContext.setPriority(Priority.newInstance(iPriority));\r\n    }\r\n    return appContext;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "generateResourceRequests",
  "errType" : null,
  "containingMethodsNum" : 44,
  "sourceCodeText" : "List<ResourceRequest> generateResourceRequests() throws IOException\n{\r\n    Resource capability = recordFactory.newRecordInstance(Resource.class);\r\n    boolean memorySet = false;\r\n    boolean cpuVcoresSet = false;\r\n    List<ResourceInformation> resourceRequests = ResourceUtils.getRequestedResourcesFromConfig(conf, MR_AM_RESOURCE_PREFIX);\r\n    for (ResourceInformation resourceReq : resourceRequests) {\r\n        String resourceName = resourceReq.getName();\r\n        if (MRJobConfig.RESOURCE_TYPE_NAME_MEMORY.equals(resourceName) || MRJobConfig.RESOURCE_TYPE_ALTERNATIVE_NAME_MEMORY.equals(resourceName)) {\r\n            if (memorySet) {\r\n                throw new IllegalArgumentException(\"Only one of the following keys \" + \"can be specified for a single job: \" + MRJobConfig.RESOURCE_TYPE_ALTERNATIVE_NAME_MEMORY + \", \" + MRJobConfig.RESOURCE_TYPE_NAME_MEMORY);\r\n            }\r\n            String units = isEmpty(resourceReq.getUnits()) ? ResourceUtils.getDefaultUnit(ResourceInformation.MEMORY_URI) : resourceReq.getUnits();\r\n            capability.setMemorySize(UnitsConversionUtil.convert(units, \"Mi\", resourceReq.getValue()));\r\n            memorySet = true;\r\n            if (conf.get(MRJobConfig.MR_AM_VMEM_MB) != null) {\r\n                LOG.warn(\"Configuration \" + MR_AM_RESOURCE_PREFIX + resourceName + \"=\" + resourceReq.getValue() + resourceReq.getUnits() + \" is overriding the \" + MRJobConfig.MR_AM_VMEM_MB + \"=\" + conf.get(MRJobConfig.MR_AM_VMEM_MB) + \" configuration\");\r\n            }\r\n        } else if (MRJobConfig.RESOURCE_TYPE_NAME_VCORE.equals(resourceName)) {\r\n            capability.setVirtualCores((int) UnitsConversionUtil.convert(resourceReq.getUnits(), \"\", resourceReq.getValue()));\r\n            cpuVcoresSet = true;\r\n            if (conf.get(MRJobConfig.MR_AM_CPU_VCORES) != null) {\r\n                LOG.warn(\"Configuration \" + MR_AM_RESOURCE_PREFIX + resourceName + \"=\" + resourceReq.getValue() + resourceReq.getUnits() + \" is overriding the \" + MRJobConfig.MR_AM_CPU_VCORES + \"=\" + conf.get(MRJobConfig.MR_AM_CPU_VCORES) + \" configuration\");\r\n            }\r\n        } else if (!MRJobConfig.MR_AM_VMEM_MB.equals(MR_AM_RESOURCE_PREFIX + resourceName) && !MRJobConfig.MR_AM_CPU_VCORES.equals(MR_AM_RESOURCE_PREFIX + resourceName)) {\r\n            ResourceInformation resourceInformation = capability.getResourceInformation(resourceName);\r\n            resourceInformation.setUnits(resourceReq.getUnits());\r\n            resourceInformation.setValue(resourceReq.getValue());\r\n            capability.setResourceInformation(resourceName, resourceInformation);\r\n        }\r\n    }\r\n    if (!memorySet) {\r\n        capability.setMemorySize(conf.getInt(MRJobConfig.MR_AM_VMEM_MB, MRJobConfig.DEFAULT_MR_AM_VMEM_MB));\r\n    }\r\n    if (!cpuVcoresSet) {\r\n        capability.setVirtualCores(conf.getInt(MRJobConfig.MR_AM_CPU_VCORES, MRJobConfig.DEFAULT_MR_AM_CPU_VCORES));\r\n    }\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"AppMaster capability = \" + capability);\r\n    }\r\n    List<ResourceRequest> amResourceRequests = new ArrayList<>();\r\n    ResourceRequest amAnyResourceRequest = createAMResourceRequest(ResourceRequest.ANY, capability);\r\n    Map<String, ResourceRequest> rackRequests = new HashMap<>();\r\n    amResourceRequests.add(amAnyResourceRequest);\r\n    Collection<String> amStrictResources = conf.getStringCollection(MRJobConfig.AM_STRICT_LOCALITY);\r\n    for (String amStrictResource : amStrictResources) {\r\n        amAnyResourceRequest.setRelaxLocality(false);\r\n        Matcher matcher = RACK_NODE_PATTERN.matcher(amStrictResource);\r\n        if (matcher.matches()) {\r\n            String nodeName;\r\n            String rackName = matcher.group(RACK_GROUP);\r\n            if (rackName == null) {\r\n                rackName = \"/default-rack\";\r\n                nodeName = matcher.group(NODE_IF_NO_RACK_GROUP);\r\n            } else {\r\n                nodeName = matcher.group(NODE_IF_RACK_GROUP);\r\n            }\r\n            ResourceRequest amRackResourceRequest = rackRequests.get(rackName);\r\n            if (amRackResourceRequest == null) {\r\n                amRackResourceRequest = createAMResourceRequest(rackName, capability);\r\n                amResourceRequests.add(amRackResourceRequest);\r\n                rackRequests.put(rackName, amRackResourceRequest);\r\n            }\r\n            if (nodeName != null) {\r\n                amRackResourceRequest.setRelaxLocality(false);\r\n                ResourceRequest amNodeResourceRequest = createAMResourceRequest(nodeName, capability);\r\n                amResourceRequests.add(amNodeResourceRequest);\r\n            }\r\n        } else {\r\n            String errMsg = \"Invalid resource name: \" + amStrictResource + \" specified.\";\r\n            LOG.warn(errMsg);\r\n            throw new IOException(errMsg);\r\n        }\r\n    }\r\n    if (LOG.isDebugEnabled()) {\r\n        for (ResourceRequest amResourceRequest : amResourceRequests) {\r\n            LOG.debug(\"ResourceRequest: resource = \" + amResourceRequest.getResourceName() + \", locality = \" + amResourceRequest.getRelaxLocality());\r\n        }\r\n    }\r\n    return amResourceRequests;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "createAMResourceRequest",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "ResourceRequest createAMResourceRequest(String resource, Resource capability)\n{\r\n    ResourceRequest resourceRequest = recordFactory.newRecordInstance(ResourceRequest.class);\r\n    resourceRequest.setPriority(AM_CONTAINER_PRIORITY);\r\n    resourceRequest.setResourceName(resource);\r\n    resourceRequest.setCapability(capability);\r\n    resourceRequest.setNumContainers(1);\r\n    resourceRequest.setRelaxLocality(true);\r\n    return resourceRequest;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setTokenRenewerConf",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void setTokenRenewerConf(ContainerLaunchContext context, Configuration conf, String regex) throws IOException\n{\r\n    DataOutputBuffer dob = new DataOutputBuffer();\r\n    Configuration copy = new Configuration(false);\r\n    copy.clear();\r\n    int count = 0;\r\n    for (Map.Entry<String, String> map : conf) {\r\n        String key = map.getKey();\r\n        String val = map.getValue();\r\n        if (key.matches(regex)) {\r\n            copy.set(key, val);\r\n            count++;\r\n        }\r\n    }\r\n    copy.write(dob);\r\n    ByteBuffer appConf = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\r\n    LOG.info(\"Send configurations that match regex expression: \" + regex + \" , total number of configs: \" + count + \", total size : \" + dob.getLength() + \" bytes.\");\r\n    if (LOG.isDebugEnabled()) {\r\n        for (Iterator<Map.Entry<String, String>> itor = copy.iterator(); itor.hasNext(); ) {\r\n            Map.Entry<String, String> entry = itor.next();\r\n            LOG.info(entry.getKey() + \" ===> \" + entry.getValue());\r\n        }\r\n    }\r\n    context.setTokensConf(appConf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setJobPriority",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobPriority(JobID arg0, String arg1) throws IOException, InterruptedException\n{\r\n    ApplicationId appId = TypeConverter.toYarn(arg0).getAppId();\r\n    try {\r\n        resMgrDelegate.updateApplicationPriority(appId, Priority.newInstance(Integer.parseInt(arg1)));\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getProtocolVersion",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getProtocolVersion(String arg0, long arg1) throws IOException\n{\r\n    return resMgrDelegate.getProtocolVersion(arg0, arg1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "renewDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long renewDelegationToken(Token<DelegationTokenIdentifier> arg0) throws IOException, InterruptedException\n{\r\n    throw new UnsupportedOperationException(\"Use Token.renew instead\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobCounters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Counters getJobCounters(JobID arg0) throws IOException, InterruptedException\n{\r\n    return clientCache.getClient(arg0).getJobCounters(arg0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobHistoryDir",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJobHistoryDir() throws IOException, InterruptedException\n{\r\n    return JobHistoryUtils.getConfiguredHistoryServerDoneDirPrefix(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobStatus getJobStatus(JobID jobID) throws IOException, InterruptedException\n{\r\n    JobStatus status = clientCache.getClient(jobID).getJobStatus(jobID);\r\n    return status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskCompletionEvent[] getTaskCompletionEvents(JobID arg0, int arg1, int arg2) throws IOException, InterruptedException\n{\r\n    return clientCache.getClient(arg0).getTaskCompletionEvents(arg0, arg1, arg2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String[] getTaskDiagnostics(TaskAttemptID arg0) throws IOException, InterruptedException\n{\r\n    return clientCache.getClient(arg0.getJobID()).getTaskDiagnostics(arg0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskReports",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskReport[] getTaskReports(JobID jobID, TaskType taskType) throws IOException, InterruptedException\n{\r\n    return clientCache.getClient(jobID).getTaskReports(jobID, taskType);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killUnFinishedApplication",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void killUnFinishedApplication(ApplicationId appId) throws IOException\n{\r\n    ApplicationReport application = null;\r\n    try {\r\n        application = resMgrDelegate.getApplicationReport(appId);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n    if (Apps.isApplicationFinalState(application.getYarnApplicationState())) {\r\n        return;\r\n    }\r\n    killApplication(appId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killApplication",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void killApplication(ApplicationId appId) throws IOException\n{\r\n    try {\r\n        resMgrDelegate.killApplication(appId);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "isJobInTerminalState",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean isJobInTerminalState(JobStatus status)\n{\r\n    return status.getState() == JobStatus.State.KILLED || status.getState() == JobStatus.State.FAILED || status.getState() == JobStatus.State.SUCCEEDED;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killJob",
  "errType" : [ "IOException", "InterruptedException" ],
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void killJob(JobID arg0) throws IOException, InterruptedException\n{\r\n    JobStatus status = clientCache.getClient(arg0).getJobStatus(arg0);\r\n    ApplicationId appId = TypeConverter.toYarn(arg0).getAppId();\r\n    if (status == null) {\r\n        killUnFinishedApplication(appId);\r\n        return;\r\n    }\r\n    if (status.getState() != JobStatus.State.RUNNING) {\r\n        killApplication(appId);\r\n        return;\r\n    }\r\n    try {\r\n        clientCache.getClient(arg0).killJob(arg0);\r\n        long currentTimeMillis = System.currentTimeMillis();\r\n        long timeKillIssued = currentTimeMillis;\r\n        long killTimeOut = conf.getLong(MRJobConfig.MR_AM_HARD_KILL_TIMEOUT_MS, MRJobConfig.DEFAULT_MR_AM_HARD_KILL_TIMEOUT_MS);\r\n        while ((currentTimeMillis < timeKillIssued + killTimeOut) && !isJobInTerminalState(status)) {\r\n            try {\r\n                Thread.sleep(1000L);\r\n            } catch (InterruptedException ie) {\r\n                break;\r\n            }\r\n            currentTimeMillis = System.currentTimeMillis();\r\n            status = clientCache.getClient(arg0).getJobStatus(arg0);\r\n            if (status == null) {\r\n                killUnFinishedApplication(appId);\r\n                return;\r\n            }\r\n        }\r\n    } catch (IOException io) {\r\n        LOG.debug(\"Error when checking for application status\", io);\r\n    }\r\n    if (status != null && !isJobInTerminalState(status)) {\r\n        killApplication(appId);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killTask",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean killTask(TaskAttemptID arg0, boolean arg1) throws IOException, InterruptedException\n{\r\n    return clientCache.getClient(arg0.getJobID()).killTask(arg0, arg1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueAdmins",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AccessControlList getQueueAdmins(String arg0) throws IOException\n{\r\n    return new AccessControlList(\"*\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobTrackerStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobTrackerStatus getJobTrackerStatus() throws IOException, InterruptedException\n{\r\n    return JobTrackerStatus.RUNNING;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getProtocolSignature",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ProtocolSignature getProtocolSignature(String protocol, long clientVersion, int clientMethodsHash) throws IOException\n{\r\n    return ProtocolSignature.getProtocolSignature(this, protocol, clientVersion, clientMethodsHash);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLogFileParams",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "LogParams getLogFileParams(JobID jobID, TaskAttemptID taskAttemptID) throws IOException\n{\r\n    return clientCache.getClient(jobID).getLogFilePath(jobID, taskAttemptID);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "warnForJavaLibPath",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void warnForJavaLibPath(String opts, String component, String javaConf, String envConf)\n{\r\n    if (opts != null && opts.contains(\"-Djava.library.path\")) {\r\n        LOG.warn(\"Usage of -Djava.library.path in \" + javaConf + \" can cause \" + \"programs to no longer function if hadoop native libraries \" + \"are used. These values should be set as part of the \" + \"LD_LIBRARY_PATH in the \" + component + \" JVM env using \" + envConf + \" config settings.\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (resMgrDelegate != null) {\r\n        resMgrDelegate.close();\r\n        resMgrDelegate = null;\r\n    }\r\n    if (clientCache != null) {\r\n        clientCache.close();\r\n        clientCache = null;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getClient",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "ClientServiceDelegate getClient(JobID jobId)\n{\r\n    if (hsProxy == null) {\r\n        try {\r\n            hsProxy = instantiateHistoryProxy();\r\n        } catch (IOException e) {\r\n            LOG.warn(\"Could not connect to History server.\", e);\r\n            throw new YarnRuntimeException(\"Could not connect to History server.\", e);\r\n        }\r\n    }\r\n    ClientServiceDelegate client = cache.get(jobId);\r\n    if (client == null) {\r\n        client = new ClientServiceDelegate(conf, rm, jobId, hsProxy);\r\n        cache.put(jobId, client);\r\n    }\r\n    return client;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getInitializedHSProxy",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "MRClientProtocol getInitializedHSProxy() throws IOException\n{\r\n    if (this.hsProxy == null) {\r\n        hsProxy = instantiateHistoryProxy();\r\n    }\r\n    return this.hsProxy;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "instantiateHistoryProxy",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "MRClientProtocol instantiateHistoryProxy() throws IOException\n{\r\n    final String serviceAddr = conf.get(JHAdminConfig.MR_HISTORY_ADDRESS);\r\n    if (StringUtils.isEmpty(serviceAddr)) {\r\n        return null;\r\n    }\r\n    LOG.debug(\"Connecting to HistoryServer at: \" + serviceAddr);\r\n    final YarnRPC rpc = YarnRPC.create(conf);\r\n    LOG.debug(\"Connected to HistoryServer at: \" + serviceAddr);\r\n    UserGroupInformation currentUser = UserGroupInformation.getCurrentUser();\r\n    return currentUser.doAs(new PrivilegedAction<MRClientProtocol>() {\r\n\r\n        @Override\r\n        public MRClientProtocol run() {\r\n            return (MRClientProtocol) rpc.getProxy(HSClientProtocol.class, NetUtils.createSocketAddr(serviceAddr), conf);\r\n        }\r\n    });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (rm != null) {\r\n        rm.close();\r\n    }\r\n    if (hsProxy != null) {\r\n        RPC.stopProxy(hsProxy);\r\n        hsProxy = null;\r\n    }\r\n    if (cache != null && !cache.isEmpty()) {\r\n        for (ClientServiceDelegate delegate : cache.values()) {\r\n            if (delegate != null) {\r\n                delegate.close();\r\n                delegate = null;\r\n            }\r\n        }\r\n        cache.clear();\r\n        cache = null;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNotRunningJob",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "NotRunningJob getNotRunningJob(ApplicationReport applicationReport, JobState state)\n{\r\n    synchronized (notRunningJobs) {\r\n        HashMap<String, NotRunningJob> map = notRunningJobs.get(state);\r\n        if (map == null) {\r\n            map = new HashMap<String, NotRunningJob>();\r\n            notRunningJobs.put(state, map);\r\n        }\r\n        String user = (applicationReport == null) ? UNKNOWN_USER : applicationReport.getUser();\r\n        NotRunningJob notRunningJob = map.get(user);\r\n        if (notRunningJob == null) {\r\n            notRunningJob = new NotRunningJob(applicationReport, state);\r\n            map.put(user, notRunningJob);\r\n        }\r\n        return notRunningJob;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getProxy",
  "errType" : [ "ApplicationNotFoundException", "YarnException", "IOException", "InterruptedException", "YarnException", "InterruptedException", "YarnException" ],
  "containingMethodsNum" : 45,
  "sourceCodeText" : "MRClientProtocol getProxy() throws IOException\n{\r\n    if (realProxy != null) {\r\n        return realProxy;\r\n    }\r\n    ApplicationReport application = null;\r\n    try {\r\n        application = rm.getApplicationReport(appId);\r\n    } catch (ApplicationNotFoundException e) {\r\n        application = null;\r\n    } catch (YarnException e2) {\r\n        throw new IOException(e2);\r\n    }\r\n    if (application != null) {\r\n        trackingUrl = application.getTrackingUrl();\r\n    }\r\n    InetSocketAddress serviceAddr = null;\r\n    while (application == null || YarnApplicationState.RUNNING == application.getYarnApplicationState()) {\r\n        if (application == null) {\r\n            LOG.info(\"Could not get Job info from RM for job \" + jobId + \". Redirecting to job history server.\");\r\n            return checkAndGetHSProxy(null, JobState.NEW);\r\n        }\r\n        try {\r\n            if (application.getHost() == null || \"\".equals(application.getHost())) {\r\n                LOG.debug(\"AM not assigned to Job. Waiting to get the AM ...\");\r\n                Thread.sleep(2000);\r\n                LOG.debug(\"Application state is \" + application.getYarnApplicationState());\r\n                application = rm.getApplicationReport(appId);\r\n                continue;\r\n            } else if (UNAVAILABLE.equals(application.getHost())) {\r\n                if (!amAclDisabledStatusLogged) {\r\n                    LOG.info(\"Job \" + jobId + \" is running, but the host is unknown.\" + \" Verify user has VIEW_JOB access.\");\r\n                    amAclDisabledStatusLogged = true;\r\n                }\r\n                return getNotRunningJob(application, JobState.RUNNING);\r\n            }\r\n            if (!conf.getBoolean(MRJobConfig.JOB_AM_ACCESS_DISABLED, false)) {\r\n                UserGroupInformation newUgi = UserGroupInformation.createRemoteUser(UserGroupInformation.getCurrentUser().getUserName());\r\n                serviceAddr = NetUtils.createSocketAddrForHost(application.getHost(), application.getRpcPort());\r\n                if (UserGroupInformation.isSecurityEnabled()) {\r\n                    org.apache.hadoop.yarn.api.records.Token clientToAMToken = application.getClientToAMToken();\r\n                    Token<ClientToAMTokenIdentifier> token = ConverterUtils.convertFromYarn(clientToAMToken, serviceAddr);\r\n                    newUgi.addToken(token);\r\n                }\r\n                LOG.debug(\"Connecting to \" + serviceAddr);\r\n                final InetSocketAddress finalServiceAddr = serviceAddr;\r\n                realProxy = newUgi.doAs(new PrivilegedExceptionAction<MRClientProtocol>() {\r\n\r\n                    @Override\r\n                    public MRClientProtocol run() throws IOException {\r\n                        return instantiateAMProxy(finalServiceAddr);\r\n                    }\r\n                });\r\n            } else {\r\n                if (!amAclDisabledStatusLogged) {\r\n                    LOG.info(\"Network ACL closed to AM for job \" + jobId + \". Not going to try to reach the AM.\");\r\n                    amAclDisabledStatusLogged = true;\r\n                }\r\n                return getNotRunningJob(null, JobState.RUNNING);\r\n            }\r\n            return realProxy;\r\n        } catch (IOException e) {\r\n            LOG.info(\"Could not connect to \" + serviceAddr + \". Waiting for getting the latest AM address...\");\r\n            try {\r\n                Thread.sleep(2000);\r\n            } catch (InterruptedException e1) {\r\n                LOG.warn(\"getProxy() call interrupted\", e1);\r\n                throw new YarnRuntimeException(e1);\r\n            }\r\n            try {\r\n                application = rm.getApplicationReport(appId);\r\n            } catch (YarnException e1) {\r\n                throw new IOException(e1);\r\n            }\r\n            if (application == null) {\r\n                LOG.info(\"Could not get Job info from RM for job \" + jobId + \". Redirecting to job history server.\");\r\n                return checkAndGetHSProxy(null, JobState.RUNNING);\r\n            }\r\n        } catch (InterruptedException e) {\r\n            LOG.warn(\"getProxy() call interrupted\", e);\r\n            throw new YarnRuntimeException(e);\r\n        } catch (YarnException e) {\r\n            throw new IOException(e);\r\n        }\r\n    }\r\n    String user = application.getUser();\r\n    if (user == null) {\r\n        throw new IOException(\"User is not set in the application report\");\r\n    }\r\n    if (application.getYarnApplicationState() == YarnApplicationState.NEW || application.getYarnApplicationState() == YarnApplicationState.NEW_SAVING || application.getYarnApplicationState() == YarnApplicationState.SUBMITTED || application.getYarnApplicationState() == YarnApplicationState.ACCEPTED) {\r\n        realProxy = null;\r\n        return getNotRunningJob(application, JobState.NEW);\r\n    }\r\n    if (application.getYarnApplicationState() == YarnApplicationState.FAILED) {\r\n        realProxy = null;\r\n        return getNotRunningJob(application, JobState.FAILED);\r\n    }\r\n    if (application.getYarnApplicationState() == YarnApplicationState.KILLED) {\r\n        realProxy = null;\r\n        return getNotRunningJob(application, JobState.KILLED);\r\n    }\r\n    if (application.getYarnApplicationState() == YarnApplicationState.FINISHED) {\r\n        LOG.info(\"Application state is completed. FinalApplicationStatus=\" + application.getFinalApplicationStatus().toString() + \". Redirecting to job history server\");\r\n        realProxy = checkAndGetHSProxy(application, JobState.SUCCEEDED);\r\n    }\r\n    return realProxy;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 4,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "checkAndGetHSProxy",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "MRClientProtocol checkAndGetHSProxy(ApplicationReport applicationReport, JobState state)\n{\r\n    if (null == historyServerProxy) {\r\n        LOG.warn(\"Job History Server is not configured.\");\r\n        return getNotRunningJob(applicationReport, state);\r\n    }\r\n    return historyServerProxy;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "instantiateAMProxy",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "MRClientProtocol instantiateAMProxy(final InetSocketAddress serviceAddr) throws IOException\n{\r\n    LOG.trace(\"Connecting to ApplicationMaster at: \" + serviceAddr);\r\n    YarnRPC rpc = YarnRPC.create(conf);\r\n    MRClientProtocol proxy = (MRClientProtocol) rpc.getProxy(MRClientProtocol.class, serviceAddr, conf);\r\n    usingAMProxy.set(true);\r\n    LOG.trace(\"Connected to ApplicationMaster at: \" + serviceAddr);\r\n    return proxy;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "invoke",
  "errType" : [ "SecurityException", "NoSuchMethodException", "InvocationTargetException", "Exception", "InterruptedException", "InterruptedException" ],
  "containingMethodsNum" : 16,
  "sourceCodeText" : "Object invoke(String method, Class argClass, Object args) throws IOException\n{\r\n    Method methodOb = null;\r\n    try {\r\n        methodOb = MRClientProtocol.class.getMethod(method, argClass);\r\n    } catch (SecurityException e) {\r\n        throw new YarnRuntimeException(e);\r\n    } catch (NoSuchMethodException e) {\r\n        throw new YarnRuntimeException(\"Method name mismatch\", e);\r\n    }\r\n    maxClientRetry = this.conf.getInt(MRJobConfig.MR_CLIENT_MAX_RETRIES, MRJobConfig.DEFAULT_MR_CLIENT_MAX_RETRIES);\r\n    IOException lastException = null;\r\n    while (maxClientRetry > 0) {\r\n        MRClientProtocol MRClientProxy = null;\r\n        try {\r\n            MRClientProxy = getProxy();\r\n            return methodOb.invoke(MRClientProxy, args);\r\n        } catch (InvocationTargetException e) {\r\n            LOG.debug(\"Failed to contact AM/History for job \" + jobId + \" retrying..\", e.getTargetException());\r\n            realProxy = null;\r\n            if (e.getCause() instanceof AuthorizationException) {\r\n                throw new IOException(e.getTargetException());\r\n            }\r\n            if (!usingAMProxy.get()) {\r\n                maxClientRetry--;\r\n            }\r\n            usingAMProxy.set(false);\r\n            lastException = new IOException(e.getTargetException());\r\n            try {\r\n                Thread.sleep(100);\r\n            } catch (InterruptedException ie) {\r\n                LOG.warn(\"ClientServiceDelegate invoke call interrupted\", ie);\r\n                throw new YarnRuntimeException(ie);\r\n            }\r\n        } catch (Exception e) {\r\n            LOG.debug(\"Failed to contact AM/History for job \" + jobId + \"  Will retry..\", e);\r\n            realProxy = null;\r\n            maxClientRetry--;\r\n            lastException = new IOException(e.getMessage());\r\n            try {\r\n                Thread.sleep(100);\r\n            } catch (InterruptedException ie) {\r\n                LOG.warn(\"ClientServiceDelegate invoke call interrupted\", ie);\r\n                throw new YarnRuntimeException(ie);\r\n            }\r\n        }\r\n    }\r\n    throw lastException;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 4,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getMaxClientRetry",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getMaxClientRetry()\n{\r\n    return this.maxClientRetry;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobCounters",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.Counters getJobCounters(JobID arg0) throws IOException, InterruptedException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobID = TypeConverter.toYarn(arg0);\r\n    GetCountersRequest request = recordFactory.newRecordInstance(GetCountersRequest.class);\r\n    request.setJobId(jobID);\r\n    Counters cnt = ((GetCountersResponse) invoke(\"getCounters\", GetCountersRequest.class, request)).getCounters();\r\n    return TypeConverter.fromYarn(cnt);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "TaskCompletionEvent[] getTaskCompletionEvents(JobID arg0, int arg1, int arg2) throws IOException, InterruptedException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobID = TypeConverter.toYarn(arg0);\r\n    GetTaskAttemptCompletionEventsRequest request = recordFactory.newRecordInstance(GetTaskAttemptCompletionEventsRequest.class);\r\n    request.setJobId(jobID);\r\n    request.setFromEventId(arg1);\r\n    request.setMaxEvents(arg2);\r\n    List<org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent> list = ((GetTaskAttemptCompletionEventsResponse) invoke(\"getTaskAttemptCompletionEvents\", GetTaskAttemptCompletionEventsRequest.class, request)).getCompletionEventList();\r\n    return TypeConverter.fromYarn(list.toArray(new org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent[0]));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID arg0) throws IOException, InterruptedException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID = TypeConverter.toYarn(arg0);\r\n    GetDiagnosticsRequest request = recordFactory.newRecordInstance(GetDiagnosticsRequest.class);\r\n    request.setTaskAttemptId(attemptID);\r\n    List<String> list = ((GetDiagnosticsResponse) invoke(\"getDiagnostics\", GetDiagnosticsRequest.class, request)).getDiagnosticsList();\r\n    String[] result = new String[list.size()];\r\n    int i = 0;\r\n    for (String c : list) {\r\n        result[i++] = c.toString();\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobStatus",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "JobStatus getJobStatus(JobID oldJobID) throws IOException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId = TypeConverter.toYarn(oldJobID);\r\n    GetJobReportRequest request = recordFactory.newRecordInstance(GetJobReportRequest.class);\r\n    request.setJobId(jobId);\r\n    JobReport report = ((GetJobReportResponse) invoke(\"getJobReport\", GetJobReportRequest.class, request)).getJobReport();\r\n    JobStatus jobStatus = null;\r\n    if (report != null) {\r\n        if (StringUtils.isEmpty(report.getJobFile())) {\r\n            String jobFile = MRApps.getJobFile(conf, report.getUser(), oldJobID);\r\n            report.setJobFile(jobFile);\r\n        }\r\n        String historyTrackingUrl = report.getTrackingUrl();\r\n        String url = StringUtils.isNotEmpty(historyTrackingUrl) ? historyTrackingUrl : trackingUrl;\r\n        jobStatus = TypeConverter.fromYarn(report, url);\r\n    }\r\n    return jobStatus;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskReports",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(JobID oldJobID, TaskType taskType) throws IOException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId = TypeConverter.toYarn(oldJobID);\r\n    GetTaskReportsRequest request = recordFactory.newRecordInstance(GetTaskReportsRequest.class);\r\n    request.setJobId(jobId);\r\n    request.setTaskType(TypeConverter.toYarn(taskType));\r\n    List<org.apache.hadoop.mapreduce.v2.api.records.TaskReport> taskReports = ((GetTaskReportsResponse) invoke(\"getTaskReports\", GetTaskReportsRequest.class, request)).getTaskReportList();\r\n    return TypeConverter.fromYarn(taskReports).toArray(new org.apache.hadoop.mapreduce.TaskReport[0]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killTask",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "boolean killTask(TaskAttemptID taskAttemptID, boolean fail) throws IOException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID = TypeConverter.toYarn(taskAttemptID);\r\n    if (fail) {\r\n        FailTaskAttemptRequest failRequest = recordFactory.newRecordInstance(FailTaskAttemptRequest.class);\r\n        failRequest.setTaskAttemptId(attemptID);\r\n        invoke(\"failTaskAttempt\", FailTaskAttemptRequest.class, failRequest);\r\n    } else {\r\n        KillTaskAttemptRequest killRequest = recordFactory.newRecordInstance(KillTaskAttemptRequest.class);\r\n        killRequest.setTaskAttemptId(attemptID);\r\n        invoke(\"killTaskAttempt\", KillTaskAttemptRequest.class, killRequest);\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killJob",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean killJob(JobID oldJobID) throws IOException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId = TypeConverter.toYarn(oldJobID);\r\n    KillJobRequest killRequest = recordFactory.newRecordInstance(KillJobRequest.class);\r\n    killRequest.setJobId(jobId);\r\n    invoke(\"killJob\", KillJobRequest.class, killRequest);\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLogFilePath",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "LogParams getLogFilePath(JobID oldJobID, TaskAttemptID oldTaskAttemptID) throws IOException\n{\r\n    org.apache.hadoop.mapreduce.v2.api.records.JobId jobId = TypeConverter.toYarn(oldJobID);\r\n    GetJobReportRequest request = recordFactory.newRecordInstance(GetJobReportRequest.class);\r\n    request.setJobId(jobId);\r\n    JobReport report = ((GetJobReportResponse) invoke(\"getJobReport\", GetJobReportRequest.class, request)).getJobReport();\r\n    if (EnumSet.of(JobState.SUCCEEDED, JobState.FAILED, JobState.KILLED, JobState.ERROR).contains(report.getJobState())) {\r\n        if (oldTaskAttemptID != null) {\r\n            GetTaskAttemptReportRequest taRequest = recordFactory.newRecordInstance(GetTaskAttemptReportRequest.class);\r\n            taRequest.setTaskAttemptId(TypeConverter.toYarn(oldTaskAttemptID));\r\n            TaskAttemptReport taReport = ((GetTaskAttemptReportResponse) invoke(\"getTaskAttemptReport\", GetTaskAttemptReportRequest.class, taRequest)).getTaskAttemptReport();\r\n            if (taReport.getContainerId() == null || taReport.getNodeManagerHost() == null) {\r\n                throw new IOException(\"Unable to get log information for task: \" + oldTaskAttemptID);\r\n            }\r\n            return new LogParams(taReport.getContainerId().toString(), taReport.getContainerId().getApplicationAttemptId().getApplicationId().toString(), NodeId.newInstance(taReport.getNodeManagerHost(), taReport.getNodeManagerPort()).toString(), report.getUser());\r\n        } else {\r\n            if (report.getAMInfos() == null || report.getAMInfos().size() == 0) {\r\n                throw new IOException(\"Unable to get log information for job: \" + oldJobID);\r\n            }\r\n            AMInfo amInfo = report.getAMInfos().get(report.getAMInfos().size() - 1);\r\n            return new LogParams(amInfo.getContainerId().toString(), amInfo.getAppAttemptId().getApplicationId().toString(), NodeId.newInstance(amInfo.getNodeManagerHost(), amInfo.getNodeManagerPort()).toString(), report.getUser());\r\n        }\r\n    } else {\r\n        throw new IOException(\"Cannot get log path for a in-progress job\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (rm != null) {\r\n        rm.close();\r\n    }\r\n    if (historyServerProxy != null) {\r\n        RPC.stopProxy(historyServerProxy);\r\n    }\r\n    if (realProxy != null) {\r\n        RPC.stopProxy(realProxy);\r\n        realProxy = null;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ClientProtocol create(Configuration conf) throws IOException\n{\r\n    if (MRConfig.YARN_FRAMEWORK_NAME.equals(conf.get(MRConfig.FRAMEWORK_NAME))) {\r\n        return new YARNRunner(conf);\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ClientProtocol create(InetSocketAddress addr, Configuration conf) throws IOException\n{\r\n    return create(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close(ClientProtocol clientProtocol) throws IOException\n{\r\n    if (clientProtocol instanceof YARNRunner) {\r\n        ((YARNRunner) clientProtocol).close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serviceInit",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void serviceInit(Configuration conf) throws Exception\n{\r\n    client.init(conf);\r\n    super.serviceInit(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serviceStart",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void serviceStart() throws Exception\n{\r\n    client.start();\r\n    super.serviceStart();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "serviceStop",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void serviceStop() throws Exception\n{\r\n    client.stop();\r\n    super.serviceStop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getActiveTrackers",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTrackerInfo[] getActiveTrackers() throws IOException, InterruptedException\n{\r\n    try {\r\n        return TypeConverter.fromYarnNodes(client.getNodeReports(NodeState.RUNNING));\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getAllJobs",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "JobStatus[] getAllJobs() throws IOException, InterruptedException\n{\r\n    try {\r\n        Set<String> appTypes = new HashSet<String>(1);\r\n        appTypes.add(MRJobConfig.MR_APPLICATION_TYPE);\r\n        EnumSet<YarnApplicationState> appStates = EnumSet.noneOf(YarnApplicationState.class);\r\n        return TypeConverter.fromYarnApps(client.getApplications(appTypes, appStates), this.conf);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getBlacklistedTrackers",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTrackerInfo[] getBlacklistedTrackers() throws IOException, InterruptedException\n{\r\n    LOG.warn(\"getBlacklistedTrackers - Not implemented yet\");\r\n    return new TaskTrackerInfo[0];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getClusterMetrics",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "ClusterMetrics getClusterMetrics() throws IOException, InterruptedException\n{\r\n    try {\r\n        YarnClusterMetrics metrics = client.getYarnClusterMetrics();\r\n        ClusterMetrics oldMetrics = new ClusterMetrics(1, 1, 1, 1, 1, 1, metrics.getNumNodeManagers() * 10, metrics.getNumNodeManagers() * 2, 1, metrics.getNumNodeManagers(), 0, 0);\r\n        return oldMetrics;\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getRMDelegationTokenService",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Text getRMDelegationTokenService()\n{\r\n    if (rmDTService == null) {\r\n        rmDTService = ClientRMProxy.getRMDelegationTokenService(conf);\r\n    }\r\n    return rmDTService;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getDelegationToken",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Token getDelegationToken(Text renewer) throws IOException, InterruptedException\n{\r\n    try {\r\n        return ConverterUtils.convertFromYarn(client.getRMDelegationToken(renewer), getRMDelegationTokenService());\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getFilesystemName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getFilesystemName() throws IOException, InterruptedException\n{\r\n    return FileSystem.get(conf).getUri().toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNewJobID",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "JobID getNewJobID() throws IOException, InterruptedException\n{\r\n    try {\r\n        this.application = client.createApplication().getApplicationSubmissionContext();\r\n        this.applicationId = this.application.getApplicationId();\r\n        return TypeConverter.fromYarn(applicationId);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueue",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "QueueInfo getQueue(String queueName) throws IOException, InterruptedException\n{\r\n    try {\r\n        org.apache.hadoop.yarn.api.records.QueueInfo queueInfo = client.getQueueInfo(queueName);\r\n        return (queueInfo == null) ? null : TypeConverter.fromYarn(queueInfo, conf);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueAclsForCurrentUser",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueAclsInfo[] getQueueAclsForCurrentUser() throws IOException, InterruptedException\n{\r\n    try {\r\n        return TypeConverter.fromYarnQueueUserAclsInfo(client.getQueueAclsInfo());\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueues",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo[] getQueues() throws IOException, InterruptedException\n{\r\n    try {\r\n        return TypeConverter.fromYarnQueueInfo(client.getAllQueues(), this.conf);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getRootQueues",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo[] getRootQueues() throws IOException, InterruptedException\n{\r\n    try {\r\n        return TypeConverter.fromYarnQueueInfo(client.getRootQueueInfos(), this.conf);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getChildQueues",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "QueueInfo[] getChildQueues(String parent) throws IOException, InterruptedException\n{\r\n    try {\r\n        return TypeConverter.fromYarnQueueInfo(client.getChildQueueInfos(parent), this.conf);\r\n    } catch (YarnException e) {\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getStagingAreaDir",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String getStagingAreaDir() throws IOException, InterruptedException\n{\r\n    String user = UserGroupInformation.getCurrentUser().getShortUserName();\r\n    Path path = MRApps.getStagingAreaDir(conf, user);\r\n    LOG.debug(\"getStagingAreaDir: dir=\" + path);\r\n    return path.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getSystemDir",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getSystemDir() throws IOException, InterruptedException\n{\r\n    Path sysDir = new Path(MRJobConfig.JOB_SUBMIT_DIR);\r\n    return sysDir.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskTrackerExpiryInterval",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getTaskTrackerExpiryInterval() throws IOException, InterruptedException\n{\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setJobPriority",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobPriority(JobID arg0, String arg1) throws IOException, InterruptedException\n{\r\n    return;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getProtocolVersion",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getProtocolVersion(String arg0, long arg1) throws IOException\n{\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplicationId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ApplicationId getApplicationId()\n{\r\n    return applicationId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "createApplication",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "YarnClientApplication createApplication() throws YarnException, IOException\n{\r\n    return client.createApplication();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "submitApplication",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ApplicationId submitApplication(ApplicationSubmissionContext appContext) throws YarnException, IOException\n{\r\n    return client.submitApplication(appContext);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "failApplicationAttempt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void failApplicationAttempt(ApplicationAttemptId attemptId) throws YarnException, IOException\n{\r\n    client.failApplicationAttempt(attemptId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killApplication",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void killApplication(ApplicationId applicationId) throws YarnException, IOException\n{\r\n    client.killApplication(applicationId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplicationReport",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ApplicationReport getApplicationReport(ApplicationId appId) throws YarnException, IOException\n{\r\n    return client.getApplicationReport(appId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getAMRMToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Token<AMRMTokenIdentifier> getAMRMToken(ApplicationId appId) throws YarnException, IOException\n{\r\n    throw new UnsupportedOperationException();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplications",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationReport> getApplications() throws YarnException, IOException\n{\r\n    return client.getApplications();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplications",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationReport> getApplications(Set<String> applicationTypes) throws YarnException, IOException\n{\r\n    return client.getApplications(applicationTypes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplications",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationReport> getApplications(EnumSet<YarnApplicationState> applicationStates) throws YarnException, IOException\n{\r\n    return client.getApplications(applicationStates);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplications",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationReport> getApplications(Set<String> applicationTypes, EnumSet<YarnApplicationState> applicationStates) throws YarnException, IOException\n{\r\n    return client.getApplications(applicationTypes, applicationStates);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplications",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationReport> getApplications(Set<String> applicationTypes, EnumSet<YarnApplicationState> applicationStates, Set<String> applicationTags) throws YarnException, IOException\n{\r\n    return client.getApplications(applicationTypes, applicationStates, applicationTags);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplications",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationReport> getApplications(Set<String> queues, Set<String> users, Set<String> applicationTypes, EnumSet<YarnApplicationState> applicationStates) throws YarnException, IOException\n{\r\n    return client.getApplications(queues, users, applicationTypes, applicationStates);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getYarnClusterMetrics",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "YarnClusterMetrics getYarnClusterMetrics() throws YarnException, IOException\n{\r\n    return client.getYarnClusterMetrics();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNodeReports",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<NodeReport> getNodeReports(NodeState... states) throws YarnException, IOException\n{\r\n    return client.getNodeReports(states);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getRMDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "org.apache.hadoop.yarn.api.records.Token getRMDelegationToken(Text renewer) throws YarnException, IOException\n{\r\n    return client.getRMDelegationToken(renewer);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueInfo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "org.apache.hadoop.yarn.api.records.QueueInfo getQueueInfo(String queueName) throws YarnException, IOException\n{\r\n    return client.getQueueInfo(queueName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getAllQueues",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<org.apache.hadoop.yarn.api.records.QueueInfo> getAllQueues() throws YarnException, IOException\n{\r\n    return client.getAllQueues();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getRootQueueInfos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<org.apache.hadoop.yarn.api.records.QueueInfo> getRootQueueInfos() throws YarnException, IOException\n{\r\n    return client.getRootQueueInfos();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getChildQueueInfos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<org.apache.hadoop.yarn.api.records.QueueInfo> getChildQueueInfos(String parent) throws YarnException, IOException\n{\r\n    return client.getChildQueueInfos(parent);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueAclsInfo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<QueueUserACLInfo> getQueueAclsInfo() throws YarnException, IOException\n{\r\n    return client.getQueueAclsInfo();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplicationAttemptReport",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ApplicationAttemptReport getApplicationAttemptReport(ApplicationAttemptId appAttemptId) throws YarnException, IOException\n{\r\n    return client.getApplicationAttemptReport(appAttemptId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getApplicationAttempts",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ApplicationAttemptReport> getApplicationAttempts(ApplicationId appId) throws YarnException, IOException\n{\r\n    return client.getApplicationAttempts(appId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getContainerReport",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ContainerReport getContainerReport(ContainerId containerId) throws YarnException, IOException\n{\r\n    return client.getContainerReport(containerId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getContainers",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ContainerReport> getContainers(ApplicationAttemptId applicationAttemptId) throws YarnException, IOException\n{\r\n    return client.getContainers(applicationAttemptId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "moveApplicationAcrossQueues",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void moveApplicationAcrossQueues(ApplicationId appId, String queue) throws YarnException, IOException\n{\r\n    client.moveApplicationAcrossQueues(appId, queue);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "createReservation",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "GetNewReservationResponse createReservation() throws YarnException, IOException\n{\r\n    return client.createReservation();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "submitReservation",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ReservationSubmissionResponse submitReservation(ReservationSubmissionRequest request) throws YarnException, IOException\n{\r\n    return client.submitReservation(request);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "updateReservation",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ReservationUpdateResponse updateReservation(ReservationUpdateRequest request) throws YarnException, IOException\n{\r\n    return client.updateReservation(request);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "deleteReservation",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ReservationDeleteResponse deleteReservation(ReservationDeleteRequest request) throws YarnException, IOException\n{\r\n    return client.deleteReservation(request);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "listReservations",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ReservationListResponse listReservations(ReservationListRequest request) throws YarnException, IOException\n{\r\n    return client.listReservations(request);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNodeToLabels",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<NodeId, Set<String>> getNodeToLabels() throws YarnException, IOException\n{\r\n    return client.getNodeToLabels();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLabelsToNodes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, Set<NodeId>> getLabelsToNodes() throws YarnException, IOException\n{\r\n    return client.getLabelsToNodes();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLabelsToNodes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, Set<NodeId>> getLabelsToNodes(Set<String> labels) throws YarnException, IOException\n{\r\n    return client.getLabelsToNodes(labels);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getClusterNodeLabels",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<NodeLabel> getClusterNodeLabels() throws YarnException, IOException\n{\r\n    return client.getClusterNodeLabels();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "updateApplicationPriority",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Priority updateApplicationPriority(ApplicationId applicationId, Priority priority) throws YarnException, IOException\n{\r\n    return client.updateApplicationPriority(applicationId, priority);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "signalToContainer",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void signalToContainer(ContainerId containerId, SignalContainerCommand command) throws YarnException, IOException\n{\r\n    client.signalToContainer(containerId, command);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killApplication",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void killApplication(ApplicationId appId, String diagnostics) throws YarnException, IOException\n{\r\n    client.killApplication(appId, diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getResourceProfiles",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, Resource> getResourceProfiles() throws YarnException, IOException\n{\r\n    return client.getResourceProfiles();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getResourceProfile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Resource getResourceProfile(String profile) throws YarnException, IOException\n{\r\n    return client.getResourceProfile(profile);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getResourceTypeInfo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<ResourceTypeInfo> getResourceTypeInfo() throws YarnException, IOException\n{\r\n    return client.getResourceTypeInfo();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getClusterAttributes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Set<NodeAttributeInfo> getClusterAttributes() throws YarnException, IOException\n{\r\n    return client.getClusterAttributes();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getAttributesToNodes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<NodeAttributeKey, List<NodeToAttributeValue>> getAttributesToNodes(Set<NodeAttributeKey> attributes) throws YarnException, IOException\n{\r\n    return client.getAttributesToNodes(attributes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNodeToAttributes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, Set<NodeAttribute>> getNodeToAttributes(Set<String> hostNames) throws YarnException, IOException\n{\r\n    return client.getNodeToAttributes(hostNames);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "shellToContainer",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void shellToContainer(ContainerId containerId, ShellContainerCommand command) throws IOException\n{\r\n    throw new IOException(\"Operation is not supported.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getUnknownApplicationReport",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "ApplicationReport getUnknownApplicationReport()\n{\r\n    ApplicationId unknownAppId = recordFactory.newRecordInstance(ApplicationId.class);\r\n    ApplicationAttemptId unknownAttemptId = recordFactory.newRecordInstance(ApplicationAttemptId.class);\r\n    return ApplicationReport.newInstance(unknownAppId, unknownAttemptId, \"N/A\", \"N/A\", \"N/A\", \"N/A\", 0, null, YarnApplicationState.NEW, \"N/A\", \"N/A\", 0, 0, 0, FinalApplicationStatus.UNDEFINED, null, \"N/A\", 0.0f, YarnConfiguration.DEFAULT_APPLICATION_TYPE, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "failTaskAttempt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FailTaskAttemptResponse failTaskAttempt(FailTaskAttemptRequest request) throws IOException\n{\r\n    FailTaskAttemptResponse resp = recordFactory.newRecordInstance(FailTaskAttemptResponse.class);\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getCounters",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "GetCountersResponse getCounters(GetCountersRequest request) throws IOException\n{\r\n    GetCountersResponse resp = recordFactory.newRecordInstance(GetCountersResponse.class);\r\n    Counters counters = recordFactory.newRecordInstance(Counters.class);\r\n    counters.addAllCounterGroups(new HashMap<String, CounterGroup>());\r\n    resp.setCounters(counters);\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDiagnosticsResponse getDiagnostics(GetDiagnosticsRequest request) throws IOException\n{\r\n    GetDiagnosticsResponse resp = recordFactory.newRecordInstance(GetDiagnosticsResponse.class);\r\n    resp.addDiagnostics(\"\");\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobReport",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "GetJobReportResponse getJobReport(GetJobReportRequest request) throws IOException\n{\r\n    JobReport jobReport = recordFactory.newRecordInstance(JobReport.class);\r\n    jobReport.setJobId(request.getJobId());\r\n    jobReport.setJobState(jobState);\r\n    jobReport.setUser(applicationReport.getUser());\r\n    jobReport.setStartTime(applicationReport.getStartTime());\r\n    YarnApplicationState state = applicationReport.getYarnApplicationState();\r\n    if (Apps.isApplicationFinalState(state)) {\r\n        jobReport.setDiagnostics(applicationReport.getDiagnostics());\r\n    }\r\n    jobReport.setJobName(applicationReport.getName());\r\n    jobReport.setTrackingUrl(applicationReport.getTrackingUrl());\r\n    jobReport.setFinishTime(applicationReport.getFinishTime());\r\n    GetJobReportResponse resp = recordFactory.newRecordInstance(GetJobReportResponse.class);\r\n    resp.setJobReport(jobReport);\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskAttemptCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptCompletionEventsResponse getTaskAttemptCompletionEvents(GetTaskAttemptCompletionEventsRequest request) throws IOException\n{\r\n    GetTaskAttemptCompletionEventsResponse resp = recordFactory.newRecordInstance(GetTaskAttemptCompletionEventsResponse.class);\r\n    resp.addAllCompletionEvents(new ArrayList<TaskAttemptCompletionEvent>());\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskAttemptReport",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "GetTaskAttemptReportResponse getTaskAttemptReport(GetTaskAttemptReportRequest request) throws IOException\n{\r\n    throw new NotImplementedException(\"Code is not implemented\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskReport",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "GetTaskReportResponse getTaskReport(GetTaskReportRequest request) throws IOException\n{\r\n    GetTaskReportResponse resp = recordFactory.newRecordInstance(GetTaskReportResponse.class);\r\n    TaskReport report = recordFactory.newRecordInstance(TaskReport.class);\r\n    report.setTaskId(request.getTaskId());\r\n    report.setTaskState(TaskState.NEW);\r\n    Counters counters = recordFactory.newRecordInstance(Counters.class);\r\n    counters.addAllCounterGroups(new HashMap<String, CounterGroup>());\r\n    report.setCounters(counters);\r\n    report.addAllRunningAttempts(new ArrayList<TaskAttemptId>());\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskReports",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportsResponse getTaskReports(GetTaskReportsRequest request) throws IOException\n{\r\n    GetTaskReportsResponse resp = recordFactory.newRecordInstance(GetTaskReportsResponse.class);\r\n    resp.addAllTaskReports(new ArrayList<TaskReport>());\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killJob",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KillJobResponse killJob(KillJobRequest request) throws IOException\n{\r\n    KillJobResponse resp = recordFactory.newRecordInstance(KillJobResponse.class);\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killTask",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KillTaskResponse killTask(KillTaskRequest request) throws IOException\n{\r\n    KillTaskResponse resp = recordFactory.newRecordInstance(KillTaskResponse.class);\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killTaskAttempt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KillTaskAttemptResponse killTaskAttempt(KillTaskAttemptRequest request) throws IOException\n{\r\n    KillTaskAttemptResponse resp = recordFactory.newRecordInstance(KillTaskAttemptResponse.class);\r\n    return resp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "GetDelegationTokenResponse getDelegationToken(GetDelegationTokenRequest request) throws IOException\n{\r\n    throw new NotImplementedException(\"Code is not implemented\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "renewDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "RenewDelegationTokenResponse renewDelegationToken(RenewDelegationTokenRequest request) throws IOException\n{\r\n    throw new NotImplementedException(\"Code is not implemented\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "cancelDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CancelDelegationTokenResponse cancelDelegationToken(CancelDelegationTokenRequest request) throws IOException\n{\r\n    throw new NotImplementedException(\"Code is not implemented\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-jobclient\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getConnectAddress",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "InetSocketAddress getConnectAddress()\n{\r\n    throw new NotImplementedException(\"Code is not implemented\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]