[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "getParameters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Collection<Object[]> getParameters()\n{\r\n    return Arrays.asList(new Object[][] { { \"DefaultResourceCalculator\", new DefaultResourceCalculator() }, { \"DominantResourceCalculator\", new DominantResourceCalculator() } });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setupNoExtraResource",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setupNoExtraResource()\n{\r\n    ResourceUtils.resetResourceTypes(new Configuration());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setupExtraResource",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setupExtraResource()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(YarnConfiguration.RESOURCE_TYPES, EXTRA_RESOURCE_NAME);\r\n    ResourceUtils.resetResourceTypes(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testFitsIn",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testFitsIn()\n{\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        Assert.assertTrue(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(2, 1)));\r\n        Assert.assertTrue(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(2, 2)));\r\n        Assert.assertTrue(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(1, 2)));\r\n        Assert.assertTrue(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(1, 1)));\r\n        Assert.assertFalse(resourceCalculator.fitsIn(Resource.newInstance(2, 1), Resource.newInstance(1, 2)));\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        Assert.assertFalse(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(2, 1)));\r\n        Assert.assertTrue(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(2, 2)));\r\n        Assert.assertTrue(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(1, 2)));\r\n        Assert.assertFalse(resourceCalculator.fitsIn(Resource.newInstance(1, 2), Resource.newInstance(1, 1)));\r\n        Assert.assertFalse(resourceCalculator.fitsIn(Resource.newInstance(2, 1), Resource.newInstance(1, 2)));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "newResource",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Resource newResource(long memory, int cpu)\n{\r\n    Resource res = Resource.newInstance(memory, cpu);\r\n    return res;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "newResource",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Resource newResource(long memory, int cpu, int extraResource)\n{\r\n    Resource res = newResource(memory, cpu);\r\n    res.setResourceValue(EXTRA_RESOURCE_NAME, extraResource);\r\n    return res;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "assertComparison",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void assertComparison(Resource cluster, Resource res1, Resource res2, int expected)\n{\r\n    int actual = resourceCalculator.compare(cluster, res1, res2);\r\n    assertEquals(String.format(\"Resource comparison did not give the expected \" + \"result for %s v/s %s\", res1.toString(), res2.toString()), expected, actual);\r\n    if (expected != 0) {\r\n        actual = resourceCalculator.compare(cluster, res2, res1);\r\n        assertEquals(String.format(\"Resource comparison did not give the \" + \"expected result for %s v/s %s\", res2.toString(), res1.toString()), expected * -1, actual);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareWithOnlyMandatory",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testCompareWithOnlyMandatory()\n{\r\n    Resource cluster = newResource(4, 4);\r\n    assertComparison(cluster, newResource(1, 1), newResource(1, 1), 0);\r\n    assertComparison(cluster, newResource(0, 0), newResource(0, 0), 0);\r\n    assertComparison(cluster, newResource(2, 2), newResource(1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2), newResource(0, 0), 1);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        testCompareDefaultWithOnlyMandatory(cluster);\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        testCompareDominantWithOnlyMandatory(cluster);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareDefaultWithOnlyMandatory",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCompareDefaultWithOnlyMandatory(Resource cluster)\n{\r\n    assertComparison(cluster, newResource(1, 1), newResource(1, 1), 0);\r\n    assertComparison(cluster, newResource(1, 2), newResource(1, 1), 0);\r\n    assertComparison(cluster, newResource(1, 1), newResource(1, 0), 0);\r\n    assertComparison(cluster, newResource(2, 1), newResource(1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 1), newResource(1, 2), 1);\r\n    assertComparison(cluster, newResource(2, 1), newResource(1, 0), 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareDominantWithOnlyMandatory",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCompareDominantWithOnlyMandatory(Resource cluster)\n{\r\n    assertComparison(cluster, newResource(2, 1), newResource(2, 1), 0);\r\n    assertComparison(cluster, newResource(2, 1), newResource(1, 2), 0);\r\n    assertComparison(cluster, newResource(2, 1), newResource(1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2), newResource(2, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2), newResource(1, 2), 1);\r\n    assertComparison(cluster, newResource(3, 1), newResource(3, 0), 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompare",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testCompare()\n{\r\n    setupExtraResource();\r\n    Resource cluster = newResource(4L, 4, 4);\r\n    assertComparison(cluster, newResource(1, 1, 1), newResource(1, 1, 1), 0);\r\n    assertComparison(cluster, newResource(0, 0, 0), newResource(0, 0, 0), 0);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(1, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(0, 0, 0), 1);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        testCompareDefault(cluster);\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        testCompareDominant(cluster);\r\n        testCompareDominantZeroValueResource();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareDefault",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testCompareDefault(Resource cluster)\n{\r\n    assertComparison(cluster, newResource(1, 1, 2), newResource(1, 1, 1), 0);\r\n    assertComparison(cluster, newResource(1, 2, 1), newResource(1, 1, 1), 0);\r\n    assertComparison(cluster, newResource(1, 2, 2), newResource(1, 1, 1), 0);\r\n    assertComparison(cluster, newResource(1, 2, 2), newResource(1, 0, 0), 0);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 2, 1), 1);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 2), 1);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 2, 2), 1);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 0, 0), 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareDominantZeroValueResource",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testCompareDominantZeroValueResource()\n{\r\n    Resource cluster = newResource(4L, 4, 0);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 2), 1);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(1, 2, 2), 1);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(2, 2, 2), 0);\r\n    assertComparison(cluster, newResource(0, 2, 1), newResource(0, 2, 2), 0);\r\n    assertComparison(cluster, newResource(0, 1, 2), newResource(1, 1, 2), -1);\r\n    assertComparison(cluster, newResource(1, 1, 2), newResource(2, 1, 2), -1);\r\n    cluster = newResource(0, 0, 0);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(1, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 2, 1), 0);\r\n    assertComparison(cluster, newResource(1, 1, 1), newResource(1, 1, 1), 0);\r\n    assertComparison(cluster, newResource(1, 1, 1), newResource(1, 1, 2), -1);\r\n    assertComparison(cluster, newResource(1, 1, 1), newResource(1, 2, 1), -1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareDominant",
  "errType" : null,
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void testCompareDominant(Resource cluster)\n{\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(2, 1, 1), 0);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 2, 1), 0);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 2), 0);\r\n    assertComparison(cluster, newResource(2, 1, 0), newResource(0, 1, 2), 0);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(1, 2, 2), 0);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(2, 1, 2), 0);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(2, 2, 1), 0);\r\n    assertComparison(cluster, newResource(2, 2, 0), newResource(2, 0, 2), 0);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(3, 2, 1), 0);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(3, 1, 2), 0);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(1, 2, 3), 0);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(1, 3, 2), 0);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(2, 1, 3), 0);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(2, 3, 1), 0);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 1, 1), newResource(1, 1, 0), 1);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(2, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(1, 2, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(1, 1, 2), 1);\r\n    assertComparison(cluster, newResource(2, 2, 1), newResource(0, 2, 2), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(2, 1, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(1, 2, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(1, 1, 2), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(2, 2, 1), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(2, 1, 2), 1);\r\n    assertComparison(cluster, newResource(2, 2, 2), newResource(1, 2, 2), 1);\r\n    assertComparison(cluster, newResource(3, 2, 1), newResource(2, 2, 2), 1);\r\n    assertComparison(cluster, newResource(3, 1, 1), newResource(2, 2, 2), 1);\r\n    assertComparison(cluster, newResource(3, 1, 1), newResource(3, 1, 0), 1);\r\n    assertComparison(cluster, newResource(3, 1, 1), newResource(3, 0, 0), 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareWithEmptyCluster",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testCompareWithEmptyCluster()\n{\r\n    Resource clusterResource = Resource.newInstance(0, 0);\r\n    Resource lhs = Resource.newInstance(0, 0);\r\n    Resource rhs = Resource.newInstance(0, 0);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, false, true, false, true, lhs, lhs);\r\n    lhs = Resource.newInstance(1, 1);\r\n    rhs = Resource.newInstance(0, 0);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, false, false, true, true, lhs, rhs);\r\n    lhs = Resource.newInstance(0, 0);\r\n    rhs = Resource.newInstance(1, 1);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, true, true, false, false, rhs, lhs);\r\n    if (!(resourceCalculator instanceof DominantResourceCalculator)) {\r\n        return;\r\n    }\r\n    lhs = Resource.newInstance(1, 0);\r\n    rhs = Resource.newInstance(0, 1);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, false, true, false, true, lhs, lhs);\r\n    lhs = Resource.newInstance(0, 1);\r\n    rhs = Resource.newInstance(1, 0);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, false, true, false, true, lhs, lhs);\r\n    lhs = Resource.newInstance(1, 1);\r\n    rhs = Resource.newInstance(1, 0);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, false, false, true, true, lhs, rhs);\r\n    lhs = Resource.newInstance(0, 1);\r\n    rhs = Resource.newInstance(1, 1);\r\n    assertResourcesOperations(clusterResource, lhs, rhs, true, true, false, false, rhs, lhs);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "assertResourcesOperations",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void assertResourcesOperations(Resource clusterResource, Resource lhs, Resource rhs, boolean lessThan, boolean lessThanOrEqual, boolean greaterThan, boolean greaterThanOrEqual, Resource max, Resource min)\n{\r\n    assertEquals(\"Less Than operation is wrongly calculated.\", lessThan, Resources.lessThan(resourceCalculator, clusterResource, lhs, rhs));\r\n    assertEquals(\"Less Than Or Equal To operation is wrongly calculated.\", lessThanOrEqual, Resources.lessThanOrEqual(resourceCalculator, clusterResource, lhs, rhs));\r\n    assertEquals(\"Greater Than operation is wrongly calculated.\", greaterThan, Resources.greaterThan(resourceCalculator, clusterResource, lhs, rhs));\r\n    assertEquals(\"Greater Than Or Equal To operation is wrongly calculated.\", greaterThanOrEqual, Resources.greaterThanOrEqual(resourceCalculator, clusterResource, lhs, rhs));\r\n    assertEquals(\"Max(value) Operation wrongly calculated.\", max, Resources.max(resourceCalculator, clusterResource, lhs, rhs));\r\n    assertEquals(\"Min(value) operation is wrongly calculated.\", min, Resources.min(resourceCalculator, clusterResource, lhs, rhs));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testNormalize",
  "errType" : null,
  "containingMethodsNum" : 36,
  "sourceCodeText" : "void testNormalize()\n{\r\n    Resource ask = Resource.newInstance(1111, 2);\r\n    Resource min = Resource.newInstance(1024, 1);\r\n    Resource max = Resource.newInstance(8 * 1024, 8);\r\n    Resource increment = Resource.newInstance(1024, 4);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(2 * 1024, result.getMemorySize());\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(2 * 1024, result.getMemorySize());\r\n        assertEquals(4, result.getVirtualCores());\r\n    }\r\n    ask = Resource.newInstance(512, 0);\r\n    min = Resource.newInstance(2 * 1024, 2);\r\n    max = Resource.newInstance(8 * 1024, 8);\r\n    increment = Resource.newInstance(1024, 1);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(2 * 1024, result.getMemorySize());\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(2 * 1024, result.getMemorySize());\r\n        assertEquals(2, result.getVirtualCores());\r\n    }\r\n    ask = Resource.newInstance(9 * 1024, 9);\r\n    min = Resource.newInstance(2 * 1024, 2);\r\n    max = Resource.newInstance(8 * 1024, 8);\r\n    increment = Resource.newInstance(1024, 1);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(8 * 1024, result.getMemorySize());\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(8 * 1024, result.getMemorySize());\r\n        assertEquals(8, result.getVirtualCores());\r\n    }\r\n    ask = Resource.newInstance(1111, 2);\r\n    min = Resource.newInstance(2 * 1024, 2);\r\n    max = Resource.newInstance(8 * 1024, 8);\r\n    increment = Resource.newInstance(0, 0);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(2 * 1024, result.getMemorySize());\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        Resource result = Resources.normalize(resourceCalculator, ask, min, max, increment);\r\n        assertEquals(2 * 1024, result.getMemorySize());\r\n        assertEquals(2, result.getVirtualCores());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testDivisionByZeroRatioDenominatorIsZero",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testDivisionByZeroRatioDenominatorIsZero()\n{\r\n    float ratio = resourceCalculator.ratio(newResource(1, 1), newResource(0, 0));\r\n    assertEquals(Float.POSITIVE_INFINITY, ratio, 0.00001);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testDivisionByZeroRatioNumeratorAndDenominatorIsZero",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testDivisionByZeroRatioNumeratorAndDenominatorIsZero()\n{\r\n    float ratio = resourceCalculator.ratio(newResource(0, 0), newResource(0, 0));\r\n    assertEquals(0.0, ratio, 0.00001);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testFitsInDiagnosticsCollector",
  "errType" : null,
  "containingMethodsNum" : 32,
  "sourceCodeText" : "void testFitsInDiagnosticsCollector()\n{\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(1, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(1, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(1, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(1, 1)));\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 0), newResource(1, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.VCORES_URI), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.VCORES_URI), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(0, 1), newResource(1, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 0), newResource(1, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI, ResourceInformation.VCORES_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(0, 0)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.MEMORY_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(0, 1)));\r\n        assertEquals(ImmutableSet.of(ResourceInformation.VCORES_URI), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(1, 0)));\r\n        assertEquals(ImmutableSet.of(), resourceCalculator.getInsufficientResourceNames(newResource(1, 1), newResource(1, 1)));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testRatioWithNoExtraResource",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testRatioWithNoExtraResource()\n{\r\n    Resource resource1 = newResource(1, 1);\r\n    Resource resource2 = newResource(2, 1);\r\n    float ratio = resourceCalculator.ratio(resource1, resource2);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        double ratioOfMemories = 0.5;\r\n        assertEquals(ratioOfMemories, ratio, 0.00001);\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        double ratioOfCPUs = 1.0;\r\n        assertEquals(ratioOfCPUs, ratio, 0.00001);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testRatioWithExtraResource",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testRatioWithExtraResource()\n{\r\n    setupExtraResource();\r\n    Resource resource1 = newResource(1, 1, 2);\r\n    Resource resource2 = newResource(2, 1, 1);\r\n    float ratio = resourceCalculator.ratio(resource1, resource2);\r\n    if (resourceCalculator instanceof DefaultResourceCalculator) {\r\n        double ratioOfMemories = 0.5;\r\n        assertEquals(ratioOfMemories, ratio, 0.00001);\r\n    } else if (resourceCalculator instanceof DominantResourceCalculator) {\r\n        double ratioOfExtraResources = 2.0;\r\n        assertEquals(ratioOfExtraResources, ratio, 0.00001);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testAccessDenied",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testAccessDenied() throws Exception\n{\r\n    FileUtil.fullyDelete(new File(\"target/logs\"));\r\n    Configuration configuration = getConfiguration();\r\n    writeLogs(\"target/logs/logs/application_0_0001/container_0_0001_01_000001\");\r\n    writeLog(configuration, \"owner\");\r\n    ByteArrayOutputStream data = new ByteArrayOutputStream();\r\n    PrintWriter printWriter = new PrintWriter(data);\r\n    HtmlBlock html = new HtmlBlockForTest();\r\n    HtmlBlock.Block block = new BlockForTest(html, printWriter, 10, false);\r\n    TFileAggregatedLogsBlockForTest aggregatedBlock = getTFileAggregatedLogsBlockForTest(configuration, \"owner\", \"container_0_0001_01_000001\", \"localhost:1234\");\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    String out = data.toString();\r\n    assertTrue(out.contains(\"User [owner] is not authorized to view the logs for entity\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testBlockContainsPortNumForUnavailableAppLog",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testBlockContainsPortNumForUnavailableAppLog()\n{\r\n    FileUtil.fullyDelete(new File(\"target/logs\"));\r\n    Configuration configuration = getConfiguration();\r\n    String nodeName = configuration.get(YarnConfiguration.NM_WEBAPP_ADDRESS, YarnConfiguration.DEFAULT_NM_WEBAPP_ADDRESS);\r\n    AggregatedLogsBlockForTest aggregatedBlock = getAggregatedLogsBlockForTest(configuration, \"admin\", \"container_0_0001_01_000001\", nodeName);\r\n    ByteArrayOutputStream data = new ByteArrayOutputStream();\r\n    PrintWriter printWriter = new PrintWriter(data);\r\n    HtmlBlock html = new HtmlBlockForTest();\r\n    HtmlBlock.Block block = new BlockForTest(html, printWriter, 10, false);\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    String out = data.toString();\r\n    assertTrue(out.contains(nodeName));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testBadLogs",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testBadLogs() throws Exception\n{\r\n    FileUtil.fullyDelete(new File(\"target/logs\"));\r\n    Configuration configuration = getConfiguration();\r\n    writeLogs(\"target/logs/logs/application_0_0001/container_0_0001_01_000001\");\r\n    writeLog(configuration, \"owner\");\r\n    AggregatedLogsBlockForTest aggregatedBlock = getAggregatedLogsBlockForTest(configuration, \"admin\", \"container_0_0001_01_000001\");\r\n    ByteArrayOutputStream data = new ByteArrayOutputStream();\r\n    PrintWriter printWriter = new PrintWriter(data);\r\n    HtmlBlock html = new HtmlBlockForTest();\r\n    HtmlBlock.Block block = new BlockForTest(html, printWriter, 10, false);\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    String out = data.toString();\r\n    assertTrue(out.contains(\"Logs not available for entity. Aggregation may not be \" + \"complete, Check back later or try to find the container logs \" + \"in the local directory of nodemanager localhost:1234\"));\r\n    assertTrue(out.contains(\"Or see application log at http://localhost:8042\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testAggregatedLogsBlock",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testAggregatedLogsBlock() throws Exception\n{\r\n    FileUtil.fullyDelete(new File(\"target/logs\"));\r\n    Configuration configuration = getConfiguration();\r\n    writeLogs(\"target/logs/logs/application_0_0001/container_0_0001_01_000001\");\r\n    writeLog(configuration, \"admin\");\r\n    ByteArrayOutputStream data = new ByteArrayOutputStream();\r\n    PrintWriter printWriter = new PrintWriter(data);\r\n    HtmlBlock html = new HtmlBlockForTest();\r\n    HtmlBlock.Block block = new BlockForTest(html, printWriter, 10, false);\r\n    TFileAggregatedLogsBlockForTest aggregatedBlock = getTFileAggregatedLogsBlockForTest(configuration, \"admin\", \"container_0_0001_01_000001\", \"localhost:1234\");\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    String out = data.toString();\r\n    assertTrue(out.contains(\"test log1\"));\r\n    assertTrue(out.contains(\"test log2\"));\r\n    assertTrue(out.contains(\"test log3\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testAggregatedLogsBlockHar",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testAggregatedLogsBlockHar() throws Exception\n{\r\n    FileUtil.fullyDelete(new File(\"target/logs\"));\r\n    Configuration configuration = getConfiguration();\r\n    URL harUrl = ClassLoader.getSystemClassLoader().getResource(\"application_1440536969523_0001.har\");\r\n    assertNotNull(harUrl);\r\n    String path = \"target/logs/admin/logs/application_1440536969523_0001\" + \"/application_1440536969523_0001.har\";\r\n    FileUtils.copyDirectory(new File(harUrl.getPath()), new File(path));\r\n    ByteArrayOutputStream data = new ByteArrayOutputStream();\r\n    PrintWriter printWriter = new PrintWriter(data);\r\n    HtmlBlock html = new HtmlBlockForTest();\r\n    HtmlBlock.Block block = new BlockForTest(html, printWriter, 10, false);\r\n    TFileAggregatedLogsBlockForTest aggregatedBlock = getTFileAggregatedLogsBlockForTest(configuration, \"admin\", \"container_1440536969523_0001_01_000001\", \"host1:1111\");\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    String out = data.toString();\r\n    assertTrue(out.contains(\"Hello stderr\"));\r\n    assertTrue(out.contains(\"Hello stdout\"));\r\n    assertTrue(out.contains(\"Hello syslog\"));\r\n    aggregatedBlock = getTFileAggregatedLogsBlockForTest(configuration, \"admin\", \"container_1440536969523_0001_01_000002\", \"host2:2222\");\r\n    data = new ByteArrayOutputStream();\r\n    printWriter = new PrintWriter(data);\r\n    html = new HtmlBlockForTest();\r\n    block = new BlockForTest(html, printWriter, 10, false);\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    out = data.toString();\r\n    assertTrue(out.contains(\"Goodbye stderr\"));\r\n    assertTrue(out.contains(\"Goodbye stdout\"));\r\n    assertTrue(out.contains(\"Goodbye syslog\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testNoLogs",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testNoLogs() throws Exception\n{\r\n    FileUtil.fullyDelete(new File(\"target/logs\"));\r\n    Configuration configuration = getConfiguration();\r\n    File f = new File(\"target/logs/logs/application_0_0001/container_0_0001_01_000001\");\r\n    if (!f.exists()) {\r\n        assertTrue(f.mkdirs());\r\n    }\r\n    writeLog(configuration, \"admin\");\r\n    ByteArrayOutputStream data = new ByteArrayOutputStream();\r\n    PrintWriter printWriter = new PrintWriter(data);\r\n    HtmlBlock html = new HtmlBlockForTest();\r\n    HtmlBlock.Block block = new BlockForTest(html, printWriter, 10, false);\r\n    TFileAggregatedLogsBlockForTest aggregatedBlock = getTFileAggregatedLogsBlockForTest(configuration, \"admin\", \"container_0_0001_01_000001\", \"localhost:1234\");\r\n    aggregatedBlock.render(block);\r\n    block.getWriter().flush();\r\n    String out = data.toString();\r\n    assertTrue(out.contains(\"No logs available for container container_0_0001_01_000001\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "getConfiguration",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "Configuration getConfiguration()\n{\r\n    Configuration configuration = new YarnConfiguration();\r\n    configuration.setBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED, true);\r\n    configuration.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, \"target/logs\");\r\n    configuration.setBoolean(YarnConfiguration.YARN_ACL_ENABLE, true);\r\n    configuration.set(YarnConfiguration.YARN_ADMIN_ACL, \"admin\");\r\n    return configuration;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "getAggregatedLogsBlockForTest",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "AggregatedLogsBlockForTest getAggregatedLogsBlockForTest(Configuration configuration, String user, String containerId)\n{\r\n    return getAggregatedLogsBlockForTest(configuration, user, containerId, \"localhost:1234\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "getTFileAggregatedLogsBlockForTest",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "TFileAggregatedLogsBlockForTest getTFileAggregatedLogsBlockForTest(Configuration configuration, String user, String containerId, String nodeName)\n{\r\n    HttpServletRequest request = mock(HttpServletRequest.class);\r\n    when(request.getRemoteUser()).thenReturn(user);\r\n    ViewContext mockContext = mock(ViewContext.class);\r\n    TFileAggregatedLogsBlockForTest aggregatedBlock = new TFileAggregatedLogsBlockForTest(mockContext, configuration);\r\n    aggregatedBlock.setRequest(request);\r\n    aggregatedBlock.moreParams().put(YarnWebParams.CONTAINER_ID, containerId);\r\n    aggregatedBlock.moreParams().put(YarnWebParams.NM_NODENAME, nodeName);\r\n    aggregatedBlock.moreParams().put(YarnWebParams.APP_OWNER, user);\r\n    aggregatedBlock.moreParams().put(\"start\", \"\");\r\n    aggregatedBlock.moreParams().put(\"end\", \"\");\r\n    aggregatedBlock.moreParams().put(YarnWebParams.ENTITY_STRING, \"entity\");\r\n    return aggregatedBlock;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "getAggregatedLogsBlockForTest",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "AggregatedLogsBlockForTest getAggregatedLogsBlockForTest(Configuration configuration, String user, String containerId, String nodeName)\n{\r\n    HttpServletRequest request = mock(HttpServletRequest.class);\r\n    when(request.getRemoteUser()).thenReturn(user);\r\n    AggregatedLogsBlockForTest aggregatedBlock = new AggregatedLogsBlockForTest(configuration);\r\n    aggregatedBlock.setRequest(request);\r\n    aggregatedBlock.moreParams().put(YarnWebParams.CONTAINER_ID, containerId);\r\n    aggregatedBlock.moreParams().put(YarnWebParams.NM_NODENAME, nodeName);\r\n    aggregatedBlock.moreParams().put(YarnWebParams.APP_OWNER, user);\r\n    aggregatedBlock.moreParams().put(\"start\", \"\");\r\n    aggregatedBlock.moreParams().put(\"end\", \"\");\r\n    aggregatedBlock.moreParams().put(YarnWebParams.ENTITY_STRING, \"entity\");\r\n    return aggregatedBlock;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "writeLog",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void writeLog(Configuration configuration, String user) throws Exception\n{\r\n    ApplicationId appId = ApplicationIdPBImpl.newInstance(0, 1);\r\n    ApplicationAttemptId appAttemptId = ApplicationAttemptIdPBImpl.newInstance(appId, 1);\r\n    ContainerId containerId = ContainerIdPBImpl.newContainerId(appAttemptId, 1);\r\n    String path = \"target/logs/\" + user + \"/logs/application_0_0001/localhost_1234\";\r\n    File f = new File(path);\r\n    if (!f.getParentFile().exists()) {\r\n        assertTrue(f.getParentFile().mkdirs());\r\n    }\r\n    List<String> rootLogDirs = Arrays.asList(\"target/logs/logs\");\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(configuration);\r\n    LogAggregationFileController fileController = factory.getFileControllerForWrite();\r\n    try {\r\n        Map<ApplicationAccessType, String> appAcls = new HashMap<>();\r\n        appAcls.put(ApplicationAccessType.VIEW_APP, ugi.getUserName());\r\n        NodeId nodeId = NodeId.newInstance(\"localhost\", 1234);\r\n        LogAggregationFileControllerContext context = new LogAggregationFileControllerContext(new Path(path), new Path(path), false, 3600, appId, appAcls, nodeId, ugi);\r\n        fileController.initializeWriter(context);\r\n        fileController.write(new AggregatedLogFormat.LogKey(\"container_0_0001_01_000001\"), new AggregatedLogFormat.LogValue(rootLogDirs, containerId, UserGroupInformation.getCurrentUser().getShortUserName()));\r\n    } finally {\r\n        fileController.closeWriter();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "writeLogs",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void writeLogs(String dirName) throws Exception\n{\r\n    File f = new File(dirName + File.separator + \"log1\");\r\n    if (!f.getParentFile().exists()) {\r\n        assertTrue(f.getParentFile().mkdirs());\r\n    }\r\n    writeLog(dirName + File.separator + \"log1\", \"test log1\");\r\n    writeLog(dirName + File.separator + \"log2\", \"test log2\");\r\n    writeLog(dirName + File.separator + \"log3\", \"test log3\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "writeLog",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeLog(String fileName, String text) throws Exception\n{\r\n    File f = new File(fileName);\r\n    Writer writer = new FileWriter(f);\r\n    writer.write(text);\r\n    writer.flush();\r\n    writer.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "test",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void test()\n{\r\n    testPbServerFactory();\r\n    testPbClientFactory();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testPbServerFactory",
  "errType" : [ "YarnRuntimeException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testPbServerFactory()\n{\r\n    InetSocketAddress addr = new InetSocketAddress(0);\r\n    Configuration conf = new Configuration();\r\n    ApplicationMasterProtocol instance = new AMRMProtocolTestImpl();\r\n    Server server = null;\r\n    try {\r\n        server = RpcServerFactoryPBImpl.get().getServer(ApplicationMasterProtocol.class, instance, addr, conf, null, 1);\r\n        server.start();\r\n    } catch (YarnRuntimeException e) {\r\n        e.printStackTrace();\r\n        Assert.fail(\"Failed to create server\");\r\n    } finally {\r\n        if (server != null) {\r\n            server.stop();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testPbClientFactory",
  "errType" : [ "YarnRuntimeException", "YarnRuntimeException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testPbClientFactory()\n{\r\n    InetSocketAddress addr = new InetSocketAddress(0);\r\n    System.err.println(addr.getHostName() + addr.getPort());\r\n    Configuration conf = new Configuration();\r\n    ApplicationMasterProtocol instance = new AMRMProtocolTestImpl();\r\n    Server server = null;\r\n    try {\r\n        server = RpcServerFactoryPBImpl.get().getServer(ApplicationMasterProtocol.class, instance, addr, conf, null, 1);\r\n        server.start();\r\n        System.err.println(server.getListenerAddress());\r\n        System.err.println(NetUtils.getConnectAddress(server));\r\n        ApplicationMasterProtocol amrmClient = null;\r\n        try {\r\n            amrmClient = (ApplicationMasterProtocol) RpcClientFactoryPBImpl.get().getClient(ApplicationMasterProtocol.class, 1, NetUtils.getConnectAddress(server), conf);\r\n        } catch (YarnRuntimeException e) {\r\n            e.printStackTrace();\r\n            Assert.fail(\"Failed to create client\");\r\n        }\r\n    } catch (YarnRuntimeException e) {\r\n        e.printStackTrace();\r\n        Assert.fail(\"Failed to create server\");\r\n    } finally {\r\n        if (server != null) {\r\n            server.stop();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testAppendInClose",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testAppendInClose() throws Exception\n{\r\n    final ContainerLogAppender claAppender = new ContainerLogAppender();\r\n    claAppender.setName(\"testCLA\");\r\n    claAppender.setLayout(new PatternLayout(\"%-5p [%t]: %m%n\"));\r\n    claAppender.setContainerLogDir(\"target/testAppendInClose/logDir\");\r\n    claAppender.setContainerLogFile(\"syslog\");\r\n    claAppender.setTotalLogFileSize(1000);\r\n    claAppender.activateOptions();\r\n    final Logger claLog = Logger.getLogger(\"testAppendInClose-catergory\");\r\n    claLog.setAdditivity(false);\r\n    claLog.addAppender(claAppender);\r\n    claLog.info(new Object() {\r\n\r\n        public String toString() {\r\n            claLog.info(\"message1\");\r\n            return \"return message1\";\r\n        }\r\n    });\r\n    claAppender.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "deleteTestDir",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void deleteTestDir() throws IOException\n{\r\n    FileContext fs = FileContext.getLocalFSFileContext();\r\n    fs.delete(new Path(\"target\", TestFSDownload.class.getSimpleName()), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createFile",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "LocalResource createFile(FileContext files, Path p, int len, Random r, LocalResourceVisibility vis) throws IOException\n{\r\n    createFile(files, p, len, r);\r\n    LocalResource ret = recordFactory.newRecordInstance(LocalResource.class);\r\n    ret.setResource(URL.fromPath(p));\r\n    ret.setSize(len);\r\n    ret.setType(LocalResourceType.FILE);\r\n    ret.setVisibility(vis);\r\n    ret.setTimestamp(files.getFileStatus(p).getModificationTime());\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createFile",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void createFile(FileContext files, Path p, int len, Random r) throws IOException\n{\r\n    FSDataOutputStream out = null;\r\n    try {\r\n        byte[] bytes = new byte[len];\r\n        out = files.create(p, EnumSet.of(CREATE, OVERWRITE));\r\n        r.nextBytes(bytes);\r\n        out.write(bytes);\r\n    } finally {\r\n        if (out != null)\r\n            out.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createJar",
  "errType" : null,
  "containingMethodsNum" : 23,
  "sourceCodeText" : "LocalResource createJar(FileContext files, Path p, LocalResourceVisibility vis) throws IOException\n{\r\n    LOG.info(\"Create jar file \" + p);\r\n    File jarFile = new File((files.makeQualified(p)).toUri());\r\n    FileOutputStream stream = new FileOutputStream(jarFile);\r\n    LOG.info(\"Create jar out stream \");\r\n    JarOutputStream out = new JarOutputStream(stream, new Manifest());\r\n    ZipEntry entry = new ZipEntry(\"classes/1.class\");\r\n    out.putNextEntry(entry);\r\n    out.write(1);\r\n    out.write(2);\r\n    out.write(3);\r\n    out.closeEntry();\r\n    ZipEntry entry2 = new ZipEntry(\"classes/2.class\");\r\n    out.putNextEntry(entry2);\r\n    out.write(1);\r\n    out.write(2);\r\n    out.write(3);\r\n    out.closeEntry();\r\n    LOG.info(\"Done writing jar stream \");\r\n    out.close();\r\n    LocalResource ret = recordFactory.newRecordInstance(LocalResource.class);\r\n    ret.setResource(URL.fromPath(p));\r\n    FileStatus status = files.getFileStatus(p);\r\n    ret.setSize(status.getLen());\r\n    ret.setTimestamp(status.getModificationTime());\r\n    ret.setType(LocalResourceType.PATTERN);\r\n    ret.setVisibility(vis);\r\n    ret.setPattern(\"classes/.*\");\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createTarFile",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "LocalResource createTarFile(FileContext files, Path p, int len, Random r, LocalResourceVisibility vis) throws IOException, URISyntaxException\n{\r\n    byte[] bytes = new byte[len];\r\n    r.nextBytes(bytes);\r\n    File archiveFile = new File(p.toUri().getPath() + \".tar\");\r\n    archiveFile.createNewFile();\r\n    TarArchiveOutputStream out = new TarArchiveOutputStream(new FileOutputStream(archiveFile));\r\n    TarArchiveEntry entry = new TarArchiveEntry(p.getName());\r\n    entry.setSize(bytes.length);\r\n    out.putArchiveEntry(entry);\r\n    out.write(bytes);\r\n    out.closeArchiveEntry();\r\n    out.close();\r\n    LocalResource ret = recordFactory.newRecordInstance(LocalResource.class);\r\n    ret.setResource(URL.fromPath(new Path(p.toString() + \".tar\")));\r\n    ret.setSize(len);\r\n    ret.setType(LocalResourceType.ARCHIVE);\r\n    ret.setVisibility(vis);\r\n    ret.setTimestamp(files.getFileStatus(new Path(p.toString() + \".tar\")).getModificationTime());\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createTgzFile",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "LocalResource createTgzFile(FileContext files, Path p, int len, Random r, LocalResourceVisibility vis) throws IOException, URISyntaxException\n{\r\n    byte[] bytes = new byte[len];\r\n    r.nextBytes(bytes);\r\n    File gzipFile = new File(p.toUri().getPath() + \".tar.gz\");\r\n    gzipFile.createNewFile();\r\n    TarArchiveOutputStream out = new TarArchiveOutputStream(new GZIPOutputStream(new FileOutputStream(gzipFile)));\r\n    TarArchiveEntry entry = new TarArchiveEntry(p.getName());\r\n    entry.setSize(bytes.length);\r\n    out.putArchiveEntry(entry);\r\n    out.write(bytes);\r\n    out.closeArchiveEntry();\r\n    out.close();\r\n    LocalResource ret = recordFactory.newRecordInstance(LocalResource.class);\r\n    ret.setResource(URL.fromPath(new Path(p.toString() + \".tar.gz\")));\r\n    ret.setSize(len);\r\n    ret.setType(LocalResourceType.ARCHIVE);\r\n    ret.setVisibility(vis);\r\n    ret.setTimestamp(files.getFileStatus(new Path(p.toString() + \".tar.gz\")).getModificationTime());\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createJarFile",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "LocalResource createJarFile(FileContext files, Path p, int len, Random r, LocalResourceVisibility vis) throws IOException, URISyntaxException\n{\r\n    byte[] bytes = new byte[len];\r\n    r.nextBytes(bytes);\r\n    File archiveFile = new File(p.toUri().getPath() + \".jar\");\r\n    archiveFile.createNewFile();\r\n    JarOutputStream out = new JarOutputStream(new FileOutputStream(archiveFile));\r\n    out.putNextEntry(new JarEntry(p.getName()));\r\n    out.write(bytes);\r\n    out.closeEntry();\r\n    out.close();\r\n    LocalResource ret = recordFactory.newRecordInstance(LocalResource.class);\r\n    ret.setResource(URL.fromPath(new Path(p.toString() + \".jar\")));\r\n    ret.setSize(len);\r\n    ret.setType(LocalResourceType.ARCHIVE);\r\n    ret.setVisibility(vis);\r\n    ret.setTimestamp(files.getFileStatus(new Path(p.toString() + \".jar\")).getModificationTime());\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createZipFile",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "LocalResource createZipFile(FileContext files, Path p, int len, Random r, LocalResourceVisibility vis) throws IOException, URISyntaxException\n{\r\n    byte[] bytes = new byte[len];\r\n    r.nextBytes(bytes);\r\n    File archiveFile = new File(p.toUri().getPath() + \".ZIP\");\r\n    archiveFile.createNewFile();\r\n    ZipOutputStream out = new ZipOutputStream(new FileOutputStream(archiveFile));\r\n    out.putNextEntry(new ZipEntry(p.getName()));\r\n    out.write(bytes);\r\n    out.closeEntry();\r\n    out.close();\r\n    LocalResource ret = recordFactory.newRecordInstance(LocalResource.class);\r\n    ret.setResource(URL.fromPath(new Path(p.toString() + \".ZIP\")));\r\n    ret.setSize(len);\r\n    ret.setType(LocalResourceType.ARCHIVE);\r\n    ret.setVisibility(vis);\r\n    ret.setTimestamp(files.getFileStatus(new Path(p.toString() + \".ZIP\")).getModificationTime());\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadBadPublic",
  "errType" : [ "ExecutionException" ],
  "containingMethodsNum" : 23,
  "sourceCodeText" : "void testDownloadBadPublic() throws IOException, URISyntaxException, InterruptedException\n{\r\n    conf.set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, \"077\");\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    final Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    Map<LocalResource, LocalResourceVisibility> rsrcVis = new HashMap<LocalResource, LocalResourceVisibility>();\r\n    Random rand = new Random();\r\n    long sharedSeed = rand.nextLong();\r\n    rand.setSeed(sharedSeed);\r\n    System.out.println(\"SEED: \" + sharedSeed);\r\n    Map<LocalResource, Future<Path>> pending = new HashMap<LocalResource, Future<Path>>();\r\n    ExecutorService exec = HadoopExecutors.newSingleThreadExecutor();\r\n    LocalDirAllocator dirs = new LocalDirAllocator(TestFSDownload.class.getName());\r\n    int size = 512;\r\n    LocalResourceVisibility vis = LocalResourceVisibility.PUBLIC;\r\n    Path path = new Path(basedir, \"test-file\");\r\n    LocalResource rsrc = createFile(files, path, size, rand, vis);\r\n    rsrcVis.put(rsrc, vis);\r\n    Path destPath = dirs.getLocalPathForWrite(basedir.toString(), size, conf);\r\n    destPath = new Path(destPath, Long.toString(uniqueNumberGenerator.incrementAndGet()));\r\n    FSDownload fsd = new FSDownload(files, UserGroupInformation.getCurrentUser(), conf, destPath, rsrc);\r\n    pending.put(rsrc, exec.submit(fsd));\r\n    exec.shutdown();\r\n    while (!exec.awaitTermination(1000, TimeUnit.MILLISECONDS)) ;\r\n    Assert.assertTrue(pending.get(rsrc).isDone());\r\n    try {\r\n        for (Map.Entry<LocalResource, Future<Path>> p : pending.entrySet()) {\r\n            p.getValue().get();\r\n            Assert.fail(\"We localized a file that is not public.\");\r\n        }\r\n    } catch (ExecutionException e) {\r\n        Assert.assertTrue(e.getCause() instanceof IOException);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadPublicWithStatCache",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testDownloadPublicWithStatCache() throws IOException, URISyntaxException, InterruptedException, ExecutionException\n{\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    FileSystem f = basedir.getFileSystem(conf);\r\n    assumeTrue(FSDownload.ancestorsHaveExecutePermissions(f, basedir, null));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    int size = 512;\r\n    final ConcurrentMap<Path, AtomicInteger> counts = new ConcurrentHashMap<Path, AtomicInteger>();\r\n    final CacheLoader<Path, Future<FileStatus>> loader = FSDownload.createStatusCacheLoader(conf);\r\n    final LoadingCache<Path, Future<FileStatus>> statCache = CacheBuilder.newBuilder().build(new CacheLoader<Path, Future<FileStatus>>() {\r\n\r\n        public Future<FileStatus> load(Path path) throws Exception {\r\n            AtomicInteger count = counts.get(path);\r\n            if (count == null) {\r\n                count = new AtomicInteger(0);\r\n                AtomicInteger existing = counts.putIfAbsent(path, count);\r\n                if (existing != null) {\r\n                    count = existing;\r\n                }\r\n            }\r\n            count.incrementAndGet();\r\n            return loader.load(path);\r\n        }\r\n    });\r\n    final int fileCount = 3;\r\n    List<Callable<Boolean>> tasks = new ArrayList<Callable<Boolean>>();\r\n    for (int i = 0; i < fileCount; i++) {\r\n        Random rand = new Random();\r\n        long sharedSeed = rand.nextLong();\r\n        rand.setSeed(sharedSeed);\r\n        System.out.println(\"SEED: \" + sharedSeed);\r\n        final Path path = new Path(basedir, \"test-file-\" + i);\r\n        createFile(files, path, size, rand);\r\n        final FileSystem fs = path.getFileSystem(conf);\r\n        final FileStatus sStat = fs.getFileStatus(path);\r\n        tasks.add(new Callable<Boolean>() {\r\n\r\n            public Boolean call() throws IOException {\r\n                return FSDownload.isPublic(fs, path, sStat, statCache);\r\n            }\r\n        });\r\n    }\r\n    ExecutorService exec = HadoopExecutors.newFixedThreadPool(fileCount);\r\n    try {\r\n        List<Future<Boolean>> futures = exec.invokeAll(tasks);\r\n        for (Future<Boolean> future : futures) {\r\n            assertTrue(future.get());\r\n        }\r\n        for (AtomicInteger count : counts.values()) {\r\n            assertSame(count.get(), 1);\r\n        }\r\n    } finally {\r\n        exec.shutdown();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownload",
  "errType" : [ "ExecutionException" ],
  "containingMethodsNum" : 32,
  "sourceCodeText" : "void testDownload() throws IOException, URISyntaxException, InterruptedException\n{\r\n    conf.set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, \"077\");\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    final Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    Map<LocalResource, LocalResourceVisibility> rsrcVis = new HashMap<LocalResource, LocalResourceVisibility>();\r\n    Random rand = new Random();\r\n    long sharedSeed = rand.nextLong();\r\n    rand.setSeed(sharedSeed);\r\n    System.out.println(\"SEED: \" + sharedSeed);\r\n    Map<LocalResource, Future<Path>> pending = new HashMap<LocalResource, Future<Path>>();\r\n    ExecutorService exec = HadoopExecutors.newSingleThreadExecutor();\r\n    LocalDirAllocator dirs = new LocalDirAllocator(TestFSDownload.class.getName());\r\n    int[] sizes = new int[10];\r\n    for (int i = 0; i < 10; ++i) {\r\n        sizes[i] = rand.nextInt(512) + 512;\r\n        LocalResourceVisibility vis = LocalResourceVisibility.PRIVATE;\r\n        if (i % 2 == 1) {\r\n            vis = LocalResourceVisibility.APPLICATION;\r\n        }\r\n        Path p = new Path(basedir, \"\" + i);\r\n        LocalResource rsrc = createFile(files, p, sizes[i], rand, vis);\r\n        rsrcVis.put(rsrc, vis);\r\n        Path destPath = dirs.getLocalPathForWrite(basedir.toString(), sizes[i], conf);\r\n        destPath = new Path(destPath, Long.toString(uniqueNumberGenerator.incrementAndGet()));\r\n        FSDownload fsd = new FSDownload(files, UserGroupInformation.getCurrentUser(), conf, destPath, rsrc);\r\n        pending.put(rsrc, exec.submit(fsd));\r\n    }\r\n    exec.shutdown();\r\n    while (!exec.awaitTermination(1000, TimeUnit.MILLISECONDS)) ;\r\n    for (Future<Path> path : pending.values()) {\r\n        Assert.assertTrue(path.isDone());\r\n    }\r\n    try {\r\n        for (Map.Entry<LocalResource, Future<Path>> p : pending.entrySet()) {\r\n            Path localized = p.getValue().get();\r\n            assertEquals(sizes[Integer.parseInt(localized.getName())], p.getKey().getSize());\r\n            FileStatus status = files.getFileStatus(localized.getParent());\r\n            FsPermission perm = status.getPermission();\r\n            assertEquals(\"Cache directory permissions are incorrect\", new FsPermission((short) 0755), perm);\r\n            status = files.getFileStatus(localized);\r\n            perm = status.getPermission();\r\n            System.out.println(\"File permission \" + perm + \" for rsrc vis \" + p.getKey().getVisibility().name());\r\n            assert (rsrcVis.containsKey(p.getKey()));\r\n            Assert.assertTrue(\"Private file should be 500\", perm.toShort() == FSDownload.PRIVATE_FILE_PERMS.toShort());\r\n        }\r\n    } catch (ExecutionException e) {\r\n        throw new IOException(\"Failed exec\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "downloadWithFileType",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 33,
  "sourceCodeText" : "void downloadWithFileType(TEST_FILE_TYPE fileType) throws IOException, URISyntaxException, InterruptedException\n{\r\n    conf.set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, \"077\");\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    final Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    Random rand = new Random();\r\n    long sharedSeed = rand.nextLong();\r\n    rand.setSeed(sharedSeed);\r\n    System.out.println(\"SEED: \" + sharedSeed);\r\n    Map<LocalResource, Future<Path>> pending = new HashMap<LocalResource, Future<Path>>();\r\n    ExecutorService exec = HadoopExecutors.newSingleThreadExecutor();\r\n    LocalDirAllocator dirs = new LocalDirAllocator(TestFSDownload.class.getName());\r\n    int size = rand.nextInt(512) + 512;\r\n    LocalResourceVisibility vis = LocalResourceVisibility.PRIVATE;\r\n    Path p = new Path(basedir, \"\" + 1);\r\n    String strFileName = \"\";\r\n    LocalResource rsrc = null;\r\n    switch(fileType) {\r\n        case TAR:\r\n            rsrc = createTarFile(files, p, size, rand, vis);\r\n            break;\r\n        case JAR:\r\n            rsrc = createJarFile(files, p, size, rand, vis);\r\n            rsrc.setType(LocalResourceType.PATTERN);\r\n            break;\r\n        case ZIP:\r\n            rsrc = createZipFile(files, p, size, rand, vis);\r\n            strFileName = p.getName() + \".ZIP\";\r\n            break;\r\n        case TGZ:\r\n            rsrc = createTgzFile(files, p, size, rand, vis);\r\n            break;\r\n    }\r\n    Path destPath = dirs.getLocalPathForWrite(basedir.toString(), size, conf);\r\n    destPath = new Path(destPath, Long.toString(uniqueNumberGenerator.incrementAndGet()));\r\n    FSDownload fsd = new FSDownload(files, UserGroupInformation.getCurrentUser(), conf, destPath, rsrc);\r\n    pending.put(rsrc, exec.submit(fsd));\r\n    exec.shutdown();\r\n    while (!exec.awaitTermination(1000, TimeUnit.MILLISECONDS)) ;\r\n    try {\r\n        pending.get(rsrc).get();\r\n        FileStatus[] filesstatus = files.getDefaultFileSystem().listStatus(basedir);\r\n        for (FileStatus filestatus : filesstatus) {\r\n            if (filestatus.isDirectory()) {\r\n                FileStatus[] childFiles = files.getDefaultFileSystem().listStatus(filestatus.getPath());\r\n                for (FileStatus childfile : childFiles) {\r\n                    if (strFileName.endsWith(\".ZIP\") && childfile.getPath().getName().equals(strFileName) && !childfile.isDirectory()) {\r\n                        Assert.fail(\"Failure...After unzip, there should have been a\" + \" directory formed with zip file name but found a file. \" + childfile.getPath());\r\n                    }\r\n                    if (childfile.getPath().getName().startsWith(\"tmp\")) {\r\n                        Assert.fail(\"Tmp File should not have been there \" + childfile.getPath());\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    } catch (Exception e) {\r\n        throw new IOException(\"Failed exec\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadArchive",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testDownloadArchive() throws IOException, URISyntaxException, InterruptedException\n{\r\n    downloadWithFileType(TEST_FILE_TYPE.TAR);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadPatternJar",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testDownloadPatternJar() throws IOException, URISyntaxException, InterruptedException\n{\r\n    downloadWithFileType(TEST_FILE_TYPE.JAR);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadArchiveZip",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testDownloadArchiveZip() throws IOException, URISyntaxException, InterruptedException\n{\r\n    downloadWithFileType(TEST_FILE_TYPE.ZIP);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadArchiveZipWithTurkishLocale",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testDownloadArchiveZipWithTurkishLocale() throws IOException, URISyntaxException, InterruptedException\n{\r\n    Locale defaultLocale = Locale.getDefault();\r\n    Locale turkishLocale = new Locale(\"tr\", \"TR\");\r\n    Locale.setDefault(turkishLocale);\r\n    downloadWithFileType(TEST_FILE_TYPE.ZIP);\r\n    Locale.setDefault(defaultLocale);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDownloadArchiveTgz",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testDownloadArchiveTgz() throws IOException, URISyntaxException, InterruptedException\n{\r\n    downloadWithFileType(TEST_FILE_TYPE.TGZ);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "verifyPermsRecursively",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void verifyPermsRecursively(FileSystem fs, FileContext files, Path p, LocalResourceVisibility vis) throws IOException\n{\r\n    FileStatus status = files.getFileStatus(p);\r\n    if (status.isDirectory()) {\r\n        if (vis == LocalResourceVisibility.PUBLIC) {\r\n            Assert.assertTrue(status.getPermission().toShort() == FSDownload.PUBLIC_DIR_PERMS.toShort());\r\n        } else {\r\n            Assert.assertTrue(status.getPermission().toShort() == FSDownload.PRIVATE_DIR_PERMS.toShort());\r\n        }\r\n        if (!status.isSymlink()) {\r\n            FileStatus[] statuses = fs.listStatus(p);\r\n            for (FileStatus stat : statuses) {\r\n                verifyPermsRecursively(fs, files, stat.getPath(), vis);\r\n            }\r\n        }\r\n    } else {\r\n        if (vis == LocalResourceVisibility.PUBLIC) {\r\n            Assert.assertTrue(status.getPermission().toShort() == FSDownload.PUBLIC_FILE_PERMS.toShort());\r\n        } else {\r\n            Assert.assertTrue(status.getPermission().toShort() == FSDownload.PRIVATE_FILE_PERMS.toShort());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDirDownload",
  "errType" : [ "ExecutionException" ],
  "containingMethodsNum" : 26,
  "sourceCodeText" : "void testDirDownload() throws IOException, InterruptedException\n{\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    final Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    Map<LocalResource, LocalResourceVisibility> rsrcVis = new HashMap<LocalResource, LocalResourceVisibility>();\r\n    Random rand = new Random();\r\n    long sharedSeed = rand.nextLong();\r\n    rand.setSeed(sharedSeed);\r\n    System.out.println(\"SEED: \" + sharedSeed);\r\n    Map<LocalResource, Future<Path>> pending = new HashMap<LocalResource, Future<Path>>();\r\n    ExecutorService exec = HadoopExecutors.newSingleThreadExecutor();\r\n    LocalDirAllocator dirs = new LocalDirAllocator(TestFSDownload.class.getName());\r\n    for (int i = 0; i < 5; ++i) {\r\n        LocalResourceVisibility vis = LocalResourceVisibility.PRIVATE;\r\n        if (i % 2 == 1) {\r\n            vis = LocalResourceVisibility.APPLICATION;\r\n        }\r\n        Path p = new Path(basedir, \"dir\" + i + \".jar\");\r\n        LocalResource rsrc = createJar(files, p, vis);\r\n        rsrcVis.put(rsrc, vis);\r\n        Path destPath = dirs.getLocalPathForWrite(basedir.toString(), conf);\r\n        destPath = new Path(destPath, Long.toString(uniqueNumberGenerator.incrementAndGet()));\r\n        FSDownload fsd = new FSDownload(files, UserGroupInformation.getCurrentUser(), conf, destPath, rsrc);\r\n        pending.put(rsrc, exec.submit(fsd));\r\n    }\r\n    exec.shutdown();\r\n    while (!exec.awaitTermination(1000, TimeUnit.MILLISECONDS)) ;\r\n    for (Future<Path> path : pending.values()) {\r\n        Assert.assertTrue(path.isDone());\r\n    }\r\n    try {\r\n        for (Map.Entry<LocalResource, Future<Path>> p : pending.entrySet()) {\r\n            Path localized = p.getValue().get();\r\n            FileStatus status = files.getFileStatus(localized);\r\n            System.out.println(\"Testing path \" + localized);\r\n            assert (status.isDirectory());\r\n            assert (rsrcVis.containsKey(p.getKey()));\r\n            verifyPermsRecursively(localized.getFileSystem(conf), files, localized, rsrcVis.get(p.getKey()));\r\n        }\r\n    } catch (ExecutionException e) {\r\n        throw new IOException(\"Failed exec\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testUniqueDestinationPath",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testUniqueDestinationPath() throws Exception\n{\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    final Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    ExecutorService singleThreadedExec = HadoopExecutors.newSingleThreadExecutor();\r\n    LocalDirAllocator dirs = new LocalDirAllocator(TestFSDownload.class.getName());\r\n    Path destPath = dirs.getLocalPathForWrite(basedir.toString(), conf);\r\n    destPath = new Path(destPath, Long.toString(uniqueNumberGenerator.incrementAndGet()));\r\n    Path p = new Path(basedir, \"dir\" + 0 + \".jar\");\r\n    LocalResourceVisibility vis = LocalResourceVisibility.PRIVATE;\r\n    LocalResource rsrc = createJar(files, p, vis);\r\n    FSDownload fsd = new FSDownload(files, UserGroupInformation.getCurrentUser(), conf, destPath, rsrc);\r\n    Future<Path> rPath = singleThreadedExec.submit(fsd);\r\n    singleThreadedExec.shutdown();\r\n    while (!singleThreadedExec.awaitTermination(1000, TimeUnit.MILLISECONDS)) ;\r\n    Assert.assertTrue(rPath.isDone());\r\n    Assert.assertEquals(destPath, rPath.get().getParent());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testResourceTimestampChangeDuringDownload",
  "errType" : [ "URISyntaxException", "ExecutionException" ],
  "containingMethodsNum" : 27,
  "sourceCodeText" : "void testResourceTimestampChangeDuringDownload() throws IOException, InterruptedException\n{\r\n    conf = new Configuration();\r\n    FileContext files = FileContext.getLocalFSFileContext(conf);\r\n    final Path basedir = files.makeQualified(new Path(\"target\", TestFSDownload.class.getSimpleName()));\r\n    files.mkdir(basedir, null, true);\r\n    conf.setStrings(TestFSDownload.class.getName(), basedir.toString());\r\n    LocalDirAllocator dirs = new LocalDirAllocator(TestFSDownload.class.getName());\r\n    Path path = new Path(basedir, \"test-file\");\r\n    Random rand = new Random();\r\n    long sharedSeed = rand.nextLong();\r\n    rand.setSeed(sharedSeed);\r\n    int size = 512;\r\n    LocalResourceVisibility vis = LocalResourceVisibility.PUBLIC;\r\n    LocalResource localResource = createFile(files, path, size, rand, vis);\r\n    Path destPath = dirs.getLocalPathForWrite(basedir.toString(), size, conf);\r\n    destPath = new Path(destPath, Long.toString(uniqueNumberGenerator.incrementAndGet()));\r\n    FSDownload fsDownload = new FSDownload(files, UserGroupInformation.getCurrentUser(), conf, destPath, localResource);\r\n    long origLRTimestamp = localResource.getTimestamp();\r\n    final long msInADay = 86400 * 1000;\r\n    long modifiedFSTimestamp = origLRTimestamp - msInADay;\r\n    try {\r\n        Path sourceFsPath = localResource.getResource().toPath();\r\n        FileSystem sourceFs = sourceFsPath.getFileSystem(conf);\r\n        sourceFs.setTimes(sourceFsPath, modifiedFSTimestamp, modifiedFSTimestamp);\r\n    } catch (URISyntaxException use) {\r\n        Assert.fail(\"No exception expected.\");\r\n    }\r\n    Map<LocalResource, Future<Path>> pending = new HashMap<>();\r\n    ExecutorService exec = HadoopExecutors.newSingleThreadExecutor();\r\n    pending.put(localResource, exec.submit(fsDownload));\r\n    exec.shutdown();\r\n    exec.awaitTermination(1000, TimeUnit.MILLISECONDS);\r\n    Assert.assertTrue(pending.get(localResource).isDone());\r\n    try {\r\n        for (Map.Entry<LocalResource, Future<Path>> p : pending.entrySet()) {\r\n            p.getValue().get();\r\n        }\r\n        Assert.fail(\"Exception expected from timestamp update during download\");\r\n    } catch (ExecutionException ee) {\r\n        Assert.assertTrue(ee.getCause() instanceof IOException);\r\n        Assert.assertTrue(\"Exception contains original timestamp\", ee.getMessage().contains(Times.formatISO8601(origLRTimestamp)));\r\n        Assert.assertTrue(\"Exception contains modified timestamp\", ee.getMessage().contains(Times.formatISO8601(modifiedFSTimestamp)));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    ResourceUtils.resetResourceTypes();\r\n    String resourceTypesFile = \"resource-types-5.xml\";\r\n    Configuration conf = new YarnConfiguration();\r\n    TestResourceUtils.setupResourceTypes(conf, resourceTypesFile);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "teardown",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void teardown()\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    File source = new File(conf.getClassLoader().getResource(\"resource-types-5.xml\").getFile());\r\n    File dest = new File(source.getParent(), \"resource-types.xml\");\r\n    if (dest.exists()) {\r\n        dest.delete();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testEmptyResourcePBInit",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testEmptyResourcePBInit() throws Exception\n{\r\n    Resource res = new ResourcePBImpl();\r\n    Assert.assertEquals(0, res.getMemorySize());\r\n    Assert.assertEquals(ResourceInformation.MEMORY_MB.getUnits(), res.getResourceInformation(ResourceInformation.MEMORY_MB.getName()).getUnits());\r\n    Assert.assertEquals(ResourceInformation.VCORES.getUnits(), res.getResourceInformation(ResourceInformation.VCORES.getName()).getUnits());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourcePBInitFromOldPB",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testResourcePBInitFromOldPB() throws Exception\n{\r\n    YarnProtos.ResourceProto proto = YarnProtos.ResourceProto.newBuilder().setMemory(1024).setVirtualCores(3).build();\r\n    Resource res = new ResourcePBImpl(proto);\r\n    Assert.assertEquals(1024, res.getMemorySize());\r\n    Assert.assertEquals(3, res.getVirtualCores());\r\n    Assert.assertEquals(ResourceInformation.MEMORY_MB.getUnits(), res.getResourceInformation(ResourceInformation.MEMORY_MB.getName()).getUnits());\r\n    Assert.assertEquals(ResourceInformation.VCORES.getUnits(), res.getResourceInformation(ResourceInformation.VCORES.getName()).getUnits());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetMemory",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetMemory()\n{\r\n    Resource res = new ResourcePBImpl();\r\n    long memorySize = Integer.MAX_VALUE + 1L;\r\n    res.setMemorySize(memorySize);\r\n    assertEquals(\"No need to cast if both are long\", memorySize, res.getMemorySize());\r\n    assertEquals(\"Cast to Integer.MAX_VALUE if the long is greater than \" + \"Integer.MAX_VALUE\", Integer.MAX_VALUE, res.getMemory());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetVirtualCores",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetVirtualCores()\n{\r\n    Resource res = new ResourcePBImpl();\r\n    long vcores = Integer.MAX_VALUE + 1L;\r\n    res.getResourceInformation(\"vcores\").setValue(vcores);\r\n    assertEquals(\"No need to cast if both are long\", vcores, res.getResourceInformation(\"vcores\").getValue());\r\n    assertEquals(\"Cast to Integer.MAX_VALUE if the long is greater than \" + \"Integer.MAX_VALUE\", Integer.MAX_VALUE, res.getVirtualCores());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourcePBWithExtraResources",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testResourcePBWithExtraResources() throws Exception\n{\r\n    YarnProtos.ResourceInformationProto riProto = YarnProtos.ResourceInformationProto.newBuilder().setType(YarnProtos.ResourceTypeInfoProto.newBuilder().setName(\"resource1\").setType(YarnProtos.ResourceTypesProto.COUNTABLE).getType()).setValue(4).setUnits(\"T\").setKey(\"resource1\").build();\r\n    YarnProtos.ResourceProto proto = YarnProtos.ResourceProto.newBuilder().setMemory(1024).setVirtualCores(3).addResourceValueMap(riProto).build();\r\n    Resource res = new ResourcePBImpl(proto);\r\n    Assert.assertEquals(4000, res.getResourceInformation(\"resource1\").getValue());\r\n    Assert.assertEquals(\"G\", res.getResourceInformation(\"resource1\").getUnits());\r\n    YarnProtos.ResourceInformationProto riProto1 = YarnProtos.ResourceInformationProto.newBuilder().setType(YarnProtos.ResourceTypeInfoProto.newBuilder().setName(\"resource2\").setType(YarnProtos.ResourceTypesProto.COUNTABLE).getType()).setValue(4).setUnits(\"M\").setKey(\"resource2\").build();\r\n    YarnProtos.ResourceProto proto1 = YarnProtos.ResourceProto.newBuilder().setMemory(1024).setVirtualCores(3).addResourceValueMap(riProto1).build();\r\n    Resource res1 = new ResourcePBImpl(proto1);\r\n    Assert.assertEquals(4000000000L, res1.getResourceInformation(\"resource2\").getValue());\r\n    Assert.assertEquals(\"m\", res1.getResourceInformation(\"resource2\").getUnits());\r\n    YarnProtos.ResourceInformationProto riProto2 = YarnProtos.ResourceInformationProto.newBuilder().setType(YarnProtos.ResourceTypeInfoProto.newBuilder().setName(\"resource1\").setType(YarnProtos.ResourceTypesProto.COUNTABLE).getType()).setValue(3).setUnits(\"M\").setKey(\"resource1\").build();\r\n    YarnProtos.ResourceProto proto2 = YarnProtos.ResourceProto.newBuilder().setMemory(1024).setVirtualCores(3).addResourceValueMap(riProto2).build();\r\n    Resource res2 = new ResourcePBImpl(proto2);\r\n    Assert.assertEquals(0, res2.getResourceInformation(\"resource1\").getValue());\r\n    Assert.assertEquals(\"G\", res2.getResourceInformation(\"resource1\").getUnits());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceTags",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testResourceTags()\n{\r\n    YarnProtos.ResourceInformationProto riProto = YarnProtos.ResourceInformationProto.newBuilder().setType(YarnProtos.ResourceTypeInfoProto.newBuilder().setName(\"yarn.io/test-volume\").setType(YarnProtos.ResourceTypesProto.COUNTABLE).getType()).setValue(10).setUnits(\"G\").setKey(\"yarn.io/test-volume\").addTags(\"tag_A\").addTags(\"tag_B\").addTags(\"tag_C\").build();\r\n    YarnProtos.ResourceProto proto = YarnProtos.ResourceProto.newBuilder().setMemory(1024).setVirtualCores(3).addResourceValueMap(riProto).build();\r\n    Resource res = new ResourcePBImpl(proto);\r\n    Assert.assertNotNull(res.getResourceInformation(\"yarn.io/test-volume\"));\r\n    Assert.assertEquals(10, res.getResourceInformation(\"yarn.io/test-volume\").getValue());\r\n    Assert.assertEquals(\"G\", res.getResourceInformation(\"yarn.io/test-volume\").getUnits());\r\n    Assert.assertEquals(3, res.getResourceInformation(\"yarn.io/test-volume\").getTags().size());\r\n    Assert.assertFalse(res.getResourceInformation(\"yarn.io/test-volume\").getTags().isEmpty());\r\n    Assert.assertTrue(res.getResourceInformation(\"yarn.io/test-volume\").getAttributes().isEmpty());\r\n    boolean protoConvertExpected = false;\r\n    YarnProtos.ResourceProto protoFormat = ProtoUtils.convertToProtoFormat(res);\r\n    for (YarnProtos.ResourceInformationProto pf : protoFormat.getResourceValueMapList()) {\r\n        if (pf.getKey().equals(\"yarn.io/test-volume\")) {\r\n            protoConvertExpected = pf.getAttributesCount() == 0 && pf.getTagsCount() == 3;\r\n        }\r\n    }\r\n    Assert.assertTrue(\"Expecting resource's protobuf message\" + \" contains 0 attributes and 3 tags\", protoConvertExpected);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceAttributes",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testResourceAttributes()\n{\r\n    YarnProtos.ResourceInformationProto riProto = YarnProtos.ResourceInformationProto.newBuilder().setType(YarnProtos.ResourceTypeInfoProto.newBuilder().setName(\"yarn.io/test-volume\").setType(YarnProtos.ResourceTypesProto.COUNTABLE).getType()).setValue(10).setUnits(\"G\").setKey(\"yarn.io/test-volume\").addAttributes(YarnProtos.StringStringMapProto.newBuilder().setKey(\"driver\").setValue(\"test-driver\").build()).addAttributes(YarnProtos.StringStringMapProto.newBuilder().setKey(\"mount\").setValue(\"/mnt/data\").build()).build();\r\n    YarnProtos.ResourceProto proto = YarnProtos.ResourceProto.newBuilder().setMemory(1024).setVirtualCores(3).addResourceValueMap(riProto).build();\r\n    Resource res = new ResourcePBImpl(proto);\r\n    Assert.assertNotNull(res.getResourceInformation(\"yarn.io/test-volume\"));\r\n    Assert.assertEquals(10, res.getResourceInformation(\"yarn.io/test-volume\").getValue());\r\n    Assert.assertEquals(\"G\", res.getResourceInformation(\"yarn.io/test-volume\").getUnits());\r\n    Assert.assertEquals(2, res.getResourceInformation(\"yarn.io/test-volume\").getAttributes().size());\r\n    Assert.assertTrue(res.getResourceInformation(\"yarn.io/test-volume\").getTags().isEmpty());\r\n    Assert.assertFalse(res.getResourceInformation(\"yarn.io/test-volume\").getAttributes().isEmpty());\r\n    boolean protoConvertExpected = false;\r\n    YarnProtos.ResourceProto protoFormat = ProtoUtils.convertToProtoFormat(res);\r\n    for (YarnProtos.ResourceInformationProto pf : protoFormat.getResourceValueMapList()) {\r\n        if (pf.getKey().equals(\"yarn.io/test-volume\")) {\r\n            protoConvertExpected = pf.getAttributesCount() == 2 && pf.getTagsCount() == 0;\r\n        }\r\n    }\r\n    Assert.assertTrue(\"Expecting resource's protobuf message\" + \" contains 2 attributes and 0 tags\", protoConvertExpected);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testParsingResourceTags",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testParsingResourceTags()\n{\r\n    ResourceInformation info = ResourceUtils.getResourceTypes().get(\"resource3\");\r\n    Assert.assertTrue(info.getAttributes().isEmpty());\r\n    Assert.assertFalse(info.getTags().isEmpty());\r\n    assertThat(info.getTags()).hasSize(2);\r\n    info.getTags().remove(\"resource3_tag_1\");\r\n    info.getTags().remove(\"resource3_tag_2\");\r\n    Assert.assertTrue(info.getTags().isEmpty());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testGeneric",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testGeneric()\n{\r\n    PrintWriter out = spy(new PrintWriter(System.out));\r\n    HamletImpl hi = new HamletImpl(out, 0, false);\r\n    hi.root(\"start\")._attr(\"name\", \"value\").__(\"start text\").elem(\"sub\")._attr(\"name\", \"value\").__(\"sub text\").__().elem(\"sub1\")._noEndTag()._attr(\"boolean\", null).__(\"sub1text\").__().__(\"start text2\").elem(\"pre\")._pre().__(\"pre text\").elem(\"i\")._inline().__(\"inline\").__().__().elem(\"i\")._inline().__(\"inline after pre\").__().__(\"start text3\").elem(\"sub2\").__(\"sub2text\").__().elem(\"sub3\")._noEndTag().__(\"sub3text\").__().elem(\"sub4\")._noEndTag().elem(\"i\")._inline().__(\"inline\").__().__(\"sub4text\").__().__();\r\n    out.flush();\r\n    assertEquals(0, hi.nestLevel);\r\n    assertEquals(20, hi.indents);\r\n    verify(out).print(\"<start\");\r\n    verify(out, times(2)).print(\" name=\\\"value\\\"\");\r\n    verify(out).print(\" boolean\");\r\n    verify(out).print(\"</start>\");\r\n    verify(out, never()).print(\"</sub1>\");\r\n    verify(out, never()).print(\"</sub3>\");\r\n    verify(out, never()).print(\"</sub4>\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testSetSelector",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testSetSelector()\n{\r\n    CoreAttrs e = mock(CoreAttrs.class);\r\n    HamletImpl.setSelector(e, \"#id.class\");\r\n    verify(e).$id(\"id\");\r\n    verify(e).$class(\"class\");\r\n    H1 t = mock(H1.class);\r\n    HamletImpl.setSelector(t, \"#id.class\").__(\"heading\");\r\n    verify(t).$id(\"id\");\r\n    verify(t).$class(\"class\");\r\n    verify(t).__(\"heading\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testSetLinkHref",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testSetLinkHref()\n{\r\n    LINK link = mock(LINK.class);\r\n    HamletImpl.setLinkHref(link, \"uri\");\r\n    HamletImpl.setLinkHref(link, \"style.css\");\r\n    verify(link).$href(\"uri\");\r\n    verify(link).$rel(\"stylesheet\");\r\n    verify(link).$href(\"style.css\");\r\n    verifyNoMoreInteractions(link);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testSetScriptSrc",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testSetScriptSrc()\n{\r\n    SCRIPT script = mock(SCRIPT.class);\r\n    HamletImpl.setScriptSrc(script, \"uri\");\r\n    HamletImpl.setScriptSrc(script, \"script.js\");\r\n    verify(script).$src(\"uri\");\r\n    verify(script).$type(\"text/javascript\");\r\n    verify(script).$src(\"script.js\");\r\n    verifyNoMoreInteractions(script);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\timeline",
  "methodName" : "testRemovingUUID",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRemovingUUID()\n{\r\n    String flowName = TEST_FLOW_NAME + \"-\" + UUID.randomUUID();\r\n    flowName = TimelineUtils.removeUUID(flowName);\r\n    Assert.assertEquals(TEST_FLOW_NAME, flowName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\timeline",
  "methodName" : "testShortenedFlowName",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testShortenedFlowName()\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    String flowName = TEST_FLOW_NAME + UUID.randomUUID();\r\n    conf.setInt(YarnConfiguration.FLOW_NAME_MAX_SIZE, 8);\r\n    String shortenedFlowName = TimelineUtils.shortenFlowName(flowName, conf);\r\n    Assert.assertEquals(\"TestFlow\", shortenedFlowName);\r\n    conf.setInt(YarnConfiguration.FLOW_NAME_MAX_SIZE, YarnConfiguration.FLOW_NAME_DEFAULT_MAX_SIZE);\r\n    shortenedFlowName = TimelineUtils.shortenFlowName(flowName, conf);\r\n    Assert.assertEquals(TEST_FLOW_NAME, shortenedFlowName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "shouldNotThrow",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void shouldNotThrow()\n{\r\n    WebAppTests.testPage(TwoColumnLayout.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    WebApps.$for(\"test\").at(8888).inDevMode().start().joinThread();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "genTypeValue",
  "errType" : null,
  "containingMethodsNum" : 47,
  "sourceCodeText" : "Object genTypeValue(Type type)\n{\r\n    Object ret = typeValueCache.get(type);\r\n    if (ret != null) {\r\n        return ret;\r\n    }\r\n    if (type.equals(boolean.class)) {\r\n        return rand.nextBoolean();\r\n    } else if (type.equals(byte.class)) {\r\n        return bytes[rand.nextInt(4)];\r\n    } else if (type.equals(int.class) || type.equals(Integer.class)) {\r\n        return rand.nextInt(1000000);\r\n    } else if (type.equals(long.class) || type.equals(Long.class)) {\r\n        return Long.valueOf(rand.nextInt(1000000));\r\n    } else if (type.equals(float.class)) {\r\n        return rand.nextFloat();\r\n    } else if (type.equals(double.class)) {\r\n        return rand.nextDouble();\r\n    } else if (type.equals(String.class)) {\r\n        return String.format(\"%c%c%c\", 'a' + rand.nextInt(26), 'a' + rand.nextInt(26), 'a' + rand.nextInt(26));\r\n    } else if (type.equals(Float.class)) {\r\n        return rand.nextFloat();\r\n    } else if (type instanceof Class) {\r\n        Class clazz = (Class) type;\r\n        if (clazz.isArray()) {\r\n            Class compClass = clazz.getComponentType();\r\n            if (compClass != null) {\r\n                ret = Array.newInstance(compClass, 2);\r\n                Array.set(ret, 0, genTypeValue(compClass));\r\n                Array.set(ret, 1, genTypeValue(compClass));\r\n            }\r\n        } else if (clazz.isEnum()) {\r\n            Object[] values = clazz.getEnumConstants();\r\n            ret = values[rand.nextInt(values.length)];\r\n        } else if (clazz.equals(ByteBuffer.class)) {\r\n            ByteBuffer buff = ByteBuffer.allocate(4);\r\n            rand.nextBytes(buff.array());\r\n            return buff;\r\n        } else if (type.equals(PlacementConstraint.class)) {\r\n            PlacementConstraint.AbstractConstraint sConstraintExpr = targetIn(NODE, allocationTag(\"foo\"));\r\n            ret = PlacementConstraints.build(sConstraintExpr);\r\n        }\r\n    } else if (type instanceof ParameterizedType) {\r\n        ParameterizedType pt = (ParameterizedType) type;\r\n        Type rawType = pt.getRawType();\r\n        Type[] params = pt.getActualTypeArguments();\r\n        if (rawType.equals(EnumSet.class)) {\r\n            if (params[0] instanceof Class) {\r\n                Class c = (Class) (params[0]);\r\n                return EnumSet.allOf(c);\r\n            }\r\n        }\r\n        if (rawType.equals(List.class)) {\r\n            ret = Lists.newArrayList(genTypeValue(params[0]));\r\n        } else if (rawType.equals(Set.class)) {\r\n            ret = Sets.newHashSet(genTypeValue(params[0]));\r\n        } else if (rawType.equals(Map.class)) {\r\n            Map<Object, Object> map = Maps.newHashMap();\r\n            map.put(genTypeValue(params[0]), genTypeValue(params[1]));\r\n            ret = map;\r\n        } else if (rawType.equals(Range.class)) {\r\n            ret = typeValueCache.get(rawType);\r\n            if (ret != null) {\r\n                return ret;\r\n            }\r\n        }\r\n    }\r\n    if (ret == null) {\r\n        throw new IllegalArgumentException(\"type \" + type + \" is not supported\");\r\n    }\r\n    typeValueCache.put(type, ret);\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "generateByNewInstance",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "Object generateByNewInstance(Class clazz) throws Exception\n{\r\n    Object ret = typeValueCache.get(clazz);\r\n    if (ret != null) {\r\n        return ret;\r\n    }\r\n    Method newInstance = null;\r\n    Type[] paramTypes = new Type[0];\r\n    for (Method m : clazz.getMethods()) {\r\n        int mod = m.getModifiers();\r\n        if (m.getDeclaringClass().equals(clazz) && Modifier.isPublic(mod) && Modifier.isStatic(mod) && m.getName().equals(\"newInstance\")) {\r\n            Type[] pts = m.getGenericParameterTypes();\r\n            if (newInstance == null || (pts.length > paramTypes.length)) {\r\n                newInstance = m;\r\n                paramTypes = pts;\r\n            }\r\n        }\r\n    }\r\n    if (newInstance == null) {\r\n        throw new IllegalArgumentException(\"type \" + clazz.getName() + \" does not have newInstance method\");\r\n    }\r\n    Object[] args = new Object[paramTypes.length];\r\n    for (int i = 0; i < args.length; i++) {\r\n        args[i] = genTypeValue(paramTypes[i]);\r\n    }\r\n    ret = newInstance.invoke(null, args);\r\n    typeValueCache.put(clazz, ret);\r\n    return ret;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "getGetSetPairs",
  "errType" : null,
  "containingMethodsNum" : 40,
  "sourceCodeText" : "Map<String, GetSetPair> getGetSetPairs(Class<R> recordClass) throws Exception\n{\r\n    Map<String, GetSetPair> ret = new HashMap<String, GetSetPair>();\r\n    List<String> excluded = null;\r\n    if (excludedPropertiesMap.containsKey(recordClass.getClass())) {\r\n        excluded = excludedPropertiesMap.get(recordClass.getClass());\r\n    }\r\n    Method[] methods = recordClass.getDeclaredMethods();\r\n    for (int i = 0; i < methods.length; i++) {\r\n        Method m = methods[i];\r\n        int mod = m.getModifiers();\r\n        if (m.getDeclaringClass().equals(recordClass) && Modifier.isPublic(mod) && (!Modifier.isStatic(mod))) {\r\n            String name = m.getName();\r\n            if (name.equals(\"getProto\")) {\r\n                continue;\r\n            }\r\n            if ((name.length() > 3) && name.startsWith(\"get\") && (m.getParameterTypes().length == 0)) {\r\n                String propertyName = name.substring(3);\r\n                Type valueType = m.getGenericReturnType();\r\n                GetSetPair p = ret.get(propertyName);\r\n                if (p == null) {\r\n                    p = new GetSetPair();\r\n                    p.propertyName = propertyName;\r\n                    p.type = valueType;\r\n                    p.getMethod = m;\r\n                    ret.put(propertyName, p);\r\n                } else {\r\n                    Assert.fail(\"Multiple get method with same name: \" + recordClass + p.propertyName);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    for (int i = 0; i < methods.length; i++) {\r\n        Method m = methods[i];\r\n        int mod = m.getModifiers();\r\n        if (m.getDeclaringClass().equals(recordClass) && Modifier.isPublic(mod) && (!Modifier.isStatic(mod))) {\r\n            String name = m.getName();\r\n            if (name.startsWith(\"set\") && (m.getParameterTypes().length == 1)) {\r\n                String propertyName = name.substring(3);\r\n                Type valueType = m.getGenericParameterTypes()[0];\r\n                GetSetPair p = ret.get(propertyName);\r\n                if (p != null && p.type.equals(valueType)) {\r\n                    p.setMethod = m;\r\n                }\r\n            }\r\n        }\r\n    }\r\n    Iterator<Map.Entry<String, GetSetPair>> itr = ret.entrySet().iterator();\r\n    while (itr.hasNext()) {\r\n        Map.Entry<String, GetSetPair> cur = itr.next();\r\n        GetSetPair gsp = cur.getValue();\r\n        if ((gsp.getMethod == null) || (gsp.setMethod == null)) {\r\n            LOG.info(String.format(\"Exclude potential property: %s\\n\", gsp.propertyName));\r\n            itr.remove();\r\n        } else if ((excluded != null && excluded.contains(gsp.propertyName))) {\r\n            LOG.info(String.format(\"Excluding potential property(present in exclusion list): %s\\n\", gsp.propertyName));\r\n            itr.remove();\r\n        } else {\r\n            LOG.info(String.format(\"New property: %s type: %s\", gsp.toString(), gsp.type));\r\n            gsp.testValue = genTypeValue(gsp.type);\r\n            LOG.info(String.format(\" testValue: %s\\n\", gsp.testValue));\r\n        }\r\n    }\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "validatePBImplRecord",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void validatePBImplRecord(Class<R> recordClass, Class<P> protoClass) throws Exception\n{\r\n    LOG.info(String.format(\"Validate %s %s\\n\", recordClass.getName(), protoClass.getName()));\r\n    Constructor<R> emptyConstructor = recordClass.getConstructor();\r\n    Constructor<R> pbConstructor = recordClass.getConstructor(protoClass);\r\n    Method getProto = recordClass.getDeclaredMethod(\"getProto\");\r\n    Map<String, GetSetPair> getSetPairs = getGetSetPairs(recordClass);\r\n    R origRecord = emptyConstructor.newInstance();\r\n    for (GetSetPair gsp : getSetPairs.values()) {\r\n        gsp.setMethod.invoke(origRecord, gsp.testValue);\r\n    }\r\n    Object ret = getProto.invoke(origRecord);\r\n    Assert.assertNotNull(recordClass.getName() + \"#getProto returns null\", ret);\r\n    if (!(protoClass.isAssignableFrom(ret.getClass()))) {\r\n        Assert.fail(\"Illegal getProto method return type: \" + ret.getClass());\r\n    }\r\n    R deserRecord = pbConstructor.newInstance(ret);\r\n    Assert.assertEquals(\"whole \" + recordClass + \" records should be equal\", origRecord, deserRecord);\r\n    for (GetSetPair gsp : getSetPairs.values()) {\r\n        Object origValue = gsp.getMethod.invoke(origRecord);\r\n        Object deserValue = gsp.getMethod.invoke(deserRecord);\r\n        Assert.assertEquals(\"property \" + recordClass.getName() + \"#\" + gsp.propertyName + \" should be equal\", origValue, deserValue);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "render",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void render(Block html)\n{\r\n    info(\"test!\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testSetEnvFromInputString",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testSetEnvFromInputString()\n{\r\n    Map<String, String> environment = new HashMap<String, String>();\r\n    environment.put(\"JAVA_HOME\", \"/path/jdk\");\r\n    String goodEnv = \"a1=1,b_2=2,_c=3,d=4,e=,f_win=%JAVA_HOME%\" + \",g_nix=$JAVA_HOME\";\r\n    Apps.setEnvFromInputString(environment, goodEnv, File.pathSeparator);\r\n    assertEquals(\"1\", environment.get(\"a1\"));\r\n    assertEquals(\"2\", environment.get(\"b_2\"));\r\n    assertEquals(\"3\", environment.get(\"_c\"));\r\n    assertEquals(\"4\", environment.get(\"d\"));\r\n    assertEquals(\"\", environment.get(\"e\"));\r\n    if (Shell.WINDOWS) {\r\n        assertEquals(\"$JAVA_HOME\", environment.get(\"g_nix\"));\r\n        assertEquals(\"/path/jdk\", environment.get(\"f_win\"));\r\n    } else {\r\n        assertEquals(\"/path/jdk\", environment.get(\"g_nix\"));\r\n        assertEquals(\"%JAVA_HOME%\", environment.get(\"f_win\"));\r\n    }\r\n    String badEnv = \"1,,2=a=b,3=a=,4==,5==a,==,c-3=3,=\";\r\n    environment.clear();\r\n    Apps.setEnvFromInputString(environment, badEnv, File.pathSeparator);\r\n    assertThat(environment).isEmpty();\r\n    environment.clear();\r\n    Apps.setEnvFromInputString(environment, \"b1,e1==,e2=a1=a2,b2\", File.pathSeparator);\r\n    assertEquals(\"=\", environment.get(\"e1\"));\r\n    assertEquals(\"a1=a2\", environment.get(\"e2\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testSetEnvFromInputProperty",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testSetEnvFromInputProperty()\n{\r\n    Configuration conf = new Configuration(false);\r\n    Map<String, String> env = new HashMap<>();\r\n    String propName = \"mapreduce.map.env\";\r\n    String defaultPropName = \"mapreduce.child.env\";\r\n    conf.set(propName, \"env1=env1_val,env2=env2_val,env3=env3_val\");\r\n    conf.set(propName + \".env4\", \"env4_val\");\r\n    conf.set(propName + \".env2\", \"new_env2_val\");\r\n    conf.set(defaultPropName, \"env1=def1_val,env2=def2_val,env3=def3_val\");\r\n    String defaultPropValue = conf.get(defaultPropName);\r\n    conf.set(defaultPropName + \".env4\", \"def4_val\");\r\n    conf.set(defaultPropName + \".env2\", \"new_def2_val\");\r\n    Apps.setEnvFromInputProperty(env, propName, defaultPropValue, conf, File.pathSeparator);\r\n    assertEquals(\"env1_val\", env.get(\"env1\"));\r\n    assertEquals(\"env3_val\", env.get(\"env3\"));\r\n    assertEquals(\"env4_val\", env.get(\"env4\"));\r\n    assertEquals(\"new_env2_val\", env.get(\"env2\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testSetEnvFromInputPropertyDefault",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testSetEnvFromInputPropertyDefault()\n{\r\n    Configuration conf = new Configuration(false);\r\n    Map<String, String> env = new HashMap<>();\r\n    String propName = \"mapreduce.map.env\";\r\n    String defaultPropName = \"mapreduce.child.env\";\r\n    conf.set(propName, \"env1=env1_val,env2=env2_val,env3=env3_val\");\r\n    conf.set(propName + \".env4\", \"env4_val\");\r\n    conf.set(propName + \".env2\", \"new_env2_val\");\r\n    conf.set(defaultPropName, \"env1=def1_val,env2=def2_val,env3=def3_val\");\r\n    String defaultPropValue = conf.get(defaultPropName);\r\n    conf.set(defaultPropName + \".env4\", \"def4_val\");\r\n    conf.set(defaultPropName + \".env2\", \"new_def2_val\");\r\n    String bogusProp = propName + \"bogus\";\r\n    Apps.setEnvFromInputProperty(env, bogusProp, defaultPropValue, conf, File.pathSeparator);\r\n    assertEquals(\"def1_val\", env.get(\"env1\"));\r\n    assertEquals(\"def2_val\", env.get(\"env2\"));\r\n    assertEquals(\"def3_val\", env.get(\"env3\"));\r\n    assertNull(env.get(\"env4\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testSetEnvFromInputPropertyOverrideDefault",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testSetEnvFromInputPropertyOverrideDefault()\n{\r\n    Configuration conf = new Configuration(false);\r\n    Map<String, String> env = new HashMap<>();\r\n    String propName = \"mapreduce.reduce.env\";\r\n    conf.set(propName + \".env2\", \"new2_val\");\r\n    conf.set(propName + \".env4\", \"new4_val\");\r\n    String defaultPropName = \"mapreduce.child.env\";\r\n    conf.set(defaultPropName, \"env1=def1_val,env2=def2_val,env3=def3_val\");\r\n    String defaultPropValue = conf.get(defaultPropName);\r\n    conf.set(defaultPropName + \".env4\", \"def4_val\");\r\n    conf.set(defaultPropName + \".env2\", \"new_def2_val\");\r\n    Apps.setEnvFromInputProperty(env, propName, defaultPropValue, conf, File.pathSeparator);\r\n    assertEquals(\"def1_val\", env.get(\"env1\"));\r\n    assertEquals(\"def3_val\", env.get(\"env3\"));\r\n    assertEquals(\"new4_val\", env.get(\"env4\"));\r\n    assertEquals(\"new2_val\", env.get(\"env2\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testSetEnvFromInputPropertyCommas",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testSetEnvFromInputPropertyCommas()\n{\r\n    Configuration conf = new Configuration(false);\r\n    Map<String, String> env = new HashMap<>();\r\n    String propName = \"mapreduce.reduce.env\";\r\n    conf.set(propName, \"env1=env1_val,env2=env2_val,env3=env3_val\");\r\n    conf.set(propName + \".env2\", \"new2_val1,new2_val2,new2_val3\");\r\n    conf.set(propName + \".env4\", \"new4_valwith=equals\");\r\n    String defaultPropName = \"mapreduce.child.env\";\r\n    conf.set(defaultPropName, \"env1=def1_val,env2=def2_val,env3=def3_val\");\r\n    String defaultPropValue = conf.get(defaultPropName);\r\n    Apps.setEnvFromInputProperty(env, propName, defaultPropValue, conf, File.pathSeparator);\r\n    assertEquals(\"env1_val\", env.get(\"env1\"));\r\n    assertEquals(\"env3_val\", env.get(\"env3\"));\r\n    assertEquals(\"new4_valwith=equals\", env.get(\"env4\"));\r\n    assertEquals(\"new2_val1,new2_val2,new2_val3\", env.get(\"env2\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testSetEnvFromInputPropertyNull",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testSetEnvFromInputPropertyNull()\n{\r\n    Configuration conf = new Configuration(false);\r\n    Map<String, String> env = new HashMap<>();\r\n    String propName = \"mapreduce.map.env\";\r\n    String defaultPropName = \"mapreduce.child.env\";\r\n    conf.set(propName, \"env1=env1_val,env2=env2_val,env3=env3_val\");\r\n    conf.set(propName + \".env4\", \"env4_val\");\r\n    conf.set(propName + \".env2\", \"new_env2_val\");\r\n    conf.set(defaultPropName, \"env1=def1_val,env2=def2_val,env3=def3_val\");\r\n    String defaultPropValue = conf.get(defaultPropName);\r\n    conf.set(defaultPropName + \".env4\", \"def4_val\");\r\n    conf.set(defaultPropName + \".env2\", \"new_def2_val\");\r\n    Apps.setEnvFromInputProperty(env, \"bogus1\", null, conf, File.pathSeparator);\r\n    assertTrue(env.isEmpty());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testHadoopProtoRPCTimeout",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testHadoopProtoRPCTimeout() throws Exception\n{\r\n    testRPCTimeout(HadoopYarnProtoRPC.class.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testRPCTimeout",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 24,
  "sourceCodeText" : "void testRPCTimeout(String rpcClass) throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setInt(\"yarn.rpc.nm-command-timeout\", 3000);\r\n    conf.set(YarnConfiguration.IPC_RPC_IMPL, rpcClass);\r\n    YarnRPC rpc = YarnRPC.create(conf);\r\n    String bindAddr = \"localhost:0\";\r\n    InetSocketAddress addr = NetUtils.createSocketAddr(bindAddr);\r\n    Server server = rpc.getServer(ContainerManagementProtocol.class, new DummyContainerManager(), addr, conf, null, 1);\r\n    server.start();\r\n    try {\r\n        ContainerManagementProtocol proxy = (ContainerManagementProtocol) rpc.getProxy(ContainerManagementProtocol.class, server.getListenerAddress(), conf);\r\n        ContainerLaunchContext containerLaunchContext = recordFactory.newRecordInstance(ContainerLaunchContext.class);\r\n        ApplicationId applicationId = ApplicationId.newInstance(0, 0);\r\n        ApplicationAttemptId applicationAttemptId = ApplicationAttemptId.newInstance(applicationId, 0);\r\n        ContainerId containerId = ContainerId.newContainerId(applicationAttemptId, 100);\r\n        NodeId nodeId = NodeId.newInstance(\"localhost\", 1234);\r\n        Resource resource = Resource.newInstance(1234, 2);\r\n        ContainerTokenIdentifier containerTokenIdentifier = new ContainerTokenIdentifier(containerId, \"localhost\", \"user\", resource, System.currentTimeMillis() + 10000, 42, 42, Priority.newInstance(0), 0);\r\n        Token containerToken = newContainerToken(nodeId, \"password\".getBytes(), containerTokenIdentifier);\r\n        StartContainerRequest scRequest = StartContainerRequest.newInstance(containerLaunchContext, containerToken);\r\n        List<StartContainerRequest> list = new ArrayList<StartContainerRequest>();\r\n        list.add(scRequest);\r\n        StartContainersRequest allRequests = StartContainersRequest.newInstance(list);\r\n        try {\r\n            proxy.startContainers(allRequests);\r\n        } catch (Exception e) {\r\n            LOG.info(StringUtils.stringifyException(e));\r\n            Assert.assertEquals(\"Error, exception is not: \" + SocketTimeoutException.class.getName(), SocketTimeoutException.class.getName(), e.getClass().getName());\r\n            return;\r\n        }\r\n    } finally {\r\n        server.stop();\r\n    }\r\n    Assert.fail(\"timeout exception should have occurred!\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newContainerToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Token newContainerToken(NodeId nodeId, byte[] password, ContainerTokenIdentifier tokenIdentifier)\n{\r\n    InetSocketAddress addr = NetUtils.createSocketAddrForHost(nodeId.getHost(), nodeId.getPort());\r\n    Token containerToken = Token.newInstance(tokenIdentifier.getBytes(), ContainerTokenIdentifier.KIND.toString(), password, SecurityUtil.buildTokenService(addr).toString());\r\n    return containerToken;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getInjector",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Injector getInjector()\n{\r\n    return internalInjector;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "setInjector",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Injector setInjector(Injector in)\n{\r\n    internalInjector = in;\r\n    return internalInjector;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testNormalAction",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNormalAction()\n{\r\n    assertEquals(Arrays.asList(\"/foo/action\", \"foo\", \"action\", \":a1\", \":a2\"), WebApp.parseRoute(\"/foo/action/:a1/:a2\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testDefaultController",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testDefaultController()\n{\r\n    assertEquals(Arrays.asList(\"/\", \"default\", \"index\"), WebApp.parseRoute(\"/\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testDefaultAction",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testDefaultAction()\n{\r\n    assertEquals(Arrays.asList(\"/foo\", \"foo\", \"index\"), WebApp.parseRoute(\"/foo\"));\r\n    assertEquals(Arrays.asList(\"/foo\", \"foo\", \"index\"), WebApp.parseRoute(\"/foo/\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testMissingAction",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testMissingAction()\n{\r\n    assertEquals(Arrays.asList(\"/foo\", \"foo\", \"index\", \":a1\"), WebApp.parseRoute(\"/foo/:a1\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testDefaultCapture",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testDefaultCapture()\n{\r\n    assertEquals(Arrays.asList(\"/\", \"default\", \"index\", \":a\"), WebApp.parseRoute(\"/:a\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testPartialCapture1",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPartialCapture1()\n{\r\n    assertEquals(Arrays.asList(\"/foo/action/bar\", \"foo\", \"action\", \"bar\", \":a\"), WebApp.parseRoute(\"/foo/action/bar/:a\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testPartialCapture2",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPartialCapture2()\n{\r\n    assertEquals(Arrays.asList(\"/foo/action\", \"foo\", \"action\", \":a1\", \"bar\", \":a2\", \":a3\"), WebApp.parseRoute(\"/foo/action/:a1/bar/:a2/:a3\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testLeadingPaddings",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testLeadingPaddings()\n{\r\n    assertEquals(Arrays.asList(\"/foo/action\", \"foo\", \"action\", \":a\"), WebApp.parseRoute(\" /foo/action/ :a\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testTrailingPaddings",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testTrailingPaddings()\n{\r\n    assertEquals(Arrays.asList(\"/foo/action\", \"foo\", \"action\", \":a\"), WebApp.parseRoute(\"/foo/action//:a / \"));\r\n    assertEquals(Arrays.asList(\"/foo/action\", \"foo\", \"action\"), WebApp.parseRoute(\"/foo/action / \"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testMissingLeadingSlash",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testMissingLeadingSlash()\n{\r\n    WebApp.parseRoute(\"foo/bar\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testErrorPage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testErrorPage()\n{\r\n    Injector injector = WebAppTests.testPage(ErrorPage.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testHeaderBlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testHeaderBlock()\n{\r\n    WebAppTests.testBlock(HeaderBlock.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testFooterBlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testFooterBlock()\n{\r\n    WebAppTests.testBlock(FooterBlock.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testJQueryUI",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testJQueryUI()\n{\r\n    WebAppTests.testBlock(JQueryUI.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testInfoBlock",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testInfoBlock()\n{\r\n    Injector injector = WebAppTests.createMockInjector(this);\r\n    ResponseInfo info = injector.getInstance(ResponseInfo.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testConvertFromOrToProtoFormat",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testConvertFromOrToProtoFormat()\n{\r\n    try {\r\n        Stream.of(ContainerState.values()).forEach(a -> ProtoUtils.convertToProtoFormat(a));\r\n        Stream.of(ContainerSubState.values()).forEach(a -> ProtoUtils.convertToProtoFormat(a));\r\n        Stream.of(ContainerSubStateProto.values()).forEach(a -> ProtoUtils.convertFromProtoFormat(a));\r\n        Stream.of(ContainerStateProto.values()).forEach(a -> ProtoUtils.convertFromProtoFormat(a));\r\n    } catch (IllegalArgumentException ex) {\r\n        fail(ex.getMessage());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "MyInfo get()\n{\r\n    return new MyInfo();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client",
  "methodName" : "testGetRMDelegationTokenService",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testGetRMDelegationTokenService()\n{\r\n    String defaultRMAddress = YarnConfiguration.DEFAULT_RM_ADDRESS;\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    Text tokenService = ClientRMProxy.getRMDelegationTokenService(conf);\r\n    String[] services = tokenService.toString().split(\",\");\r\n    assertEquals(1, services.length);\r\n    for (String service : services) {\r\n        assertTrue(\"Incorrect token service name\", service.contains(defaultRMAddress));\r\n    }\r\n    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf.set(YarnConfiguration.RM_HA_IDS, \"rm1,rm2\");\r\n    conf.set(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, \"rm1\"), \"0.0.0.0\");\r\n    conf.set(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, \"rm2\"), \"0.0.0.0\");\r\n    tokenService = ClientRMProxy.getRMDelegationTokenService(conf);\r\n    services = tokenService.toString().split(\",\");\r\n    assertEquals(2, services.length);\r\n    for (String service : services) {\r\n        assertTrue(\"Incorrect token service name\", service.contains(defaultRMAddress));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client",
  "methodName" : "testGetAMRMTokenService",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testGetAMRMTokenService()\n{\r\n    String defaultRMAddress = YarnConfiguration.DEFAULT_RM_SCHEDULER_ADDRESS;\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    Text tokenService = ClientRMProxy.getAMRMTokenService(conf);\r\n    String[] services = tokenService.toString().split(\",\");\r\n    assertEquals(1, services.length);\r\n    for (String service : services) {\r\n        assertTrue(\"Incorrect token service name\", service.contains(defaultRMAddress));\r\n    }\r\n    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf.set(YarnConfiguration.RM_HA_IDS, \"rm1,rm2\");\r\n    conf.set(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, \"rm1\"), \"0.0.0.0\");\r\n    conf.set(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, \"rm2\"), \"0.0.0.0\");\r\n    tokenService = ClientRMProxy.getAMRMTokenService(conf);\r\n    services = tokenService.toString().split(\",\");\r\n    assertEquals(2, services.length);\r\n    for (String service : services) {\r\n        assertTrue(\"Incorrect token service name\", service.contains(defaultRMAddress));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client",
  "methodName" : "testProxyUserCorrectUGI",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testProxyUserCorrectUGI() throws Exception\n{\r\n    final YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf.set(YarnConfiguration.RM_HA_IDS, \"rm1,rm2\");\r\n    conf.set(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, \"rm1\"), \"0.0.0.0\");\r\n    conf.set(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, \"rm2\"), \"0.0.0.0\");\r\n    conf.setLong(YarnConfiguration.CLIENT_FAILOVER_MAX_ATTEMPTS, 2);\r\n    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS, 2);\r\n    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS, 2);\r\n    conf.setClass(YarnConfiguration.IPC_RPC_IMPL, UGICapturingHadoopYarnProtoRPC.class, YarnRPC.class);\r\n    UserGroupInformation realUser = UserGroupInformation.getCurrentUser();\r\n    UserGroupInformation proxyUser = UserGroupInformation.createProxyUserForTesting(\"proxy\", realUser, new String[] { \"group1\" });\r\n    ApplicationClientProtocol rmProxy = proxyUser.doAs(new PrivilegedExceptionAction<ApplicationClientProtocol>() {\r\n\r\n        @Override\r\n        public ApplicationClientProtocol run() throws Exception {\r\n            return ClientRMProxy.createRMProxy(conf, ApplicationClientProtocol.class);\r\n        }\r\n    });\r\n    assertUGI();\r\n    GetNewApplicationRequest request = Records.newRecord(GetNewApplicationRequest.class);\r\n    UGICapturingHadoopYarnProtoRPC.lastCurrentUser = null;\r\n    try {\r\n        rmProxy.getNewApplication(request);\r\n    } catch (IOException ioe) {\r\n    }\r\n    assertUGI();\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client",
  "methodName" : "assertUGI",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void assertUGI() throws IOException\n{\r\n    UserGroupInformation lastCurrentUser = UGICapturingHadoopYarnProtoRPC.lastCurrentUser;\r\n    assertNotNull(lastCurrentUser);\r\n    assertEquals(\"proxy\", lastCurrentUser.getShortUserName());\r\n    Assert.assertEquals(UserGroupInformation.AuthenticationMethod.PROXY, lastCurrentUser.getAuthenticationMethod());\r\n    assertEquals(UserGroupInformation.getCurrentUser(), lastCurrentUser.getRealUser());\r\n    UGICapturingHadoopYarnProtoRPC.lastCurrentUser = null;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testSerializedException",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testSerializedException() throws Exception\n{\r\n    SerializedExceptionPBImpl orig = new SerializedExceptionPBImpl();\r\n    orig.init(new Exception(\"test exception\"));\r\n    SerializedExceptionProto proto = orig.getProto();\r\n    SerializedExceptionPBImpl deser = new SerializedExceptionPBImpl(proto);\r\n    Assert.assertEquals(orig, deser);\r\n    Assert.assertEquals(orig.getMessage(), deser.getMessage());\r\n    Assert.assertEquals(orig.getRemoteTrace(), deser.getRemoteTrace());\r\n    Assert.assertEquals(orig.getCause(), deser.getCause());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testDeserialize",
  "errType" : [ "YarnRuntimeException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testDeserialize() throws Exception\n{\r\n    Exception ex = new Exception(\"test exception\");\r\n    SerializedExceptionPBImpl pb = new SerializedExceptionPBImpl();\r\n    try {\r\n        pb.deSerialize();\r\n        Assert.fail(\"deSerialze should throw YarnRuntimeException\");\r\n    } catch (YarnRuntimeException e) {\r\n        Assert.assertEquals(ClassNotFoundException.class, e.getCause().getClass());\r\n    }\r\n    pb.init(ex);\r\n    Assert.assertEquals(ex.toString(), pb.deSerialize().toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testDeserializeWithDefaultConstructor",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testDeserializeWithDefaultConstructor()\n{\r\n    ClosedChannelException ex = new ClosedChannelException();\r\n    SerializedExceptionPBImpl pb = new SerializedExceptionPBImpl();\r\n    pb.init(ex);\r\n    Assert.assertEquals(ex.getClass(), pb.deSerialize().getClass());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testBeforeInit",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testBeforeInit() throws Exception\n{\r\n    SerializedExceptionProto defaultProto = SerializedExceptionProto.newBuilder().build();\r\n    SerializedExceptionPBImpl pb1 = new SerializedExceptionPBImpl();\r\n    Assert.assertNull(pb1.getCause());\r\n    SerializedExceptionPBImpl pb2 = new SerializedExceptionPBImpl();\r\n    Assert.assertEquals(defaultProto, pb2.getProto());\r\n    SerializedExceptionPBImpl pb3 = new SerializedExceptionPBImpl();\r\n    Assert.assertEquals(defaultProto.getTrace(), pb3.getRemoteTrace());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testThrowableDeserialization",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testThrowableDeserialization()\n{\r\n    Error ex = new Error();\r\n    SerializedExceptionPBImpl pb = new SerializedExceptionPBImpl();\r\n    pb.init(ex);\r\n    Assert.assertEquals(ex.getClass(), pb.deSerialize().getClass());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testRemoteDirCreationDefault",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testRemoteDirCreationDefault() throws Exception\n{\r\n    FileSystem fs = mock(FileSystem.class);\r\n    doReturn(new URI(\"\")).when(fs).getUri();\r\n    doThrow(FileNotFoundException.class).when(fs).getFileStatus(any(Path.class));\r\n    Configuration conf = new Configuration();\r\n    LogAggregationFileController controller = mock(LogAggregationFileController.class, Mockito.CALLS_REAL_METHODS);\r\n    doReturn(fs).when(controller).getFileSystem(any(Configuration.class));\r\n    UserGroupInformation ugi = UserGroupInformation.createUserForTesting(\"yarn_user\", new String[] { \"yarn_group\", \"other_group\" });\r\n    UserGroupInformation.setLoginUser(ugi);\r\n    controller.initialize(conf, \"TFile\");\r\n    controller.verifyAndCreateRemoteLogDir();\r\n    verify(fs).setOwner(any(), eq(\"yarn_user\"), eq(\"yarn_group\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testRemoteDirCreationWithCustomGroup",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testRemoteDirCreationWithCustomGroup() throws Exception\n{\r\n    String testGroupName = \"testGroup\";\r\n    FileSystem fs = mock(FileSystem.class);\r\n    doReturn(new URI(\"\")).when(fs).getUri();\r\n    doThrow(FileNotFoundException.class).when(fs).getFileStatus(any(Path.class));\r\n    Configuration conf = new Configuration();\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_GROUPNAME, testGroupName);\r\n    LogAggregationFileController controller = mock(LogAggregationFileController.class, Mockito.CALLS_REAL_METHODS);\r\n    doReturn(fs).when(controller).getFileSystem(any(Configuration.class));\r\n    UserGroupInformation ugi = UserGroupInformation.createUserForTesting(\"yarn_user\", new String[] { \"yarn_group\", \"other_group\" });\r\n    UserGroupInformation.setLoginUser(ugi);\r\n    controller.initialize(conf, \"TFile\");\r\n    controller.verifyAndCreateRemoteLogDir();\r\n    verify(fs).setOwner(any(), eq(\"yarn_user\"), eq(testGroupName));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testRemoteDirCreationWithCustomUser",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testRemoteDirCreationWithCustomUser() throws Exception\n{\r\n    FileSystem fs = mock(FileSystem.class);\r\n    doReturn(new URI(\"\")).when(fs).getUri();\r\n    doReturn(new FileStatus(128, false, 0, 64, System.currentTimeMillis(), System.currentTimeMillis(), new FsPermission(TLDIR_PERMISSIONS), \"not_yarn_user\", \"yarn_group\", new Path(\"/tmp/logs\"))).when(fs).getFileStatus(any(Path.class));\r\n    Configuration conf = new Configuration();\r\n    LogAggregationFileController controller = mock(LogAggregationFileController.class, Mockito.CALLS_REAL_METHODS);\r\n    controller.fsSupportsChmod = true;\r\n    doReturn(fs).when(controller).getFileSystem(any(Configuration.class));\r\n    UserGroupInformation ugi = UserGroupInformation.createUserForTesting(\"yarn_user\", new String[] { \"yarn_group\", \"other_group\" });\r\n    UserGroupInformation.setLoginUser(ugi);\r\n    controller.initialize(conf, \"TFile\");\r\n    controller.verifyAndCreateRemoteLogDir();\r\n    verify(fs).createNewFile(argThat(new PathContainsString(\".permission_check\")));\r\n    verify(fs).setPermission(argThat(new PathContainsString(\".permission_check\")), eq(new FsPermission(TLDIR_PERMISSIONS)));\r\n    verify(fs).delete(argThat(new PathContainsString(\".permission_check\")), eq(false));\r\n    Assert.assertTrue(controller.fsSupportsChmod);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testLRUCache",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testLRUCache() throws YarnException, IOException, InterruptedException\n{\r\n    int mapSize = 5;\r\n    LRUCacheHashMap<String, Integer> map = new LRUCacheHashMap<String, Integer>(mapSize, true);\r\n    map.put(\"1\", 1);\r\n    map.put(\"2\", 2);\r\n    map.put(\"3\", 3);\r\n    map.put(\"4\", 4);\r\n    map.put(\"5\", 5);\r\n    Assert.assertEquals(mapSize, map.size());\r\n    for (int i = 1; i < mapSize; i++) {\r\n        Assert.assertTrue(map.containsKey(Integer.toString(i)));\r\n    }\r\n    map.put(\"6\", 6);\r\n    map.put(\"3\", 3);\r\n    map.put(\"7\", 7);\r\n    map.put(\"8\", 8);\r\n    Assert.assertEquals(mapSize, map.size());\r\n    for (int i = 5; i < mapSize; i++) {\r\n        Assert.assertTrue(map.containsKey(Integer.toString(i)));\r\n    }\r\n    Assert.assertTrue(map.containsKey(\"3\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "getParameters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Collection<String[]> getParameters()\n{\r\n    return Arrays.asList(new String[][] { { FileSystemNodeLabelsStore.class.getCanonicalName() }, { NonAppendableFSNodeLabelStore.class.getCanonicalName() } });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "before",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void before() throws IOException\n{\r\n    mgr = new MockNodeLabelManager();\r\n    conf = new Configuration();\r\n    conf.setBoolean(YarnConfiguration.NODE_LABELS_ENABLED, true);\r\n    conf.set(YarnConfiguration.FS_NODE_LABELS_STORE_IMPL_CLASS, storeClassName);\r\n    File tempDir = File.createTempFile(\"nlb\", \".tmp\");\r\n    tempDir.delete();\r\n    tempDir.mkdirs();\r\n    tempDir.deleteOnExit();\r\n    conf.set(YarnConfiguration.FS_NODE_LABELS_STORE_ROOT_DIR, tempDir.getAbsolutePath());\r\n    mgr.init(conf);\r\n    mgr.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "after",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void after() throws IOException\n{\r\n    if (mgr.store instanceof FileSystemNodeLabelsStore) {\r\n        FileSystemNodeLabelsStore fsStore = ((FileSystemNodeLabelsStore) mgr.store);\r\n        fsStore.getFs().delete(fsStore.getFsWorkingPath(), true);\r\n    }\r\n    mgr.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testRecoverWithMirror",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testRecoverWithMirror() throws Exception\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p4\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p5\", \"p6\"));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n5\"), toSet(\"p5\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    mgr.removeFromClusterNodeLabels(toSet(\"p1\"));\r\n    mgr.removeFromClusterNodeLabels(Arrays.asList(\"p3\", \"p5\"));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    Assert.assertEquals(3, mgr.getClusterNodeLabelNames().size());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"p2\", \"p4\", \"p6\")));\r\n    assertMapContains(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(), ImmutableMap.of(\"p6\", toSet(toNodeId(\"n6\"), toNodeId(\"n7\")), \"p4\", toSet(toNodeId(\"n4\")), \"p2\", toSet(toNodeId(\"n2\"))));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    Assert.assertEquals(3, mgr.getClusterNodeLabelNames().size());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"p2\", \"p4\", \"p6\")));\r\n    assertMapContains(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(), ImmutableMap.of(\"p6\", toSet(toNodeId(\"n6\"), toNodeId(\"n7\")), \"p4\", toSet(toNodeId(\"n4\")), \"p2\", toSet(toNodeId(\"n2\"))));\r\n    mgr.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testRecoverWithDistributedNodeLabels",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testRecoverWithDistributedNodeLabels() throws Exception\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p4\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p5\", \"p6\"));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n5\"), toSet(\"p5\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    mgr.removeFromClusterNodeLabels(toSet(\"p1\"));\r\n    mgr.removeFromClusterNodeLabels(Arrays.asList(\"p3\", \"p5\"));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    Configuration cf = new Configuration(conf);\r\n    cf.set(YarnConfiguration.NODELABEL_CONFIGURATION_TYPE, YarnConfiguration.DISTRIBUTED_NODELABEL_CONFIGURATION_TYPE);\r\n    mgr.init(cf);\r\n    mgr.start();\r\n    Assert.assertEquals(3, mgr.getClusterNodeLabels().size());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"p2\", \"p4\", \"p6\")));\r\n    Assert.assertTrue(\"During recovery in distributed node-labels setup, \" + \"node to labels mapping should not be recovered \", mgr.getNodeLabels().size() == 0);\r\n    mgr.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testEditlogRecover",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testEditlogRecover() throws Exception\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p4\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p5\", \"p6\"));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n5\"), toSet(\"p5\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    mgr.removeFromClusterNodeLabels(toSet(\"p1\"));\r\n    mgr.removeFromClusterNodeLabels(Arrays.asList(\"p3\", \"p5\"));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    Assert.assertEquals(3, mgr.getClusterNodeLabelNames().size());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"p2\", \"p4\", \"p6\")));\r\n    assertMapContains(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(), ImmutableMap.of(\"p6\", toSet(toNodeId(\"n6\"), toNodeId(\"n7\")), \"p4\", toSet(toNodeId(\"n4\")), \"p2\", toSet(toNodeId(\"n2\"))));\r\n    mgr.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testSerilizationAfterRecovery",
  "errType" : null,
  "containingMethodsNum" : 28,
  "sourceCodeText" : "void testSerilizationAfterRecovery() throws Exception\n{\r\n    mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"p1\", true), NodeLabel.newInstance(\"p2\", false), NodeLabel.newInstance(\"p3\", true), NodeLabel.newInstance(\"p4\", true), NodeLabel.newInstance(\"p5\", true), NodeLabel.newInstance(\"p6\", false)));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n5\"), toSet(\"p5\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    mgr.removeFromClusterNodeLabels(toSet(\"p1\"));\r\n    mgr.removeFromClusterNodeLabels(Arrays.asList(\"p3\", \"p5\"));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    Assert.assertEquals(3, mgr.getClusterNodeLabelNames().size());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"p2\", \"p4\", \"p6\")));\r\n    assertMapContains(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\"), toNodeId(\"n4\"), toSet(\"p4\"), toNodeId(\"n6\"), toSet(\"p6\"), toNodeId(\"n7\"), toSet(\"p6\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(), ImmutableMap.of(\"p6\", toSet(toNodeId(\"n6\"), toNodeId(\"n7\")), \"p4\", toSet(toNodeId(\"n4\")), \"p2\", toSet(toNodeId(\"n2\"))));\r\n    Assert.assertFalse(mgr.isExclusiveNodeLabel(\"p2\"));\r\n    Assert.assertTrue(mgr.isExclusiveNodeLabel(\"p4\"));\r\n    Assert.assertFalse(mgr.isExclusiveNodeLabel(\"p6\"));\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p7\", \"p8\"));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p9\"));\r\n    mgr.stop();\r\n    mgr = new MockNodeLabelManager();\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    Assert.assertEquals(6, mgr.getClusterNodeLabelNames().size());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"p2\", \"p4\", \"p6\", \"p7\", \"p8\", \"p9\")));\r\n    mgr.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testRootMkdirOnInitStore",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testRootMkdirOnInitStore() throws Exception\n{\r\n    final FileSystem mockFs = Mockito.mock(FileSystem.class);\r\n    FileSystemNodeLabelsStore mockStore = new FileSystemNodeLabelsStore() {\r\n\r\n        public void initFileSystem(Configuration config) throws IOException {\r\n            setFs(mockFs);\r\n        }\r\n    };\r\n    mockStore.setFs(mockFs);\r\n    verifyMkdirsCount(mockStore, true, 1);\r\n    verifyMkdirsCount(mockStore, false, 2);\r\n    verifyMkdirsCount(mockStore, true, 3);\r\n    verifyMkdirsCount(mockStore, false, 4);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "verifyMkdirsCount",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void verifyMkdirsCount(FileSystemNodeLabelsStore store, boolean existsRetVal, int expectedNumOfCalls) throws Exception\n{\r\n    Mockito.when(store.getFs().exists(Mockito.any(Path.class))).thenReturn(existsRetVal);\r\n    store.init(conf, mgr);\r\n    Mockito.verify(store.getFs(), Mockito.times(expectedNumOfCalls)).mkdirs(Mockito.any(Path.class));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "getTestConf",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Configuration getTestConf()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(\"yarn.log-aggregation.Indexed.remote-app-log-dir\", remoteLogDir);\r\n    conf.set(\"yarn.log-aggregation.Indexed.remote-app-log-dir-suffix\", \"logs\");\r\n    conf.set(YarnConfiguration.NM_LOG_AGG_COMPRESSION_TYPE, \"gz\");\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void setUp() throws IOException\n{\r\n    setConf(getTestConf());\r\n    appId = ApplicationId.newInstance(123456, 1);\r\n    ApplicationAttemptId attemptId = ApplicationAttemptId.newInstance(appId, 1);\r\n    containerId = ContainerId.newContainerId(attemptId, 1);\r\n    nodeId = NodeId.newInstance(\"localhost\", 9999);\r\n    fs = FileSystem.get(getConf());\r\n    sysOutStream = new ByteArrayOutputStream();\r\n    PrintStream sysOut = new PrintStream(sysOutStream);\r\n    System.setOut(sysOut);\r\n    ByteArrayOutputStream sysErrStream = new ByteArrayOutputStream();\r\n    PrintStream sysErr = new PrintStream(sysErrStream);\r\n    System.setErr(sysErr);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "teardown",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void teardown() throws Exception\n{\r\n    fs.delete(rootLocalLogDirPath, true);\r\n    fs.delete(new Path(remoteLogDir), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "testLogAggregationIndexFileFormat",
  "errType" : null,
  "containingMethodsNum" : 135,
  "sourceCodeText" : "void testLogAggregationIndexFileFormat() throws Exception\n{\r\n    if (fs.exists(rootLocalLogDirPath)) {\r\n        fs.delete(rootLocalLogDirPath, true);\r\n    }\r\n    assertTrue(fs.mkdirs(rootLocalLogDirPath));\r\n    Path appLogsDir = new Path(rootLocalLogDirPath, appId.toString());\r\n    if (fs.exists(appLogsDir)) {\r\n        fs.delete(appLogsDir, true);\r\n    }\r\n    assertTrue(fs.mkdirs(appLogsDir));\r\n    List<String> logTypes = new ArrayList<String>();\r\n    logTypes.add(\"syslog\");\r\n    logTypes.add(\"stdout\");\r\n    logTypes.add(\"stderr\");\r\n    Set<File> files = new HashSet<>();\r\n    LogKey key1 = new LogKey(containerId.toString());\r\n    for (String logType : logTypes) {\r\n        File file = createAndWriteLocalLogFile(containerId, appLogsDir, logType);\r\n        files.add(file);\r\n    }\r\n    files.add(createZeroLocalLogFile(appLogsDir));\r\n    LogValue value = mock(LogValue.class);\r\n    when(value.getPendingLogFilesToUploadForThisContainer()).thenReturn(files);\r\n    final ControlledClock clock = new ControlledClock();\r\n    clock.setTime(System.currentTimeMillis());\r\n    LogAggregationIndexedFileController fileFormat = new LogAggregationIndexedFileController() {\r\n\r\n        private int rollOverCheck = 0;\r\n\r\n        @Override\r\n        public Clock getSystemClock() {\r\n            return clock;\r\n        }\r\n\r\n        @Override\r\n        public boolean isRollover(final FileContext fc, final Path candidate) throws IOException {\r\n            rollOverCheck++;\r\n            if (rollOverCheck >= 3) {\r\n                return true;\r\n            }\r\n            return false;\r\n        }\r\n    };\r\n    fileFormat.initialize(getConf(), \"Indexed\");\r\n    Map<ApplicationAccessType, String> appAcls = new HashMap<>();\r\n    Path appDir = fileFormat.getRemoteAppLogDir(appId, USER_UGI.getShortUserName());\r\n    if (fs.exists(appDir)) {\r\n        fs.delete(appDir, true);\r\n    }\r\n    assertTrue(fs.mkdirs(appDir));\r\n    Path logPath = fileFormat.getRemoteNodeLogFileForApp(appId, USER_UGI.getShortUserName(), nodeId);\r\n    LogAggregationFileControllerContext context = new LogAggregationFileControllerContext(logPath, logPath, true, 1000, appId, appAcls, nodeId, USER_UGI);\r\n    fileFormat.initializeWriter(context);\r\n    fileFormat.write(key1, value);\r\n    fileFormat.postWrite(context);\r\n    fileFormat.closeWriter();\r\n    ContainerLogsRequest logRequest = new ContainerLogsRequest();\r\n    logRequest.setAppId(appId);\r\n    logRequest.setNodeId(nodeId.toString());\r\n    logRequest.setAppOwner(USER_UGI.getShortUserName());\r\n    logRequest.setContainerId(containerId.toString());\r\n    logRequest.setBytes(Long.MAX_VALUE);\r\n    List<ContainerLogMeta> meta = fileFormat.readAggregatedLogsMeta(logRequest);\r\n    assertEquals(1, meta.size());\r\n    List<String> fileNames = new ArrayList<>();\r\n    for (ContainerLogMeta log : meta) {\r\n        assertEquals(containerId.toString(), log.getContainerId());\r\n        assertEquals(nodeId.toString(), log.getNodeId());\r\n        assertEquals(4, log.getContainerLogMeta().size());\r\n        for (ContainerLogFileInfo file : log.getContainerLogMeta()) {\r\n            fileNames.add(file.getFileName());\r\n        }\r\n    }\r\n    fileNames.removeAll(logTypes);\r\n    fileNames.remove(ZERO_FILE);\r\n    assertTrue(fileNames.isEmpty());\r\n    boolean foundLogs = fileFormat.readAggregatedLogs(logRequest, System.out);\r\n    assertTrue(foundLogs);\r\n    for (String logType : logTypes) {\r\n        assertTrue(sysOutStream.toString().contains(logMessage(containerId, logType)));\r\n    }\r\n    assertZeroFileIsContained(sysOutStream.toString());\r\n    sysOutStream.reset();\r\n    Configuration factoryConf = new Configuration(getConf());\r\n    factoryConf.set(\"yarn.log-aggregation.file-formats\", \"Indexed\");\r\n    factoryConf.set(\"yarn.log-aggregation.file-controller.Indexed.class\", \"org.apache.hadoop.yarn.logaggregation.filecontroller.ifile\" + \".LogAggregationIndexedFileController\");\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(factoryConf);\r\n    LogAggregationFileController fileController = factory.getFileControllerForRead(appId, USER_UGI.getShortUserName());\r\n    assertTrue(fileController instanceof LogAggregationIndexedFileController);\r\n    foundLogs = fileController.readAggregatedLogs(logRequest, System.out);\r\n    assertTrue(foundLogs);\r\n    for (String logType : logTypes) {\r\n        assertTrue(sysOutStream.toString().contains(logMessage(containerId, logType)));\r\n    }\r\n    sysOutStream.reset();\r\n    Path checksumFile = new Path(fileFormat.getRemoteAppLogDir(appId, USER_UGI.getShortUserName()), LogAggregationUtils.getNodeString(nodeId) + LogAggregationIndexedFileController.CHECK_SUM_FILE_SUFFIX);\r\n    FSDataOutputStream fInput = null;\r\n    try {\r\n        String nodeName = logPath.getName() + \"_\" + clock.getTime();\r\n        fInput = FileSystem.create(fs, checksumFile, LOG_FILE_UMASK);\r\n        fInput.writeInt(nodeName.length());\r\n        fInput.write(nodeName.getBytes(Charset.forName(\"UTF-8\")));\r\n        fInput.writeLong(0);\r\n    } finally {\r\n        IOUtils.closeStream(fInput);\r\n    }\r\n    meta = fileFormat.readAggregatedLogsMeta(logRequest);\r\n    assertTrue(meta.isEmpty());\r\n    foundLogs = fileFormat.readAggregatedLogs(logRequest, System.out);\r\n    assertFalse(foundLogs);\r\n    sysOutStream.reset();\r\n    fs.delete(checksumFile, false);\r\n    assertFalse(fs.exists(checksumFile));\r\n    List<String> newLogTypes = new ArrayList<>(logTypes);\r\n    files.clear();\r\n    newLogTypes.add(\"test1\");\r\n    files.add(createAndWriteLocalLogFile(containerId, appLogsDir, \"test1\"));\r\n    newLogTypes.add(\"test2\");\r\n    files.add(createAndWriteLocalLogFile(containerId, appLogsDir, \"test2\"));\r\n    LogValue value2 = mock(LogValue.class);\r\n    when(value2.getPendingLogFilesToUploadForThisContainer()).thenReturn(files);\r\n    fileFormat.initializeWriter(context);\r\n    fileFormat.write(key1, value2);\r\n    fileFormat.closeWriter();\r\n    meta = fileFormat.readAggregatedLogsMeta(logRequest);\r\n    assertThat(meta.size()).isEqualTo(1);\r\n    for (ContainerLogMeta log : meta) {\r\n        assertEquals(containerId.toString(), log.getContainerId());\r\n        assertEquals(nodeId.toString(), log.getNodeId());\r\n        assertEquals(4, log.getContainerLogMeta().size());\r\n        for (ContainerLogFileInfo file : log.getContainerLogMeta()) {\r\n            fileNames.add(file.getFileName());\r\n        }\r\n    }\r\n    fileNames.removeAll(logTypes);\r\n    fileNames.remove(ZERO_FILE);\r\n    assertTrue(fileNames.isEmpty());\r\n    foundLogs = fileFormat.readAggregatedLogs(logRequest, System.out);\r\n    assertTrue(foundLogs);\r\n    for (String logType : logTypes) {\r\n        assertTrue(sysOutStream.toString().contains(logMessage(containerId, logType)));\r\n    }\r\n    assertFalse(sysOutStream.toString().contains(logMessage(containerId, \"test1\")));\r\n    assertFalse(sysOutStream.toString().contains(logMessage(containerId, \"test2\")));\r\n    sysOutStream.reset();\r\n    fileFormat.initializeWriter(context);\r\n    fileFormat.write(key1, value2);\r\n    fileFormat.postWrite(context);\r\n    fileFormat.closeWriter();\r\n    meta = fileFormat.readAggregatedLogsMeta(logRequest);\r\n    assertThat(meta.size()).isEqualTo(2);\r\n    for (ContainerLogMeta log : meta) {\r\n        assertEquals(containerId.toString(), log.getContainerId());\r\n        assertEquals(nodeId.toString(), log.getNodeId());\r\n        for (ContainerLogFileInfo file : log.getContainerLogMeta()) {\r\n            fileNames.add(file.getFileName());\r\n        }\r\n    }\r\n    fileNames.removeAll(newLogTypes);\r\n    fileNames.remove(ZERO_FILE);\r\n    assertTrue(fileNames.isEmpty());\r\n    foundLogs = fileFormat.readAggregatedLogs(logRequest, System.out);\r\n    assertTrue(foundLogs);\r\n    for (String logType : newLogTypes) {\r\n        assertTrue(sysOutStream.toString().contains(logMessage(containerId, logType)));\r\n    }\r\n    sysOutStream.reset();\r\n    clock.setTime(System.currentTimeMillis());\r\n    fileFormat.initializeWriter(context);\r\n    fileFormat.write(key1, value2);\r\n    fileFormat.postWrite(context);\r\n    fileFormat.closeWriter();\r\n    FileStatus[] status = fs.listStatus(logPath.getParent());\r\n    assertEquals(2, status.length);\r\n    meta = fileFormat.readAggregatedLogsMeta(logRequest);\r\n    assertThat(meta.size()).isEqualTo(3);\r\n    for (ContainerLogMeta log : meta) {\r\n        assertEquals(containerId.toString(), log.getContainerId());\r\n        assertEquals(nodeId.toString(), log.getNodeId());\r\n        for (ContainerLogFileInfo file : log.getContainerLogMeta()) {\r\n            fileNames.add(file.getFileName());\r\n        }\r\n    }\r\n    fileNames.removeAll(newLogTypes);\r\n    fileNames.remove(ZERO_FILE);\r\n    assertTrue(fileNames.isEmpty());\r\n    foundLogs = fileFormat.readAggregatedLogs(logRequest, System.out);\r\n    assertTrue(foundLogs);\r\n    for (String logType : newLogTypes) {\r\n        assertTrue(sysOutStream.toString().contains(logMessage(containerId, logType)));\r\n    }\r\n    sysOutStream.reset();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "testFetchApplictionLogsHar",
  "errType" : null,
  "containingMethodsNum" : 31,
  "sourceCodeText" : "void testFetchApplictionLogsHar() throws Exception\n{\r\n    List<String> newLogTypes = new ArrayList<>();\r\n    newLogTypes.add(\"syslog\");\r\n    newLogTypes.add(\"stdout\");\r\n    newLogTypes.add(\"stderr\");\r\n    newLogTypes.add(\"test1\");\r\n    newLogTypes.add(\"test2\");\r\n    URL harUrl = ClassLoader.getSystemClassLoader().getResource(\"application_123456_0001.har\");\r\n    assertNotNull(harUrl);\r\n    Path path = new Path(remoteLogDir + \"/\" + USER_UGI.getShortUserName() + \"/logs/application_123456_0001\");\r\n    if (fs.exists(path)) {\r\n        fs.delete(path, true);\r\n    }\r\n    assertTrue(fs.mkdirs(path));\r\n    Path harPath = new Path(path, \"application_123456_0001.har\");\r\n    fs.copyFromLocalFile(false, new Path(harUrl.toURI()), harPath);\r\n    assertTrue(fs.exists(harPath));\r\n    LogAggregationIndexedFileController fileFormat = new LogAggregationIndexedFileController();\r\n    fileFormat.initialize(getConf(), \"Indexed\");\r\n    ContainerLogsRequest logRequest = new ContainerLogsRequest();\r\n    logRequest.setAppId(appId);\r\n    logRequest.setNodeId(nodeId.toString());\r\n    logRequest.setAppOwner(USER_UGI.getShortUserName());\r\n    logRequest.setContainerId(containerId.toString());\r\n    logRequest.setBytes(Long.MAX_VALUE);\r\n    List<ContainerLogMeta> meta = fileFormat.readAggregatedLogsMeta(logRequest);\r\n    assertEquals(3, meta.size());\r\n    List<String> fileNames = new ArrayList<>();\r\n    for (ContainerLogMeta log : meta) {\r\n        assertEquals(containerId.toString(), log.getContainerId());\r\n        assertEquals(nodeId.toString(), log.getNodeId());\r\n        for (ContainerLogFileInfo file : log.getContainerLogMeta()) {\r\n            fileNames.add(file.getFileName());\r\n        }\r\n    }\r\n    fileNames.removeAll(newLogTypes);\r\n    assertTrue(fileNames.isEmpty());\r\n    boolean foundLogs = fileFormat.readAggregatedLogs(logRequest, System.out);\r\n    assertTrue(foundLogs);\r\n    for (String logType : newLogTypes) {\r\n        assertTrue(sysOutStream.toString().contains(logMessage(containerId, logType)));\r\n    }\r\n    sysOutStream.reset();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "assertZeroFileIsContained",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void assertZeroFileIsContained(String outStream)\n{\r\n    assertTrue(outStream.contains(\"LogContents:\\n\" + \"\\n\" + \"End of LogType:zero\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "createZeroLocalLogFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "File createZeroLocalLogFile(Path localLogDir) throws IOException\n{\r\n    return createAndWriteLocalLogFile(localLogDir, ZERO_FILE, \"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "createAndWriteLocalLogFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "File createAndWriteLocalLogFile(ContainerId containerId, Path localLogDir, String logType) throws IOException\n{\r\n    return createAndWriteLocalLogFile(localLogDir, logType, logMessage(containerId, logType));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "createAndWriteLocalLogFile",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "File createAndWriteLocalLogFile(Path localLogDir, String logType, String message) throws IOException\n{\r\n    File file = new File(localLogDir.toString(), logType);\r\n    if (file.exists()) {\r\n        file.delete();\r\n    }\r\n    file.createNewFile();\r\n    Writer writer = null;\r\n    try {\r\n        writer = new FileWriter(file);\r\n        writer.write(message);\r\n        writer.close();\r\n        return file;\r\n    } finally {\r\n        IOUtils.closeStream(writer);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "logMessage",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String logMessage(ContainerId containerId, String logType)\n{\r\n    return \"Hello \" + containerId + \" in \" + logType + \"!\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "testGetRollOverLogMaxSize",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testGetRollOverLogMaxSize()\n{\r\n    String fileControllerName = \"testController\";\r\n    String remoteDirConf = String.format(YarnConfiguration.LOG_AGGREGATION_REMOTE_APP_LOG_DIR_FMT, fileControllerName);\r\n    Configuration conf = new Configuration();\r\n    LogAggregationIndexedFileController fileFormat = new LogAggregationIndexedFileController();\r\n    long defaultRolloverSize = 10L * 1024 * 1024 * 1024;\r\n    fileFormat.initialize(conf, fileControllerName);\r\n    assertThat(fileFormat.getRollOverLogMaxSize(conf)).isEqualTo(defaultRolloverSize);\r\n    conf.set(remoteDirConf, \"webhdfs://localhost/path\");\r\n    fileFormat.initialize(conf, fileControllerName);\r\n    assertThat(fileFormat.getRollOverLogMaxSize(conf)).isEqualTo(defaultRolloverSize);\r\n    conf.set(remoteDirConf, \"s3a://test/path\");\r\n    fileFormat.initialize(conf, fileControllerName);\r\n    assertThat(fileFormat.getRollOverLogMaxSize(conf)).isZero();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller\\ifile",
  "methodName" : "testGetLogMetaFilesOfNode",
  "errType" : null,
  "containingMethodsNum" : 49,
  "sourceCodeText" : "void testGetLogMetaFilesOfNode() throws Exception\n{\r\n    if (fs.exists(rootLocalLogDirPath)) {\r\n        fs.delete(rootLocalLogDirPath, true);\r\n    }\r\n    assertTrue(fs.mkdirs(rootLocalLogDirPath));\r\n    Path appLogsDir = new Path(rootLocalLogDirPath, appId.toString());\r\n    if (fs.exists(appLogsDir)) {\r\n        fs.delete(appLogsDir, true);\r\n    }\r\n    assertTrue(fs.mkdirs(appLogsDir));\r\n    List<String> logTypes = new ArrayList<String>();\r\n    logTypes.add(\"syslog\");\r\n    logTypes.add(\"stdout\");\r\n    logTypes.add(\"stderr\");\r\n    Set<File> files = new HashSet<>();\r\n    LogKey key1 = new LogKey(containerId.toString());\r\n    for (String logType : logTypes) {\r\n        File file = createAndWriteLocalLogFile(containerId, appLogsDir, logType);\r\n        files.add(file);\r\n    }\r\n    files.add(createZeroLocalLogFile(appLogsDir));\r\n    LogValue value = mock(LogValue.class);\r\n    when(value.getPendingLogFilesToUploadForThisContainer()).thenReturn(files);\r\n    LogAggregationIndexedFileController fileFormat = new LogAggregationIndexedFileController();\r\n    fileFormat.initialize(getConf(), \"Indexed\");\r\n    Map<ApplicationAccessType, String> appAcls = new HashMap<>();\r\n    Path appDir = fileFormat.getRemoteAppLogDir(appId, USER_UGI.getShortUserName());\r\n    if (fs.exists(appDir)) {\r\n        fs.delete(appDir, true);\r\n    }\r\n    assertTrue(fs.mkdirs(appDir));\r\n    Path logPath = fileFormat.getRemoteNodeLogFileForApp(appId, USER_UGI.getShortUserName(), nodeId);\r\n    LogAggregationFileControllerContext context = new LogAggregationFileControllerContext(logPath, logPath, true, 1000, appId, appAcls, nodeId, USER_UGI);\r\n    fileFormat.initializeWriter(context);\r\n    fileFormat.write(key1, value);\r\n    fileFormat.postWrite(context);\r\n    fileFormat.closeWriter();\r\n    ContainerLogsRequest logRequest = new ContainerLogsRequest();\r\n    logRequest.setAppId(appId);\r\n    logRequest.setNodeId(nodeId.toString());\r\n    logRequest.setAppOwner(USER_UGI.getShortUserName());\r\n    logRequest.setContainerId(containerId.toString());\r\n    logRequest.setBytes(Long.MAX_VALUE);\r\n    final ControlledClock clock = new ControlledClock();\r\n    clock.setTime(System.currentTimeMillis());\r\n    Path checksumFile = new Path(fileFormat.getRemoteAppLogDir(appId, USER_UGI.getShortUserName()), LogAggregationUtils.getNodeString(nodeId) + LogAggregationIndexedFileController.CHECK_SUM_FILE_SUFFIX);\r\n    FSDataOutputStream fInput = null;\r\n    try {\r\n        String nodeName = logPath.getName() + \"_\" + clock.getTime();\r\n        fInput = FileSystem.create(fs, checksumFile, LOG_FILE_UMASK);\r\n        fInput.writeInt(nodeName.length());\r\n        fInput.write(nodeName.getBytes(Charset.forName(\"UTF-8\")));\r\n        fInput.writeLong(0);\r\n    } finally {\r\n        IOUtils.closeStream(fInput);\r\n    }\r\n    Path nodePath = LogAggregationUtils.getRemoteAppLogDir(fileFormat.getRemoteRootLogDir(), appId, USER_UGI.getShortUserName(), fileFormat.getRemoteRootLogDirSuffix());\r\n    FileStatus[] nodes = fs.listStatus(nodePath);\r\n    ExtendedLogMetaRequest req = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder().build();\r\n    for (FileStatus node : nodes) {\r\n        Map<String, List<ContainerLogFileInfo>> metas = fileFormat.getLogMetaFilesOfNode(req, node, appId);\r\n        if (node.getPath().getName().contains(LogAggregationIndexedFileController.CHECK_SUM_FILE_SUFFIX)) {\r\n            assertTrue(\"Checksum node files should not contain any logs\", metas.isEmpty());\r\n        } else {\r\n            assertFalse(\"Non-checksum node files should contain log files\", metas.isEmpty());\r\n            assertEquals(4, metas.values().stream().findFirst().get().size());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "getConfigurationInputStream",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "InputStream getConfigurationInputStream(Configuration bootstrapConf, String name) throws YarnException, IOException\n{\r\n    if (YarnConfiguration.RESOURCE_TYPES_CONFIGURATION_FILE.equals(name)) {\r\n        return new ByteArrayInputStream(customResourceTypes.getXml().getBytes());\r\n    } else {\r\n        return super.getConfigurationInputStream(bootstrapConf, name);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "initResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initResourceTypes(Map<String, String> resourcesWithUnits)\n{\r\n    CustomResourceTypesConfigurationProvider.setResourceTypes(resourcesWithUnits);\r\n    initResourceTypesInternal();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "initResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initResourceTypes(int count, String units)\n{\r\n    CustomResourceTypesConfigurationProvider.setResourceTypes(count, units);\r\n    initResourceTypesInternal();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "initResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void initResourceTypes(String... resourceTypes)\n{\r\n    Map<String, ResourceInformation> riMap = new HashMap<>();\r\n    riMap.put(ResourceInformation.MEMORY_URI, ResourceInformation.MEMORY_MB);\r\n    riMap.put(ResourceInformation.VCORES_URI, ResourceInformation.VCORES);\r\n    for (String newResource : resourceTypes) {\r\n        riMap.put(newResource, ResourceInformation.newInstance(newResource, \"\", 0, ResourceTypes.COUNTABLE, 0, Integer.MAX_VALUE));\r\n    }\r\n    ResourceUtils.initializeResourcesFromResourceInformationMap(riMap);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "initResourceTypesInternal",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initResourceTypesInternal()\n{\r\n    Configuration configuration = new Configuration();\r\n    configuration.set(YarnConfiguration.RM_CONFIGURATION_PROVIDER_CLASS, CustomResourceTypesConfigurationProvider.class.getName());\r\n    ResourceUtils.resetResourceTypes(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "createCustomResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "CustomResourceTypes createCustomResourceTypes(int count, String units)\n{\r\n    List<String> resourceNames = generateResourceTypeNames(count);\r\n    Map<String, String> resourcesWithUnits = resourceNames.stream().collect(Collectors.toMap(e -> e, e -> units));\r\n    return createCustomResourceTypes(resourcesWithUnits);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "createCustomResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "CustomResourceTypes createCustomResourceTypes(Map<String, String> resourcesWithUnits)\n{\r\n    int count = resourcesWithUnits.size();\r\n    List<String> resourceNames = Lists.newArrayList(resourcesWithUnits.keySet());\r\n    List<String> resourceUnitXmlElements = IntStream.range(0, count).boxed().map(i -> getResourceUnitsXml(resourceNames.get(i), resourcesWithUnits.get(resourceNames.get(i)))).collect(toList());\r\n    StringBuilder sb = new StringBuilder(\"<configuration>\\n\");\r\n    sb.append(getResourceTypesXml(resourceNames));\r\n    for (String resourceUnitXml : resourceUnitXmlElements) {\r\n        sb.append(resourceUnitXml);\r\n    }\r\n    sb.append(\"</configuration>\");\r\n    return new CustomResourceTypes(sb.toString(), count);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "generateResourceTypeNames",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> generateResourceTypeNames(int count)\n{\r\n    return IntStream.range(0, count).boxed().map(i -> CUSTOM_RESOURCE_PREFIX + (i + 1)).collect(toList());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "getResourceUnitsXml",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getResourceUnitsXml(String resource, String units)\n{\r\n    return \"<property>\\n\" + \"<name>yarn.resource-types.\" + resource + \".units</name>\\n\" + \"<value>\" + units + \"</value>\\n\" + \"</property>\\n\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "getResourceTypesXml",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getResourceTypesXml(List<String> resources)\n{\r\n    final String resourceTypes = String.join(\",\", resources);\r\n    return \"<property>\\n\" + \"<name>yarn.resource-types</name>\\n\" + \"<value>\" + resourceTypes + \"</value>\\n\" + \"</property>\\n\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "reset",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void reset()\n{\r\n    customResourceTypes = createCustomResourceTypes(2, UNIT_KILO);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setResourceTypes(int count, String units)\n{\r\n    customResourceTypes = createCustomResourceTypes(count, units);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setResourceTypes(Map<String, String> resourcesWithUnits)\n{\r\n    customResourceTypes = createCustomResourceTypes(resourcesWithUnits);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "getCustomResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> getCustomResourceTypes()\n{\r\n    return generateResourceTypeNames(customResourceTypes.getCount());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "versionInfoGenerated",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void versionInfoGenerated() throws IOException\n{\r\n    assertNotEquals(\"getVersion returned Unknown\", \"Unknown\", YarnVersionInfo.getVersion());\r\n    assertNotEquals(\"getUser returned Unknown\", \"Unknown\", YarnVersionInfo.getUser());\r\n    assertNotEquals(\"getSrcChecksum returned Unknown\", \"Unknown\", YarnVersionInfo.getSrcChecksum());\r\n    assertNotNull(\"getUrl returned null\", YarnVersionInfo.getUrl());\r\n    assertNotNull(\"getRevision returned null\", YarnVersionInfo.getRevision());\r\n    assertNotNull(\"getBranch returned null\", YarnVersionInfo.getBranch());\r\n    assertTrue(\"getBuildVersion check doesn't contain: source checksum\", YarnVersionInfo.getBuildVersion().contains(\"source checksum\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\factories\\impl\\pb",
  "methodName" : "testToUseCustomClassloader",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testToUseCustomClassloader() throws Exception\n{\r\n    Configuration configuration = mock(Configuration.class);\r\n    RpcServerFactoryPBImpl rpcServerFactoryPB = RpcServerFactoryPBImpl.get();\r\n    try {\r\n        rpcServerFactoryPB.getServer(Class.forName(\"org.apache.hadoop.yarn.api.ApplicationClientProtocol\"), -1, new InetSocketAddress(0), configuration, null, 1);\r\n    } catch (Exception e) {\r\n    }\r\n    verify(configuration, atLeastOnce()).getClassByName(anyString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void setup()\n{\r\n    conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION, 2.0f);\r\n    conf.setInt(YarnConfiguration.NUMBER_OF_ASYNC_ENTITIES_TO_MERGE, 3);\r\n    if (!currTestName.getMethodName().contains(\"testRetryOnConnectionFailure\")) {\r\n        client = createTimelineClient(conf);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "createTimelineClient",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TestV2TimelineClient createTimelineClient(YarnConfiguration config)\n{\r\n    ApplicationId id = ApplicationId.newInstance(0, 0);\r\n    TestV2TimelineClient tc = new TestV2TimelineClient(id);\r\n    tc.init(config);\r\n    tc.start();\r\n    return tc;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testExceptionMultipleRetry",
  "errType" : [ "IOException", "YarnException", "IOException", "YarnException" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testExceptionMultipleRetry()\n{\r\n    TestV2TimelineClientForExceptionHandling c = new TestV2TimelineClientForExceptionHandling(ApplicationId.newInstance(0, 0));\r\n    int maxRetries = 2;\r\n    conf.setInt(YarnConfiguration.TIMELINE_SERVICE_CLIENT_MAX_RETRIES, maxRetries);\r\n    c.init(conf);\r\n    c.start();\r\n    c.setTimelineCollectorInfo(CollectorInfo.newInstance(\"localhost:12345\"));\r\n    try {\r\n        c.putEntities(new TimelineEntity());\r\n    } catch (IOException e) {\r\n        Assert.fail(\"YARN exception is expected\");\r\n    } catch (YarnException e) {\r\n        Throwable cause = e.getCause();\r\n        Assert.assertTrue(\"IOException is expected\", cause instanceof IOException);\r\n        Assert.assertTrue(\"YARN exception is expected\", cause.getMessage().contains(\"TimelineClient has reached to max retry times : \" + maxRetries));\r\n    }\r\n    c.setThrowYarnException(true);\r\n    try {\r\n        c.putEntities(new TimelineEntity());\r\n    } catch (IOException e) {\r\n        Assert.fail(\"YARN exception is expected\");\r\n    } catch (YarnException e) {\r\n        Throwable cause = e.getCause();\r\n        Assert.assertTrue(\"YARN exception is expected\", cause instanceof YarnException);\r\n        Assert.assertTrue(\"YARN exception is expected\", cause.getMessage().contains(EXCEPTION_MSG));\r\n    }\r\n    c.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntities",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testPostEntities() throws Exception\n{\r\n    try {\r\n        client.putEntities(generateEntity(\"1\"));\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Exception is not expected\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testASyncCallMerge",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testASyncCallMerge() throws Exception\n{\r\n    client.setSleepBeforeReturn(true);\r\n    try {\r\n        client.putEntitiesAsync(generateEntity(\"1\"));\r\n        Thread.sleep(TIME_TO_SLEEP / 2);\r\n        client.putEntitiesAsync(generateEntity(\"2\"));\r\n        client.putEntitiesAsync(generateEntity(\"3\"));\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Exception is not expected\");\r\n    }\r\n    for (int i = 0; i < 4; i++) {\r\n        if (client.getNumOfTimelineEntitiesPublished() == 2) {\r\n            break;\r\n        }\r\n        Thread.sleep(TIME_TO_SLEEP);\r\n    }\r\n    Assert.assertEquals(\"two merged TimelineEntities needs to be published\", 2, client.getNumOfTimelineEntitiesPublished());\r\n    TimelineEntities secondPublishedEntities = client.getPublishedEntities(1);\r\n    Assert.assertEquals(\"Merged TimelineEntities Object needs to 2 TimelineEntity Object\", 2, secondPublishedEntities.getEntities().size());\r\n    Assert.assertEquals(\"Order of Async Events Needs to be FIFO\", \"2\", secondPublishedEntities.getEntities().get(0).getId());\r\n    Assert.assertEquals(\"Order of Async Events Needs to be FIFO\", \"3\", secondPublishedEntities.getEntities().get(1).getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testSyncCall",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testSyncCall() throws Exception\n{\r\n    try {\r\n        client.putEntities(generateEntity(\"1\"));\r\n        client.putEntitiesAsync(generateEntity(\"2\"));\r\n        client.putEntitiesAsync(generateEntity(\"3\"));\r\n        client.putEntities(generateEntity(\"4\"));\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Exception is not expected\");\r\n    }\r\n    for (int i = 0; i < 4; i++) {\r\n        if (client.getNumOfTimelineEntitiesPublished() == 3) {\r\n            break;\r\n        }\r\n        Thread.sleep(TIME_TO_SLEEP);\r\n    }\r\n    printReceivedEntities();\r\n    boolean asyncPushesMerged = client.getNumOfTimelineEntitiesPublished() == 3;\r\n    int lastPublishIndex = asyncPushesMerged ? 2 : 3;\r\n    TimelineEntities firstPublishedEntities = client.getPublishedEntities(0);\r\n    Assert.assertEquals(\"sync entities should not be merged with async\", 1, firstPublishedEntities.getEntities().size());\r\n    if (asyncPushesMerged) {\r\n        TimelineEntities secondPublishedEntities = client.getPublishedEntities(1);\r\n        Assert.assertEquals(\"async entities should be merged before publishing sync\", 2, secondPublishedEntities.getEntities().size());\r\n        Assert.assertEquals(\"Order of Async Events Needs to be FIFO\", \"2\", secondPublishedEntities.getEntities().get(0).getId());\r\n        Assert.assertEquals(\"Order of Async Events Needs to be FIFO\", \"3\", secondPublishedEntities.getEntities().get(1).getId());\r\n    } else {\r\n        TimelineEntities secondAsyncPublish = client.getPublishedEntities(1);\r\n        Assert.assertEquals(\"Order of Async Events Needs to be FIFO\", \"2\", secondAsyncPublish.getEntities().get(0).getId());\r\n        TimelineEntities thirdAsyncPublish = client.getPublishedEntities(2);\r\n        Assert.assertEquals(\"Order of Async Events Needs to be FIFO\", \"3\", thirdAsyncPublish.getEntities().get(0).getId());\r\n    }\r\n    TimelineEntities thirdPublishedEntities = client.getPublishedEntities(lastPublishIndex);\r\n    Assert.assertEquals(\"sync entities had to be published at the last\", 1, thirdPublishedEntities.getEntities().size());\r\n    Assert.assertEquals(\"Expected last sync Event is not proper\", \"4\", thirdPublishedEntities.getEntities().get(0).getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testExceptionCalls",
  "errType" : [ "YarnException", "YarnException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testExceptionCalls() throws Exception\n{\r\n    client.setThrowYarnException(true);\r\n    try {\r\n        client.putEntitiesAsync(generateEntity(\"1\"));\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Async calls are not expected to throw exception\");\r\n    }\r\n    try {\r\n        client.putEntities(generateEntity(\"2\"));\r\n        Assert.fail(\"Sync calls are expected to throw exception\");\r\n    } catch (YarnException e) {\r\n        Assert.assertEquals(\"Same exception needs to be thrown\", \"ActualException\", e.getCause().getMessage());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testConfigurableNumberOfMerges",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testConfigurableNumberOfMerges() throws Exception\n{\r\n    client.setSleepBeforeReturn(true);\r\n    try {\r\n        client.putEntitiesAsync(generateEntity(\"1\"));\r\n        client.putEntitiesAsync(generateEntity(\"2\"));\r\n        client.putEntitiesAsync(generateEntity(\"3\"));\r\n        client.putEntitiesAsync(generateEntity(\"4\"));\r\n        client.putEntities(generateEntity(\"5\"));\r\n        client.putEntitiesAsync(generateEntity(\"6\"));\r\n        client.putEntitiesAsync(generateEntity(\"7\"));\r\n        client.putEntitiesAsync(generateEntity(\"8\"));\r\n        client.putEntitiesAsync(generateEntity(\"9\"));\r\n        client.putEntitiesAsync(generateEntity(\"10\"));\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"No exception expected\");\r\n    }\r\n    Thread.sleep(2 * TIME_TO_SLEEP);\r\n    printReceivedEntities();\r\n    for (TimelineEntities publishedEntities : client.publishedEntities) {\r\n        Assert.assertTrue(\"Number of entities should not be greater than 3 for each publish,\" + \" but was \" + publishedEntities.getEntities().size(), publishedEntities.getEntities().size() <= 3);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testSetTimelineToken",
  "errType" : null,
  "containingMethodsNum" : 24,
  "sourceCodeText" : "void testSetTimelineToken() throws Exception\n{\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    assertEquals(0, ugi.getTokens().size());\r\n    assertNull(\"Timeline token in v2 client should not be set\", client.currentTimelineToken);\r\n    Token token = Token.newInstance(new byte[0], \"kind\", new byte[0], \"service\");\r\n    client.setTimelineCollectorInfo(CollectorInfo.newInstance(null, token));\r\n    assertNull(\"Timeline token in v2 client should not be set as token kind \" + \"is unexepcted.\", client.currentTimelineToken);\r\n    assertEquals(0, ugi.getTokens().size());\r\n    token = Token.newInstance(new byte[0], TimelineDelegationTokenIdentifier.KIND_NAME.toString(), new byte[0], null);\r\n    client.setTimelineCollectorInfo(CollectorInfo.newInstance(null, token));\r\n    assertNull(\"Timeline token in v2 client should not be set as serice is \" + \"not set.\", client.currentTimelineToken);\r\n    assertEquals(0, ugi.getTokens().size());\r\n    TimelineDelegationTokenIdentifier ident = new TimelineDelegationTokenIdentifier(new Text(ugi.getUserName()), new Text(\"renewer\"), null);\r\n    ident.setSequenceNumber(1);\r\n    token = Token.newInstance(ident.getBytes(), TimelineDelegationTokenIdentifier.KIND_NAME.toString(), new byte[0], \"localhost:1234\");\r\n    client.setTimelineCollectorInfo(CollectorInfo.newInstance(null, token));\r\n    assertEquals(1, ugi.getTokens().size());\r\n    assertNotNull(\"Timeline token should be set in v2 client.\", client.currentTimelineToken);\r\n    assertEquals(token, client.currentTimelineToken);\r\n    ident.setSequenceNumber(20);\r\n    Token newToken = Token.newInstance(ident.getBytes(), TimelineDelegationTokenIdentifier.KIND_NAME.toString(), new byte[0], \"localhost:1234\");\r\n    client.setTimelineCollectorInfo(CollectorInfo.newInstance(null, newToken));\r\n    assertEquals(1, ugi.getTokens().size());\r\n    assertNotEquals(token, client.currentTimelineToken);\r\n    assertEquals(newToken, client.currentTimelineToken);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testAfterStop",
  "errType" : [ "YarnException", "YarnException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testAfterStop() throws Exception\n{\r\n    client.setSleepBeforeReturn(true);\r\n    try {\r\n        client.putEntities(generateEntity(\"1\"));\r\n        for (int i = 2; i < 20; i++) {\r\n            client.putEntitiesAsync(generateEntity(\"\" + i));\r\n        }\r\n        client.stop();\r\n        try {\r\n            client.putEntitiesAsync(generateEntity(\"50\"));\r\n            Assert.fail(\"Exception expected\");\r\n        } catch (YarnException e) {\r\n        }\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"No exception expected\");\r\n    }\r\n    for (int i = 0; i < 5; i++) {\r\n        TimelineEntities publishedEntities = client.publishedEntities.get(client.publishedEntities.size() - 1);\r\n        TimelineEntity timelineEntity = publishedEntities.getEntities().get(publishedEntities.getEntities().size() - 1);\r\n        if (!timelineEntity.getId().equals(\"19\")) {\r\n            Thread.sleep(2 * TIME_TO_SLEEP);\r\n        }\r\n    }\r\n    printReceivedEntities();\r\n    TimelineEntities publishedEntities = client.publishedEntities.get(client.publishedEntities.size() - 1);\r\n    TimelineEntity timelineEntity = publishedEntities.getEntities().get(publishedEntities.getEntities().size() - 1);\r\n    Assert.assertEquals(\"\", \"19\", timelineEntity.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "printReceivedEntities",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void printReceivedEntities()\n{\r\n    for (int i = 0; i < client.getNumOfTimelineEntitiesPublished(); i++) {\r\n        TimelineEntities publishedEntities = client.getPublishedEntities(i);\r\n        StringBuilder entitiesPerPublish = new StringBuilder();\r\n        for (TimelineEntity entity : publishedEntities.getEntities()) {\r\n            entitiesPerPublish.append(entity.getId());\r\n            entitiesPerPublish.append(\",\");\r\n        }\r\n        LOG.info(\"Entities Published @ index \" + i + \" : \" + entitiesPerPublish.toString());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "generateEntity",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineEntity generateEntity(String id)\n{\r\n    TimelineEntity entity = new TimelineEntity();\r\n    entity.setId(id);\r\n    entity.setType(\"testEntity\");\r\n    entity.setCreatedTime(System.currentTimeMillis());\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void tearDown()\n{\r\n    if (client != null) {\r\n        client.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\factories\\impl\\pb",
  "methodName" : "testToUseCustomClassloader",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testToUseCustomClassloader() throws Exception\n{\r\n    Configuration configuration = mock(Configuration.class);\r\n    RpcClientFactoryPBImpl rpcClientFactoryPB = RpcClientFactoryPBImpl.get();\r\n    try {\r\n        rpcClientFactoryPB.getClient(Class.forName(\"org.apache.hadoop.yarn.api.ApplicationClientProtocol\"), -1, new InetSocketAddress(0), configuration);\r\n    } catch (Exception e) {\r\n    }\r\n    verify(configuration, atLeastOnce()).getClassByName(anyString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testUncaughtExceptionHandlerWithRuntimeException",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testUncaughtExceptionHandlerWithRuntimeException() throws InterruptedException\n{\r\n    final YarnUncaughtExceptionHandler spyYarnHandler = spy(exHandler);\r\n    final YarnRuntimeException yarnException = new YarnRuntimeException(\"test-yarn-runtime-exception\");\r\n    final Thread yarnThread = new Thread(new Runnable() {\r\n\r\n        @Override\r\n        public void run() {\r\n            throw yarnException;\r\n        }\r\n    });\r\n    yarnThread.setUncaughtExceptionHandler(spyYarnHandler);\r\n    assertSame(spyYarnHandler, yarnThread.getUncaughtExceptionHandler());\r\n    yarnThread.start();\r\n    yarnThread.join();\r\n    verify(spyYarnHandler).uncaughtException(yarnThread, yarnException);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testUncaughtExceptionHandlerWithError",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testUncaughtExceptionHandlerWithError() throws InterruptedException\n{\r\n    ExitUtil.disableSystemExit();\r\n    final YarnUncaughtExceptionHandler spyErrorHandler = spy(exHandler);\r\n    final java.lang.Error error = new java.lang.Error(\"test-error\");\r\n    final Thread errorThread = new Thread(new Runnable() {\r\n\r\n        @Override\r\n        public void run() {\r\n            throw error;\r\n        }\r\n    });\r\n    errorThread.setUncaughtExceptionHandler(spyErrorHandler);\r\n    assertSame(spyErrorHandler, errorThread.getUncaughtExceptionHandler());\r\n    errorThread.start();\r\n    errorThread.join();\r\n    verify(spyErrorHandler).uncaughtException(errorThread, error);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testUncaughtExceptionHandlerWithOutOfMemoryError",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testUncaughtExceptionHandlerWithOutOfMemoryError() throws InterruptedException\n{\r\n    ExitUtil.disableSystemHalt();\r\n    final YarnUncaughtExceptionHandler spyOomHandler = spy(exHandler);\r\n    final OutOfMemoryError oomError = new OutOfMemoryError(\"out-of-memory-error\");\r\n    final Thread oomThread = new Thread(new Runnable() {\r\n\r\n        @Override\r\n        public void run() {\r\n            throw oomError;\r\n        }\r\n    });\r\n    oomThread.setUncaughtExceptionHandler(spyOomHandler);\r\n    assertSame(spyOomHandler, oomThread.getUncaughtExceptionHandler());\r\n    oomThread.start();\r\n    oomThread.join();\r\n    verify(spyOomHandler).uncaughtException(oomThread, oomError);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "dispatch",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void dispatch(Event event)\n{\r\n    LOG.info(\"Dispatching the event \" + event.getClass().getName() + \".\" + event.toString());\r\n    Class<? extends Enum> type = event.getType().getDeclaringClass();\r\n    if (eventDispatchers.get(type) != null) {\r\n        eventDispatchers.get(type).handle(event);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "getEventHandler",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "EventHandler<Event> getEventHandler()\n{\r\n    return new TestEventHandler();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeId",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testNodeId()\n{\r\n    NodeId nodeId1 = NodeId.newInstance(\"10.18.52.124\", 8041);\r\n    NodeId nodeId2 = NodeId.newInstance(\"10.18.52.125\", 8038);\r\n    NodeId nodeId3 = NodeId.newInstance(\"10.18.52.124\", 8041);\r\n    NodeId nodeId4 = NodeId.newInstance(\"10.18.52.124\", 8039);\r\n    Assert.assertTrue(nodeId1.equals(nodeId3));\r\n    Assert.assertFalse(nodeId1.equals(nodeId2));\r\n    Assert.assertFalse(nodeId3.equals(nodeId4));\r\n    Assert.assertTrue(nodeId1.compareTo(nodeId3) == 0);\r\n    Assert.assertTrue(nodeId1.compareTo(nodeId2) < 0);\r\n    Assert.assertTrue(nodeId3.compareTo(nodeId4) > 0);\r\n    Assert.assertTrue(nodeId1.hashCode() == nodeId3.hashCode());\r\n    Assert.assertFalse(nodeId1.hashCode() == nodeId2.hashCode());\r\n    Assert.assertFalse(nodeId3.hashCode() == nodeId4.hashCode());\r\n    Assert.assertEquals(\"10.18.52.124:8041\", nodeId1.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testUsual",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testUsual()\n{\r\n    Injector injector = WebAppTests.testBlock(TestBlock.class);\r\n    PrintWriter out = injector.getInstance(PrintWriter.class);\r\n    verify(out).print(\" id=\\\"testid\\\"\");\r\n    verify(out).print(\"test note\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testShortBlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testShortBlock()\n{\r\n    WebAppTests.testBlock(ShortBlock.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testShortPage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testShortPage()\n{\r\n    WebAppTests.testPage(ShortPage.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationId",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testApplicationId()\n{\r\n    ApplicationId a1 = ApplicationId.newInstance(10l, 1);\r\n    ApplicationId a2 = ApplicationId.newInstance(10l, 2);\r\n    ApplicationId a3 = ApplicationId.newInstance(10l, 1);\r\n    ApplicationId a4 = ApplicationId.newInstance(8l, 3);\r\n    Assert.assertFalse(a1.equals(a2));\r\n    Assert.assertFalse(a1.equals(a4));\r\n    Assert.assertTrue(a1.equals(a3));\r\n    Assert.assertTrue(a1.compareTo(a2) < 0);\r\n    Assert.assertTrue(a1.compareTo(a3) == 0);\r\n    Assert.assertTrue(a1.compareTo(a4) > 0);\r\n    Assert.assertTrue(a1.hashCode() == a3.hashCode());\r\n    Assert.assertFalse(a1.hashCode() == a2.hashCode());\r\n    Assert.assertFalse(a2.hashCode() == a4.hashCode());\r\n    long ts = System.currentTimeMillis();\r\n    ApplicationId a5 = ApplicationId.newInstance(ts, 45436343);\r\n    Assert.assertEquals(\"application_10_0001\", a1.toString());\r\n    Assert.assertEquals(\"application_\" + ts + \"_45436343\", a5.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testFactoryProvider",
  "errType" : [ "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testFactoryProvider()\n{\r\n    Configuration conf = new Configuration();\r\n    RpcClientFactory clientFactory = null;\r\n    RpcServerFactory serverFactory = null;\r\n    clientFactory = RpcFactoryProvider.getClientFactory(conf);\r\n    serverFactory = RpcFactoryProvider.getServerFactory(conf);\r\n    Assert.assertEquals(RpcClientFactoryPBImpl.class, clientFactory.getClass());\r\n    Assert.assertEquals(RpcServerFactoryPBImpl.class, serverFactory.getClass());\r\n    conf.set(YarnConfiguration.IPC_CLIENT_FACTORY_CLASS, \"unknown\");\r\n    conf.set(YarnConfiguration.IPC_SERVER_FACTORY_CLASS, \"unknown\");\r\n    conf.set(YarnConfiguration.IPC_RECORD_FACTORY_CLASS, \"unknown\");\r\n    try {\r\n        clientFactory = RpcFactoryProvider.getClientFactory(conf);\r\n        Assert.fail(\"Expected an exception - unknown serializer\");\r\n    } catch (YarnRuntimeException e) {\r\n    }\r\n    try {\r\n        serverFactory = RpcFactoryProvider.getServerFactory(conf);\r\n        Assert.fail(\"Expected an exception - unknown serializer\");\r\n    } catch (YarnRuntimeException e) {\r\n    }\r\n    conf = new Configuration();\r\n    conf.set(YarnConfiguration.IPC_CLIENT_FACTORY_CLASS, \"NonExistantClass\");\r\n    conf.set(YarnConfiguration.IPC_SERVER_FACTORY_CLASS, RpcServerFactoryPBImpl.class.getName());\r\n    try {\r\n        clientFactory = RpcFactoryProvider.getClientFactory(conf);\r\n        Assert.fail(\"Expected an exception - unknown class\");\r\n    } catch (YarnRuntimeException e) {\r\n    }\r\n    try {\r\n        serverFactory = RpcFactoryProvider.getServerFactory(conf);\r\n    } catch (YarnRuntimeException e) {\r\n        Assert.fail(\"Error while loading factory using reflection: [\" + RpcServerFactoryPBImpl.class.getName() + \"]\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 4,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testInstances",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testInstances() throws Exception\n{\r\n    Injector injector = WebAppTests.createMockInjector(this);\r\n    HttpServletRequest req = injector.getInstance(HttpServletRequest.class);\r\n    HttpServletResponse res = injector.getInstance(HttpServletResponse.class);\r\n    String val = req.getParameter(\"foo\");\r\n    PrintWriter out = res.getWriter();\r\n    out.println(\"Hello world!\");\r\n    logInstances(req, res, out);\r\n    assertSame(req, injector.getInstance(HttpServletRequest.class));\r\n    assertSame(res, injector.getInstance(HttpServletResponse.class));\r\n    assertSame(this, injector.getInstance(TestWebAppTests.class));\r\n    verify(req).getParameter(\"foo\");\r\n    verify(res).getWriter();\r\n    verify(out).println(\"Hello world!\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testCreateInjector",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testCreateInjector() throws Exception\n{\r\n    Bar bar = new Bar();\r\n    Injector injector = WebAppTests.createMockInjector(Foo.class, bar);\r\n    logInstances(injector.getInstance(HttpServletRequest.class), injector.getInstance(HttpServletResponse.class), injector.getInstance(HttpServletResponse.class).getWriter());\r\n    assertSame(bar, injector.getInstance(Foo.class));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testCreateInjector2",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testCreateInjector2()\n{\r\n    final FooBar foobar = new FooBar();\r\n    Bar bar = new Bar();\r\n    Injector injector = WebAppTests.createMockInjector(Foo.class, bar, new AbstractModule() {\r\n\r\n        @Override\r\n        protected void configure() {\r\n            bind(Bar.class).toInstance(foobar);\r\n        }\r\n    });\r\n    assertNotSame(bar, injector.getInstance(Bar.class));\r\n    assertSame(foobar, injector.getInstance(Bar.class));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testRequestScope",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testRequestScope()\n{\r\n    Injector injector = WebAppTests.createMockInjector(this);\r\n    assertSame(injector.getInstance(ScopeTest.class), injector.getInstance(ScopeTest.class));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "logInstances",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void logInstances(HttpServletRequest req, HttpServletResponse res, PrintWriter out)\n{\r\n    LOG.info(\"request: {}\", req);\r\n    LOG.info(\"response: {}\", res);\r\n    LOG.info(\"writer: {}\", out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "testGetWebServiceClient",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testGetWebServiceClient() throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(YarnConfiguration.YARN_HTTP_POLICY_KEY, \"HTTPS_ONLY\");\r\n    WebServiceClient.initialize(conf);\r\n    WebServiceClient client = WebServiceClient.getWebServiceClient();\r\n    Assert.assertNotNull(client.getSSLFactory());\r\n    WebServiceClient.destroy();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "testCreateClient",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void testCreateClient() throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(YarnConfiguration.YARN_HTTP_POLICY_KEY, \"HTTPS_ONLY\");\r\n    File base = new File(BASEDIR);\r\n    FileUtil.fullyDelete(base);\r\n    base.mkdirs();\r\n    String keystoresDir = new File(BASEDIR).getAbsolutePath();\r\n    String sslConfDir = KeyStoreTestUtil.getClasspathDir(TestWebServiceClient.class);\r\n    KeyStoreTestUtil.setupSSLConfig(keystoresDir, sslConfDir, conf, false, true);\r\n    Configuration sslConf = KeyStoreTestUtil.getSslConfig();\r\n    sslConf.set(YarnConfiguration.YARN_HTTP_POLICY_KEY, \"HTTPS_ONLY\");\r\n    HttpServer2 server = new HttpServer2.Builder().setName(\"test\").addEndpoint(new URI(\"https://localhost\")).setConf(sslConf).keyPassword(sslConf.get(SSL_SERVER_KEYSTORE_PROP_PREFIX + \".keypassword\")).keyStore(sslConf.get(SSL_SERVER_KEYSTORE_PROP_PREFIX + \".location\"), sslConf.get(SSL_SERVER_KEYSTORE_PROP_PREFIX + \".password\"), sslConf.get(SSL_SERVER_KEYSTORE_PROP_PREFIX + \".type\", \"jks\")).trustStore(sslConf.get(SSL_SERVER_TRUSTSTORE_PROP_PREFIX + \".location\"), sslConf.get(SSL_SERVER_TRUSTSTORE_PROP_PREFIX + \".password\"), sslConf.get(SSL_SERVER_TRUSTSTORE_PROP_PREFIX + \".type\", \"jks\")).excludeCiphers(sslConf.get(\"ssl.server.exclude.cipher.list\")).build();\r\n    server.addServlet(SERVLET_NAME_ECHO, SERVLET_PATH_ECHO, EchoServlet.class);\r\n    server.start();\r\n    final URL baseUrl = new URL(\"https://\" + NetUtils.getHostPortString(server.getConnectorAddress(0)));\r\n    URL u = new URL(baseUrl, SERVLET_PATH_ECHO + \"?a=b&c=d\");\r\n    WebServiceClient.initialize(sslConf);\r\n    WebServiceClient client = WebServiceClient.getWebServiceClient();\r\n    HttpURLConnection conn = client.getHttpURLConnectionFactory().getHttpURLConnection(u);\r\n    Assert.assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());\r\n    WebServiceClient.destroy();\r\n    server.stop();\r\n    FileUtil.fullyDelete(new File(BASEDIR));\r\n    KeyStoreTestUtil.cleanupSSLConfig(keystoresDir, sslConfDir);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testHadoopProtoRPCTimeout",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testHadoopProtoRPCTimeout() throws Exception\n{\r\n    testRPCTimeout(HadoopYarnProtoRPC.class.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testRPCTimeout",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testRPCTimeout(String rpcClass) throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setInt(\"yarn.rpc.nm-command-timeout\", 3000);\r\n    conf.set(YarnConfiguration.IPC_RPC_IMPL, rpcClass);\r\n    YarnRPC rpc = YarnRPC.create(conf);\r\n    String bindAddr = \"localhost:0\";\r\n    InetSocketAddress addr = NetUtils.createSocketAddr(bindAddr);\r\n    Server server = rpc.getServer(ContainerManagementProtocol.class, new DummyContainerManager(), addr, conf, null, 1);\r\n    server.start();\r\n    try {\r\n        ContainerManagementProtocol proxy = (ContainerManagementProtocol) rpc.getProxy(ContainerManagementProtocol.class, server.getListenerAddress(), conf);\r\n        ApplicationId applicationId = ApplicationId.newInstance(0, 0);\r\n        ApplicationAttemptId applicationAttemptId = ApplicationAttemptId.newInstance(applicationId, 0);\r\n        ContainerId containerId = ContainerId.newContainerId(applicationAttemptId, 100);\r\n        NodeId nodeId = NodeId.newInstance(\"localhost\", 1234);\r\n        Resource resource = Resource.newInstance(1234, 2);\r\n        ContainerTokenIdentifier containerTokenIdentifier = new ContainerTokenIdentifier(containerId, \"localhost\", \"user\", resource, System.currentTimeMillis() + 10000, 42, 42, Priority.newInstance(0), 0);\r\n        Token containerToken = newContainerToken(nodeId, \"password\".getBytes(), containerTokenIdentifier);\r\n        List<Token> increaseTokens = new ArrayList<>();\r\n        increaseTokens.add(containerToken);\r\n        ContainerUpdateRequest request = ContainerUpdateRequest.newInstance(increaseTokens);\r\n        try {\r\n            proxy.updateContainer(request);\r\n        } catch (Exception e) {\r\n            LOG.info(StringUtils.stringifyException(e));\r\n            Assert.assertEquals(\"Error, exception is not: \" + SocketTimeoutException.class.getName(), SocketTimeoutException.class.getName(), e.getClass().getName());\r\n            return;\r\n        }\r\n    } finally {\r\n        server.stop();\r\n    }\r\n    Assert.fail(\"timeout exception should have occurred!\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newContainerToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Token newContainerToken(NodeId nodeId, byte[] password, ContainerTokenIdentifier tokenIdentifier)\n{\r\n    InetSocketAddress addr = NetUtils.createSocketAddrForHost(nodeId.getHost(), nodeId.getPort());\r\n    Token containerToken = Token.newInstance(tokenIdentifier.getBytes(), ContainerTokenIdentifier.KIND.toString(), password, SecurityUtil.buildTokenService(addr).toString());\r\n    return containerToken;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setupAppender",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setupAppender(int cleanupIntervalSeconds, long messageAgeLimitSeconds, int maxUniqueMessages)\n{\r\n    removeAppender();\r\n    appender = new Log4jWarningErrorMetricsAppender(cleanupIntervalSeconds, messageAgeLimitSeconds, maxUniqueMessages);\r\n    LogManager.getRootLogger().addAppender(appender);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "removeAppender",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void removeAppender()\n{\r\n    LogManager.getRootLogger().removeAppender(appender);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "logMessages",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void logMessages(Level level, String message, int count)\n{\r\n    for (int i = 0; i < count; ++i) {\r\n        switch(level.toInt()) {\r\n            case Level.FATAL_INT:\r\n                LOG.error(FATAL, message);\r\n                break;\r\n            case Level.ERROR_INT:\r\n                LOG.error(message);\r\n                break;\r\n            case Level.WARN_INT:\r\n                LOG.warn(message);\r\n                break;\r\n            case Level.INFO_INT:\r\n                LOG.info(message);\r\n                break;\r\n            case Level.DEBUG_INT:\r\n                LOG.debug(message);\r\n                break;\r\n            case Level.TRACE_INT:\r\n                LOG.trace(message);\r\n                break;\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testPurge",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testPurge() throws Exception\n{\r\n    setupAppender(2, 1, 1);\r\n    logMessages(Level.ERROR, \"test message 1\", 1);\r\n    cutoff.clear();\r\n    cutoff.add(0L);\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(1, appender.getErrorMessagesAndCounts(cutoff).get(0).size());\r\n    Thread.sleep(3000);\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(0, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(0, appender.getErrorMessagesAndCounts(cutoff).get(0).size());\r\n    setupAppender(2, 1000, 2);\r\n    logMessages(Level.ERROR, \"test message 1\", 3);\r\n    logMessages(Level.ERROR, \"test message 2\", 2);\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(5, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(2, appender.getErrorMessagesAndCounts(cutoff).get(0).size());\r\n    logMessages(Level.ERROR, \"test message 3\", 3);\r\n    Thread.sleep(2000);\r\n    Assert.assertEquals(8, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(2, appender.getErrorMessagesAndCounts(cutoff).get(0).size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testErrorCounts",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testErrorCounts() throws Exception\n{\r\n    cutoff.clear();\r\n    setupAppender(100, 100, 100);\r\n    cutoff.add(0L);\r\n    logMessages(Level.ERROR, \"test message 1\", 2);\r\n    logMessages(Level.ERROR, \"test message 2\", 3);\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getWarningCounts(cutoff).size());\r\n    Assert.assertEquals(5, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(0, appender.getWarningCounts(cutoff).get(0).longValue());\r\n    Thread.sleep(1000);\r\n    cutoff.add(Time.now() / 1000);\r\n    logMessages(Level.ERROR, \"test message 3\", 2);\r\n    Assert.assertEquals(2, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(2, appender.getWarningCounts(cutoff).size());\r\n    Assert.assertEquals(7, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(2, appender.getErrorCounts(cutoff).get(1).longValue());\r\n    Assert.assertEquals(0, appender.getWarningCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(0, appender.getWarningCounts(cutoff).get(1).longValue());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testWarningCounts",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testWarningCounts() throws Exception\n{\r\n    cutoff.clear();\r\n    setupAppender(100, 100, 100);\r\n    cutoff.add(0L);\r\n    logMessages(Level.WARN, \"test message 1\", 2);\r\n    logMessages(Level.WARN, \"test message 2\", 3);\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getWarningCounts(cutoff).size());\r\n    Assert.assertEquals(0, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(5, appender.getWarningCounts(cutoff).get(0).longValue());\r\n    Thread.sleep(1000);\r\n    cutoff.add(Time.now() / 1000);\r\n    logMessages(Level.WARN, \"test message 3\", 2);\r\n    Assert.assertEquals(2, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(2, appender.getWarningCounts(cutoff).size());\r\n    Assert.assertEquals(0, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(0, appender.getErrorCounts(cutoff).get(1).longValue());\r\n    Assert.assertEquals(7, appender.getWarningCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(2, appender.getWarningCounts(cutoff).get(1).longValue());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testWarningMessages",
  "errType" : null,
  "containingMethodsNum" : 34,
  "sourceCodeText" : "void testWarningMessages() throws Exception\n{\r\n    cutoff.clear();\r\n    setupAppender(100, 100, 100);\r\n    cutoff.add(0L);\r\n    logMessages(Level.WARN, \"test message 1\", 2);\r\n    logMessages(Level.WARN, \"test message 2\", 3);\r\n    Assert.assertEquals(1, appender.getErrorMessagesAndCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getWarningMessagesAndCounts(cutoff).size());\r\n    Map<String, Log4jWarningErrorMetricsAppender.Element> errorsMap = appender.getErrorMessagesAndCounts(cutoff).get(0);\r\n    Map<String, Log4jWarningErrorMetricsAppender.Element> warningsMap = appender.getWarningMessagesAndCounts(cutoff).get(0);\r\n    Assert.assertEquals(0, errorsMap.size());\r\n    Assert.assertEquals(2, warningsMap.size());\r\n    Assert.assertTrue(warningsMap.containsKey(\"test message 1\"));\r\n    Assert.assertTrue(warningsMap.containsKey(\"test message 2\"));\r\n    Log4jWarningErrorMetricsAppender.Element msg1Info = warningsMap.get(\"test message 1\");\r\n    Log4jWarningErrorMetricsAppender.Element msg2Info = warningsMap.get(\"test message 2\");\r\n    Assert.assertEquals(2, msg1Info.count.intValue());\r\n    Assert.assertEquals(3, msg2Info.count.intValue());\r\n    Thread.sleep(1000);\r\n    cutoff.add(Time.now() / 1000);\r\n    logMessages(Level.WARN, \"test message 3\", 2);\r\n    Assert.assertEquals(2, appender.getErrorMessagesAndCounts(cutoff).size());\r\n    Assert.assertEquals(2, appender.getWarningMessagesAndCounts(cutoff).size());\r\n    errorsMap = appender.getErrorMessagesAndCounts(cutoff).get(0);\r\n    warningsMap = appender.getWarningMessagesAndCounts(cutoff).get(0);\r\n    Assert.assertEquals(0, errorsMap.size());\r\n    Assert.assertEquals(3, warningsMap.size());\r\n    Assert.assertTrue(warningsMap.containsKey(\"test message 3\"));\r\n    errorsMap = appender.getErrorMessagesAndCounts(cutoff).get(1);\r\n    warningsMap = appender.getWarningMessagesAndCounts(cutoff).get(1);\r\n    Assert.assertEquals(0, errorsMap.size());\r\n    Assert.assertEquals(1, warningsMap.size());\r\n    Assert.assertTrue(warningsMap.containsKey(\"test message 3\"));\r\n    Log4jWarningErrorMetricsAppender.Element msg3Info = warningsMap.get(\"test message 3\");\r\n    Assert.assertEquals(2, msg3Info.count.intValue());\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testErrorMessages",
  "errType" : null,
  "containingMethodsNum" : 34,
  "sourceCodeText" : "void testErrorMessages() throws Exception\n{\r\n    cutoff.clear();\r\n    setupAppender(100, 100, 100);\r\n    cutoff.add(0L);\r\n    logMessages(Level.ERROR, \"test message 1\", 2);\r\n    logMessages(Level.ERROR, \"test message 2\", 3);\r\n    Assert.assertEquals(1, appender.getErrorMessagesAndCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getWarningMessagesAndCounts(cutoff).size());\r\n    Map<String, Log4jWarningErrorMetricsAppender.Element> errorsMap = appender.getErrorMessagesAndCounts(cutoff).get(0);\r\n    Map<String, Log4jWarningErrorMetricsAppender.Element> warningsMap = appender.getWarningMessagesAndCounts(cutoff).get(0);\r\n    Assert.assertEquals(2, errorsMap.size());\r\n    Assert.assertEquals(0, warningsMap.size());\r\n    Assert.assertTrue(errorsMap.containsKey(\"test message 1\"));\r\n    Assert.assertTrue(errorsMap.containsKey(\"test message 2\"));\r\n    Log4jWarningErrorMetricsAppender.Element msg1Info = errorsMap.get(\"test message 1\");\r\n    Log4jWarningErrorMetricsAppender.Element msg2Info = errorsMap.get(\"test message 2\");\r\n    Assert.assertEquals(2, msg1Info.count.intValue());\r\n    Assert.assertEquals(3, msg2Info.count.intValue());\r\n    Thread.sleep(1000);\r\n    cutoff.add(Time.now() / 1000);\r\n    logMessages(Level.ERROR, \"test message 3\", 2);\r\n    Assert.assertEquals(2, appender.getErrorMessagesAndCounts(cutoff).size());\r\n    Assert.assertEquals(2, appender.getWarningMessagesAndCounts(cutoff).size());\r\n    errorsMap = appender.getErrorMessagesAndCounts(cutoff).get(0);\r\n    warningsMap = appender.getWarningMessagesAndCounts(cutoff).get(0);\r\n    Assert.assertEquals(3, errorsMap.size());\r\n    Assert.assertEquals(0, warningsMap.size());\r\n    Assert.assertTrue(errorsMap.containsKey(\"test message 3\"));\r\n    errorsMap = appender.getErrorMessagesAndCounts(cutoff).get(1);\r\n    warningsMap = appender.getWarningMessagesAndCounts(cutoff).get(1);\r\n    Assert.assertEquals(1, errorsMap.size());\r\n    Assert.assertEquals(0, warningsMap.size());\r\n    Assert.assertTrue(errorsMap.containsKey(\"test message 3\"));\r\n    Log4jWarningErrorMetricsAppender.Element msg3Info = errorsMap.get(\"test message 3\");\r\n    Assert.assertEquals(2, msg3Info.count.intValue());\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testInfoDebugTrace",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testInfoDebugTrace()\n{\r\n    cutoff.clear();\r\n    setupAppender(100, 100, 100);\r\n    cutoff.add(0L);\r\n    logMessages(Level.INFO, \"test message 1\", 2);\r\n    logMessages(Level.DEBUG, \"test message 2\", 2);\r\n    logMessages(Level.TRACE, \"test message 3\", 2);\r\n    Assert.assertEquals(1, appender.getErrorMessagesAndCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getWarningMessagesAndCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getErrorCounts(cutoff).size());\r\n    Assert.assertEquals(1, appender.getWarningCounts(cutoff).size());\r\n    Assert.assertEquals(0, appender.getErrorCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(0, appender.getWarningCounts(cutoff).get(0).longValue());\r\n    Assert.assertEquals(0, appender.getErrorMessagesAndCounts(cutoff).get(0).size());\r\n    Assert.assertEquals(0, appender.getWarningMessagesAndCounts(cutoff).get(0).size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timelineservice",
  "methodName" : "testTimelineEntities",
  "errType" : [ "IllegalArgumentException", "IllegalArgumentException" ],
  "containingMethodsNum" : 79,
  "sourceCodeText" : "void testTimelineEntities() throws Exception\n{\r\n    TimelineEntity entity = new TimelineEntity();\r\n    entity.setType(\"test type 1\");\r\n    entity.setId(\"test id 1\");\r\n    entity.addInfo(\"test info key 1\", \"test info value 1\");\r\n    entity.addInfo(\"test info key 2\", Arrays.asList(\"test info value 2\", \"test info value 3\"));\r\n    entity.addInfo(\"test info key 3\", true);\r\n    Assert.assertTrue(entity.getInfo().get(\"test info key 3\") instanceof Boolean);\r\n    entity.addConfig(\"test config key 1\", \"test config value 1\");\r\n    entity.addConfig(\"test config key 2\", \"test config value 2\");\r\n    TimelineMetric metric1 = new TimelineMetric(TimelineMetric.Type.TIME_SERIES);\r\n    metric1.setId(\"test metric id 1\");\r\n    metric1.addValue(1L, 1.0F);\r\n    metric1.addValue(3L, 3.0D);\r\n    metric1.addValue(2L, 2);\r\n    Assert.assertEquals(TimelineMetric.Type.TIME_SERIES, metric1.getType());\r\n    Iterator<Map.Entry<Long, Number>> itr = metric1.getValues().entrySet().iterator();\r\n    Map.Entry<Long, Number> entry = itr.next();\r\n    Assert.assertEquals(new Long(3L), entry.getKey());\r\n    Assert.assertEquals(3.0D, entry.getValue());\r\n    entry = itr.next();\r\n    Assert.assertEquals(new Long(2L), entry.getKey());\r\n    Assert.assertEquals(2, entry.getValue());\r\n    entry = itr.next();\r\n    Assert.assertEquals(new Long(1L), entry.getKey());\r\n    Assert.assertEquals(1.0F, entry.getValue());\r\n    Assert.assertFalse(itr.hasNext());\r\n    entity.addMetric(metric1);\r\n    TimelineMetric metric2 = new TimelineMetric(TimelineMetric.Type.SINGLE_VALUE);\r\n    metric2.setId(\"test metric id 1\");\r\n    metric2.addValue(3L, (short) 3);\r\n    Assert.assertEquals(TimelineMetric.Type.SINGLE_VALUE, metric2.getType());\r\n    Assert.assertTrue(metric2.getValues().values().iterator().next() instanceof Short);\r\n    Map<Long, Number> points = new HashMap<>();\r\n    points.put(4L, 4.0D);\r\n    points.put(5L, 5.0D);\r\n    try {\r\n        metric2.setValues(points);\r\n        Assert.fail();\r\n    } catch (IllegalArgumentException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Values cannot contain more than one point in\"));\r\n    }\r\n    try {\r\n        metric2.addValues(points);\r\n        Assert.fail();\r\n    } catch (IllegalArgumentException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Values cannot contain more than one point in\"));\r\n    }\r\n    entity.addMetric(metric2);\r\n    TimelineMetric metric3 = new TimelineMetric(TimelineMetric.Type.SINGLE_VALUE);\r\n    metric3.setId(\"test metric id 1\");\r\n    metric3.addValue(4L, (short) 4);\r\n    Assert.assertEquals(\"metric3 should equal to metric2! \", metric3, metric2);\r\n    Assert.assertNotEquals(\"metric1 should not equal to metric2! \", metric1, metric2);\r\n    TimelineEvent event1 = new TimelineEvent();\r\n    event1.setId(\"test event id 1\");\r\n    event1.addInfo(\"test info key 1\", \"test info value 1\");\r\n    event1.addInfo(\"test info key 2\", Arrays.asList(\"test info value 2\", \"test info value 3\"));\r\n    event1.addInfo(\"test info key 3\", true);\r\n    Assert.assertTrue(event1.getInfo().get(\"test info key 3\") instanceof Boolean);\r\n    event1.setTimestamp(1L);\r\n    entity.addEvent(event1);\r\n    TimelineEvent event2 = new TimelineEvent();\r\n    event2.setId(\"test event id 2\");\r\n    event2.addInfo(\"test info key 1\", \"test info value 1\");\r\n    event2.addInfo(\"test info key 2\", Arrays.asList(\"test info value 2\", \"test info value 3\"));\r\n    event2.addInfo(\"test info key 3\", true);\r\n    Assert.assertTrue(event2.getInfo().get(\"test info key 3\") instanceof Boolean);\r\n    event2.setTimestamp(2L);\r\n    entity.addEvent(event2);\r\n    Assert.assertFalse(\"event1 should not equal to event2! \", event1.equals(event2));\r\n    TimelineEvent event3 = new TimelineEvent();\r\n    event3.setId(\"test event id 1\");\r\n    event3.setTimestamp(1L);\r\n    Assert.assertEquals(\"event1 should equal to event3! \", event3, event1);\r\n    Assert.assertNotEquals(\"event1 should not equal to event2! \", event1, event2);\r\n    entity.setCreatedTime(0L);\r\n    entity.addRelatesToEntity(\"test type 2\", \"test id 2\");\r\n    entity.addRelatesToEntity(\"test type 3\", \"test id 3\");\r\n    entity.addIsRelatedToEntity(\"test type 4\", \"test id 4\");\r\n    entity.addIsRelatedToEntity(\"test type 5\", \"test id 5\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(entity, true));\r\n    TimelineEntities entities = new TimelineEntities();\r\n    TimelineEntity entity1 = new TimelineEntity();\r\n    entities.addEntity(entity1);\r\n    TimelineEntity entity2 = new TimelineEntity();\r\n    entities.addEntity(entity2);\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(entities, true));\r\n    Assert.assertFalse(\"entity 1 should not be valid without type and id\", entity1.isValid());\r\n    entity1.setId(\"test id 2\");\r\n    entity1.setType(\"test type 2\");\r\n    entity2.setId(\"test id 1\");\r\n    entity2.setType(\"test type 1\");\r\n    Assert.assertEquals(\"Timeline entity should equal to entity2! \", entity, entity2);\r\n    Assert.assertNotEquals(\"entity1 should not equal to entity! \", entity1, entity);\r\n    Assert.assertEquals(\"entity should be less than entity1! \", entity1.compareTo(entity), 1);\r\n    Assert.assertEquals(\"entity's hash code should be -28727840 but not \" + entity.hashCode(), entity.hashCode(), -28727840);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timelineservice",
  "methodName" : "testFirstClassCitizenEntities",
  "errType" : [ "Exception", "Exception", "Exception" ],
  "containingMethodsNum" : 58,
  "sourceCodeText" : "void testFirstClassCitizenEntities() throws Exception\n{\r\n    UserEntity user = new UserEntity();\r\n    user.setId(\"test user id\");\r\n    QueueEntity queue = new QueueEntity();\r\n    queue.setId(\"test queue id\");\r\n    ClusterEntity cluster = new ClusterEntity();\r\n    cluster.setId(\"test cluster id\");\r\n    FlowRunEntity flow1 = new FlowRunEntity();\r\n    flow1.setUser(user.getId());\r\n    flow1.setName(\"test flow name 1\");\r\n    flow1.setVersion(\"test flow version 1\");\r\n    flow1.setRunId(1L);\r\n    FlowRunEntity flow2 = new FlowRunEntity();\r\n    flow2.setUser(user.getId());\r\n    flow2.setName(\"test flow name 2\");\r\n    flow2.setVersion(\"test flow version 2\");\r\n    flow2.setRunId(2L);\r\n    ApplicationEntity app1 = new ApplicationEntity();\r\n    app1.setId(ApplicationId.newInstance(0, 1).toString());\r\n    app1.setQueue(queue.getId());\r\n    ApplicationEntity app2 = new ApplicationEntity();\r\n    app2.setId(ApplicationId.newInstance(0, 2).toString());\r\n    app2.setQueue(queue.getId());\r\n    ApplicationAttemptEntity appAttempt = new ApplicationAttemptEntity();\r\n    appAttempt.setId(ApplicationAttemptId.newInstance(ApplicationId.newInstance(0, 1), 1).toString());\r\n    ContainerEntity container = new ContainerEntity();\r\n    container.setId(ContainerId.newContainerId(ApplicationAttemptId.newInstance(ApplicationId.newInstance(0, 1), 1), 1).toString());\r\n    cluster.addChild(TimelineEntityType.YARN_FLOW_RUN.toString(), flow1.getId());\r\n    flow1.setParent(TimelineEntityType.YARN_CLUSTER.toString(), cluster.getId());\r\n    flow1.addChild(TimelineEntityType.YARN_FLOW_RUN.toString(), flow2.getId());\r\n    flow2.setParent(TimelineEntityType.YARN_FLOW_RUN.toString(), flow1.getId());\r\n    flow2.addChild(TimelineEntityType.YARN_APPLICATION.toString(), app1.getId());\r\n    flow2.addChild(TimelineEntityType.YARN_APPLICATION.toString(), app2.getId());\r\n    app1.setParent(TimelineEntityType.YARN_FLOW_RUN.toString(), flow2.getId());\r\n    app1.addChild(TimelineEntityType.YARN_APPLICATION_ATTEMPT.toString(), appAttempt.getId());\r\n    appAttempt.setParent(TimelineEntityType.YARN_APPLICATION.toString(), app1.getId());\r\n    app2.setParent(TimelineEntityType.YARN_FLOW_RUN.toString(), flow2.getId());\r\n    appAttempt.addChild(TimelineEntityType.YARN_CONTAINER.toString(), container.getId());\r\n    container.setParent(TimelineEntityType.YARN_APPLICATION_ATTEMPT.toString(), appAttempt.getId());\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(cluster, true));\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(flow1, true));\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(flow2, true));\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(app1, true));\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(app2, true));\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(appAttempt, true));\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(container, true));\r\n    Assert.assertNotNull(app1.getParent());\r\n    Assert.assertEquals(flow2.getType(), app1.getParent().getType());\r\n    Assert.assertEquals(flow2.getId(), app1.getParent().getId());\r\n    app1.addInfo(ApplicationEntity.PARENT_INFO_KEY, \"invalid parent object\");\r\n    try {\r\n        app1.getParent();\r\n        Assert.fail();\r\n    } catch (Exception e) {\r\n        Assert.assertTrue(e instanceof YarnRuntimeException);\r\n        Assert.assertTrue(e.getMessage().contains(\"Parent info is invalid identifier object\"));\r\n    }\r\n    Assert.assertNotNull(app1.getChildren());\r\n    Assert.assertEquals(1, app1.getChildren().size());\r\n    Assert.assertEquals(appAttempt.getType(), app1.getChildren().iterator().next().getType());\r\n    Assert.assertEquals(appAttempt.getId(), app1.getChildren().iterator().next().getId());\r\n    app1.addInfo(ApplicationEntity.CHILDREN_INFO_KEY, Collections.singletonList(\"invalid children set\"));\r\n    try {\r\n        app1.getChildren();\r\n        Assert.fail();\r\n    } catch (Exception e) {\r\n        Assert.assertTrue(e instanceof YarnRuntimeException);\r\n        Assert.assertTrue(e.getMessage().contains(\"Children info is invalid identifier set\"));\r\n    }\r\n    app1.addInfo(ApplicationEntity.CHILDREN_INFO_KEY, Collections.singleton(\"invalid child object\"));\r\n    try {\r\n        app1.getChildren();\r\n        Assert.fail();\r\n    } catch (Exception e) {\r\n        Assert.assertTrue(e instanceof YarnRuntimeException);\r\n        Assert.assertTrue(e.getMessage().contains(\"Children info contains invalid identifier object\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timelineservice",
  "methodName" : "testUser",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testUser() throws Exception\n{\r\n    UserEntity user = new UserEntity();\r\n    user.setId(\"test user id\");\r\n    user.addInfo(\"test info key 1\", \"test info value 1\");\r\n    user.addInfo(\"test info key 2\", \"test info value 2\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(user, true));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timelineservice",
  "methodName" : "testQueue",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testQueue() throws Exception\n{\r\n    QueueEntity queue = new QueueEntity();\r\n    queue.setId(\"test queue id\");\r\n    queue.addInfo(\"test info key 1\", \"test info value 1\");\r\n    queue.addInfo(\"test info key 2\", \"test info value 2\");\r\n    queue.setParent(TimelineEntityType.YARN_QUEUE.toString(), \"test parent queue id\");\r\n    queue.addChild(TimelineEntityType.YARN_QUEUE.toString(), \"test child queue id 1\");\r\n    queue.addChild(TimelineEntityType.YARN_QUEUE.toString(), \"test child queue id 2\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(queue, true));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "createMockInjector",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Injector createMockInjector(final Class<T> api, final T impl, final Module... modules)\n{\r\n    return Guice.createInjector(new AbstractModule() {\r\n\r\n        final PrintWriter writer = spy(new PrintWriter(System.out));\r\n\r\n        final HttpServletRequest request = createRequest();\r\n\r\n        final HttpServletResponse response = createResponse();\r\n\r\n        @Override\r\n        protected void configure() {\r\n            if (api != null) {\r\n                bind(api).toInstance(impl);\r\n            }\r\n            bindScope(RequestScoped.class, Scopes.SINGLETON);\r\n            if (modules != null) {\r\n                for (Module module : modules) {\r\n                    install(module);\r\n                }\r\n            }\r\n        }\r\n\r\n        @Provides\r\n        HttpServletRequest request() {\r\n            return request;\r\n        }\r\n\r\n        @Provides\r\n        HttpServletResponse response() {\r\n            return response;\r\n        }\r\n\r\n        @Provides\r\n        PrintWriter writer() {\r\n            return writer;\r\n        }\r\n\r\n        HttpServletRequest createRequest() {\r\n            return mock(HttpServletRequest.class);\r\n        }\r\n\r\n        HttpServletResponse createResponse() {\r\n            try {\r\n                HttpServletResponse res = mock(HttpServletResponse.class);\r\n                when(res.getWriter()).thenReturn(writer);\r\n                return res;\r\n            } catch (Exception e) {\r\n                throw new WebAppException(e);\r\n            }\r\n        }\r\n    });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "createMockInjector",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Injector createMockInjector(T impl)\n{\r\n    return createMockInjector((Class<T>) impl.getClass(), impl);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "flushOutput",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void flushOutput(Injector injector)\n{\r\n    HttpServletResponse res = injector.getInstance(HttpServletResponse.class);\r\n    try {\r\n        res.getWriter().flush();\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testController",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Injector testController(Class<? extends Controller> ctrlr, String methodName, Class<T> api, T impl, Module... modules)\n{\r\n    try {\r\n        Injector injector = createMockInjector(api, impl, modules);\r\n        Method method = ctrlr.getMethod(methodName, (Class<?>[]) null);\r\n        method.invoke(injector.getInstance(ctrlr), (Object[]) null);\r\n        return injector;\r\n    } catch (Exception e) {\r\n        throw new WebAppException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testController",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Injector testController(Class<? extends Controller> ctrlr, String methodName)\n{\r\n    return testController(ctrlr, methodName, null, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testPage",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "Injector testPage(Class<? extends View> page, Class<T> api, T impl, Map<String, String> params, Module... modules)\n{\r\n    Injector injector = createMockInjector(api, impl, modules);\r\n    View view = injector.getInstance(page);\r\n    if (params != null) {\r\n        for (Map.Entry<String, String> entry : params.entrySet()) {\r\n            view.set(entry.getKey(), entry.getValue());\r\n        }\r\n    }\r\n    view.render();\r\n    flushOutput(injector);\r\n    return injector;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testPage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Injector testPage(Class<? extends View> page, Class<T> api, T impl, Module... modules)\n{\r\n    return testPage(page, api, impl, null, modules);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testPage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Injector testPage(Class<? extends View> page)\n{\r\n    return testPage(page, null, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testBlock",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Injector testBlock(Class<? extends SubView> block, Class<T> api, T impl, Module... modules)\n{\r\n    Injector injector = createMockInjector(api, impl, modules);\r\n    injector.getInstance(block).renderPartial();\r\n    flushOutput(injector);\r\n    return injector;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "testBlock",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Injector testBlock(Class<? extends SubView> block)\n{\r\n    return testBlock(block, null, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\test",
  "methodName" : "getPrintWriter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "PrintWriter getPrintWriter(Injector injector) throws IOException\n{\r\n    HttpServletResponse res = injector.getInstance(HttpServletResponse.class);\r\n    return res.getWriter();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testDispatcherOnCloseIfQueueEmpty",
  "errType" : [ "YarnRuntimeException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testDispatcherOnCloseIfQueueEmpty() throws Exception\n{\r\n    BlockingQueue<Event> eventQueue = spy(new LinkedBlockingQueue<Event>());\r\n    Event event = mock(Event.class);\r\n    doThrow(new InterruptedException()).when(eventQueue).put(event);\r\n    DrainDispatcher disp = new DrainDispatcher(eventQueue);\r\n    disp.init(new Configuration());\r\n    disp.setDrainEventsOnStop();\r\n    disp.start();\r\n    disp.waitForEventThreadToWait();\r\n    try {\r\n        disp.getEventHandler().handle(event);\r\n        Assert.fail(\"Expected YarnRuntimeException\");\r\n    } catch (YarnRuntimeException e) {\r\n        Assert.assertTrue(e.getCause() instanceof InterruptedException);\r\n    }\r\n    Assert.assertTrue(\"Event Queue should have been empty\", eventQueue.isEmpty());\r\n    disp.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testDispatchStopOnTimeout",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testDispatchStopOnTimeout() throws Exception\n{\r\n    BlockingQueue<Event> eventQueue = new LinkedBlockingQueue<Event>();\r\n    eventQueue = spy(eventQueue);\r\n    when(eventQueue.isEmpty()).thenReturn(false);\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setInt(YarnConfiguration.DISPATCHER_DRAIN_EVENTS_TIMEOUT, 2000);\r\n    DrainDispatcher disp = new DrainDispatcher(eventQueue);\r\n    disp.init(conf);\r\n    disp.setDrainEventsOnStop();\r\n    disp.start();\r\n    disp.waitForEventThreadToWait();\r\n    disp.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "dispatchDummyEvents",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void dispatchDummyEvents(Dispatcher disp, int count)\n{\r\n    for (int i = 0; i < count; i++) {\r\n        Event event = mock(Event.class);\r\n        when(event.getType()).thenReturn(DummyType.DUMMY);\r\n        disp.getEventHandler().handle(event);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testDrainDispatcherDrainEventsOnStop",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testDrainDispatcherDrainEventsOnStop() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setInt(YarnConfiguration.DISPATCHER_DRAIN_EVENTS_TIMEOUT, 2000);\r\n    BlockingQueue<Event> queue = new LinkedBlockingQueue<Event>();\r\n    DrainDispatcher disp = new DrainDispatcher(queue);\r\n    disp.init(conf);\r\n    disp.register(DummyType.class, new DummyHandler());\r\n    disp.setDrainEventsOnStop();\r\n    disp.start();\r\n    disp.waitForEventThreadToWait();\r\n    dispatchDummyEvents(disp, 2);\r\n    disp.close();\r\n    assertEquals(0, queue.size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testPrintDispatcherEventDetails",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testPrintDispatcherEventDetails() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setInt(YarnConfiguration.YARN_DISPATCHER_PRINT_EVENTS_INFO_THRESHOLD, 5000);\r\n    Logger log = mock(Logger.class);\r\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\r\n    dispatcher.init(conf);\r\n    Field logger = AsyncDispatcher.class.getDeclaredField(\"LOG\");\r\n    logger.setAccessible(true);\r\n    Field modifiers = Field.class.getDeclaredField(\"modifiers\");\r\n    modifiers.setAccessible(true);\r\n    modifiers.setInt(logger, logger.getModifiers() & ~Modifier.FINAL);\r\n    Object oldLog = logger.get(null);\r\n    try {\r\n        logger.set(null, log);\r\n        dispatcher.register(TestEnum.class, new TestHandler());\r\n        dispatcher.start();\r\n        for (int i = 0; i < 10000; ++i) {\r\n            Event event = mock(Event.class);\r\n            when(event.getType()).thenReturn(TestEnum.TestEventType);\r\n            dispatcher.getEventHandler().handle(event);\r\n        }\r\n        Thread.sleep(2000);\r\n        verify(log, atLeastOnce()).info(\"Latest dispatch event type: TestEventType\");\r\n    } finally {\r\n        logger.set(null, oldLog);\r\n        dispatcher.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testPrintDispatcherEventDetailsAvoidDeadLoop",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPrintDispatcherEventDetailsAvoidDeadLoop() throws Exception\n{\r\n    for (int i = 0; i < 5; i++) {\r\n        testPrintDispatcherEventDetailsAvoidDeadLoopInternal();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testPrintDispatcherEventDetailsAvoidDeadLoopInternal",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testPrintDispatcherEventDetailsAvoidDeadLoopInternal() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setInt(YarnConfiguration.YARN_DISPATCHER_PRINT_EVENTS_INFO_THRESHOLD, 10);\r\n    Logger log = mock(Logger.class);\r\n    AsyncDispatcher dispatcher = new AsyncDispatcher();\r\n    dispatcher.init(conf);\r\n    Field logger = AsyncDispatcher.class.getDeclaredField(\"LOG\");\r\n    logger.setAccessible(true);\r\n    Field modifiers = Field.class.getDeclaredField(\"modifiers\");\r\n    modifiers.setAccessible(true);\r\n    modifiers.setInt(logger, logger.getModifiers() & ~Modifier.FINAL);\r\n    Object oldLog = logger.get(null);\r\n    try {\r\n        logger.set(null, log);\r\n        dispatcher.register(TestEnum.class, new TestHandler(0));\r\n        dispatcher.start();\r\n        for (int i = 0; i < 10000; ++i) {\r\n            Event event = mock(Event.class);\r\n            when(event.getType()).thenReturn(TestEnum.TestEventType);\r\n            dispatcher.getEventHandler().handle(event);\r\n        }\r\n        Thread.sleep(3000);\r\n    } finally {\r\n        logger.set(null, oldLog);\r\n        dispatcher.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testMetricsForDispatcher",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testMetricsForDispatcher() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    AsyncDispatcher dispatcher = null;\r\n    try {\r\n        dispatcher = new AsyncDispatcher(\"RM Event dispatcher\");\r\n        GenericEventTypeMetrics genericEventTypeMetrics = new GenericEventTypeMetrics.EventTypeMetricsBuilder().setMs(DefaultMetricsSystem.instance()).setInfo(info(\"GenericEventTypeMetrics for \" + TestEnum.class.getName(), \"Metrics for \" + dispatcher.getName())).setEnumClass(TestEnum.class).setEnums(TestEnum.class.getEnumConstants()).build().registerMetrics();\r\n        dispatcher.addMetrics(genericEventTypeMetrics, genericEventTypeMetrics.getEnumClass());\r\n        dispatcher.init(conf);\r\n        dispatcher.register(TestEnum.class, new TestHandler());\r\n        dispatcher.start();\r\n        for (int i = 0; i < 3; ++i) {\r\n            Event event = mock(Event.class);\r\n            when(event.getType()).thenReturn(TestEnum.TestEventType);\r\n            dispatcher.getEventHandler().handle(event);\r\n        }\r\n        for (int i = 0; i < 2; ++i) {\r\n            Event event = mock(Event.class);\r\n            when(event.getType()).thenReturn(TestEnum.TestEventType2);\r\n            dispatcher.getEventHandler().handle(event);\r\n        }\r\n        GenericTestUtils.waitFor(() -> genericEventTypeMetrics.get(TestEnum.TestEventType) == 3, 1000, 10000);\r\n        GenericTestUtils.waitFor(() -> genericEventTypeMetrics.get(TestEnum.TestEventType2) == 2, 1000, 10000);\r\n        Assert.assertTrue(genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType) >= 1500 * 3);\r\n        Assert.assertTrue(genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType) < 1500 * 4);\r\n        Assert.assertTrue(genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType2) >= 1500 * 2);\r\n        Assert.assertTrue(genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType2) < 1500 * 3);\r\n        Assert.assertEquals(Long.toString(genericEventTypeMetrics.get(TestEnum.TestEventType)), genericEventTypeMetrics.getRegistry().get(\"TestEventType_event_count\").toString());\r\n        Assert.assertEquals(Long.toString(genericEventTypeMetrics.get(TestEnum.TestEventType2)), genericEventTypeMetrics.getRegistry().get(\"TestEventType2_event_count\").toString());\r\n        Assert.assertEquals(Long.toString(genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType)), genericEventTypeMetrics.getRegistry().get(\"TestEventType_processing_time\").toString());\r\n        Assert.assertEquals(Long.toString(genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType2)), genericEventTypeMetrics.getRegistry().get(\"TestEventType2_processing_time\").toString());\r\n    } finally {\r\n        dispatcher.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "testDispatcherMetricsHistogram",
  "errType" : null,
  "containingMethodsNum" : 27,
  "sourceCodeText" : "void testDispatcherMetricsHistogram() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    AsyncDispatcher dispatcher = null;\r\n    try {\r\n        dispatcher = new AsyncDispatcher(\"RM Event dispatcher\");\r\n        GenericEventTypeMetrics genericEventTypeMetrics = new GenericEventTypeMetrics.EventTypeMetricsBuilder().setMs(DefaultMetricsSystem.instance()).setInfo(info(\"GenericEventTypeMetrics for \" + TestEnum.class.getName(), \"Metrics for \" + dispatcher.getName())).setEnumClass(TestEnum.class).setEnums(TestEnum.class.getEnumConstants()).build().registerMetrics();\r\n        dispatcher.addMetrics(genericEventTypeMetrics, genericEventTypeMetrics.getEnumClass());\r\n        dispatcher.init(conf);\r\n        dispatcher.register(TestEnum.class, new TestHandler());\r\n        dispatcher.start();\r\n        for (int i = 0; i < 3; ++i) {\r\n            Event event = mock(Event.class);\r\n            when(event.getType()).thenReturn(TestEnum.TestEventType);\r\n            dispatcher.getEventHandler().handle(event);\r\n        }\r\n        for (int i = 0; i < 2; ++i) {\r\n            Event event = mock(Event.class);\r\n            when(event.getType()).thenReturn(TestEnum.TestEventType2);\r\n            dispatcher.getEventHandler().handle(event);\r\n        }\r\n        GenericTestUtils.waitFor(() -> genericEventTypeMetrics.get(TestEnum.TestEventType) == 3, 1000, 10000);\r\n        GenericTestUtils.waitFor(() -> genericEventTypeMetrics.get(TestEnum.TestEventType2) == 2, 1000, 10000);\r\n        Map<String, Long> expectedValues = new HashMap<>();\r\n        expectedValues.put(\"TestEventType_event_count\", genericEventTypeMetrics.get(TestEnum.TestEventType));\r\n        expectedValues.put(\"TestEventType_processing_time\", genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType));\r\n        expectedValues.put(\"TestEventType2_event_count\", genericEventTypeMetrics.get(TestEnum.TestEventType2));\r\n        expectedValues.put(\"TestEventType2_processing_time\", genericEventTypeMetrics.getTotalProcessingTime(TestEnum.TestEventType2));\r\n        Set<String> testResults = new HashSet<>();\r\n        MetricsCollectorImpl collector = new MetricsCollectorImpl();\r\n        genericEventTypeMetrics.getMetrics(collector, true);\r\n        for (MetricsRecord record : collector.getRecords()) {\r\n            for (AbstractMetric metric : record.metrics()) {\r\n                String metricName = metric.name();\r\n                if (expectedValues.containsKey(metricName)) {\r\n                    Long expectedValue = expectedValues.get(metricName);\r\n                    Assert.assertEquals(\"Metric \" + metricName + \" doesn't have expected value\", expectedValue, metric.value());\r\n                    testResults.add(metricName);\r\n                }\r\n            }\r\n        }\r\n        Assert.assertEquals(expectedValues.keySet(), testResults);\r\n    } finally {\r\n        dispatcher.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "tree",
  "errType" : null,
  "containingMethodsNum" : 27,
  "sourceCodeText" : "void tree()\n{\r\n    assumeWindows();\r\n    assertTrue(\"WindowsBasedProcessTree should be available on Windows\", WindowsBasedProcessTree.isAvailable());\r\n    ControlledClock testClock = new ControlledClock();\r\n    long elapsedTimeBetweenUpdatesMsec = 0;\r\n    testClock.setTime(elapsedTimeBetweenUpdatesMsec);\r\n    WindowsBasedProcessTreeTester pTree = new WindowsBasedProcessTreeTester(\"-1\", testClock);\r\n    pTree.infoStr = \"3524,1024,1024,500\\r\\n2844,1024,1024,500\\r\\n\";\r\n    pTree.updateProcessTree();\r\n    assertTrue(pTree.getVirtualMemorySize() == 2048);\r\n    assertTrue(pTree.getVirtualMemorySize(0) == 2048);\r\n    assertTrue(pTree.getRssMemorySize() == 2048);\r\n    assertTrue(pTree.getRssMemorySize(0) == 2048);\r\n    assertTrue(pTree.getCumulativeCpuTime() == 1000);\r\n    assertTrue(pTree.getCpuUsagePercent() == ResourceCalculatorProcessTree.UNAVAILABLE);\r\n    pTree.infoStr = \"3524,1024,1024,1000\\r\\n2844,1024,1024,1000\\r\\n1234,1024,1024,1000\\r\\n\";\r\n    elapsedTimeBetweenUpdatesMsec = 1000;\r\n    testClock.setTime(elapsedTimeBetweenUpdatesMsec);\r\n    pTree.updateProcessTree();\r\n    assertTrue(pTree.getVirtualMemorySize() == 3072);\r\n    assertTrue(pTree.getVirtualMemorySize(1) == 2048);\r\n    assertTrue(pTree.getRssMemorySize() == 3072);\r\n    assertTrue(pTree.getRssMemorySize(1) == 2048);\r\n    assertTrue(pTree.getCumulativeCpuTime() == 3000);\r\n    assertTrue(pTree.getCpuUsagePercent() == 200);\r\n    Assert.assertEquals(\"Percent CPU time is not correct\", pTree.getCpuUsagePercent(), 200, 0.01);\r\n    pTree.infoStr = \"3524,1024,1024,1500\\r\\n2844,1024,1024,1500\\r\\n\";\r\n    elapsedTimeBetweenUpdatesMsec = 2000;\r\n    testClock.setTime(elapsedTimeBetweenUpdatesMsec);\r\n    pTree.updateProcessTree();\r\n    assertTrue(pTree.getVirtualMemorySize() == 2048);\r\n    assertTrue(pTree.getVirtualMemorySize(2) == 2048);\r\n    assertTrue(pTree.getRssMemorySize() == 2048);\r\n    assertTrue(pTree.getRssMemorySize(2) == 2048);\r\n    assertTrue(pTree.getCumulativeCpuTime() == 4000);\r\n    Assert.assertEquals(\"Percent CPU time is not correct\", pTree.getCpuUsagePercent(), 0, 0.01);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "testEntities",
  "errType" : null,
  "containingMethodsNum" : 35,
  "sourceCodeText" : "void testEntities() throws Exception\n{\r\n    TimelineEntities entities = new TimelineEntities();\r\n    for (int j = 0; j < 2; ++j) {\r\n        TimelineEntity entity = new TimelineEntity();\r\n        entity.setEntityId(\"entity id \" + j);\r\n        entity.setEntityType(\"entity type \" + j);\r\n        entity.setStartTime(System.currentTimeMillis());\r\n        for (int i = 0; i < 2; ++i) {\r\n            TimelineEvent event = new TimelineEvent();\r\n            event.setTimestamp(System.currentTimeMillis());\r\n            event.setEventType(\"event type \" + i);\r\n            event.addEventInfo(\"key1\", \"val1\");\r\n            event.addEventInfo(\"key2\", \"val2\");\r\n            entity.addEvent(event);\r\n        }\r\n        entity.addRelatedEntity(\"test ref type 1\", \"test ref id 1\");\r\n        entity.addRelatedEntity(\"test ref type 2\", \"test ref id 2\");\r\n        entity.addPrimaryFilter(\"pkey1\", \"pval1\");\r\n        entity.addPrimaryFilter(\"pkey2\", \"pval2\");\r\n        entity.addOtherInfo(\"okey1\", \"oval1\");\r\n        entity.addOtherInfo(\"okey2\", \"oval2\");\r\n        entity.setDomainId(\"domain id \" + j);\r\n        entities.addEntity(entity);\r\n    }\r\n    LOG.info(\"Entities in JSON:\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(entities, true));\r\n    Assert.assertEquals(2, entities.getEntities().size());\r\n    TimelineEntity entity1 = entities.getEntities().get(0);\r\n    Assert.assertEquals(\"entity id 0\", entity1.getEntityId());\r\n    Assert.assertEquals(\"entity type 0\", entity1.getEntityType());\r\n    Assert.assertEquals(2, entity1.getRelatedEntities().size());\r\n    Assert.assertEquals(2, entity1.getEvents().size());\r\n    Assert.assertEquals(2, entity1.getPrimaryFilters().size());\r\n    Assert.assertEquals(2, entity1.getOtherInfo().size());\r\n    Assert.assertEquals(\"domain id 0\", entity1.getDomainId());\r\n    TimelineEntity entity2 = entities.getEntities().get(1);\r\n    Assert.assertEquals(\"entity id 1\", entity2.getEntityId());\r\n    Assert.assertEquals(\"entity type 1\", entity2.getEntityType());\r\n    Assert.assertEquals(2, entity2.getRelatedEntities().size());\r\n    Assert.assertEquals(2, entity2.getEvents().size());\r\n    Assert.assertEquals(2, entity2.getPrimaryFilters().size());\r\n    Assert.assertEquals(2, entity2.getOtherInfo().size());\r\n    Assert.assertEquals(\"domain id 1\", entity2.getDomainId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "testEvents",
  "errType" : null,
  "containingMethodsNum" : 31,
  "sourceCodeText" : "void testEvents() throws Exception\n{\r\n    TimelineEvents events = new TimelineEvents();\r\n    for (int j = 0; j < 2; ++j) {\r\n        TimelineEvents.EventsOfOneEntity partEvents = new TimelineEvents.EventsOfOneEntity();\r\n        partEvents.setEntityId(\"entity id \" + j);\r\n        partEvents.setEntityType(\"entity type \" + j);\r\n        for (int i = 0; i < 2; ++i) {\r\n            TimelineEvent event = new TimelineEvent();\r\n            event.setTimestamp(System.currentTimeMillis());\r\n            event.setEventType(\"event type \" + i);\r\n            event.addEventInfo(\"key1\", \"val1\");\r\n            event.addEventInfo(\"key2\", \"val2\");\r\n            partEvents.addEvent(event);\r\n        }\r\n        events.addEvent(partEvents);\r\n    }\r\n    LOG.info(\"Events in JSON:\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(events, true));\r\n    Assert.assertEquals(2, events.getAllEvents().size());\r\n    TimelineEvents.EventsOfOneEntity partEvents1 = events.getAllEvents().get(0);\r\n    Assert.assertEquals(\"entity id 0\", partEvents1.getEntityId());\r\n    Assert.assertEquals(\"entity type 0\", partEvents1.getEntityType());\r\n    Assert.assertEquals(2, partEvents1.getEvents().size());\r\n    TimelineEvent event11 = partEvents1.getEvents().get(0);\r\n    Assert.assertEquals(\"event type 0\", event11.getEventType());\r\n    Assert.assertEquals(2, event11.getEventInfo().size());\r\n    TimelineEvent event12 = partEvents1.getEvents().get(1);\r\n    Assert.assertEquals(\"event type 1\", event12.getEventType());\r\n    Assert.assertEquals(2, event12.getEventInfo().size());\r\n    TimelineEvents.EventsOfOneEntity partEvents2 = events.getAllEvents().get(1);\r\n    Assert.assertEquals(\"entity id 1\", partEvents2.getEntityId());\r\n    Assert.assertEquals(\"entity type 1\", partEvents2.getEntityType());\r\n    Assert.assertEquals(2, partEvents2.getEvents().size());\r\n    TimelineEvent event21 = partEvents2.getEvents().get(0);\r\n    Assert.assertEquals(\"event type 0\", event21.getEventType());\r\n    Assert.assertEquals(2, event21.getEventInfo().size());\r\n    TimelineEvent event22 = partEvents2.getEvents().get(1);\r\n    Assert.assertEquals(\"event type 1\", event22.getEventType());\r\n    Assert.assertEquals(2, event22.getEventInfo().size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "testTimelinePutErrors",
  "errType" : null,
  "containingMethodsNum" : 25,
  "sourceCodeText" : "void testTimelinePutErrors() throws Exception\n{\r\n    TimelinePutResponse TimelinePutErrors = new TimelinePutResponse();\r\n    TimelinePutError error1 = new TimelinePutError();\r\n    error1.setEntityId(\"entity id 1\");\r\n    error1.setEntityId(\"entity type 1\");\r\n    error1.setErrorCode(TimelinePutError.NO_START_TIME);\r\n    TimelinePutErrors.addError(error1);\r\n    List<TimelinePutError> response = new ArrayList<TimelinePutError>();\r\n    response.add(error1);\r\n    TimelinePutError error2 = new TimelinePutError();\r\n    error2.setEntityId(\"entity id 2\");\r\n    error2.setEntityId(\"entity type 2\");\r\n    error2.setErrorCode(TimelinePutError.IO_EXCEPTION);\r\n    response.add(error2);\r\n    TimelinePutErrors.addErrors(response);\r\n    LOG.info(\"Errors in JSON:\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(TimelinePutErrors, true));\r\n    Assert.assertEquals(3, TimelinePutErrors.getErrors().size());\r\n    TimelinePutError e = TimelinePutErrors.getErrors().get(0);\r\n    Assert.assertEquals(error1.getEntityId(), e.getEntityId());\r\n    Assert.assertEquals(error1.getEntityType(), e.getEntityType());\r\n    Assert.assertEquals(error1.getErrorCode(), e.getErrorCode());\r\n    e = TimelinePutErrors.getErrors().get(1);\r\n    Assert.assertEquals(error1.getEntityId(), e.getEntityId());\r\n    Assert.assertEquals(error1.getEntityType(), e.getEntityType());\r\n    Assert.assertEquals(error1.getErrorCode(), e.getErrorCode());\r\n    e = TimelinePutErrors.getErrors().get(2);\r\n    Assert.assertEquals(error2.getEntityId(), e.getEntityId());\r\n    Assert.assertEquals(error2.getEntityType(), e.getEntityType());\r\n    Assert.assertEquals(error2.getErrorCode(), e.getErrorCode());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "testTimelineDomain",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void testTimelineDomain() throws Exception\n{\r\n    TimelineDomains domains = new TimelineDomains();\r\n    TimelineDomain domain = null;\r\n    for (int i = 0; i < 2; ++i) {\r\n        domain = new TimelineDomain();\r\n        domain.setId(\"test id \" + (i + 1));\r\n        domain.setDescription(\"test description \" + (i + 1));\r\n        domain.setOwner(\"test owner \" + (i + 1));\r\n        domain.setReaders(\"test_reader_user_\" + (i + 1) + \" test_reader_group+\" + (i + 1));\r\n        domain.setWriters(\"test_writer_user_\" + (i + 1) + \" test_writer_group+\" + (i + 1));\r\n        domain.setCreatedTime(0L);\r\n        domain.setModifiedTime(1L);\r\n        domains.addDomain(domain);\r\n    }\r\n    LOG.info(\"Domain in JSON:\");\r\n    LOG.info(TimelineUtils.dumpTimelineRecordtoJSON(domains, true));\r\n    Assert.assertEquals(2, domains.getDomains().size());\r\n    for (int i = 0; i < domains.getDomains().size(); ++i) {\r\n        domain = domains.getDomains().get(i);\r\n        Assert.assertEquals(\"test id \" + (i + 1), domain.getId());\r\n        Assert.assertEquals(\"test description \" + (i + 1), domain.getDescription());\r\n        Assert.assertEquals(\"test owner \" + (i + 1), domain.getOwner());\r\n        Assert.assertEquals(\"test_reader_user_\" + (i + 1) + \" test_reader_group+\" + (i + 1), domain.getReaders());\r\n        Assert.assertEquals(\"test_writer_user_\" + (i + 1) + \" test_writer_group+\" + (i + 1), domain.getWriters());\r\n        Assert.assertEquals(new Long(0L), domain.getCreatedTime());\r\n        Assert.assertEquals(new Long(1L), domain.getModifiedTime());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "testMapInterfaceOrTimelineRecords",
  "errType" : null,
  "containingMethodsNum" : 40,
  "sourceCodeText" : "void testMapInterfaceOrTimelineRecords() throws Exception\n{\r\n    TimelineEntity entity = new TimelineEntity();\r\n    List<Map<String, Set<Object>>> primaryFiltersList = new ArrayList<Map<String, Set<Object>>>();\r\n    primaryFiltersList.add(Collections.singletonMap(\"pkey\", Collections.singleton((Object) \"pval\")));\r\n    Map<String, Set<Object>> primaryFilters = new TreeMap<String, Set<Object>>();\r\n    primaryFilters.put(\"pkey1\", Collections.singleton((Object) \"pval1\"));\r\n    primaryFilters.put(\"pkey2\", Collections.singleton((Object) \"pval2\"));\r\n    primaryFiltersList.add(primaryFilters);\r\n    entity.setPrimaryFilters(null);\r\n    for (Map<String, Set<Object>> primaryFiltersToSet : primaryFiltersList) {\r\n        entity.setPrimaryFilters(primaryFiltersToSet);\r\n        assertPrimaryFilters(entity);\r\n        Map<String, Set<Object>> primaryFiltersToAdd = new WeakHashMap<String, Set<Object>>();\r\n        primaryFiltersToAdd.put(\"pkey3\", Collections.singleton((Object) \"pval3\"));\r\n        entity.addPrimaryFilters(primaryFiltersToAdd);\r\n        assertPrimaryFilters(entity);\r\n    }\r\n    List<Map<String, Set<String>>> relatedEntitiesList = new ArrayList<Map<String, Set<String>>>();\r\n    relatedEntitiesList.add(Collections.singletonMap(\"rkey\", Collections.singleton(\"rval\")));\r\n    Map<String, Set<String>> relatedEntities = new TreeMap<String, Set<String>>();\r\n    relatedEntities.put(\"rkey1\", Collections.singleton(\"rval1\"));\r\n    relatedEntities.put(\"rkey2\", Collections.singleton(\"rval2\"));\r\n    relatedEntitiesList.add(relatedEntities);\r\n    entity.setRelatedEntities(null);\r\n    for (Map<String, Set<String>> relatedEntitiesToSet : relatedEntitiesList) {\r\n        entity.setRelatedEntities(relatedEntitiesToSet);\r\n        assertRelatedEntities(entity);\r\n        Map<String, Set<String>> relatedEntitiesToAdd = new WeakHashMap<String, Set<String>>();\r\n        relatedEntitiesToAdd.put(\"rkey3\", Collections.singleton(\"rval3\"));\r\n        entity.addRelatedEntities(relatedEntitiesToAdd);\r\n        assertRelatedEntities(entity);\r\n    }\r\n    List<Map<String, Object>> otherInfoList = new ArrayList<Map<String, Object>>();\r\n    otherInfoList.add(Collections.singletonMap(\"okey\", (Object) \"oval\"));\r\n    Map<String, Object> otherInfo = new TreeMap<String, Object>();\r\n    otherInfo.put(\"okey1\", \"oval1\");\r\n    otherInfo.put(\"okey2\", \"oval2\");\r\n    otherInfoList.add(otherInfo);\r\n    entity.setOtherInfo(null);\r\n    for (Map<String, Object> otherInfoToSet : otherInfoList) {\r\n        entity.setOtherInfo(otherInfoToSet);\r\n        assertOtherInfo(entity);\r\n        Map<String, Object> otherInfoToAdd = new WeakHashMap<String, Object>();\r\n        otherInfoToAdd.put(\"okey3\", \"oval3\");\r\n        entity.addOtherInfo(otherInfoToAdd);\r\n        assertOtherInfo(entity);\r\n    }\r\n    TimelineEvent event = new TimelineEvent();\r\n    List<Map<String, Object>> eventInfoList = new ArrayList<Map<String, Object>>();\r\n    eventInfoList.add(Collections.singletonMap(\"ekey\", (Object) \"eval\"));\r\n    Map<String, Object> eventInfo = new TreeMap<String, Object>();\r\n    eventInfo.put(\"ekey1\", \"eval1\");\r\n    eventInfo.put(\"ekey2\", \"eval2\");\r\n    eventInfoList.add(eventInfo);\r\n    event.setEventInfo(null);\r\n    for (Map<String, Object> eventInfoToSet : eventInfoList) {\r\n        event.setEventInfo(eventInfoToSet);\r\n        assertEventInfo(event);\r\n        Map<String, Object> eventInfoToAdd = new WeakHashMap<String, Object>();\r\n        eventInfoToAdd.put(\"ekey3\", \"eval3\");\r\n        event.addEventInfo(eventInfoToAdd);\r\n        assertEventInfo(event);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "assertPrimaryFilters",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void assertPrimaryFilters(TimelineEntity entity)\n{\r\n    Assert.assertNotNull(entity.getPrimaryFilters());\r\n    Assert.assertNotNull(entity.getPrimaryFiltersJAXB());\r\n    Assert.assertTrue(entity.getPrimaryFilters() instanceof HashMap);\r\n    Assert.assertTrue(entity.getPrimaryFiltersJAXB() instanceof HashMap);\r\n    Assert.assertEquals(entity.getPrimaryFilters(), entity.getPrimaryFiltersJAXB());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "assertRelatedEntities",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void assertRelatedEntities(TimelineEntity entity)\n{\r\n    Assert.assertNotNull(entity.getRelatedEntities());\r\n    Assert.assertNotNull(entity.getRelatedEntitiesJAXB());\r\n    Assert.assertTrue(entity.getRelatedEntities() instanceof HashMap);\r\n    Assert.assertTrue(entity.getRelatedEntitiesJAXB() instanceof HashMap);\r\n    Assert.assertEquals(entity.getRelatedEntities(), entity.getRelatedEntitiesJAXB());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "assertOtherInfo",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void assertOtherInfo(TimelineEntity entity)\n{\r\n    Assert.assertNotNull(entity.getOtherInfo());\r\n    Assert.assertNotNull(entity.getOtherInfoJAXB());\r\n    Assert.assertTrue(entity.getOtherInfo() instanceof HashMap);\r\n    Assert.assertTrue(entity.getOtherInfoJAXB() instanceof HashMap);\r\n    Assert.assertEquals(entity.getOtherInfo(), entity.getOtherInfoJAXB());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\timeline",
  "methodName" : "assertEventInfo",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void assertEventInfo(TimelineEvent event)\n{\r\n    Assert.assertNotNull(event);\r\n    Assert.assertNotNull(event.getEventInfoJAXB());\r\n    Assert.assertTrue(event.getEventInfo() instanceof HashMap);\r\n    Assert.assertTrue(event.getEventInfoJAXB() instanceof HashMap);\r\n    Assert.assertEquals(event.getEventInfo(), event.getEventInfoJAXB());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "initWithZeroLimitThrowsException",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initWithZeroLimitThrowsException()\n{\r\n    expected.expect(IllegalArgumentException.class);\r\n    expected.expectMessage(\"limit should be positive\");\r\n    new BoundedAppender(0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "nullAppendedNullStringRead",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void nullAppendedNullStringRead()\n{\r\n    final BoundedAppender boundedAppender = new BoundedAppender(4);\r\n    boundedAppender.append(null);\r\n    assertEquals(\"null appended, \\\"null\\\" read\", \"null\", boundedAppender.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "appendBelowLimitOnceValueIsReadCorrectly",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void appendBelowLimitOnceValueIsReadCorrectly()\n{\r\n    final BoundedAppender boundedAppender = new BoundedAppender(2);\r\n    boundedAppender.append(\"ab\");\r\n    assertEquals(\"value appended is read correctly\", \"ab\", boundedAppender.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "appendValuesBelowLimitAreReadCorrectlyInFifoOrder",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void appendValuesBelowLimitAreReadCorrectlyInFifoOrder()\n{\r\n    final BoundedAppender boundedAppender = new BoundedAppender(3);\r\n    boundedAppender.append(\"ab\");\r\n    boundedAppender.append(\"cd\");\r\n    boundedAppender.append(\"e\");\r\n    boundedAppender.append(\"fg\");\r\n    assertEquals(\"last values appended fitting limit are read correctly\", String.format(BoundedAppender.TRUNCATED_MESSAGES_TEMPLATE, 3, 7, \"efg\"), boundedAppender.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "appendLastAboveLimitPreservesLastMessagePostfix",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void appendLastAboveLimitPreservesLastMessagePostfix()\n{\r\n    final BoundedAppender boundedAppender = new BoundedAppender(3);\r\n    boundedAppender.append(\"ab\");\r\n    boundedAppender.append(\"cde\");\r\n    boundedAppender.append(\"fghij\");\r\n    assertEquals(\"last value appended above limit postfix is read correctly\", String.format(BoundedAppender.TRUNCATED_MESSAGES_TEMPLATE, 3, 10, \"hij\"), boundedAppender.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "appendMiddleAboveLimitPreservesLastMessageAndMiddlePostfix",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void appendMiddleAboveLimitPreservesLastMessageAndMiddlePostfix()\n{\r\n    final BoundedAppender boundedAppender = new BoundedAppender(3);\r\n    boundedAppender.append(\"ab\");\r\n    boundedAppender.append(\"cde\");\r\n    assertEquals(\"last value appended above limit postfix is read correctly\", String.format(BoundedAppender.TRUNCATED_MESSAGES_TEMPLATE, 3, 5, \"cde\"), boundedAppender.toString());\r\n    boundedAppender.append(\"fg\");\r\n    assertEquals(\"middle value appended above limit postfix and last value are \" + \"read correctly\", String.format(BoundedAppender.TRUNCATED_MESSAGES_TEMPLATE, 3, 7, \"efg\"), boundedAppender.toString());\r\n    boundedAppender.append(\"hijkl\");\r\n    assertEquals(\"last value appended above limit postfix is read correctly\", String.format(BoundedAppender.TRUNCATED_MESSAGES_TEMPLATE, 3, 12, \"jkl\"), boundedAppender.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "closeFilesystems",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void closeFilesystems() throws IOException\n{\r\n    FileSystem.closeAll();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testDeletion",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 41,
  "sourceCodeText" : "void testDeletion() throws Exception\n{\r\n    long now = System.currentTimeMillis();\r\n    long toDeleteTime = now - (2000 * 1000);\r\n    long toKeepTime = now - (1500 * 1000);\r\n    String root = \"mockfs://foo/\";\r\n    String remoteRootLogDir = root + \"tmp/logs\";\r\n    String suffix = \"logs\";\r\n    String newSuffix = LogAggregationUtils.getBucketSuffix() + suffix;\r\n    final Configuration conf = new Configuration();\r\n    conf.setClass(\"fs.mockfs.impl\", MockFileSystem.class, FileSystem.class);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_ENABLED, \"true\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_SECONDS, \"1800\");\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, remoteRootLogDir);\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX, suffix);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TFile\");\r\n    conf.set(String.format(LOG_AGGREGATION_FILE_CONTROLLER_FMT, \"TFile\"), LogAggregationTFileController.class.getName());\r\n    Path rootPath = new Path(root);\r\n    FileSystem rootFs = rootPath.getFileSystem(conf);\r\n    FileSystem mockFs = ((FilterFileSystem) rootFs).getRawFileSystem();\r\n    Path remoteRootLogPath = new Path(remoteRootLogDir);\r\n    Path userDir = new Path(remoteRootLogPath, \"me\");\r\n    FileStatus userDirStatus = new FileStatus(0, true, 0, 0, toKeepTime, userDir);\r\n    when(mockFs.listStatus(remoteRootLogPath)).thenReturn(new FileStatus[] { userDirStatus });\r\n    ApplicationId appId1 = ApplicationId.newInstance(now, 1);\r\n    Path suffixDir = new Path(userDir, newSuffix);\r\n    FileStatus suffixDirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, suffixDir);\r\n    Path bucketDir = LogAggregationUtils.getRemoteBucketDir(remoteRootLogPath, \"me\", suffix, appId1);\r\n    FileStatus bucketDirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, bucketDir);\r\n    Path app1Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId1, \"me\", suffix);\r\n    FileStatus app1DirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, app1Dir);\r\n    ApplicationId appId2 = ApplicationId.newInstance(now, 2);\r\n    Path app2Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId2, \"me\", suffix);\r\n    FileStatus app2DirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, app2Dir);\r\n    ApplicationId appId3 = ApplicationId.newInstance(now, 3);\r\n    Path app3Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId3, \"me\", suffix);\r\n    FileStatus app3DirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, app3Dir);\r\n    ApplicationId appId4 = ApplicationId.newInstance(now, 4);\r\n    Path app4Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId4, \"me\", suffix);\r\n    FileStatus app4DirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, app4Dir);\r\n    when(mockFs.listStatus(userDir)).thenReturn(new FileStatus[] { suffixDirStatus });\r\n    when(mockFs.listStatus(suffixDir)).thenReturn(new FileStatus[] { bucketDirStatus });\r\n    when(mockFs.listStatus(bucketDir)).thenReturn(new FileStatus[] { app1DirStatus, app2DirStatus, app3DirStatus, app4DirStatus });\r\n    when(mockFs.listStatus(app1Dir)).thenReturn(new FileStatus[] {});\r\n    Path app2Log1 = new Path(app2Dir, \"host1\");\r\n    FileStatus app2Log1Status = new FileStatus(10, false, 1, 1, toDeleteTime, app2Log1);\r\n    Path app2Log2 = new Path(app2Dir, \"host2\");\r\n    FileStatus app2Log2Status = new FileStatus(10, false, 1, 1, toKeepTime, app2Log2);\r\n    when(mockFs.listStatus(app2Dir)).thenReturn(new FileStatus[] { app2Log1Status, app2Log2Status });\r\n    Path app3Log1 = new Path(app3Dir, \"host1\");\r\n    FileStatus app3Log1Status = new FileStatus(10, false, 1, 1, toDeleteTime, app3Log1);\r\n    Path app3Log2 = new Path(app3Dir, \"host2\");\r\n    FileStatus app3Log2Status = new FileStatus(10, false, 1, 1, toDeleteTime, app3Log2);\r\n    when(mockFs.delete(app3Dir, true)).thenThrow(new AccessControlException(\"Injected Error\\nStack Trace :(\"));\r\n    when(mockFs.listStatus(app3Dir)).thenReturn(new FileStatus[] { app3Log1Status, app3Log2Status });\r\n    Path app4Log1 = new Path(app4Dir, \"host1\");\r\n    FileStatus app4Log1Status = new FileStatus(10, false, 1, 1, toDeleteTime, app4Log1);\r\n    Path app4Log2 = new Path(app4Dir, \"host2\");\r\n    FileStatus app4Log2Status = new FileStatus(10, false, 1, 1, toKeepTime, app4Log2);\r\n    when(mockFs.listStatus(app4Dir)).thenReturn(new FileStatus[] { app4Log1Status, app4Log2Status });\r\n    final List<ApplicationId> finishedApplications = Collections.unmodifiableList(Arrays.asList(appId1, appId2, appId3));\r\n    final List<ApplicationId> runningApplications = Collections.unmodifiableList(Arrays.asList(appId4));\r\n    AggregatedLogDeletionService deletionService = new AggregatedLogDeletionService() {\r\n\r\n        @Override\r\n        protected ApplicationClientProtocol createRMClient() throws IOException {\r\n            try {\r\n                return createMockRMClient(finishedApplications, runningApplications);\r\n            } catch (Exception e) {\r\n                throw new IOException(e);\r\n            }\r\n        }\r\n\r\n        @Override\r\n        protected void stopRMClient() {\r\n        }\r\n    };\r\n    deletionService.init(conf);\r\n    deletionService.start();\r\n    verify(mockFs, timeout(2000)).delete(app1Dir, true);\r\n    verify(mockFs, timeout(2000).times(0)).delete(app2Dir, true);\r\n    verify(mockFs, timeout(2000)).delete(app3Dir, true);\r\n    verify(mockFs, timeout(2000).times(0)).delete(app4Dir, true);\r\n    verify(mockFs, timeout(2000)).delete(app4Log1, true);\r\n    verify(mockFs, timeout(2000).times(0)).delete(app4Log2, true);\r\n    deletionService.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testRefreshLogRetentionSettings",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 36,
  "sourceCodeText" : "void testRefreshLogRetentionSettings() throws Exception\n{\r\n    long now = System.currentTimeMillis();\r\n    long before2000Secs = now - (2000 * 1000);\r\n    long before50Secs = now - (50 * 1000);\r\n    String root = \"mockfs://foo/\";\r\n    String remoteRootLogDir = root + \"tmp/logs\";\r\n    String suffix = \"logs\";\r\n    String newSuffix = LogAggregationUtils.getBucketSuffix() + suffix;\r\n    final Configuration conf = new Configuration();\r\n    conf.setClass(\"fs.mockfs.impl\", MockFileSystem.class, FileSystem.class);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_ENABLED, \"true\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_SECONDS, \"1800\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS, \"1\");\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, remoteRootLogDir);\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX, suffix);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TFile\");\r\n    conf.set(String.format(LOG_AGGREGATION_FILE_CONTROLLER_FMT, \"TFile\"), LogAggregationTFileController.class.getName());\r\n    Path rootPath = new Path(root);\r\n    FileSystem rootFs = rootPath.getFileSystem(conf);\r\n    FileSystem mockFs = ((FilterFileSystem) rootFs).getRawFileSystem();\r\n    Path remoteRootLogPath = new Path(remoteRootLogDir);\r\n    Path userDir = new Path(remoteRootLogPath, \"me\");\r\n    FileStatus userDirStatus = new FileStatus(0, true, 0, 0, before50Secs, userDir);\r\n    when(mockFs.listStatus(remoteRootLogPath)).thenReturn(new FileStatus[] { userDirStatus });\r\n    Path suffixDir = new Path(userDir, newSuffix);\r\n    FileStatus suffixStatus = new FileStatus(0, true, 0, 0, before50Secs, suffixDir);\r\n    ApplicationId appId1 = ApplicationId.newInstance(System.currentTimeMillis(), 1);\r\n    Path app1Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId1, \"me\", suffix);\r\n    Path bucketDir = LogAggregationUtils.getRemoteBucketDir(remoteRootLogPath, \"me\", suffix, appId1);\r\n    FileStatus bucketDirStatus = new FileStatus(0, true, 0, 0, before50Secs, bucketDir);\r\n    FileStatus app1DirStatus = new FileStatus(0, true, 0, 0, before2000Secs, app1Dir);\r\n    ApplicationId appId2 = ApplicationId.newInstance(System.currentTimeMillis(), 2);\r\n    Path app2Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId2, \"me\", suffix);\r\n    FileStatus app2DirStatus = new FileStatus(0, true, 0, 0, before50Secs, app2Dir);\r\n    when(mockFs.listStatus(userDir)).thenReturn(new FileStatus[] { suffixStatus });\r\n    when(mockFs.listStatus(suffixDir)).thenReturn(new FileStatus[] { bucketDirStatus });\r\n    when(mockFs.listStatus(bucketDir)).thenReturn(new FileStatus[] { app1DirStatus, app2DirStatus });\r\n    Path app1Log1 = new Path(app1Dir, \"host1\");\r\n    FileStatus app1Log1Status = new FileStatus(10, false, 1, 1, before2000Secs, app1Log1);\r\n    when(mockFs.listStatus(app1Dir)).thenReturn(new FileStatus[] { app1Log1Status });\r\n    Path app2Log1 = new Path(app2Dir, \"host1\");\r\n    FileStatus app2Log1Status = new FileStatus(10, false, 1, 1, before50Secs, app2Log1);\r\n    when(mockFs.listStatus(app2Dir)).thenReturn(new FileStatus[] { app2Log1Status });\r\n    final List<ApplicationId> finishedApplications = Collections.unmodifiableList(Arrays.asList(appId1, appId2));\r\n    AggregatedLogDeletionService deletionSvc = new AggregatedLogDeletionService() {\r\n\r\n        @Override\r\n        protected Configuration createConf() {\r\n            return conf;\r\n        }\r\n\r\n        @Override\r\n        protected ApplicationClientProtocol createRMClient() throws IOException {\r\n            try {\r\n                return createMockRMClient(finishedApplications, null);\r\n            } catch (Exception e) {\r\n                throw new IOException(e);\r\n            }\r\n        }\r\n\r\n        @Override\r\n        protected void stopRMClient() {\r\n        }\r\n    };\r\n    deletionSvc.init(conf);\r\n    deletionSvc.start();\r\n    verify(mockFs, timeout(10000)).delete(app1Dir, true);\r\n    verify(mockFs, timeout(3000).times(0)).delete(app2Dir, true);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_SECONDS, \"50\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS, \"2\");\r\n    Assert.assertTrue(2000l != deletionSvc.getCheckIntervalMsecs());\r\n    deletionSvc.refreshLogRetentionSettings();\r\n    Assert.assertTrue(2000l == deletionSvc.getCheckIntervalMsecs());\r\n    verify(mockFs, timeout(10000)).delete(app2Dir, true);\r\n    deletionSvc.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testCheckInterval",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 33,
  "sourceCodeText" : "void testCheckInterval() throws Exception\n{\r\n    long RETENTION_SECS = 10 * 24 * 3600;\r\n    long now = System.currentTimeMillis();\r\n    long toDeleteTime = now - RETENTION_SECS * 1000;\r\n    String root = \"mockfs://foo/\";\r\n    String remoteRootLogDir = root + \"tmp/logs\";\r\n    String suffix = \"logs\";\r\n    String newSuffix = LogAggregationUtils.getBucketSuffix() + suffix;\r\n    Configuration conf = new Configuration();\r\n    conf.setClass(\"fs.mockfs.impl\", MockFileSystem.class, FileSystem.class);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_ENABLED, \"true\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_SECONDS, \"864000\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS, \"1\");\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, remoteRootLogDir);\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX, suffix);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TFile\");\r\n    conf.set(String.format(LOG_AGGREGATION_FILE_CONTROLLER_FMT, \"TFile\"), LogAggregationTFileController.class.getName());\r\n    FileSystem.closeAll();\r\n    Path rootPath = new Path(root);\r\n    FileSystem rootFs = rootPath.getFileSystem(conf);\r\n    FileSystem mockFs = ((FilterFileSystem) rootFs).getRawFileSystem();\r\n    Path remoteRootLogPath = new Path(remoteRootLogDir);\r\n    Path userDir = new Path(remoteRootLogPath, \"me\");\r\n    FileStatus userDirStatus = new FileStatus(0, true, 0, 0, now, userDir);\r\n    when(mockFs.listStatus(remoteRootLogPath)).thenReturn(new FileStatus[] { userDirStatus });\r\n    ApplicationId appId1 = ApplicationId.newInstance(System.currentTimeMillis(), 1);\r\n    Path suffixDir = new Path(userDir, newSuffix);\r\n    FileStatus suffixDirStatus = new FileStatus(0, true, 0, 0, now, suffixDir);\r\n    Path bucketDir = LogAggregationUtils.getRemoteBucketDir(remoteRootLogPath, \"me\", suffix, appId1);\r\n    Path app1Dir = LogAggregationUtils.getRemoteAppLogDir(remoteRootLogPath, appId1, \"me\", suffix);\r\n    FileStatus bucketDirStatus = new FileStatus(0, true, 0, 0, now, bucketDir);\r\n    FileStatus app1DirStatus = new FileStatus(0, true, 0, 0, now, app1Dir);\r\n    when(mockFs.listStatus(userDir)).thenReturn(new FileStatus[] { suffixDirStatus });\r\n    when(mockFs.listStatus(suffixDir)).thenReturn(new FileStatus[] { bucketDirStatus });\r\n    when(mockFs.listStatus(bucketDir)).thenReturn(new FileStatus[] { app1DirStatus });\r\n    Path app1Log1 = new Path(app1Dir, \"host1\");\r\n    FileStatus app1Log1Status = new FileStatus(10, false, 1, 1, now, app1Log1);\r\n    when(mockFs.listStatus(app1Dir)).thenReturn(new FileStatus[] { app1Log1Status });\r\n    final List<ApplicationId> finishedApplications = Collections.unmodifiableList(Arrays.asList(appId1));\r\n    AggregatedLogDeletionService deletionSvc = new AggregatedLogDeletionService() {\r\n\r\n        @Override\r\n        protected ApplicationClientProtocol createRMClient() throws IOException {\r\n            try {\r\n                return createMockRMClient(finishedApplications, null);\r\n            } catch (Exception e) {\r\n                throw new IOException(e);\r\n            }\r\n        }\r\n\r\n        @Override\r\n        protected void stopRMClient() {\r\n        }\r\n    };\r\n    deletionSvc.init(conf);\r\n    deletionSvc.start();\r\n    verify(mockFs, timeout(10000).atLeast(4)).listStatus(any(Path.class));\r\n    verify(mockFs, never()).delete(app1Dir, true);\r\n    bucketDirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, bucketDir);\r\n    app1DirStatus = new FileStatus(0, true, 0, 0, toDeleteTime, app1Dir);\r\n    app1Log1Status = new FileStatus(10, false, 1, 1, toDeleteTime, app1Log1);\r\n    when(mockFs.listStatus(userDir)).thenReturn(new FileStatus[] { suffixDirStatus });\r\n    when(mockFs.listStatus(suffixDir)).thenReturn(new FileStatus[] { bucketDirStatus });\r\n    when(mockFs.listStatus(bucketDir)).thenReturn(new FileStatus[] { app1DirStatus });\r\n    when(mockFs.listStatus(app1Dir)).thenReturn(new FileStatus[] { app1Log1Status });\r\n    verify(mockFs, timeout(10000)).delete(app1Dir, true);\r\n    deletionSvc.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testRobustLogDeletion",
  "errType" : null,
  "containingMethodsNum" : 29,
  "sourceCodeText" : "void testRobustLogDeletion() throws Exception\n{\r\n    final long RETENTION_SECS = 10 * 24 * 3600;\r\n    String root = \"mockfs://foo/\";\r\n    String remoteRootLogDir = root + \"tmp/logs\";\r\n    String suffix = \"logs\";\r\n    String newSuffix = LogAggregationUtils.getBucketSuffix() + suffix;\r\n    Configuration conf = new Configuration();\r\n    conf.setClass(\"fs.mockfs.impl\", MockFileSystem.class, FileSystem.class);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_ENABLED, \"true\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_SECONDS, \"864000\");\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_RETAIN_CHECK_INTERVAL_SECONDS, \"1\");\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, remoteRootLogDir);\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX, suffix);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TFile\");\r\n    conf.set(String.format(LOG_AGGREGATION_FILE_CONTROLLER_FMT, \"TFile\"), LogAggregationTFileController.class.getName());\r\n    FileSystem.closeAll();\r\n    Path rootPath = new Path(root);\r\n    FileSystem rootFs = rootPath.getFileSystem(conf);\r\n    FileSystem mockFs = ((FilterFileSystem) rootFs).getRawFileSystem();\r\n    Path remoteRootLogPath = new Path(remoteRootLogDir);\r\n    Path userDir = new Path(remoteRootLogPath, \"me\");\r\n    Path suffixDir = new Path(userDir, newSuffix);\r\n    FileStatus userDirStatus = new FileStatus(0, true, 0, 0, 0, userDir);\r\n    FileStatus suffixStatus = new FileStatus(0, true, 0, 0, 0, suffixDir);\r\n    Path bucketDir = new Path(suffixDir, String.valueOf(0));\r\n    FileStatus bucketDirStatus = new FileStatus(0, true, 0, 0, 0, bucketDir);\r\n    when(mockFs.listStatus(remoteRootLogPath)).thenReturn(new FileStatus[] { userDirStatus });\r\n    when(mockFs.listStatus(userDir)).thenReturn(new FileStatus[] { suffixStatus });\r\n    when(mockFs.listStatus(suffixDir)).thenReturn(new FileStatus[] { bucketDirStatus });\r\n    ApplicationId appId1 = ApplicationId.newInstance(System.currentTimeMillis(), 1);\r\n    Path app1Dir = new Path(bucketDir, appId1.toString());\r\n    FileStatus app1DirStatus = new FileStatus(0, true, 0, 0, 0, app1Dir);\r\n    ApplicationId appId2 = ApplicationId.newInstance(System.currentTimeMillis(), 2);\r\n    Path app2Dir = new Path(bucketDir, \"application_a\");\r\n    FileStatus app2DirStatus = new FileStatus(0, true, 0, 0, 0, app2Dir);\r\n    ApplicationId appId3 = ApplicationId.newInstance(System.currentTimeMillis(), 3);\r\n    Path app3Dir = new Path(bucketDir, appId3.toString());\r\n    FileStatus app3DirStatus = new FileStatus(0, true, 0, 0, 0, app3Dir);\r\n    when(mockFs.listStatus(bucketDir)).thenReturn(new FileStatus[] { app1DirStatus, app2DirStatus, app3DirStatus });\r\n    when(mockFs.listStatus(app2Dir)).thenReturn(new FileStatus[] {});\r\n    when(mockFs.listStatus(app1Dir)).thenThrow(new RuntimeException(\"Should Be Caught and Logged\"));\r\n    Path app3Log3 = new Path(app3Dir, \"host1\");\r\n    FileStatus app3Log3Status = new FileStatus(10, false, 1, 1, 0, app3Log3);\r\n    when(mockFs.listStatus(app3Dir)).thenReturn(new FileStatus[] { app3Log3Status });\r\n    final List<ApplicationId> finishedApplications = Collections.unmodifiableList(Arrays.asList(appId1, appId3));\r\n    ApplicationClientProtocol rmClient = createMockRMClient(finishedApplications, null);\r\n    AggregatedLogDeletionService.LogDeletionTask deletionTask = new AggregatedLogDeletionService.LogDeletionTask(conf, RETENTION_SECS, rmClient);\r\n    deletionTask.run();\r\n    verify(mockFs).delete(app3Dir, true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createMockRMClient",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "ApplicationClientProtocol createMockRMClient(List<ApplicationId> finishedApplicaitons, List<ApplicationId> runningApplications) throws Exception\n{\r\n    final ApplicationClientProtocol mockProtocol = mock(ApplicationClientProtocol.class);\r\n    if (finishedApplicaitons != null && !finishedApplicaitons.isEmpty()) {\r\n        for (ApplicationId appId : finishedApplicaitons) {\r\n            GetApplicationReportRequest request = GetApplicationReportRequest.newInstance(appId);\r\n            GetApplicationReportResponse response = createApplicationReportWithFinishedApplication();\r\n            when(mockProtocol.getApplicationReport(request)).thenReturn(response);\r\n        }\r\n    }\r\n    if (runningApplications != null && !runningApplications.isEmpty()) {\r\n        for (ApplicationId appId : runningApplications) {\r\n            GetApplicationReportRequest request = GetApplicationReportRequest.newInstance(appId);\r\n            GetApplicationReportResponse response = createApplicationReportWithRunningApplication();\r\n            when(mockProtocol.getApplicationReport(request)).thenReturn(response);\r\n        }\r\n    }\r\n    return mockProtocol;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createApplicationReportWithRunningApplication",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "GetApplicationReportResponse createApplicationReportWithRunningApplication()\n{\r\n    ApplicationReport report = mock(ApplicationReport.class);\r\n    when(report.getYarnApplicationState()).thenReturn(YarnApplicationState.RUNNING);\r\n    GetApplicationReportResponse response = mock(GetApplicationReportResponse.class);\r\n    when(response.getApplicationReport()).thenReturn(report);\r\n    return response;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createApplicationReportWithFinishedApplication",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "GetApplicationReportResponse createApplicationReportWithFinishedApplication()\n{\r\n    ApplicationReport report = mock(ApplicationReport.class);\r\n    when(report.getYarnApplicationState()).thenReturn(YarnApplicationState.FINISHED);\r\n    GetApplicationReportResponse response = mock(GetApplicationReportResponse.class);\r\n    when(response.getApplicationReport()).thenReturn(report);\r\n    return response;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertMapEquals",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void assertMapEquals(Map<NodeId, Set<String>> expected, ImmutableMap<NodeId, Set<String>> actual)\n{\r\n    Assert.assertEquals(expected.size(), actual.size());\r\n    for (NodeId k : expected.keySet()) {\r\n        Assert.assertTrue(actual.containsKey(k));\r\n        assertCollectionEquals(expected.get(k), actual.get(k));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertLabelInfoMapEquals",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void assertLabelInfoMapEquals(Map<NodeId, Set<NodeLabel>> expected, ImmutableMap<NodeId, Set<NodeLabel>> actual)\n{\r\n    Assert.assertEquals(expected.size(), actual.size());\r\n    for (NodeId k : expected.keySet()) {\r\n        Assert.assertTrue(actual.containsKey(k));\r\n        assertNLCollectionEquals(expected.get(k), actual.get(k));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertLabelsToNodesEquals",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void assertLabelsToNodesEquals(Map<String, Set<NodeId>> expected, ImmutableMap<String, Set<NodeId>> actual)\n{\r\n    Assert.assertEquals(expected.size(), actual.size());\r\n    for (String k : expected.keySet()) {\r\n        Assert.assertTrue(actual.containsKey(k));\r\n        Set<NodeId> expectedS1 = new HashSet<>(expected.get(k));\r\n        Set<NodeId> actualS2 = new HashSet<>(actual.get(k));\r\n        Assert.assertEquals(expectedS1, actualS2);\r\n        Assert.assertTrue(expectedS1.containsAll(actualS2));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "transposeNodeToLabels",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "ImmutableMap<String, Set<NodeId>> transposeNodeToLabels(Map<NodeId, Set<String>> mapNodeToLabels)\n{\r\n    Map<String, Set<NodeId>> mapLabelsToNodes = new HashMap<>();\r\n    for (Entry<NodeId, Set<String>> entry : mapNodeToLabels.entrySet()) {\r\n        NodeId node = entry.getKey();\r\n        Set<String> setLabels = entry.getValue();\r\n        for (String label : setLabels) {\r\n            Set<NodeId> setNode = mapLabelsToNodes.get(label);\r\n            if (setNode == null) {\r\n                setNode = new HashSet<>();\r\n            }\r\n            setNode.add(NodeId.newInstance(node.getHost(), node.getPort()));\r\n            mapLabelsToNodes.put(label, setNode);\r\n        }\r\n    }\r\n    return ImmutableMap.copyOf(mapLabelsToNodes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertMapContains",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void assertMapContains(Map<NodeId, Set<String>> expected, ImmutableMap<NodeId, Set<String>> actual)\n{\r\n    for (NodeId k : actual.keySet()) {\r\n        Assert.assertTrue(expected.containsKey(k));\r\n        assertCollectionEquals(expected.get(k), actual.get(k));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertCollectionEquals",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void assertCollectionEquals(Collection<String> expected, Collection<String> actual)\n{\r\n    if (expected == null) {\r\n        Assert.assertNull(actual);\r\n    } else {\r\n        Assert.assertNotNull(actual);\r\n    }\r\n    Set<String> expectedSet = new HashSet<>(expected);\r\n    Set<String> actualSet = new HashSet<>(actual);\r\n    Assert.assertEquals(expectedSet, actualSet);\r\n    Assert.assertTrue(expectedSet.containsAll(actualSet));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertNLCollectionEquals",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void assertNLCollectionEquals(Collection<NodeLabel> expected, Collection<NodeLabel> actual)\n{\r\n    if (expected == null) {\r\n        Assert.assertNull(actual);\r\n    } else {\r\n        Assert.assertNotNull(actual);\r\n    }\r\n    Set<NodeLabel> expectedSet = new HashSet<>(expected);\r\n    Set<NodeLabel> actualSet = new HashSet<>(actual);\r\n    Assert.assertEquals(expectedSet, actualSet);\r\n    Assert.assertTrue(expectedSet.containsAll(actualSet));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "toSet",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Set<E> toSet(E... elements)\n{\r\n    Set<E> set = Sets.newHashSet(elements);\r\n    return set;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "toNodeLabelSet",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Set<NodeLabel> toNodeLabelSet(String... nodeLabelsStr)\n{\r\n    if (null == nodeLabelsStr) {\r\n        return null;\r\n    }\r\n    Set<NodeLabel> labels = new HashSet<>();\r\n    for (String label : nodeLabelsStr) {\r\n        labels.add(NodeLabel.newInstance(label));\r\n    }\r\n    return labels;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "toNodeId",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "NodeId toNodeId(String str)\n{\r\n    if (str.contains(\":\")) {\r\n        int idx = str.indexOf(':');\r\n        NodeId id = NodeId.newInstance(str.substring(0, idx), Integer.parseInt(str.substring(idx + 1)));\r\n        return id;\r\n    } else {\r\n        return NodeId.newInstance(str, CommonNodeLabelsManager.WILDCARD_PORT);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertLabelsInfoToNodesEquals",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void assertLabelsInfoToNodesEquals(Map<NodeLabel, Set<NodeId>> expected, ImmutableMap<NodeLabel, Set<NodeId>> actual)\n{\r\n    Assert.assertEquals(expected.size(), actual.size());\r\n    for (NodeLabel k : expected.keySet()) {\r\n        Assert.assertTrue(actual.containsKey(k));\r\n        Set<NodeId> expectedS1 = new HashSet<>(expected.get(k));\r\n        Set<NodeId> actualS2 = new HashSet<>(actual.get(k));\r\n        Assert.assertEquals(expectedS1, actualS2);\r\n        Assert.assertTrue(expectedS1.containsAll(actualS2));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testTimelineEntityGroupId",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testTimelineEntityGroupId()\n{\r\n    ApplicationId appId1 = ApplicationId.newInstance(1234, 1);\r\n    ApplicationId appId2 = ApplicationId.newInstance(1234, 2);\r\n    TimelineEntityGroupId group1 = TimelineEntityGroupId.newInstance(appId1, \"1\");\r\n    TimelineEntityGroupId group2 = TimelineEntityGroupId.newInstance(appId1, \"2\");\r\n    TimelineEntityGroupId group3 = TimelineEntityGroupId.newInstance(appId2, \"1\");\r\n    TimelineEntityGroupId group4 = TimelineEntityGroupId.newInstance(appId1, \"1\");\r\n    Assert.assertTrue(group1.equals(group4));\r\n    Assert.assertFalse(group1.equals(group2));\r\n    Assert.assertFalse(group1.equals(group3));\r\n    Assert.assertTrue(group1.compareTo(group4) == 0);\r\n    Assert.assertTrue(group1.compareTo(group2) < 0);\r\n    Assert.assertTrue(group1.compareTo(group3) < 0);\r\n    Assert.assertTrue(group1.hashCode() == group4.hashCode());\r\n    Assert.assertFalse(group1.hashCode() == group2.hashCode());\r\n    Assert.assertFalse(group1.hashCode() == group3.hashCode());\r\n    Assert.assertEquals(\"timelineEntityGroupId_1234_1_1\", group1.toString());\r\n    Assert.assertEquals(TimelineEntityGroupId.fromString(\"timelineEntityGroupId_1234_1_1\"), group1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setup()\n{\r\n    sw = new StringWriter();\r\n    pw = new PrintWriter(sw);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testMultilineInfoBlock",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testMultilineInfoBlock() throws Exception\n{\r\n    WebAppTests.testBlock(MultilineInfoBlock.class);\r\n    TestInfoBlock.pw.flush();\r\n    String output = TestInfoBlock.sw.toString().replaceAll(\" +\", \" \");\r\n    String expectedMultilineData1 = String.format(\"<tr class=\\\"odd\\\">%n\" + \" <th>%n Multiple_line_value%n </th>%n\" + \" <td>%n This is one line.%n </td>%n\");\r\n    String expectedMultilineData2 = String.format(\"<tr class=\\\"even\\\">%n\" + \" <th>%n Multiple_line_value%n </th>%n <td>%n <div>%n\" + \" This is first line.%n </div>%n <div>%n\" + \" This is second line.%n </div>%n\");\r\n    assertTrue(output.contains(expectedMultilineData1) && output.contains(expectedMultilineData2));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testJavaScriptInfoBlock",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testJavaScriptInfoBlock() throws Exception\n{\r\n    WebAppTests.testBlock(JavaScriptInfoBlock.class);\r\n    TestInfoBlock.pw.flush();\r\n    String output = TestInfoBlock.sw.toString();\r\n    assertFalse(output.contains(\"<script>\"));\r\n    assertTrue(output.contains(JAVASCRIPT_ESCAPED));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testUnknownExceptionUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testUnknownExceptionUnwrapping()\n{\r\n    Class<? extends Throwable> exception = YarnException.class;\r\n    String className = \"UnknownException.class\";\r\n    verifyRemoteExceptionUnwrapping(exception, className);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRemoteIOExceptionUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoteIOExceptionUnwrapping()\n{\r\n    Class<? extends Throwable> exception = IOException.class;\r\n    verifyRemoteExceptionUnwrapping(exception, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRemoteIOExceptionDerivativeUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoteIOExceptionDerivativeUnwrapping()\n{\r\n    Class<? extends Throwable> exception = FileNotFoundException.class;\r\n    verifyRemoteExceptionUnwrapping(exception, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRemoteYarnExceptionUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoteYarnExceptionUnwrapping()\n{\r\n    Class<? extends Throwable> exception = YarnException.class;\r\n    verifyRemoteExceptionUnwrapping(exception, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRemoteYarnExceptionDerivativeUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoteYarnExceptionDerivativeUnwrapping()\n{\r\n    Class<? extends Throwable> exception = YarnTestException.class;\r\n    verifyRemoteExceptionUnwrapping(exception, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRemoteRuntimeExceptionUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoteRuntimeExceptionUnwrapping()\n{\r\n    Class<? extends Throwable> exception = NullPointerException.class;\r\n    verifyRemoteExceptionUnwrapping(exception, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testUnexpectedRemoteExceptionUnwrapping",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testUnexpectedRemoteExceptionUnwrapping()\n{\r\n    Class<? extends Throwable> exception = Exception.class;\r\n    verifyRemoteExceptionUnwrapping(RemoteException.class, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRemoteYarnExceptionWithoutStringConstructor",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoteYarnExceptionWithoutStringConstructor()\n{\r\n    Class<? extends Throwable> exception = YarnTestExceptionNoConstructor.class;\r\n    verifyRemoteExceptionUnwrapping(RemoteException.class, exception.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRPCServiceExceptionUnwrapping",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRPCServiceExceptionUnwrapping()\n{\r\n    String message = \"ServiceExceptionMessage\";\r\n    ServiceException se = new ServiceException(message);\r\n    Throwable t = null;\r\n    try {\r\n        RPCUtil.unwrapAndThrowException(se);\r\n    } catch (Throwable thrown) {\r\n        t = thrown;\r\n    }\r\n    Assert.assertTrue(IOException.class.isInstance(t));\r\n    Assert.assertTrue(t.getMessage().contains(message));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRPCIOExceptionUnwrapping",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRPCIOExceptionUnwrapping()\n{\r\n    String message = \"DirectIOExceptionMessage\";\r\n    IOException ioException = new FileNotFoundException(message);\r\n    ServiceException se = new ServiceException(ioException);\r\n    Throwable t = null;\r\n    try {\r\n        RPCUtil.unwrapAndThrowException(se);\r\n    } catch (Throwable thrown) {\r\n        t = thrown;\r\n    }\r\n    Assert.assertTrue(FileNotFoundException.class.isInstance(t));\r\n    Assert.assertTrue(t.getMessage().contains(message));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "testRPCRuntimeExceptionUnwrapping",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRPCRuntimeExceptionUnwrapping()\n{\r\n    String message = \"RPCRuntimeExceptionUnwrapping\";\r\n    RuntimeException re = new NullPointerException(message);\r\n    ServiceException se = new ServiceException(re);\r\n    Throwable t = null;\r\n    try {\r\n        RPCUtil.unwrapAndThrowException(se);\r\n    } catch (Throwable thrown) {\r\n        t = thrown;\r\n    }\r\n    Assert.assertTrue(NullPointerException.class.isInstance(t));\r\n    Assert.assertTrue(t.getMessage().contains(message));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\ipc",
  "methodName" : "verifyRemoteExceptionUnwrapping",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void verifyRemoteExceptionUnwrapping(Class<? extends Throwable> expectedLocalException, String realExceptionClassName)\n{\r\n    String message = realExceptionClassName + \"Message\";\r\n    RemoteException re = new RemoteException(realExceptionClassName, message);\r\n    ServiceException se = new ServiceException(re);\r\n    Throwable t = null;\r\n    try {\r\n        RPCUtil.unwrapAndThrowException(se);\r\n    } catch (Throwable thrown) {\r\n        t = thrown;\r\n    }\r\n    Assert.assertTrue(\"Expected exception [\" + expectedLocalException + \"] but found \" + t, expectedLocalException.isInstance(t));\r\n    Assert.assertTrue(\"Expected message [\" + message + \"] but found \" + t.getMessage(), t.getMessage().contains(message));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "initNodeLabelStore",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initNodeLabelStore(Configuration conf)\n{\r\n    this.store = new NodeLabelsStore() {\r\n\r\n        @Override\r\n        public void recover() throws IOException {\r\n        }\r\n\r\n        @Override\r\n        public void init(Configuration conf, CommonNodeLabelsManager mgr) throws Exception {\r\n        }\r\n\r\n        @Override\r\n        public void removeClusterNodeLabels(Collection<String> labels) throws IOException {\r\n            lastRemovedlabels = labels;\r\n        }\r\n\r\n        @Override\r\n        public void updateNodeToLabelsMappings(Map<NodeId, Set<String>> nodeToLabels) throws IOException {\r\n            lastNodeToLabels = nodeToLabels;\r\n        }\r\n\r\n        @Override\r\n        public void storeNewClusterNodeLabels(List<NodeLabel> label) throws IOException {\r\n            lastAddedlabels = label;\r\n        }\r\n\r\n        @Override\r\n        public void close() throws IOException {\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "initDispatcher",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initDispatcher(Configuration conf)\n{\r\n    super.dispatcher = new InlineDispatcher();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "startDispatcher",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void startDispatcher()\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "stopDispatcher",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void stopDispatcher()\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "serviceStop",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void serviceStop() throws Exception\n{\r\n    super.serviceStop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testAttributeValueAddition",
  "errType" : [ "Exception", "Exception" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testAttributeValueAddition()\n{\r\n    String[] values = new String[] { \"1_8\", \"1.8\", \"ABZ\", \"ABZ\", \"az\", \"a-z\", \"a_z\", \"123456789\" };\r\n    for (String val : values) {\r\n        try {\r\n            NodeLabelUtil.checkAndThrowAttributeValue(val);\r\n        } catch (Exception e) {\r\n            fail(\"Valid values for NodeAttributeValue :\" + val);\r\n        }\r\n    }\r\n    String[] invalidVals = new String[] { \"_18\", \"1,8\", \"1/5\", \".15\", \"1\\\\5\" };\r\n    for (String val : invalidVals) {\r\n        try {\r\n            NodeLabelUtil.checkAndThrowAttributeValue(val);\r\n            fail(\"Valid values for NodeAttributeValue :\" + val);\r\n        } catch (Exception e) {\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testIsNodeAttributesEquals",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testIsNodeAttributesEquals()\n{\r\n    NodeAttribute nodeAttributeCK1V1 = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, \"K1\", NodeAttributeType.STRING, \"V1\");\r\n    NodeAttribute nodeAttributeCK1V1Copy = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, \"K1\", NodeAttributeType.STRING, \"V1\");\r\n    NodeAttribute nodeAttributeDK1V1 = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, \"K1\", NodeAttributeType.STRING, \"V1\");\r\n    NodeAttribute nodeAttributeDK1V1Copy = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, \"K1\", NodeAttributeType.STRING, \"V1\");\r\n    NodeAttribute nodeAttributeDK2V1 = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, \"K2\", NodeAttributeType.STRING, \"V1\");\r\n    NodeAttribute nodeAttributeDK2V2 = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, \"K2\", NodeAttributeType.STRING, \"V2\");\r\n    Assert.assertTrue(NodeLabelUtil.isNodeAttributesEquals(null, null));\r\n    Assert.assertTrue(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(), ImmutableSet.of()));\r\n    Assert.assertTrue(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeCK1V1), ImmutableSet.of(nodeAttributeCK1V1Copy)));\r\n    Assert.assertTrue(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeDK1V1), ImmutableSet.of(nodeAttributeDK1V1Copy)));\r\n    Assert.assertTrue(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeCK1V1, nodeAttributeDK1V1), ImmutableSet.of(nodeAttributeCK1V1Copy, nodeAttributeDK1V1Copy)));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(null, ImmutableSet.of()));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(), null));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeCK1V1), ImmutableSet.of(nodeAttributeDK1V1)));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeDK1V1), ImmutableSet.of(nodeAttributeDK2V1)));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeDK2V1), ImmutableSet.of(nodeAttributeDK2V2)));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeCK1V1), ImmutableSet.of()));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeCK1V1), ImmutableSet.of(nodeAttributeCK1V1, nodeAttributeDK1V1)));\r\n    Assert.assertFalse(NodeLabelUtil.isNodeAttributesEquals(ImmutableSet.of(nodeAttributeCK1V1, nodeAttributeDK1V1), ImmutableSet.of(nodeAttributeDK1V1)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testNMTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNMTokenIdentifier() throws IOException\n{\r\n    testNMTokenIdentifier(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testNMTokenIdentifierOldFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNMTokenIdentifierOldFormat() throws IOException\n{\r\n    testNMTokenIdentifier(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testNMTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testNMTokenIdentifier(boolean oldFormat) throws IOException\n{\r\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(ApplicationId.newInstance(1, 1), 1);\r\n    NodeId nodeId = NodeId.newInstance(\"host0\", 0);\r\n    String applicationSubmitter = \"usr0\";\r\n    int masterKeyId = 1;\r\n    NMTokenIdentifier token = new NMTokenIdentifier(appAttemptId, nodeId, applicationSubmitter, masterKeyId);\r\n    NMTokenIdentifier anotherToken = new NMTokenIdentifier();\r\n    byte[] tokenContent;\r\n    if (oldFormat) {\r\n        tokenContent = writeInOldFormat(token);\r\n    } else {\r\n        tokenContent = token.getBytes();\r\n    }\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(\"Token is not the same after serialization \" + \"and deserialization.\", token, anotherToken);\r\n    Assert.assertEquals(\"appAttemptId from proto is not the same with original token\", anotherToken.getApplicationAttemptId(), appAttemptId);\r\n    Assert.assertEquals(\"NodeId from proto is not the same with original token\", anotherToken.getNodeId(), nodeId);\r\n    Assert.assertEquals(\"applicationSubmitter from proto is not the same with original token\", anotherToken.getApplicationSubmitter(), applicationSubmitter);\r\n    Assert.assertEquals(\"masterKeyId from proto is not the same with original token\", anotherToken.getKeyId(), masterKeyId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testAMRMTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAMRMTokenIdentifier() throws IOException\n{\r\n    testAMRMTokenIdentifier(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testAMRMTokenIdentifierOldFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAMRMTokenIdentifierOldFormat() throws IOException\n{\r\n    testAMRMTokenIdentifier(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testAMRMTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testAMRMTokenIdentifier(boolean oldFormat) throws IOException\n{\r\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(ApplicationId.newInstance(1, 1), 1);\r\n    int masterKeyId = 1;\r\n    AMRMTokenIdentifier token = new AMRMTokenIdentifier(appAttemptId, masterKeyId);\r\n    AMRMTokenIdentifier anotherToken = new AMRMTokenIdentifier();\r\n    byte[] tokenContent;\r\n    if (oldFormat) {\r\n        tokenContent = writeInOldFormat(token);\r\n    } else {\r\n        tokenContent = token.getBytes();\r\n    }\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(\"Token is not the same after serialization \" + \"and deserialization.\", token, anotherToken);\r\n    Assert.assertEquals(\"ApplicationAttemptId from proto is not the same with original token\", anotherToken.getApplicationAttemptId(), appAttemptId);\r\n    Assert.assertEquals(\"masterKeyId from proto is not the same with original token\", anotherToken.getKeyId(), masterKeyId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testClientToAMTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testClientToAMTokenIdentifier() throws IOException\n{\r\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(ApplicationId.newInstance(1, 1), 1);\r\n    String clientName = \"user\";\r\n    ClientToAMTokenIdentifier token = new ClientToAMTokenIdentifier(appAttemptId, clientName);\r\n    ClientToAMTokenIdentifier anotherToken = new ClientToAMTokenIdentifier();\r\n    byte[] tokenContent = token.getBytes();\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(\"Token is not the same after serialization \" + \"and deserialization.\", token, anotherToken);\r\n    Assert.assertEquals(\"ApplicationAttemptId from proto is not the same with original token\", anotherToken.getApplicationAttemptID(), appAttemptId);\r\n    Assert.assertEquals(\"clientName from proto is not the same with original token\", anotherToken.getClientName(), clientName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testContainerTokenIdentifierProtoMissingFields",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testContainerTokenIdentifierProtoMissingFields() throws IOException\n{\r\n    ContainerTokenIdentifierProto.Builder builder = ContainerTokenIdentifierProto.newBuilder();\r\n    ContainerTokenIdentifierProto proto = builder.build();\r\n    Assert.assertFalse(proto.hasContainerType());\r\n    Assert.assertFalse(proto.hasExecutionType());\r\n    Assert.assertFalse(proto.hasNodeLabelExpression());\r\n    byte[] tokenData = proto.toByteArray();\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenData, tokenData.length);\r\n    ContainerTokenIdentifier tid = new ContainerTokenIdentifier();\r\n    tid.readFields(dib);\r\n    Assert.assertEquals(\"container type\", ContainerType.TASK, tid.getContainerType());\r\n    Assert.assertEquals(\"execution type\", ExecutionType.GUARANTEED, tid.getExecutionType());\r\n    Assert.assertEquals(\"node label expression\", CommonNodeLabelsManager.NO_LABEL, tid.getNodeLabelExpression());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testContainerTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerTokenIdentifier() throws IOException\n{\r\n    testContainerTokenIdentifier(false, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testContainerTokenIdentifierOldFormat",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testContainerTokenIdentifierOldFormat() throws IOException\n{\r\n    testContainerTokenIdentifier(true, true);\r\n    testContainerTokenIdentifier(true, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testContainerTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testContainerTokenIdentifier(boolean oldFormat, boolean withLogAggregation) throws IOException\n{\r\n    ContainerId containerID = ContainerId.newContainerId(ApplicationAttemptId.newInstance(ApplicationId.newInstance(1, 1), 1), 1);\r\n    String hostName = \"host0\";\r\n    String appSubmitter = \"usr0\";\r\n    Resource r = Resource.newInstance(1024, 1);\r\n    long expiryTimeStamp = 1000;\r\n    int masterKeyId = 1;\r\n    long rmIdentifier = 1;\r\n    Priority priority = Priority.newInstance(1);\r\n    long creationTime = 1000;\r\n    ContainerTokenIdentifier token = new ContainerTokenIdentifier(containerID, hostName, appSubmitter, r, expiryTimeStamp, masterKeyId, rmIdentifier, priority, creationTime);\r\n    ContainerTokenIdentifier anotherToken = new ContainerTokenIdentifier();\r\n    byte[] tokenContent;\r\n    if (oldFormat) {\r\n        tokenContent = writeInOldFormat(token, withLogAggregation);\r\n    } else {\r\n        tokenContent = token.getBytes();\r\n    }\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(\"Token is not the same after serialization \" + \"and deserialization.\", token, anotherToken);\r\n    Assert.assertEquals(\"ContainerID from proto is not the same with original token\", anotherToken.getContainerID(), containerID);\r\n    Assert.assertEquals(\"Hostname from proto is not the same with original token\", anotherToken.getNmHostAddress(), hostName);\r\n    Assert.assertEquals(\"ApplicationSubmitter from proto is not the same with original token\", anotherToken.getApplicationSubmitter(), appSubmitter);\r\n    Assert.assertEquals(\"Resource from proto is not the same with original token\", anotherToken.getResource(), r);\r\n    Assert.assertEquals(\"expiryTimeStamp from proto is not the same with original token\", anotherToken.getExpiryTimeStamp(), expiryTimeStamp);\r\n    Assert.assertEquals(\"KeyId from proto is not the same with original token\", anotherToken.getMasterKeyId(), masterKeyId);\r\n    Assert.assertEquals(\"RMIdentifier from proto is not the same with original token\", anotherToken.getRMIdentifier(), rmIdentifier);\r\n    Assert.assertEquals(\"Priority from proto is not the same with original token\", anotherToken.getPriority(), priority);\r\n    Assert.assertEquals(\"CreationTime from proto is not the same with original token\", anotherToken.getCreationTime(), creationTime);\r\n    Assert.assertNull(anotherToken.getLogAggregationContext());\r\n    Assert.assertEquals(CommonNodeLabelsManager.NO_LABEL, anotherToken.getNodeLabelExpression());\r\n    Assert.assertEquals(ContainerType.TASK, anotherToken.getContainerType());\r\n    Assert.assertEquals(ExecutionType.GUARANTEED, anotherToken.getExecutionType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testRMDelegationTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRMDelegationTokenIdentifier() throws IOException\n{\r\n    testRMDelegationTokenIdentifier(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testRMDelegationTokenIdentifierOldFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRMDelegationTokenIdentifierOldFormat() throws IOException\n{\r\n    testRMDelegationTokenIdentifier(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testRMDelegationTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 28,
  "sourceCodeText" : "void testRMDelegationTokenIdentifier(boolean oldFormat) throws IOException\n{\r\n    Text owner = new Text(\"user1\");\r\n    Text renewer = new Text(\"user2\");\r\n    Text realUser = new Text(\"user3\");\r\n    long issueDate = 1;\r\n    long maxDate = 2;\r\n    int sequenceNumber = 3;\r\n    int masterKeyId = 4;\r\n    RMDelegationTokenIdentifier originalToken = new RMDelegationTokenIdentifier(owner, renewer, realUser);\r\n    originalToken.setIssueDate(issueDate);\r\n    originalToken.setMaxDate(maxDate);\r\n    originalToken.setSequenceNumber(sequenceNumber);\r\n    originalToken.setMasterKeyId(masterKeyId);\r\n    RMDelegationTokenIdentifier anotherToken = new RMDelegationTokenIdentifier();\r\n    if (oldFormat) {\r\n        DataInputBuffer inBuf = new DataInputBuffer();\r\n        DataOutputBuffer outBuf = new DataOutputBuffer();\r\n        originalToken.writeInOldFormat(outBuf);\r\n        inBuf.reset(outBuf.getData(), 0, outBuf.getLength());\r\n        anotherToken.readFieldsInOldFormat(inBuf);\r\n        inBuf.close();\r\n    } else {\r\n        byte[] tokenContent = originalToken.getBytes();\r\n        DataInputBuffer dib = new DataInputBuffer();\r\n        dib.reset(tokenContent, tokenContent.length);\r\n        anotherToken.readFields(dib);\r\n        dib.close();\r\n    }\r\n    Assert.assertEquals(\"Token is not the same after serialization and deserialization.\", originalToken, anotherToken);\r\n    Assert.assertEquals(\"owner from proto is not the same with original token\", owner, anotherToken.getOwner());\r\n    Assert.assertEquals(\"renewer from proto is not the same with original token\", renewer, anotherToken.getRenewer());\r\n    Assert.assertEquals(\"realUser from proto is not the same with original token\", realUser, anotherToken.getRealUser());\r\n    Assert.assertEquals(\"issueDate from proto is not the same with original token\", issueDate, anotherToken.getIssueDate());\r\n    Assert.assertEquals(\"maxDate from proto is not the same with original token\", maxDate, anotherToken.getMaxDate());\r\n    Assert.assertEquals(\"sequenceNumber from proto is not the same with original token\", sequenceNumber, anotherToken.getSequenceNumber());\r\n    Assert.assertEquals(\"masterKeyId from proto is not the same with original token\", masterKeyId, anotherToken.getMasterKeyId());\r\n    YARNDelegationTokenIdentifierProto tokenProto = originalToken.getProto();\r\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n    DataOutputStream out = new DataOutputStream(baos);\r\n    tokenProto.writeTo(out);\r\n    byte[] tokenData = baos.toByteArray();\r\n    RMDelegationTokenIdentifier readToken = new RMDelegationTokenIdentifier();\r\n    DataInputBuffer db = new DataInputBuffer();\r\n    db.reset(tokenData, tokenData.length);\r\n    readToken.readFields(db);\r\n    Assert.assertEquals(\"Token from getProto is not the same after \" + \"serialization and deserialization.\", originalToken, readToken);\r\n    db.close();\r\n    out.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testTimelineDelegationTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testTimelineDelegationTokenIdentifier() throws IOException\n{\r\n    Text owner = new Text(\"user1\");\r\n    Text renewer = new Text(\"user2\");\r\n    Text realUser = new Text(\"user3\");\r\n    long issueDate = 1;\r\n    long maxDate = 2;\r\n    int sequenceNumber = 3;\r\n    int masterKeyId = 4;\r\n    TimelineDelegationTokenIdentifier token = new TimelineDelegationTokenIdentifier(owner, renewer, realUser);\r\n    token.setIssueDate(issueDate);\r\n    token.setMaxDate(maxDate);\r\n    token.setSequenceNumber(sequenceNumber);\r\n    token.setMasterKeyId(masterKeyId);\r\n    TimelineDelegationTokenIdentifier anotherToken = new TimelineDelegationTokenIdentifier();\r\n    byte[] tokenContent = token.getBytes();\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(\"Token is not the same after serialization \" + \"and deserialization.\", token, anotherToken);\r\n    Assert.assertEquals(\"owner from proto is not the same with original token\", anotherToken.getOwner(), owner);\r\n    Assert.assertEquals(\"renewer from proto is not the same with original token\", anotherToken.getRenewer(), renewer);\r\n    Assert.assertEquals(\"realUser from proto is not the same with original token\", anotherToken.getRealUser(), realUser);\r\n    Assert.assertEquals(\"issueDate from proto is not the same with original token\", anotherToken.getIssueDate(), issueDate);\r\n    Assert.assertEquals(\"maxDate from proto is not the same with original token\", anotherToken.getMaxDate(), maxDate);\r\n    Assert.assertEquals(\"sequenceNumber from proto is not the same with original token\", anotherToken.getSequenceNumber(), sequenceNumber);\r\n    Assert.assertEquals(\"masterKeyId from proto is not the same with original token\", anotherToken.getMasterKeyId(), masterKeyId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testParseTimelineDelegationTokenIdentifierRenewer",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testParseTimelineDelegationTokenIdentifierRenewer() throws IOException\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTH_TO_LOCAL, \"RULE:[2:$1@$0]([nr]m@.*EXAMPLE.COM)s/.*/yarn/\");\r\n    HadoopKerberosName.setConfiguration(conf);\r\n    Text owner = new Text(\"owner\");\r\n    Text renewer = new Text(\"rm/localhost@EXAMPLE.COM\");\r\n    Text realUser = new Text(\"realUser\");\r\n    TimelineDelegationTokenIdentifier token = new TimelineDelegationTokenIdentifier(owner, renewer, realUser);\r\n    Assert.assertEquals(new Text(\"yarn\"), token.getRenewer());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testAMContainerTokenIdentifier",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testAMContainerTokenIdentifier() throws IOException\n{\r\n    ContainerId containerID = ContainerId.newContainerId(ApplicationAttemptId.newInstance(ApplicationId.newInstance(1, 1), 1), 1);\r\n    String hostName = \"host0\";\r\n    String appSubmitter = \"usr0\";\r\n    Resource r = Resource.newInstance(1024, 1);\r\n    long expiryTimeStamp = 1000;\r\n    int masterKeyId = 1;\r\n    long rmIdentifier = 1;\r\n    Priority priority = Priority.newInstance(1);\r\n    long creationTime = 1000;\r\n    ContainerTokenIdentifier token = new ContainerTokenIdentifier(containerID, hostName, appSubmitter, r, expiryTimeStamp, masterKeyId, rmIdentifier, priority, creationTime, null, CommonNodeLabelsManager.NO_LABEL, ContainerType.APPLICATION_MASTER);\r\n    ContainerTokenIdentifier anotherToken = new ContainerTokenIdentifier();\r\n    byte[] tokenContent = token.getBytes();\r\n    DataInputBuffer dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(ContainerType.APPLICATION_MASTER, anotherToken.getContainerType());\r\n    Assert.assertEquals(ExecutionType.GUARANTEED, anotherToken.getExecutionType());\r\n    token = new ContainerTokenIdentifier(containerID, 0, hostName, appSubmitter, r, expiryTimeStamp, masterKeyId, rmIdentifier, priority, creationTime, null, CommonNodeLabelsManager.NO_LABEL, ContainerType.TASK, ExecutionType.OPPORTUNISTIC);\r\n    anotherToken = new ContainerTokenIdentifier();\r\n    tokenContent = token.getBytes();\r\n    dib = new DataInputBuffer();\r\n    dib.reset(tokenContent, tokenContent.length);\r\n    anotherToken.readFields(dib);\r\n    Assert.assertEquals(ContainerType.TASK, anotherToken.getContainerType());\r\n    Assert.assertEquals(ExecutionType.OPPORTUNISTIC, anotherToken.getExecutionType());\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "writeInOldFormat",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "byte[] writeInOldFormat(ContainerTokenIdentifier token, boolean withLogAggregation) throws IOException\n{\r\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n    DataOutputStream out = new DataOutputStream(baos);\r\n    ApplicationAttemptId applicationAttemptId = token.getContainerID().getApplicationAttemptId();\r\n    ApplicationId applicationId = applicationAttemptId.getApplicationId();\r\n    out.writeLong(applicationId.getClusterTimestamp());\r\n    out.writeInt(applicationId.getId());\r\n    out.writeInt(applicationAttemptId.getAttemptId());\r\n    out.writeLong(token.getContainerID().getContainerId());\r\n    out.writeUTF(token.getNmHostAddress());\r\n    out.writeUTF(token.getApplicationSubmitter());\r\n    out.writeInt(token.getResource().getMemory());\r\n    out.writeInt(token.getResource().getVirtualCores());\r\n    out.writeLong(token.getExpiryTimeStamp());\r\n    out.writeInt(token.getMasterKeyId());\r\n    out.writeLong(token.getRMIdentifier());\r\n    out.writeInt(token.getPriority().getPriority());\r\n    out.writeLong(token.getCreationTime());\r\n    if (withLogAggregation) {\r\n        if (token.getLogAggregationContext() == null) {\r\n            out.writeInt(-1);\r\n        } else {\r\n            byte[] logAggregationContext = ((LogAggregationContextPBImpl) token.getLogAggregationContext()).getProto().toByteArray();\r\n            out.writeInt(logAggregationContext.length);\r\n            out.write(logAggregationContext);\r\n        }\r\n    }\r\n    out.close();\r\n    return baos.toByteArray();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "writeInOldFormat",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "byte[] writeInOldFormat(NMTokenIdentifier token) throws IOException\n{\r\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n    DataOutputStream out = new DataOutputStream(baos);\r\n    ApplicationId applicationId = token.getApplicationAttemptId().getApplicationId();\r\n    out.writeLong(applicationId.getClusterTimestamp());\r\n    out.writeInt(applicationId.getId());\r\n    out.writeInt(token.getApplicationAttemptId().getAttemptId());\r\n    out.writeUTF(token.getNodeId().toString());\r\n    out.writeUTF(token.getApplicationSubmitter());\r\n    out.writeInt(token.getKeyId());\r\n    out.close();\r\n    return baos.toByteArray();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "writeInOldFormat",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "byte[] writeInOldFormat(AMRMTokenIdentifier token) throws IOException\n{\r\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n    DataOutputStream out = new DataOutputStream(baos);\r\n    ApplicationId applicationId = token.getApplicationAttemptId().getApplicationId();\r\n    out.writeLong(applicationId.getClusterTimestamp());\r\n    out.writeInt(applicationId.getId());\r\n    out.writeInt(token.getApplicationAttemptId().getAttemptId());\r\n    out.writeInt(token.getKeyId());\r\n    out.close();\r\n    return baos.toByteArray();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createContainerLogFileInRemoteFS",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void createContainerLogFileInRemoteFS(Configuration conf, FileSystem fs, String rootLogDir, ApplicationId appId, Map<ContainerId, String> containerToContent, NodeId nodeId, String fileName, String user, boolean deleteRemoteLogDir) throws Exception\n{\r\n    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(user);\r\n    List<String> rootLogDirList = new ArrayList<String>();\r\n    rootLogDirList.add(rootLogDir);\r\n    Path rootLogDirPath = new Path(rootLogDir);\r\n    if (fs.exists(rootLogDirPath)) {\r\n        fs.delete(rootLogDirPath, true);\r\n    }\r\n    assertTrue(fs.mkdirs(rootLogDirPath));\r\n    Path appLogsDir = new Path(rootLogDirPath, appId.toString());\r\n    if (fs.exists(appLogsDir)) {\r\n        fs.delete(appLogsDir, true);\r\n    }\r\n    assertTrue(fs.mkdirs(appLogsDir));\r\n    createContainerLogInLocalDir(appLogsDir, containerToContent, fs, fileName);\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(conf);\r\n    LogAggregationFileController fileController = factory.getFileControllerForWrite();\r\n    Path path = fileController.getRemoteAppLogDir(appId, user);\r\n    if (fs.exists(path) && deleteRemoteLogDir) {\r\n        fs.delete(path, true);\r\n    }\r\n    assertTrue(fs.mkdirs(path));\r\n    uploadContainerLogIntoRemoteDir(ugi, conf, rootLogDirList, nodeId, appId, containerToContent.keySet(), path);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createContainerLogInLocalDir",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void createContainerLogInLocalDir(Path appLogsDir, Map<ContainerId, String> containerToContent, FileSystem fs, String fileName) throws IOException\n{\r\n    for (Map.Entry<ContainerId, String> containerAndContent : containerToContent.entrySet()) {\r\n        ContainerId containerId = containerAndContent.getKey();\r\n        String content = containerAndContent.getValue();\r\n        Path containerLogsDir = new Path(appLogsDir, containerId.toString());\r\n        if (fs.exists(containerLogsDir)) {\r\n            fs.delete(containerLogsDir, true);\r\n        }\r\n        assertTrue(fs.mkdirs(containerLogsDir));\r\n        Writer writer = new FileWriter(new File(containerLogsDir.toString(), fileName));\r\n        writer.write(content);\r\n        writer.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "uploadContainerLogIntoRemoteDir",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void uploadContainerLogIntoRemoteDir(UserGroupInformation ugi, Configuration configuration, List<String> rootLogDirs, NodeId nodeId, ApplicationId appId, Iterable<ContainerId> containerIds, Path appDir) throws Exception\n{\r\n    Path path = new Path(appDir, LogAggregationUtils.getNodeString(nodeId));\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(configuration);\r\n    LogAggregationFileController fileController = factory.getFileControllerForWrite();\r\n    try {\r\n        Map<ApplicationAccessType, String> appAcls = new HashMap<>();\r\n        appAcls.put(ApplicationAccessType.VIEW_APP, ugi.getUserName());\r\n        LogAggregationFileControllerContext context = new LogAggregationFileControllerContext(path, path, true, 1000, appId, appAcls, nodeId, ugi);\r\n        fileController.initializeWriter(context);\r\n        for (ContainerId containerId : containerIds) {\r\n            fileController.write(new AggregatedLogFormat.LogKey(containerId), new AggregatedLogFormat.LogValue(rootLogDirs, containerId, ugi.getShortUserName()));\r\n        }\r\n    } finally {\r\n        fileController.closeWriter();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDumpingSchedulerLogs",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testDumpingSchedulerLogs() throws Exception\n{\r\n    Map<Appender, Priority> levels = new HashMap<>();\r\n    String logFilename = \"test.log\";\r\n    Logger logger = LoggerFactory.getLogger(TestAdHocLogDumper.class);\r\n    if (isLog4jLogger(this.getClass())) {\r\n        for (Enumeration appenders = LogManager.getRootLogger().getAllAppenders(); appenders.hasMoreElements(); ) {\r\n            Object obj = appenders.nextElement();\r\n            if (obj instanceof AppenderSkeleton) {\r\n                AppenderSkeleton appender = (AppenderSkeleton) obj;\r\n                levels.put(appender, appender.getThreshold());\r\n            }\r\n        }\r\n    }\r\n    AdHocLogDumper dumper = new AdHocLogDumper(this.getClass().getName(), logFilename);\r\n    dumper.dumpLogs(\"DEBUG\", 1000);\r\n    LOG.debug(\"test message 1\");\r\n    LOG.info(\"test message 2\");\r\n    File logFile = new File(logFilename);\r\n    Assert.assertTrue(logFile.exists());\r\n    Thread.sleep(2000);\r\n    long lastWrite = logFile.lastModified();\r\n    Assert.assertTrue(lastWrite < Time.now());\r\n    Assert.assertTrue(logFile.length() != 0);\r\n    if (isLog4jLogger(this.getClass())) {\r\n        for (Enumeration appenders = LogManager.getRootLogger().getAllAppenders(); appenders.hasMoreElements(); ) {\r\n            Object obj = appenders.nextElement();\r\n            if (obj instanceof AppenderSkeleton) {\r\n                AppenderSkeleton appender = (AppenderSkeleton) obj;\r\n                Assert.assertEquals(levels.get(appender), appender.getThreshold());\r\n            }\r\n        }\r\n    }\r\n    boolean del = logFile.delete();\r\n    if (!del) {\r\n        LOG.info(\"Couldn't clean up after test\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testEqualsOnExecutionTypeRequest",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testEqualsOnExecutionTypeRequest()\n{\r\n    ResourceRequest resourceRequestA = ResourceRequest.newInstance(Priority.newInstance(0), \"localhost\", Resource.newInstance(1024, 1), 1, false, \"\", ExecutionTypeRequest.newInstance(ExecutionType.GUARANTEED, true));\r\n    ResourceRequest resourceRequestB = ResourceRequest.newInstance(Priority.newInstance(0), \"localhost\", Resource.newInstance(1024, 1), 1, false, \"\", ExecutionTypeRequest.newInstance(ExecutionType.GUARANTEED, false));\r\n    Assert.assertFalse(resourceRequestA.equals(resourceRequestB));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testNegativeStartTimes",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testNegativeStartTimes()\n{\r\n    long elapsed = Times.elapsed(-5, 10, true);\r\n    Assert.assertEquals(\"Elapsed time is not 0\", 0, elapsed);\r\n    elapsed = Times.elapsed(-5, 10, false);\r\n    Assert.assertEquals(\"Elapsed time is not -1\", -1, elapsed);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testNegativeFinishTimes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testNegativeFinishTimes()\n{\r\n    long elapsed = Times.elapsed(5, -10, false);\r\n    Assert.assertEquals(\"Elapsed time is not -1\", -1, elapsed);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testNegativeStartandFinishTimes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testNegativeStartandFinishTimes()\n{\r\n    long elapsed = Times.elapsed(-5, -10, false);\r\n    Assert.assertEquals(\"Elapsed time is not -1\", -1, elapsed);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testPositiveStartandFinishTimes",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPositiveStartandFinishTimes()\n{\r\n    long elapsed = Times.elapsed(5, 10, true);\r\n    Assert.assertEquals(\"Elapsed time is not 5\", 5, elapsed);\r\n    elapsed = Times.elapsed(5, 10, false);\r\n    Assert.assertEquals(\"Elapsed time is not 5\", 5, elapsed);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testFinishTimesAheadOfStartTimes",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testFinishTimesAheadOfStartTimes()\n{\r\n    long elapsed = Times.elapsed(10, 5, true);\r\n    Assert.assertEquals(\"Elapsed time is not -1\", -1, elapsed);\r\n    elapsed = Times.elapsed(10, 5, false);\r\n    Assert.assertEquals(\"Elapsed time is not -1\", -1, elapsed);\r\n    elapsed = Times.elapsed(Long.MAX_VALUE, 0, true);\r\n    Assert.assertEquals(\"Elapsed time is not -1\", -1, elapsed);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testUsual",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testUsual()\n{\r\n    Injector injector = WebAppTests.testPage(TestView.class);\r\n    PrintWriter out = injector.getInstance(PrintWriter.class);\r\n    verify(out).print(\" http-equiv=\\\"X-UA-Compatible\\\"\");\r\n    verify(out).print(\" content=\\\"IE=8\\\"\");\r\n    verify(out).print(\" http-equiv=\\\"Content-type\\\"\");\r\n    verify(out).print(String.format(\" content=\\\"%s\\\"\", MimeType.HTML));\r\n    verify(out).print(\"test\");\r\n    verify(out).print(\" id=\\\"testid\\\"\");\r\n    verify(out).print(\"test note\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "testShort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testShort()\n{\r\n    WebAppTests.testPage(ShortView.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "shouldNotThrow",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void shouldNotThrow()\n{\r\n    WebAppTests.testPage(TwoColumnCssLayout.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\view",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    WebApps.$for(\"test\").at(8888).inDevMode().start().joinThread();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testConvertUrlWithNoPort",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testConvertUrlWithNoPort() throws URISyntaxException\n{\r\n    Path expectedPath = new Path(\"hdfs://foo.com\");\r\n    URL url = URL.fromPath(expectedPath);\r\n    Path actualPath = url.toPath();\r\n    assertEquals(expectedPath, actualPath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testConvertUrlWithUserinfo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testConvertUrlWithUserinfo() throws URISyntaxException\n{\r\n    Path expectedPath = new Path(\"foo://username:password@example.com:8042\");\r\n    URL url = URL.fromPath(expectedPath);\r\n    Path actualPath = url.toPath();\r\n    assertEquals(expectedPath, actualPath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testContainerId",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testContainerId() throws URISyntaxException\n{\r\n    ContainerId id = TestContainerId.newContainerId(0, 0, 0, 0);\r\n    String cid = id.toString();\r\n    assertEquals(\"container_0_0000_00_000000\", cid);\r\n    ContainerId gen = ContainerId.fromString(cid);\r\n    assertEquals(gen, id);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testContainerIdWithEpoch",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void testContainerIdWithEpoch() throws URISyntaxException\n{\r\n    ContainerId id = TestContainerId.newContainerId(0, 0, 0, 25645811);\r\n    String cid = id.toString();\r\n    assertEquals(\"container_0_0000_00_25645811\", cid);\r\n    ContainerId gen = ContainerId.fromString(cid);\r\n    assertEquals(gen.toString(), id.toString());\r\n    long ts = System.currentTimeMillis();\r\n    ContainerId id2 = TestContainerId.newContainerId(36473, 4365472, ts, 4298334883325L);\r\n    String cid2 = id2.toString();\r\n    assertEquals(\"container_e03_\" + ts + \"_36473_4365472_999799999997\", cid2);\r\n    ContainerId gen2 = ContainerId.fromString(cid2);\r\n    assertEquals(gen2.toString(), id2.toString());\r\n    ContainerId id3 = TestContainerId.newContainerId(36473, 4365472, ts, 844424930131965L);\r\n    String cid3 = id3.toString();\r\n    assertEquals(\"container_e767_\" + ts + \"_36473_4365472_1099511627773\", cid3);\r\n    ContainerId gen3 = ContainerId.fromString(cid3);\r\n    assertEquals(gen3.toString(), id3.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testContainerIdNull",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerIdNull() throws URISyntaxException\n{\r\n    assertNull(ConverterUtils.toString((ContainerId) null));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testNodeIdWithDefaultPort",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testNodeIdWithDefaultPort() throws URISyntaxException\n{\r\n    NodeId nid;\r\n    nid = ConverterUtils.toNodeIdWithDefaultPort(\"node:10\");\r\n    assertThat(nid.getPort()).isEqualTo(10);\r\n    assertThat(nid.getHost()).isEqualTo(\"node\");\r\n    nid = ConverterUtils.toNodeIdWithDefaultPort(\"node\");\r\n    assertThat(nid.getPort()).isEqualTo(0);\r\n    assertThat(nid.getHost()).isEqualTo(\"node\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testInvalidContainerId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testInvalidContainerId()\n{\r\n    ContainerId.fromString(\"container_e20_1423221031460_0003_01\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testInvalidAppattemptId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testInvalidAppattemptId()\n{\r\n    ConverterUtils.toApplicationAttemptId(\"appattempt_1423221031460\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testApplicationId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testApplicationId()\n{\r\n    ConverterUtils.toApplicationId(\"application_1423221031460\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testAppTagsLowerCaseConversionDefault",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testAppTagsLowerCaseConversionDefault()\n{\r\n    impl.setApplicationTags(Sets.newHashSet(\"ABcd\", \"efgH\"));\r\n    impl.getApplicationTags().forEach(s -> assertEquals(s, s.toLowerCase()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testAppTagsLowerCaseConversionDisabled",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testAppTagsLowerCaseConversionDisabled()\n{\r\n    ApplicationSubmissionContextPBImpl.setForceLowerCaseTags(false);\r\n    impl.setApplicationTags(Sets.newHashSet(\"ABcd\", \"efgH\"));\r\n    impl.getApplicationTags().forEach(s -> assertNotEquals(s, s.toLowerCase()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testAppTagsLowerCaseConversionEnabled",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testAppTagsLowerCaseConversionEnabled()\n{\r\n    ApplicationSubmissionContextPBImpl.setForceLowerCaseTags(true);\r\n    impl.setApplicationTags(Sets.newHashSet(\"ABcd\", \"efgH\"));\r\n    impl.getApplicationTags().forEach(s -> assertEquals(s, s.toLowerCase()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "data",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Collection<Object[]> data()\n{\r\n    List<Object[]> list = new ArrayList<>();\r\n    list.add(new Object[] { new ApplicationSubmissionContextPBImpl() });\r\n    list.add(new Object[] { new ApplicationSubmissionContextPBImpl(ApplicationSubmissionContextProto.newBuilder().build()) });\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\server\\security",
  "methodName" : "testCheckAccess",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testCheckAccess()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setBoolean(YarnConfiguration.YARN_ACL_ENABLE, true);\r\n    conf.set(YarnConfiguration.YARN_ADMIN_ACL, ADMIN_USER);\r\n    ApplicationACLsManager aclManager = new ApplicationACLsManager(conf);\r\n    Map<ApplicationAccessType, String> aclMap = new HashMap<ApplicationAccessType, String>();\r\n    aclMap.put(ApplicationAccessType.VIEW_APP, TESTUSER1 + \",\" + TESTUSER3);\r\n    aclMap.put(ApplicationAccessType.MODIFY_APP, TESTUSER1);\r\n    ApplicationId appId = ApplicationId.newInstance(1, 1);\r\n    aclManager.addApplication(appId, aclMap);\r\n    UserGroupInformation testUser1 = UserGroupInformation.createRemoteUser(TESTUSER1);\r\n    assertTrue(aclManager.checkAccess(testUser1, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(testUser1, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation testUser2 = UserGroupInformation.createRemoteUser(TESTUSER2);\r\n    assertFalse(aclManager.checkAccess(testUser2, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertFalse(aclManager.checkAccess(testUser2, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation testUser3 = UserGroupInformation.createRemoteUser(TESTUSER3);\r\n    assertTrue(aclManager.checkAccess(testUser3, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertFalse(aclManager.checkAccess(testUser3, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation appOwner = UserGroupInformation.createRemoteUser(APP_OWNER);\r\n    assertTrue(aclManager.checkAccess(appOwner, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(appOwner, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation adminUser = UserGroupInformation.createRemoteUser(ADMIN_USER);\r\n    assertTrue(aclManager.checkAccess(adminUser, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(adminUser, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\server\\security",
  "methodName" : "testCheckAccessWithNullACLS",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testCheckAccessWithNullACLS()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setBoolean(YarnConfiguration.YARN_ACL_ENABLE, true);\r\n    conf.set(YarnConfiguration.YARN_ADMIN_ACL, ADMIN_USER);\r\n    ApplicationACLsManager aclManager = new ApplicationACLsManager(conf);\r\n    UserGroupInformation appOwner = UserGroupInformation.createRemoteUser(APP_OWNER);\r\n    ApplicationId appId = ApplicationId.newInstance(1, 1);\r\n    assertTrue(aclManager.checkAccess(appOwner, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(appOwner, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    UserGroupInformation adminUser = UserGroupInformation.createRemoteUser(ADMIN_USER);\r\n    assertTrue(aclManager.checkAccess(adminUser, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(adminUser, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation testUser1 = UserGroupInformation.createRemoteUser(TESTUSER1);\r\n    assertFalse(aclManager.checkAccess(testUser1, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertFalse(aclManager.checkAccess(testUser1, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\server\\security",
  "methodName" : "testCheckAccessWithPartialACLS",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testCheckAccessWithPartialACLS()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setBoolean(YarnConfiguration.YARN_ACL_ENABLE, true);\r\n    conf.set(YarnConfiguration.YARN_ADMIN_ACL, ADMIN_USER);\r\n    ApplicationACLsManager aclManager = new ApplicationACLsManager(conf);\r\n    UserGroupInformation appOwner = UserGroupInformation.createRemoteUser(APP_OWNER);\r\n    Map<ApplicationAccessType, String> aclMap = new HashMap<ApplicationAccessType, String>();\r\n    aclMap.put(ApplicationAccessType.VIEW_APP, TESTUSER1);\r\n    ApplicationId appId = ApplicationId.newInstance(1, 1);\r\n    aclManager.addApplication(appId, aclMap);\r\n    assertTrue(aclManager.checkAccess(appOwner, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(appOwner, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    UserGroupInformation adminUser = UserGroupInformation.createRemoteUser(ADMIN_USER);\r\n    assertTrue(aclManager.checkAccess(adminUser, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertTrue(aclManager.checkAccess(adminUser, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation testUser1 = UserGroupInformation.createRemoteUser(TESTUSER1);\r\n    assertTrue(aclManager.checkAccess(testUser1, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertFalse(aclManager.checkAccess(testUser1, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n    UserGroupInformation testUser2 = UserGroupInformation.createRemoteUser(TESTUSER2);\r\n    assertFalse(aclManager.checkAccess(testUser2, ApplicationAccessType.VIEW_APP, APP_OWNER, appId));\r\n    assertFalse(aclManager.checkAccess(testUser2, ApplicationAccessType.MODIFY_APP, APP_OWNER, appId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    fileController = createFileController();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void tearDown() throws Exception\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testAllNull",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testAllNull() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    request.setAppId(null);\r\n    request.setContainerId(null);\r\n    request.setFileName(null);\r\n    request.setFileSize(null);\r\n    request.setModificationTime(null);\r\n    request.setNodeId(null);\r\n    request.setUser(null);\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(8, allFile.size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testAllSet",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testAllSet() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    Set<String> fileSizeExpressions = new HashSet<>();\r\n    fileSizeExpressions.add(\"<51\");\r\n    Set<String> modificationTimeExpressions = new HashSet<>();\r\n    modificationTimeExpressions.add(\"<1000\");\r\n    request.setAppId(app.toString());\r\n    request.setContainerId(attemptContainer.toString());\r\n    request.setFileName(String.format(\"%s.*\", SMALL_FILE_NAME));\r\n    request.setFileSize(fileSizeExpressions);\r\n    request.setModificationTime(modificationTimeExpressions);\r\n    request.setNodeId(TEST_NODE);\r\n    request.setUser(\"TEST\");\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(1, allFile.size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testSingleNodeRequest",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testSingleNodeRequest() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    request.setAppId(null);\r\n    request.setContainerId(null);\r\n    request.setFileName(null);\r\n    request.setFileSize(null);\r\n    request.setModificationTime(null);\r\n    request.setNodeId(TEST_NODE);\r\n    request.setUser(null);\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(4, allFile.stream().filter(f -> f.getFileName().contains(TEST_NODE)).count());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testMultipleNodeRegexRequest",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testMultipleNodeRegexRequest() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    request.setAppId(null);\r\n    request.setContainerId(null);\r\n    request.setFileName(null);\r\n    request.setFileSize(null);\r\n    request.setModificationTime(null);\r\n    request.setNodeId(\"TEST_NODE_.*\");\r\n    request.setUser(null);\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(8, allFile.size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testMultipleFileRegex",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testMultipleFileRegex() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    request.setAppId(null);\r\n    request.setContainerId(null);\r\n    request.setFileName(String.format(\"%s.*\", BIG_FILE_NAME));\r\n    request.setFileSize(null);\r\n    request.setModificationTime(null);\r\n    request.setNodeId(null);\r\n    request.setUser(null);\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(4, allFile.size());\r\n    assertTrue(allFile.stream().allMatch(f -> f.getFileName().contains(BIG_FILE_NAME)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testContainerIdExactMatch",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testContainerIdExactMatch() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    request.setAppId(null);\r\n    request.setContainerId(attemptContainer.toString());\r\n    request.setFileName(null);\r\n    request.setFileSize(null);\r\n    request.setModificationTime(null);\r\n    request.setNodeId(null);\r\n    request.setUser(null);\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(2, allFile.size());\r\n    assertTrue(allFile.stream().allMatch(f -> f.getFileName().contains(attemptContainer.toString())));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testMultipleFileBetweenSize",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testMultipleFileBetweenSize() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    Set<String> fileSizeExpressions = new HashSet<>();\r\n    fileSizeExpressions.add(\">50\");\r\n    fileSizeExpressions.add(\"<101\");\r\n    request.setAppId(null);\r\n    request.setContainerId(null);\r\n    request.setFileName(null);\r\n    request.setFileSize(fileSizeExpressions);\r\n    request.setModificationTime(null);\r\n    request.setNodeId(null);\r\n    request.setUser(null);\r\n    LogAggregationMetaCollector collector = new LogAggregationMetaCollector(request.build(), new YarnConfiguration());\r\n    List<ContainerLogMeta> res = collector.collect(fileController);\r\n    List<ContainerLogFileInfo> allFile = res.stream().flatMap(m -> m.getContainerLogMeta().stream()).collect(Collectors.toList());\r\n    assertEquals(4, allFile.size());\r\n    assertTrue(allFile.stream().allMatch(f -> f.getFileSize().equals(\"100\")));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testInvalidQueryStrings",
  "errType" : [ "IllegalArgumentException", "IllegalArgumentException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testInvalidQueryStrings() throws IOException\n{\r\n    ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder request = new ExtendedLogMetaRequest.ExtendedLogMetaRequestBuilder();\r\n    Set<String> fileSizeExpressions = new HashSet<>();\r\n    fileSizeExpressions.add(\"50\");\r\n    fileSizeExpressions.add(\"101\");\r\n    try {\r\n        request.setFileName(\"*\");\r\n        fail(\"An error should be thrown due to an invalid regex\");\r\n    } catch (IllegalArgumentException ignored) {\r\n    }\r\n    try {\r\n        request.setFileSize(fileSizeExpressions);\r\n        fail(\"An error should be thrown due to multiple exact match expression\");\r\n    } catch (IllegalArgumentException ignored) {\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createFileController",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "FakeNodeFileController createFileController()\n{\r\n    FileStatus appDir = new FileStatus();\r\n    appDir.setPath(new Path(String.format(\"test/%s\", app.toString())));\r\n    FileStatus appDir2 = new FileStatus();\r\n    appDir2.setPath(new Path(String.format(\"test/%s\", app2.toString())));\r\n    List<FileStatus> appDirs = new ArrayList<>();\r\n    appDirs.add(appDir);\r\n    appDirs.add(appDir2);\r\n    FileStatus nodeFile = new FileStatus();\r\n    nodeFile.setPath(new Path(String.format(\"test/%s\", TEST_NODE)));\r\n    FileStatus nodeFile2 = new FileStatus();\r\n    nodeFile2.setPath(new Path(String.format(\"test/%s\", TEST_NODE_2)));\r\n    List<FileStatus> nodeFiles = new ArrayList<>();\r\n    nodeFiles.add(nodeFile);\r\n    nodeFiles.add(nodeFile2);\r\n    Map<ImmutablePair<String, String>, Map<String, List<ContainerLogFileInfo>>> internal = new HashMap<>();\r\n    internal.put(new ImmutablePair<>(app.toString(), TEST_NODE), createLogFiles(TEST_NODE, attemptContainer));\r\n    internal.put(new ImmutablePair<>(app.toString(), TEST_NODE_2), createLogFiles(TEST_NODE_2, attemptContainer2));\r\n    internal.put(new ImmutablePair<>(app2.toString(), TEST_NODE), createLogFiles(TEST_NODE, attempt2Container));\r\n    internal.put(new ImmutablePair<>(app2.toString(), TEST_NODE_2), createLogFiles(TEST_NODE_2, attempt2Container2));\r\n    return new FakeNodeFileController(internal, appDirs, nodeFiles);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "createLogFiles",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "Map<String, List<ContainerLogFileInfo>> createLogFiles(String nodeId, ContainerId... containerId)\n{\r\n    Map<String, List<ContainerLogFileInfo>> logFiles = new HashMap<>();\r\n    for (ContainerId c : containerId) {\r\n        List<ContainerLogFileInfo> files = new ArrayList<>();\r\n        ContainerLogFileInfo bigFile = new ContainerLogFileInfo();\r\n        bigFile.setFileName(generateFileName(BIG_FILE_NAME, nodeId, c.toString()));\r\n        bigFile.setFileSize(\"100\");\r\n        bigFile.setLastModifiedTime(\"1000\");\r\n        ContainerLogFileInfo smallFile = new ContainerLogFileInfo();\r\n        smallFile.setFileName(generateFileName(SMALL_FILE_NAME, nodeId, c.toString()));\r\n        smallFile.setFileSize(\"50\");\r\n        smallFile.setLastModifiedTime(\"100\");\r\n        files.add(bigFile);\r\n        files.add(smallFile);\r\n        logFiles.put(c.toString(), files);\r\n    }\r\n    return logFiles;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "generateFileName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String generateFileName(String name, String nodeId, String containerId)\n{\r\n    return String.format(\"%s_%s_%s\", name, nodeId, containerId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTime(long time)\n{\r\n    this.time = time;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "reset",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void reset()\n{\r\n    time = -1;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "tickSec",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void tickSec(int seconds)\n{\r\n    tickMsec(seconds * 1000L);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "tickMsec",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void tickMsec(long millisec)\n{\r\n    if (time == -1) {\r\n        throw new IllegalStateException(\"ControlledClock setTime should be \" + \"called before incrementing time\");\r\n    }\r\n    time = time + millisec;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "getTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getTime()\n{\r\n    if (time != -1) {\r\n        return time;\r\n    }\r\n    return actualClock.getTime();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "waitForEventThreadToWait",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void waitForEventThreadToWait()\n{\r\n    while (!isEventThreadWaiting()) {\r\n        Thread.yield();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "await",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void await()\n{\r\n    while (!isDrained()) {\r\n        Thread.yield();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "createThread",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Runnable createThread()\n{\r\n    return new Runnable() {\r\n\r\n        @Override\r\n        public void run() {\r\n            while (!isStopped() && !Thread.currentThread().isInterrupted()) {\r\n                synchronized (mutex) {\r\n                    drained = queue.isEmpty();\r\n                }\r\n                Event event;\r\n                try {\r\n                    event = queue.take();\r\n                } catch (InterruptedException ie) {\r\n                    return;\r\n                }\r\n                if (event != null) {\r\n                    dispatch(event);\r\n                }\r\n            }\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "getEventHandler",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "EventHandler<Event> getEventHandler()\n{\r\n    final EventHandler<Event> actual = super.getEventHandler();\r\n    return new EventHandler<Event>() {\r\n\r\n        @Override\r\n        public void handle(Event event) {\r\n            synchronized (mutex) {\r\n                actual.handle(event);\r\n                drained = false;\r\n            }\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\event",
  "methodName" : "isDrained",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isDrained()\n{\r\n    synchronized (mutex) {\r\n        return drained;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testHamlet",
  "errType" : null,
  "containingMethodsNum" : 28,
  "sourceCodeText" : "void testHamlet()\n{\r\n    Hamlet h = newHamlet().title(\"test\").h1(\"heading 1\").p(\"#id.class\").b(\"hello\").em(\"world!\").__().div(\"#footer\").__(\"Brought to you by\").a(\"https://hostname/\", \"Somebody\").__();\r\n    PrintWriter out = h.getWriter();\r\n    out.flush();\r\n    assertEquals(0, h.nestLevel);\r\n    verify(out).print(\"<title\");\r\n    verify(out).print(\"test\");\r\n    verify(out).print(\"</title>\");\r\n    verify(out).print(\"<h1\");\r\n    verify(out).print(\"heading 1\");\r\n    verify(out).print(\"</h1>\");\r\n    verify(out).print(\"<p\");\r\n    verify(out).print(\" id=\\\"id\\\"\");\r\n    verify(out).print(\" class=\\\"class\\\"\");\r\n    verify(out).print(\"<b\");\r\n    verify(out).print(\"hello\");\r\n    verify(out).print(\"</b>\");\r\n    verify(out).print(\"<em\");\r\n    verify(out).print(\"world!\");\r\n    verify(out).print(\"</em>\");\r\n    verify(out).print(\"<div\");\r\n    verify(out).print(\" id=\\\"footer\\\"\");\r\n    verify(out).print(\"Brought to you by\");\r\n    verify(out).print(\"<a\");\r\n    verify(out).print(\" href=\\\"https://hostname/\\\"\");\r\n    verify(out).print(\"Somebody\");\r\n    verify(out).print(\"</a>\");\r\n    verify(out).print(\"</div>\");\r\n    verify(out, never()).print(\"</p>\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testTable",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testTable()\n{\r\n    Hamlet h = newHamlet().title(\"test table\").link(\"style.css\");\r\n    TABLE t = h.table(\"#id\");\r\n    for (int i = 0; i < 3; ++i) {\r\n        t.tr().td(\"1\").td(\"2\").__();\r\n    }\r\n    t.__();\r\n    PrintWriter out = h.getWriter();\r\n    out.flush();\r\n    assertEquals(0, h.nestLevel);\r\n    verify(out).print(\"<table\");\r\n    verify(out).print(\"</table>\");\r\n    verify(out, atLeast(1)).print(\"</td>\");\r\n    verify(out, atLeast(1)).print(\"</tr>\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testEnumAttrs",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testEnumAttrs()\n{\r\n    Hamlet h = newHamlet().meta_http(\"Content-type\", \"text/html; charset=utf-8\").title(\"test enum attrs\").link().$rel(\"stylesheet\").$media(EnumSet.of(Media.screen, Media.print)).$type(\"text/css\").$href(\"style.css\").__().link().$rel(EnumSet.of(LinkType.index, LinkType.start)).$href(\"index.html\").__();\r\n    h.div(\"#content\").__(\"content\").__();\r\n    PrintWriter out = h.getWriter();\r\n    out.flush();\r\n    assertEquals(0, h.nestLevel);\r\n    verify(out).print(\" media=\\\"screen, print\\\"\");\r\n    verify(out).print(\" rel=\\\"start index\\\"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testScriptStyle",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testScriptStyle()\n{\r\n    Hamlet h = newHamlet().script(\"a.js\").script(\"b.js\").style(\"h1 { font-size: 1.2em }\");\r\n    PrintWriter out = h.getWriter();\r\n    out.flush();\r\n    assertEquals(0, h.nestLevel);\r\n    verify(out, times(2)).print(\" type=\\\"text/javascript\\\"\");\r\n    verify(out).print(\" type=\\\"text/css\\\"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testPreformatted",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPreformatted()\n{\r\n    Hamlet h = newHamlet().div().i(\"inline before pre\").pre().__(\"pre text1\\npre text2\").i(\"inline in pre\").__(\"pre text after inline\").__().i(\"inline after pre\").__();\r\n    PrintWriter out = h.getWriter();\r\n    out.flush();\r\n    assertEquals(5, h.indents);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testSubViews",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testSubViews()\n{\r\n    Hamlet h = newHamlet().title(\"test sub-views\").div(\"#view1\").__(TestView1.class).__().div(\"#view2\").__(TestView2.class).__();\r\n    PrintWriter out = h.getWriter();\r\n    out.flush();\r\n    assertEquals(0, h.nestLevel);\r\n    verify(out).print(\"[\" + TestView1.class.getName() + \"]\");\r\n    verify(out).print(\"[\" + TestView2.class.getName() + \"]\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "newHamlet",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Hamlet newHamlet()\n{\r\n    PrintWriter out = spy(new PrintWriter(System.out));\r\n    return new Hamlet(out, 0, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\protocolrecords\\impl\\pb",
  "methodName" : "testAppTagsLowerCaseConversionDefault",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testAppTagsLowerCaseConversionDefault()\n{\r\n    impl.setApplicationTags(Sets.newHashSet(\"ABcd\", \"efgH\"));\r\n    impl.getApplicationTags().forEach(s -> assertEquals(s, s.toLowerCase()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\protocolrecords\\impl\\pb",
  "methodName" : "testAppTagsLowerCaseConversionDisabled",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testAppTagsLowerCaseConversionDisabled()\n{\r\n    GetApplicationsRequestPBImpl.setForceLowerCaseTags(false);\r\n    impl.setApplicationTags(Sets.newHashSet(\"ABcd\", \"efgH\"));\r\n    impl.getApplicationTags().forEach(s -> assertNotEquals(s, s.toLowerCase()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\protocolrecords\\impl\\pb",
  "methodName" : "testAppTagsLowerCaseConversionEnabled",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testAppTagsLowerCaseConversionEnabled()\n{\r\n    GetApplicationsRequestPBImpl.setForceLowerCaseTags(true);\r\n    impl.setApplicationTags(Sets.newHashSet(\"ABcd\", \"efgH\"));\r\n    impl.getApplicationTags().forEach(s -> assertEquals(s, s.toLowerCase()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\protocolrecords\\impl\\pb",
  "methodName" : "data",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Collection<Object[]> data()\n{\r\n    List<Object[]> list = new ArrayList<>();\r\n    list.add(new Object[] { new GetApplicationsRequestPBImpl() });\r\n    list.add(new Object[] { new GetApplicationsRequestPBImpl(GetApplicationsRequestProto.newBuilder().build()) });\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationReport",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testApplicationReport()\n{\r\n    long timestamp = System.currentTimeMillis();\r\n    ApplicationReport appReport1 = createApplicationReport(1, 1, timestamp);\r\n    ApplicationReport appReport2 = createApplicationReport(1, 1, timestamp);\r\n    ApplicationReport appReport3 = createApplicationReport(1, 1, timestamp);\r\n    Assert.assertEquals(appReport1, appReport2);\r\n    Assert.assertEquals(appReport2, appReport3);\r\n    appReport1.setApplicationId(null);\r\n    Assert.assertNull(appReport1.getApplicationId());\r\n    Assert.assertNotSame(appReport1, appReport2);\r\n    appReport2.setCurrentApplicationAttemptId(null);\r\n    Assert.assertNull(appReport2.getCurrentApplicationAttemptId());\r\n    Assert.assertNotSame(appReport2, appReport3);\r\n    Assert.assertNull(appReport1.getAMRMToken());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "createApplicationReport",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "ApplicationReport createApplicationReport(int appIdInt, int appAttemptIdInt, long timestamp)\n{\r\n    ApplicationId appId = ApplicationId.newInstance(timestamp, appIdInt);\r\n    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(appId, appAttemptIdInt);\r\n    ApplicationReport appReport = ApplicationReport.newInstance(appId, appAttemptId, \"user\", \"queue\", \"appname\", \"host\", 124, null, YarnApplicationState.FINISHED, \"diagnostics\", \"url\", 0, 0, 0, FinalApplicationStatus.SUCCEEDED, null, \"N/A\", 0.53789f, YarnConfiguration.DEFAULT_APPLICATION_TYPE, null, null, false, Priority.newInstance(0), \"\", \"\");\r\n    return appReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setup()\n{\r\n    client = new MockTimelineReaderClient();\r\n    Configuration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION, 2.0f);\r\n    client.init(conf);\r\n    client.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testGetApplication",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetApplication() throws Exception\n{\r\n    ApplicationId applicationId = ApplicationId.fromString(\"application_1234_0001\");\r\n    TimelineEntity entity = client.getApplicationEntity(applicationId, null, null);\r\n    Assert.assertEquals(\"mockApp1\", entity.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "getApplicationAttemptEntity",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void getApplicationAttemptEntity() throws Exception\n{\r\n    ApplicationAttemptId attemptId = ApplicationAttemptId.fromString(\"appattempt_1234_0001_000001\");\r\n    TimelineEntity entity = client.getApplicationAttemptEntity(attemptId, null, null);\r\n    Assert.assertEquals(\"mockAppAttempt1\", entity.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "getApplicationAttemptEntities",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void getApplicationAttemptEntities() throws Exception\n{\r\n    ApplicationId applicationId = ApplicationId.fromString(\"application_1234_0001\");\r\n    List<TimelineEntity> entities = client.getApplicationAttemptEntities(applicationId, null, null, 0, null);\r\n    Assert.assertEquals(2, entities.size());\r\n    Assert.assertEquals(\"mockAppAttempt2\", entities.get(1).getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testGetContainer",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetContainer() throws Exception\n{\r\n    ContainerId containerId = ContainerId.fromString(\"container_1234_0001_01_000001\");\r\n    TimelineEntity entity = client.getContainerEntity(containerId, null, null);\r\n    Assert.assertEquals(\"mockContainer1\", entity.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testGetContainers",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testGetContainers() throws Exception\n{\r\n    ApplicationId appId = ApplicationId.fromString(\"application_1234_0001\");\r\n    List<TimelineEntity> entities = client.getContainerEntities(appId, null, null, 0, null);\r\n    Assert.assertEquals(2, entities.size());\r\n    Assert.assertEquals(\"mockContainer2\", entities.get(1).getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void tearDown()\n{\r\n    if (client != null) {\r\n        client.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "createTimelineEntity",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TimelineEntity createTimelineEntity(String id)\n{\r\n    TimelineEntity entity = new TimelineEntity();\r\n    entity.setId(id);\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "createTimelineEntities",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineEntity[] createTimelineEntities(String... ids)\n{\r\n    List<TimelineEntity> entities = new ArrayList<>();\r\n    for (String id : ids) {\r\n        TimelineEntity entity = new TimelineEntity();\r\n        entity.setId(id);\r\n        entities.add(entity);\r\n    }\r\n    return entities.toArray(new TimelineEntity[entities.size()]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 73,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    typeValueCache.put(Range.class, Range.between(1000L, 2000L));\r\n    typeValueCache.put(URL.class, URL.newInstance(\"http\", \"localhost\", 8080, \"file0\"));\r\n    typeValueCache.put(SerializedException.class, SerializedException.newInstance(new IOException(\"exception for test\")));\r\n    generateByNewInstance(ExecutionTypeRequest.class);\r\n    typeValueCache.put(ResourceInformation.class, ResourceInformation.newInstance(\"localhost.test/sample\", 1l));\r\n    generateByNewInstance(LogAggregationContext.class);\r\n    generateByNewInstance(ApplicationId.class);\r\n    generateByNewInstance(ApplicationAttemptId.class);\r\n    generateByNewInstance(ContainerId.class);\r\n    generateByNewInstance(Resource.class);\r\n    generateByNewInstance(ResourceBlacklistRequest.class);\r\n    generateByNewInstance(ResourceOption.class);\r\n    generateByNewInstance(LocalResource.class);\r\n    generateByNewInstance(Priority.class);\r\n    generateByNewInstance(NodeId.class);\r\n    generateByNewInstance(NodeReport.class);\r\n    generateByNewInstance(Token.class);\r\n    generateByNewInstance(NMToken.class);\r\n    generateByNewInstance(ResourceRequest.class);\r\n    generateByNewInstance(ApplicationAttemptReport.class);\r\n    generateByNewInstance(ApplicationResourceUsageReport.class);\r\n    generateByNewInstance(ApplicationReport.class);\r\n    generateByNewInstance(Container.class);\r\n    generateByNewInstance(ContainerRetryContext.class);\r\n    generateByNewInstance(ContainerLaunchContext.class);\r\n    generateByNewInstance(ApplicationSubmissionContext.class);\r\n    generateByNewInstance(ContainerReport.class);\r\n    generateByNewInstance(UpdateContainerRequest.class);\r\n    generateByNewInstance(UpdateContainerError.class);\r\n    generateByNewInstance(IncreaseContainersResourceRequest.class);\r\n    generateByNewInstance(IncreaseContainersResourceResponse.class);\r\n    generateByNewInstance(ContainerStatus.class);\r\n    generateByNewInstance(PreemptionContainer.class);\r\n    generateByNewInstance(PreemptionResourceRequest.class);\r\n    generateByNewInstance(PreemptionContainer.class);\r\n    generateByNewInstance(PreemptionContract.class);\r\n    generateByNewInstance(StrictPreemptionContract.class);\r\n    generateByNewInstance(PreemptionMessage.class);\r\n    generateByNewInstance(StartContainerRequest.class);\r\n    generateByNewInstance(NodeLabel.class);\r\n    generateByNewInstance(UpdatedContainer.class);\r\n    generateByNewInstance(ContainerUpdateRequest.class);\r\n    generateByNewInstance(ContainerUpdateResponse.class);\r\n    generateByNewInstance(EnhancedHeadroom.class);\r\n    typeValueCache.put(QueueInfo.class, QueueInfo.newInstance(\"root\", \"root\", 1.0f, 1.0f, 0.1f, null, null, QueueState.RUNNING, ImmutableSet.of(\"x\", \"y\"), \"x && y\", null, false, -1.0f, 10, null, false));\r\n    generateByNewInstance(QueueStatistics.class);\r\n    generateByNewInstance(QueueUserACLInfo.class);\r\n    generateByNewInstance(YarnClusterMetrics.class);\r\n    generateByNewInstance(ReservationId.class);\r\n    generateByNewInstance(ReservationRequest.class);\r\n    generateByNewInstance(ReservationRequests.class);\r\n    generateByNewInstance(ReservationDefinition.class);\r\n    generateByNewInstance(ResourceAllocationRequest.class);\r\n    generateByNewInstance(ReservationAllocationState.class);\r\n    generateByNewInstance(ResourceUtilization.class);\r\n    generateByNewInstance(ReInitializeContainerRequest.class);\r\n    generateByNewInstance(ReInitializeContainerResponse.class);\r\n    generateByNewInstance(RestartContainerResponse.class);\r\n    generateByNewInstance(RollbackResponse.class);\r\n    generateByNewInstance(CommitResponse.class);\r\n    generateByNewInstance(ApplicationTimeout.class);\r\n    generateByNewInstance(QueueConfigurations.class);\r\n    generateByNewInstance(CollectorInfo.class);\r\n    generateByNewInstance(ResourceTypeInfo.class);\r\n    generateByNewInstance(ResourceSizing.class);\r\n    generateByNewInstance(SchedulingRequest.class);\r\n    generateByNewInstance(RejectedSchedulingRequest.class);\r\n    generateByNewInstance(NodeAttributeKey.class);\r\n    generateByNewInstance(NodeAttribute.class);\r\n    generateByNewInstance(NodeToAttributes.class);\r\n    generateByNewInstance(NodeToAttributeValue.class);\r\n    generateByNewInstance(NodeAttributeInfo.class);\r\n    generateByNewInstance(NodesToAttributesMappingRequest.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testAllocateRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAllocateRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(AllocateRequestPBImpl.class, AllocateRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testAllocateResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAllocateResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(AllocateResponsePBImpl.class, AllocateResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testCancelDelegationTokenRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testCancelDelegationTokenRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(CancelDelegationTokenRequestPBImpl.class, CancelDelegationTokenRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testCancelDelegationTokenResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testCancelDelegationTokenResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(CancelDelegationTokenResponsePBImpl.class, CancelDelegationTokenResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testFinishApplicationMasterRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testFinishApplicationMasterRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(FinishApplicationMasterRequestPBImpl.class, FinishApplicationMasterRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testFinishApplicationMasterResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testFinishApplicationMasterResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(FinishApplicationMasterResponsePBImpl.class, FinishApplicationMasterResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationAttemptReportRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationAttemptReportRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationAttemptReportRequestPBImpl.class, GetApplicationAttemptReportRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationAttemptReportResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationAttemptReportResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationAttemptReportResponsePBImpl.class, GetApplicationAttemptReportResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationAttemptsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationAttemptsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationAttemptsRequestPBImpl.class, GetApplicationAttemptsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationAttemptsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationAttemptsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationAttemptsResponsePBImpl.class, GetApplicationAttemptsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationReportRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationReportRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationReportRequestPBImpl.class, GetApplicationReportRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationReportResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationReportResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationReportResponsePBImpl.class, GetApplicationReportResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationsRequestPBImpl.class, GetApplicationsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetApplicationsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetApplicationsResponsePBImpl.class, GetApplicationsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterMetricsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterMetricsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterMetricsRequestPBImpl.class, GetClusterMetricsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterMetricsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterMetricsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterMetricsResponsePBImpl.class, GetClusterMetricsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterNodesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterNodesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterNodesRequestPBImpl.class, GetClusterNodesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterNodesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterNodesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterNodesResponsePBImpl.class, GetClusterNodesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetContainerReportRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetContainerReportRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetContainerReportRequestPBImpl.class, GetContainerReportRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetContainerReportResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetContainerReportResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetContainerReportResponsePBImpl.class, GetContainerReportResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetContainersRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetContainersRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetContainersRequestPBImpl.class, GetContainersRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetContainersResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetContainersResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetContainersResponsePBImpl.class, GetContainersResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetContainerStatusesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetContainerStatusesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetContainerStatusesRequestPBImpl.class, GetContainerStatusesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetContainerStatusesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetContainerStatusesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetContainerStatusesResponsePBImpl.class, GetContainerStatusesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetDelegationTokenRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetDelegationTokenRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetDelegationTokenRequestPBImpl.class, GetDelegationTokenRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetDelegationTokenResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetDelegationTokenResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetDelegationTokenResponsePBImpl.class, GetDelegationTokenResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetNewApplicationRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetNewApplicationRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetNewApplicationRequestPBImpl.class, GetNewApplicationRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetNewApplicationResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetNewApplicationResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetNewApplicationResponsePBImpl.class, GetNewApplicationResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetQueueInfoRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetQueueInfoRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetQueueInfoRequestPBImpl.class, GetQueueInfoRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetQueueInfoResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetQueueInfoResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetQueueInfoResponsePBImpl.class, GetQueueInfoResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetQueueUserAclsInfoRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetQueueUserAclsInfoRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetQueueUserAclsInfoRequestPBImpl.class, GetQueueUserAclsInfoRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetQueueUserAclsInfoResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetQueueUserAclsInfoResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetQueueUserAclsInfoResponsePBImpl.class, GetQueueUserAclsInfoResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testKillApplicationRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testKillApplicationRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(KillApplicationRequestPBImpl.class, KillApplicationRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testKillApplicationResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testKillApplicationResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(KillApplicationResponsePBImpl.class, KillApplicationResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testMoveApplicationAcrossQueuesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testMoveApplicationAcrossQueuesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(MoveApplicationAcrossQueuesRequestPBImpl.class, MoveApplicationAcrossQueuesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testMoveApplicationAcrossQueuesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testMoveApplicationAcrossQueuesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(MoveApplicationAcrossQueuesResponsePBImpl.class, MoveApplicationAcrossQueuesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRegisterApplicationMasterRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRegisterApplicationMasterRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RegisterApplicationMasterRequestPBImpl.class, RegisterApplicationMasterRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRegisterApplicationMasterResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRegisterApplicationMasterResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RegisterApplicationMasterResponsePBImpl.class, RegisterApplicationMasterResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRenewDelegationTokenRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRenewDelegationTokenRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RenewDelegationTokenRequestPBImpl.class, RenewDelegationTokenRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRenewDelegationTokenResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRenewDelegationTokenResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RenewDelegationTokenResponsePBImpl.class, RenewDelegationTokenResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testStartContainerRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStartContainerRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(StartContainerRequestPBImpl.class, StartContainerRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testStartContainersRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStartContainersRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(StartContainersRequestPBImpl.class, StartContainersRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testStartContainersResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStartContainersResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(StartContainersResponsePBImpl.class, StartContainersResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testStopContainersRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStopContainersRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(StopContainersRequestPBImpl.class, StopContainersRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testStopContainersResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStopContainersResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(StopContainersResponsePBImpl.class, StopContainersResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testIncreaseContainersResourceRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testIncreaseContainersResourceRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(IncreaseContainersResourceRequestPBImpl.class, IncreaseContainersResourceRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testIncreaseContainersResourceResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testIncreaseContainersResourceResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(IncreaseContainersResourceResponsePBImpl.class, IncreaseContainersResourceResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testSubmitApplicationRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testSubmitApplicationRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(SubmitApplicationRequestPBImpl.class, SubmitApplicationRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testSubmitApplicationResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testSubmitApplicationResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(SubmitApplicationResponsePBImpl.class, SubmitApplicationResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationAttemptIdPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testApplicationAttemptIdPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ApplicationAttemptIdPBImpl.class, ApplicationAttemptIdProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationAttemptReportPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testApplicationAttemptReportPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ApplicationAttemptReportPBImpl.class, ApplicationAttemptReportProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationIdPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testApplicationIdPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ApplicationIdPBImpl.class, ApplicationIdProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationReportPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testApplicationReportPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ApplicationReportPBImpl.class, ApplicationReportProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationResourceUsageReportPBImpl",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testApplicationResourceUsageReportPBImpl() throws Exception\n{\r\n    excludedPropertiesMap.put(ApplicationResourceUsageReportPBImpl.class.getClass(), Arrays.asList(\"PreemptedResourceSecondsMap\", \"ResourceSecondsMap\"));\r\n    validatePBImplRecord(ApplicationResourceUsageReportPBImpl.class, ApplicationResourceUsageReportProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationSubmissionContextPBImpl",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testApplicationSubmissionContextPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ApplicationSubmissionContextPBImpl.class, ApplicationSubmissionContextProto.class);\r\n    ApplicationSubmissionContext ctx = ApplicationSubmissionContext.newInstance(null, null, null, null, null, false, false, 0, Resources.none(), null, false, null, null);\r\n    Assert.assertNotNull(ctx.getResource());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerIdPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerIdPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ContainerIdPBImpl.class, ContainerIdProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerRetryPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerRetryPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ContainerRetryContextPBImpl.class, ContainerRetryContextProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerLaunchContextPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerLaunchContextPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ContainerLaunchContextPBImpl.class, ContainerLaunchContextProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceLocalizationRequest",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceLocalizationRequest() throws Exception\n{\r\n    validatePBImplRecord(ResourceLocalizationRequestPBImpl.class, YarnServiceProtos.ResourceLocalizationRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceLocalizationResponse",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceLocalizationResponse() throws Exception\n{\r\n    validatePBImplRecord(ResourceLocalizationResponsePBImpl.class, YarnServiceProtos.ResourceLocalizationResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ContainerPBImpl.class, ContainerProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerReportPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerReportPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ContainerReportPBImpl.class, ContainerReportProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testUpdateContainerRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testUpdateContainerRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(UpdateContainerRequestPBImpl.class, YarnServiceProtos.UpdateContainerRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerStatusPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testContainerStatusPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ContainerStatusPBImpl.class, ContainerStatusProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testLocalResourcePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testLocalResourcePBImpl() throws Exception\n{\r\n    validatePBImplRecord(LocalResourcePBImpl.class, LocalResourceProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNMTokenPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNMTokenPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NMTokenPBImpl.class, NMTokenProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeIdPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeIdPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeIdPBImpl.class, NodeIdProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeReportPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeReportPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeReportPBImpl.class, NodeReportProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testPreemptionContainerPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPreemptionContainerPBImpl() throws Exception\n{\r\n    validatePBImplRecord(PreemptionContainerPBImpl.class, PreemptionContainerProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testPreemptionContractPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPreemptionContractPBImpl() throws Exception\n{\r\n    validatePBImplRecord(PreemptionContractPBImpl.class, PreemptionContractProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testPreemptionMessagePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPreemptionMessagePBImpl() throws Exception\n{\r\n    validatePBImplRecord(PreemptionMessagePBImpl.class, PreemptionMessageProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testPreemptionResourceRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPreemptionResourceRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(PreemptionResourceRequestPBImpl.class, PreemptionResourceRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testPriorityPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testPriorityPBImpl() throws Exception\n{\r\n    validatePBImplRecord(PriorityPBImpl.class, PriorityProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testQueueInfoPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testQueueInfoPBImpl() throws Exception\n{\r\n    validatePBImplRecord(QueueInfoPBImpl.class, QueueInfoProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testQueueUserACLInfoPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testQueueUserACLInfoPBImpl() throws Exception\n{\r\n    validatePBImplRecord(QueueUserACLInfoPBImpl.class, QueueUserACLInfoProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceBlacklistRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceBlacklistRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ResourceBlacklistRequestPBImpl.class, ResourceBlacklistRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceOptionPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceOptionPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ResourceOptionPBImpl.class, ResourceOptionProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourcePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourcePBImpl() throws Exception\n{\r\n    validatePBImplRecord(ResourcePBImpl.class, ResourceProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ResourceRequestPBImpl.class, ResourceRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceSizingPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceSizingPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ResourceSizingPBImpl.class, ResourceSizingProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testSchedulingRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testSchedulingRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(SchedulingRequestPBImpl.class, SchedulingRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testSerializedExceptionPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testSerializedExceptionPBImpl() throws Exception\n{\r\n    validatePBImplRecord(SerializedExceptionPBImpl.class, SerializedExceptionProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testStrictPreemptionContractPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testStrictPreemptionContractPBImpl() throws Exception\n{\r\n    validatePBImplRecord(StrictPreemptionContractPBImpl.class, StrictPreemptionContractProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testTokenPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testTokenPBImpl() throws Exception\n{\r\n    validatePBImplRecord(TokenPBImpl.class, TokenProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testURLPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testURLPBImpl() throws Exception\n{\r\n    validatePBImplRecord(URLPBImpl.class, URLProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testYarnClusterMetricsPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testYarnClusterMetricsPBImpl() throws Exception\n{\r\n    validatePBImplRecord(YarnClusterMetricsPBImpl.class, YarnClusterMetricsProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshAdminAclsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshAdminAclsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshAdminAclsRequestPBImpl.class, RefreshAdminAclsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshAdminAclsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshAdminAclsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshAdminAclsResponsePBImpl.class, RefreshAdminAclsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshNodesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshNodesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshNodesRequestPBImpl.class, RefreshNodesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshNodesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshNodesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshNodesResponsePBImpl.class, RefreshNodesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshQueuesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshQueuesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshQueuesRequestPBImpl.class, RefreshQueuesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshQueuesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshQueuesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshQueuesResponsePBImpl.class, RefreshQueuesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshNodesResourcesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshNodesResourcesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshNodesResourcesRequestPBImpl.class, RefreshNodesResourcesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshNodesResourcesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshNodesResourcesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshNodesResourcesResponsePBImpl.class, RefreshNodesResourcesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshServiceAclsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshServiceAclsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshServiceAclsRequestPBImpl.class, RefreshServiceAclsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshServiceAclsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshServiceAclsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshServiceAclsResponsePBImpl.class, RefreshServiceAclsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshSuperUserGroupsConfigurationRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshSuperUserGroupsConfigurationRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshSuperUserGroupsConfigurationRequestPBImpl.class, RefreshSuperUserGroupsConfigurationRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshSuperUserGroupsConfigurationResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshSuperUserGroupsConfigurationResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshSuperUserGroupsConfigurationResponsePBImpl.class, RefreshSuperUserGroupsConfigurationResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshUserToGroupsMappingsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshUserToGroupsMappingsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshUserToGroupsMappingsRequestPBImpl.class, RefreshUserToGroupsMappingsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRefreshUserToGroupsMappingsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRefreshUserToGroupsMappingsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RefreshUserToGroupsMappingsResponsePBImpl.class, RefreshUserToGroupsMappingsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testUpdateNodeResourceRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testUpdateNodeResourceRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(UpdateNodeResourceRequestPBImpl.class, UpdateNodeResourceRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testUpdateNodeResourceResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testUpdateNodeResourceResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(UpdateNodeResourceResponsePBImpl.class, UpdateNodeResourceResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationSubmissionRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationSubmissionRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationSubmissionRequestPBImpl.class, ReservationSubmissionRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationSubmissionResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationSubmissionResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationSubmissionResponsePBImpl.class, ReservationSubmissionResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationUpdateRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationUpdateRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationUpdateRequestPBImpl.class, ReservationUpdateRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationUpdateResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationUpdateResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationUpdateResponsePBImpl.class, ReservationUpdateResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationDeleteRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationDeleteRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationDeleteRequestPBImpl.class, ReservationDeleteRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationDeleteResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationDeleteResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationDeleteResponsePBImpl.class, ReservationDeleteResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationListRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationListRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationListRequestPBImpl.class, ReservationListRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReservationListResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReservationListResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReservationListResponsePBImpl.class, ReservationListResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testAddToClusterNodeLabelsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAddToClusterNodeLabelsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(AddToClusterNodeLabelsRequestPBImpl.class, AddToClusterNodeLabelsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testAddToClusterNodeLabelsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAddToClusterNodeLabelsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(AddToClusterNodeLabelsResponsePBImpl.class, AddToClusterNodeLabelsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRemoveFromClusterNodeLabelsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoveFromClusterNodeLabelsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(RemoveFromClusterNodeLabelsRequestPBImpl.class, RemoveFromClusterNodeLabelsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testRemoveFromClusterNodeLabelsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRemoveFromClusterNodeLabelsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(RemoveFromClusterNodeLabelsResponsePBImpl.class, RemoveFromClusterNodeLabelsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterNodeLabelsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterNodeLabelsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterNodeLabelsRequestPBImpl.class, GetClusterNodeLabelsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterNodeLabelsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterNodeLabelsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterNodeLabelsResponsePBImpl.class, GetClusterNodeLabelsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReplaceLabelsOnNodeRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReplaceLabelsOnNodeRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReplaceLabelsOnNodeRequestPBImpl.class, ReplaceLabelsOnNodeRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testReplaceLabelsOnNodeResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReplaceLabelsOnNodeResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(ReplaceLabelsOnNodeResponsePBImpl.class, ReplaceLabelsOnNodeResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetNodeToLabelsRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetNodeToLabelsRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetNodesToLabelsRequestPBImpl.class, GetNodesToLabelsRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetNodeToLabelsResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetNodeToLabelsResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetNodesToLabelsResponsePBImpl.class, GetNodesToLabelsResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetLabelsToNodesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetLabelsToNodesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetLabelsToNodesRequestPBImpl.class, GetLabelsToNodesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetLabelsToNodesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetLabelsToNodesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetLabelsToNodesResponsePBImpl.class, GetLabelsToNodesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeLabelAttributesPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeLabelAttributesPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeLabelPBImpl.class, NodeLabelProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testCheckForDecommissioningNodesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testCheckForDecommissioningNodesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(CheckForDecommissioningNodesRequestPBImpl.class, CheckForDecommissioningNodesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testCheckForDecommissioningNodesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testCheckForDecommissioningNodesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(CheckForDecommissioningNodesResponsePBImpl.class, CheckForDecommissioningNodesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testExecutionTypeRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testExecutionTypeRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ExecutionTypeRequestPBImpl.class, ExecutionTypeRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetAllResourceProfilesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetAllResourceProfilesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetAllResourceProfilesResponsePBImpl.class, GetAllResourceProfilesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetResourceProfileRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetResourceProfileRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetResourceProfileRequestPBImpl.class, GetResourceProfileRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetResourceProfileResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetResourceProfileResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetResourceProfileResponsePBImpl.class, GetResourceProfileResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testResourceTypesInfoPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testResourceTypesInfoPBImpl() throws Exception\n{\r\n    validatePBImplRecord(ResourceTypeInfoPBImpl.class, YarnProtos.ResourceTypeInfoProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetAllResourceTypesInfoRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetAllResourceTypesInfoRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetAllResourceTypeInfoRequestPBImpl.class, YarnServiceProtos.GetAllResourceTypeInfoRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetAllResourceTypesInfoResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetAllResourceTypesInfoResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetAllResourceTypeInfoResponsePBImpl.class, YarnServiceProtos.GetAllResourceTypeInfoResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeAttributeKeyPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeAttributeKeyPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeAttributeKeyPBImpl.class, NodeAttributeKeyProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeToAttributeValuePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeToAttributeValuePBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeToAttributeValuePBImpl.class, NodeToAttributeValueProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeAttributePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeAttributePBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeAttributePBImpl.class, NodeAttributeProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeAttributeInfoPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeAttributeInfoPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeAttributeInfoPBImpl.class, NodeAttributeInfoProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodeToAttributesPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodeToAttributesPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodeToAttributesPBImpl.class, NodeToAttributesProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testNodesToAttributesMappingRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testNodesToAttributesMappingRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(NodesToAttributesMappingRequestPBImpl.class, NodesToAttributesMappingRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetAttributesToNodesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetAttributesToNodesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetAttributesToNodesRequestPBImpl.class, YarnServiceProtos.GetAttributesToNodesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetAttributesToNodesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetAttributesToNodesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetAttributesToNodesResponsePBImpl.class, YarnServiceProtos.GetAttributesToNodesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterNodeAttributesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterNodeAttributesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterNodeAttributesRequestPBImpl.class, YarnServiceProtos.GetClusterNodeAttributesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetClusterNodeAttributesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetClusterNodeAttributesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetClusterNodeAttributesResponsePBImpl.class, YarnServiceProtos.GetClusterNodeAttributesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetNodesToAttributesRequestPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetNodesToAttributesRequestPBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetNodesToAttributesRequestPBImpl.class, YarnServiceProtos.GetNodesToAttributesRequestProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetNodesToAttributesResponsePBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetNodesToAttributesResponsePBImpl() throws Exception\n{\r\n    validatePBImplRecord(GetNodesToAttributesResponsePBImpl.class, YarnServiceProtos.GetNodesToAttributesResponseProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetEnhancedHeadroomPBImpl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testGetEnhancedHeadroomPBImpl() throws Exception\n{\r\n    validatePBImplRecord(EnhancedHeadroomPBImpl.class, YarnServiceProtos.EnhancedHeadroomProto.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setup()\n{\r\n    ResourceUtils.resetResourceTypes();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "teardown",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void teardown()\n{\r\n    if (nodeResourcesFile != null && nodeResourcesFile.exists()) {\r\n        nodeResourcesFile.delete();\r\n    }\r\n    if (resourceTypesFile != null && resourceTypesFile.exists()) {\r\n        resourceTypesFile.delete();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setupResourceTypes",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "String setupResourceTypes(Configuration conf, String filename) throws Exception\n{\r\n    File source = new File(conf.getClassLoader().getResource(filename).getFile());\r\n    File dest = new File(source.getParent(), \"resource-types.xml\");\r\n    FileUtils.copyFile(source, dest);\r\n    try {\r\n        ResourceUtils.getResourceTypes();\r\n    } catch (Exception e) {\r\n        if (!dest.delete()) {\r\n            LOG.error(\"Could not delete {}\", dest);\r\n        }\r\n        throw e;\r\n    }\r\n    return dest.getAbsolutePath();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setupResourceTypesInternal",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Map<String, ResourceInformation> setupResourceTypesInternal(Configuration conf, String srcFileName) throws IOException\n{\r\n    URL srcFileUrl = conf.getClassLoader().getResource(srcFileName);\r\n    if (srcFileUrl == null) {\r\n        throw new IllegalArgumentException(\"Source file does not exist: \" + srcFileName);\r\n    }\r\n    File source = new File(srcFileUrl.getFile());\r\n    File dest = new File(source.getParent(), \"resource-types.xml\");\r\n    FileUtils.copyFile(source, dest);\r\n    this.resourceTypesFile = dest;\r\n    return ResourceUtils.getResourceTypes();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setupNodeResources",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Map<String, ResourceInformation> setupNodeResources(Configuration conf, String srcFileName) throws IOException\n{\r\n    URL srcFileUrl = conf.getClassLoader().getResource(srcFileName);\r\n    if (srcFileUrl == null) {\r\n        throw new IllegalArgumentException(\"Source file does not exist: \" + srcFileName);\r\n    }\r\n    File source = new File(srcFileUrl.getFile());\r\n    File dest = new File(source.getParent(), \"node-resources.xml\");\r\n    FileUtils.copyFile(source, dest);\r\n    this.nodeResourcesFile = dest;\r\n    return ResourceUtils.getNodeResourceInformation(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMemoryAndVcores",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testMemoryAndVcores(Map<String, ResourceInformation> res)\n{\r\n    String memory = ResourceInformation.MEMORY_MB.getName();\r\n    String vcores = ResourceInformation.VCORES.getName();\r\n    Assert.assertTrue(\"Resource 'memory' missing\", res.containsKey(memory));\r\n    Assert.assertEquals(\"'memory' units incorrect\", ResourceInformation.MEMORY_MB.getUnits(), res.get(memory).getUnits());\r\n    Assert.assertEquals(\"'memory' types incorrect\", ResourceInformation.MEMORY_MB.getResourceType(), res.get(memory).getResourceType());\r\n    Assert.assertTrue(\"Resource 'vcores' missing\", res.containsKey(vcores));\r\n    Assert.assertEquals(\"'vcores' units incorrect\", ResourceInformation.VCORES.getUnits(), res.get(vcores).getUnits());\r\n    Assert.assertEquals(\"'vcores' type incorrect\", ResourceInformation.VCORES.getResourceType(), res.get(vcores).getResourceType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetResourceTypes()\n{\r\n    Map<String, ResourceInformation> res = ResourceUtils.getResourceTypes();\r\n    Assert.assertEquals(2, res.size());\r\n    testMemoryAndVcores(res);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetResourceTypesConfigs",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testGetResourceTypesConfigs() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    ResourceFileInformation testFile1 = new ResourceFileInformation(\"resource-types-1.xml\", 2);\r\n    ResourceFileInformation testFile2 = new ResourceFileInformation(\"resource-types-2.xml\", 3);\r\n    testFile2.resourceNameUnitsMap.put(\"resource1\", \"G\");\r\n    ResourceFileInformation testFile3 = new ResourceFileInformation(\"resource-types-3.xml\", 3);\r\n    testFile3.resourceNameUnitsMap.put(\"resource2\", \"\");\r\n    ResourceFileInformation testFile4 = new ResourceFileInformation(\"resource-types-4.xml\", 5);\r\n    testFile4.resourceNameUnitsMap.put(\"resource1\", \"G\");\r\n    testFile4.resourceNameUnitsMap.put(\"resource2\", \"m\");\r\n    testFile4.resourceNameUnitsMap.put(\"yarn.io/gpu\", \"\");\r\n    ResourceFileInformation[] tests = { testFile1, testFile2, testFile3, testFile4 };\r\n    Map<String, ResourceInformation> res;\r\n    for (ResourceFileInformation testInformation : tests) {\r\n        ResourceUtils.resetResourceTypes();\r\n        res = setupResourceTypesInternal(conf, testInformation.filename);\r\n        testMemoryAndVcores(res);\r\n        Assert.assertEquals(testInformation.resourceCount, res.size());\r\n        for (Map.Entry<String, String> entry : testInformation.resourceNameUnitsMap.entrySet()) {\r\n            String resourceName = entry.getKey();\r\n            Assert.assertTrue(\"Missing key \" + resourceName, res.containsKey(resourceName));\r\n            Assert.assertEquals(entry.getValue(), res.get(resourceName).getUnits());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetRequestedResourcesFromConfig",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testGetRequestedResourcesFromConfig()\n{\r\n    Configuration conf = new Configuration();\r\n    String propertyPrefix = \"mapreduce.mapper.proper.rt.\";\r\n    String[] expectedKeys = { \"yarn.io/gpu\", \"yarn.io/fpga\", \"yarn.io/anything_without_a_dot\", \"regular_rt\", \"regular_rt/with_slash\" };\r\n    String[] invalidKeys = { propertyPrefix + \"too.many_parts\", propertyPrefix + \"yarn.notio/gpu\", \"incorrect.prefix.yarn.io/gpu\", propertyPrefix + \"yarn.io/\", propertyPrefix };\r\n    for (String s : expectedKeys) {\r\n        conf.set(propertyPrefix + s, \"42\");\r\n    }\r\n    for (String s : invalidKeys) {\r\n        conf.set(s, \"24\");\r\n    }\r\n    List<ResourceInformation> properList = ResourceUtils.getRequestedResourcesFromConfig(conf, propertyPrefix);\r\n    Set<String> expectedSet = new HashSet<>(Arrays.asList(expectedKeys));\r\n    Assert.assertEquals(properList.size(), expectedKeys.length);\r\n    properList.forEach(item -> Assert.assertTrue(expectedSet.contains(item.getName())));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetResourceTypesConfigErrors",
  "errType" : [ "YarnRuntimeException|IllegalArgumentException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetResourceTypesConfigErrors() throws IOException\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    String[] resourceFiles = { \"resource-types-error-1.xml\", \"resource-types-error-2.xml\", \"resource-types-error-3.xml\", \"resource-types-error-4.xml\" };\r\n    for (String resourceFile : resourceFiles) {\r\n        ResourceUtils.resetResourceTypes();\r\n        try {\r\n            setupResourceTypesInternal(conf, resourceFile);\r\n            Assert.fail(\"Expected error with file \" + resourceFile);\r\n        } catch (YarnRuntimeException | IllegalArgumentException e) {\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testInitializeResourcesMap",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testInitializeResourcesMap()\n{\r\n    String[] empty = { \"\", \"\" };\r\n    String[] res1 = { \"resource1\", \"m\" };\r\n    String[] res2 = { \"resource2\", \"G\" };\r\n    String[][] test1 = { empty };\r\n    String[][] test2 = { res1 };\r\n    String[][] test3 = { res2 };\r\n    String[][] test4 = { res1, res2 };\r\n    String[][][] allTests = { test1, test2, test3, test4 };\r\n    for (String[][] test : allTests) {\r\n        Configuration conf = new YarnConfiguration();\r\n        String resSt = \"\";\r\n        for (String[] resources : test) {\r\n            resSt += (resources[0] + \",\");\r\n        }\r\n        resSt = resSt.substring(0, resSt.length() - 1);\r\n        conf.set(YarnConfiguration.RESOURCE_TYPES, resSt);\r\n        for (String[] resources : test) {\r\n            String name = YarnConfiguration.RESOURCE_TYPES + \".\" + resources[0] + \".units\";\r\n            conf.set(name, resources[1]);\r\n        }\r\n        Map<String, ResourceInformation> ret = ResourceUtils.resetResourceTypes(conf);\r\n        int len = 3;\r\n        if (test == test1) {\r\n            len = 2;\r\n        } else if (test == test4) {\r\n            len = 4;\r\n        }\r\n        Assert.assertEquals(len, ret.size());\r\n        for (String[] resources : test) {\r\n            if (resources[0].length() == 0) {\r\n                continue;\r\n            }\r\n            Assert.assertTrue(ret.containsKey(resources[0]));\r\n            ResourceInformation resInfo = ret.get(resources[0]);\r\n            Assert.assertEquals(resources[1], resInfo.getUnits());\r\n            Assert.assertEquals(ResourceTypes.COUNTABLE, resInfo.getResourceType());\r\n        }\r\n        Assert.assertTrue(ret.containsKey(\"memory-mb\"));\r\n        ResourceInformation memInfo = ret.get(\"memory-mb\");\r\n        Assert.assertEquals(\"Mi\", memInfo.getUnits());\r\n        Assert.assertEquals(ResourceTypes.COUNTABLE, memInfo.getResourceType());\r\n        Assert.assertTrue(ret.containsKey(\"vcores\"));\r\n        ResourceInformation vcoresInfo = ret.get(\"vcores\");\r\n        Assert.assertEquals(\"\", vcoresInfo.getUnits());\r\n        Assert.assertEquals(ResourceTypes.COUNTABLE, vcoresInfo.getResourceType());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testInitializeResourcesMapErrors",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testInitializeResourcesMapErrors()\n{\r\n    String[] mem1 = { \"memory-mb\", \"\" };\r\n    String[] vcores1 = { \"vcores\", \"M\" };\r\n    String[] mem2 = { \"memory-mb\", \"m\" };\r\n    String[] vcores2 = { \"vcores\", \"G\" };\r\n    String[] mem3 = { \"memory\", \"\" };\r\n    String[][] test1 = { mem1, vcores1 };\r\n    String[][] test2 = { mem2, vcores2 };\r\n    String[][] test3 = { mem3 };\r\n    String[][][] allTests = { test1, test2, test3 };\r\n    for (String[][] test : allTests) {\r\n        Configuration conf = new YarnConfiguration();\r\n        String resSt = \"\";\r\n        for (String[] resources : test) {\r\n            resSt += (resources[0] + \",\");\r\n        }\r\n        resSt = resSt.substring(0, resSt.length() - 1);\r\n        conf.set(YarnConfiguration.RESOURCE_TYPES, resSt);\r\n        for (String[] resources : test) {\r\n            String name = YarnConfiguration.RESOURCE_TYPES + \".\" + resources[0] + \".units\";\r\n            conf.set(name, resources[1]);\r\n        }\r\n        try {\r\n            ResourceUtils.initializeResourcesMap(conf);\r\n            Assert.fail(\"resource map initialization should fail\");\r\n        } catch (Exception e) {\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetResourceInformation",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testGetResourceInformation() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    Map<String, Resource> testRun = new HashMap<>();\r\n    setupResourceTypesInternal(conf, \"resource-types-4.xml\");\r\n    Resource test3Resources = Resource.newInstance(0, 0);\r\n    test3Resources.setResourceInformation(\"resource1\", ResourceInformation.newInstance(\"resource1\", \"Gi\", 5L));\r\n    test3Resources.setResourceInformation(\"resource2\", ResourceInformation.newInstance(\"resource2\", \"m\", 2L));\r\n    test3Resources.setResourceInformation(\"yarn.io/gpu\", ResourceInformation.newInstance(\"yarn.io/gpu\", \"\", 1));\r\n    testRun.put(\"node-resources-2.xml\", test3Resources);\r\n    for (Map.Entry<String, Resource> entry : testRun.entrySet()) {\r\n        String resourceFile = entry.getKey();\r\n        ResourceUtils.resetNodeResources();\r\n        Map<String, ResourceInformation> actual = setupNodeResources(conf, resourceFile);\r\n        Assert.assertEquals(actual.size(), entry.getValue().getResources().length);\r\n        for (ResourceInformation resInfo : entry.getValue().getResources()) {\r\n            Assert.assertEquals(resInfo, actual.get(resInfo.getName()));\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetNodeResourcesConfigErrors",
  "errType" : [ "YarnRuntimeException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testGetNodeResourcesConfigErrors() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    setupResourceTypesInternal(conf, \"resource-types-4.xml\");\r\n    String[] invalidNodeResFiles = { \"node-resources-error-1.xml\" };\r\n    for (String resourceFile : invalidNodeResFiles) {\r\n        ResourceUtils.resetNodeResources();\r\n        try {\r\n            setupNodeResources(conf, resourceFile);\r\n            Assert.fail(\"Expected error with file \" + resourceFile);\r\n        } catch (YarnRuntimeException e) {\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetNodeResourcesRedefineFpgaErrors",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetNodeResourcesRedefineFpgaErrors() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    expexted.expect(YarnRuntimeException.class);\r\n    expexted.expectMessage(\"Defined mandatory resource type=yarn.io/fpga\");\r\n    setupResourceTypesInternal(conf, \"resource-types-error-redefine-fpga-unit.xml\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetNodeResourcesRedefineGpuErrors",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testGetNodeResourcesRedefineGpuErrors() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    expexted.expect(YarnRuntimeException.class);\r\n    expexted.expectMessage(\"Defined mandatory resource type=yarn.io/gpu\");\r\n    setupResourceTypesInternal(conf, \"resource-types-error-redefine-gpu-unit.xml\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testResourceNameFormatValidation",
  "errType" : [ "YarnRuntimeException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testResourceNameFormatValidation()\n{\r\n    String[] validNames = new String[] { \"yarn.io/gpu\", \"gpu\", \"g_1_2\", \"123.io/gpu\", \"prefix/resource_1\", \"a___-3\", \"a....b\" };\r\n    String[] invalidNames = new String[] { \"asd/resource/-name\", \"prefix/-resource_1\", \"prefix/0123resource\", \"0123resource\", \"-resource_1\", \"........abc\" };\r\n    for (String validName : validNames) {\r\n        ResourceUtils.validateNameOfResourceNameAndThrowException(validName);\r\n    }\r\n    for (String invalidName : invalidNames) {\r\n        try {\r\n            ResourceUtils.validateNameOfResourceNameAndThrowException(invalidName);\r\n            Assert.fail(\"Expected to fail name check, the name=\" + invalidName + \" is illegal.\");\r\n        } catch (YarnRuntimeException e) {\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testGetResourceInformationWithDiffUnits",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testGetResourceInformationWithDiffUnits() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    Map<String, Resource> testRun = new HashMap<>();\r\n    setupResourceTypesInternal(conf, \"resource-types-4.xml\");\r\n    Resource test3Resources = Resource.newInstance(0, 0);\r\n    test3Resources.setResourceInformation(\"resource1\", ResourceInformation.newInstance(\"resource1\", \"T\", 5L));\r\n    test3Resources.setResourceInformation(\"resource2\", ResourceInformation.newInstance(\"resource2\", \"M\", 2L));\r\n    test3Resources.setResourceInformation(\"yarn.io/gpu\", ResourceInformation.newInstance(\"yarn.io/gpu\", \"\", 1));\r\n    testRun.put(\"node-resources-3.xml\", test3Resources);\r\n    for (Map.Entry<String, Resource> entry : testRun.entrySet()) {\r\n        String resourceFile = entry.getKey();\r\n        ResourceUtils.resetNodeResources();\r\n        Map<String, ResourceInformation> actual = setupNodeResources(conf, resourceFile);\r\n        Assert.assertEquals(actual.size(), entry.getValue().getResources().length);\r\n        for (ResourceInformation resInfo : entry.getValue().getResources()) {\r\n            Assert.assertEquals(resInfo, actual.get(resInfo.getName()));\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testResourceUnitParsing",
  "errType" : null,
  "containingMethodsNum" : 34,
  "sourceCodeText" : "void testResourceUnitParsing() throws Exception\n{\r\n    Resource res = ResourceUtils.createResourceFromString(\"memory=20g,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20 * 1024, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory=20G,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20 * 1024, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory=20M,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory=20m,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory-mb=20,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory-mb=20m,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory-mb=20G,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(20 * 1024, 3), res);\r\n    res = ResourceUtils.createResourceFromString(\"memory=20,vcores=3\", ResourceUtils.getResourcesTypeInfo());\r\n    Assert.assertEquals(Resources.createResource(0, 3), res);\r\n    List<ResourceTypeInfo> resTypes = new ArrayList<>(ResourceUtils.getResourcesTypeInfo());\r\n    resTypes.add(ResourceTypeInfo.newInstance(ResourceInformation.GPU_URI, \"\"));\r\n    ResourceUtils.reinitializeResources(resTypes);\r\n    res = ResourceUtils.createResourceFromString(\"memory=2G,vcores=3,gpu=0\", resTypes);\r\n    Assert.assertEquals(2 * 1024, res.getMemorySize());\r\n    Assert.assertEquals(0, res.getResourceValue(ResourceInformation.GPU_URI));\r\n    res = ResourceUtils.createResourceFromString(\"memory=2G,vcores=3,gpu=3\", resTypes);\r\n    Assert.assertEquals(2 * 1024, res.getMemorySize());\r\n    Assert.assertEquals(3, res.getResourceValue(ResourceInformation.GPU_URI));\r\n    res = ResourceUtils.createResourceFromString(\"memory=2G,vcores=3\", resTypes);\r\n    Assert.assertEquals(2 * 1024, res.getMemorySize());\r\n    Assert.assertEquals(0, res.getResourceValue(ResourceInformation.GPU_URI));\r\n    res = ResourceUtils.createResourceFromString(\"memory=2G,vcores=3,yarn.io/gpu=0\", resTypes);\r\n    Assert.assertEquals(2 * 1024, res.getMemorySize());\r\n    Assert.assertEquals(0, res.getResourceValue(ResourceInformation.GPU_URI));\r\n    res = ResourceUtils.createResourceFromString(\"memory=2G,vcores=3,yarn.io/gpu=3\", resTypes);\r\n    Assert.assertEquals(2 * 1024, res.getMemorySize());\r\n    Assert.assertEquals(3, res.getResourceValue(ResourceInformation.GPU_URI));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMultipleOpsForResourcesWithTags",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testMultipleOpsForResourcesWithTags() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    setupResourceTypes(conf, \"resource-types-6.xml\");\r\n    Resource resourceA = Resource.newInstance(2, 4);\r\n    Resource resourceB = Resource.newInstance(3, 6);\r\n    resourceA.setResourceInformation(\"resource1\", ResourceInformation.newInstance(\"resource1\", \"T\", 5L));\r\n    resourceA.setResourceInformation(\"resource2\", ResourceInformation.newInstance(\"resource2\", \"M\", 2L));\r\n    resourceA.setResourceInformation(\"yarn.io/gpu\", ResourceInformation.newInstance(\"yarn.io/gpu\", \"\", 1));\r\n    resourceA.setResourceInformation(\"yarn.io/test-volume\", ResourceInformation.newInstance(\"yarn.io/test-volume\", \"\", 2));\r\n    resourceB.setResourceInformation(\"resource1\", ResourceInformation.newInstance(\"resource1\", \"T\", 3L));\r\n    resourceB.setResourceInformation(\"resource2\", ResourceInformation.newInstance(\"resource2\", \"M\", 4L));\r\n    resourceB.setResourceInformation(\"yarn.io/gpu\", ResourceInformation.newInstance(\"yarn.io/gpu\", \"\", 2));\r\n    resourceB.setResourceInformation(\"yarn.io/test-volume\", ResourceInformation.newInstance(\"yarn.io/test-volume\", \"\", 3));\r\n    Resource addedResource = Resources.add(resourceA, resourceB);\r\n    assertThat(addedResource.getMemorySize()).isEqualTo(5);\r\n    assertThat(addedResource.getVirtualCores()).isEqualTo(10);\r\n    assertThat(addedResource.getResourceInformation(\"resource1\").getValue()).isEqualTo(8);\r\n    assertThat(addedResource.getResourceInformation(\"yarn.io/test-volume\").getValue()).isEqualTo(2);\r\n    Resource mulResource = Resources.multiplyAndRoundDown(resourceA, 3);\r\n    assertThat(mulResource.getMemorySize()).isEqualTo(6);\r\n    assertThat(mulResource.getVirtualCores()).isEqualTo(12);\r\n    assertThat(mulResource.getResourceInformation(\"resource1\").getValue()).isEqualTo(15);\r\n    assertThat(mulResource.getResourceInformation(\"yarn.io/test-volume\").getValue()).isEqualTo(2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setup() throws IOException\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.LOG_AGGREGATION_ENABLED, true);\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR, REMOTE_LOG_ROOT + REMOTE_DEFAULT_DIR);\r\n    conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX, \"log\");\r\n    setConf(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "verifyFileControllerInstance",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void verifyFileControllerInstance(LogAggregationFileControllerFactory factory, Class<? extends LogAggregationFileController> className) throws IOException\n{\r\n    List<LogAggregationFileController> fileControllers = factory.getConfiguredLogAggregationFileControllerList();\r\n    FileSystem fs = FileSystem.get(getConf());\r\n    Path logPath = fileControllers.get(0).getRemoteAppLogDir(appId, APP_OWNER);\r\n    LOG.debug(\"Checking \" + logPath);\r\n    try {\r\n        if (fs.exists(logPath)) {\r\n            fs.delete(logPath, true);\r\n        }\r\n        assertTrue(fs.mkdirs(logPath));\r\n        try (Writer writer = new FileWriter(new File(logPath.toString(), \"testLog\"))) {\r\n            writer.write(\"test\");\r\n        }\r\n        assertTrue(\"The used LogAggregationFileController is not instance of \" + className.getSimpleName(), className.isInstance(factory.getFileControllerForRead(appId, APP_OWNER)));\r\n    } finally {\r\n        fs.delete(logPath, true);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testDefaultLogAggregationFileControllerFactory",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testDefaultLogAggregationFileControllerFactory() throws IOException\n{\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(getConf());\r\n    List<LogAggregationFileController> list = factory.getConfiguredLogAggregationFileControllerList();\r\n    assertEquals(\"Only one LogAggregationFileController is expected!\", 1, list.size());\r\n    assertTrue(\"TFile format is expected to be the first \" + \"LogAggregationFileController!\", list.get(0) instanceof LogAggregationTFileController);\r\n    assertTrue(\"TFile format is expected to be used for writing!\", factory.getFileControllerForWrite() instanceof LogAggregationTFileController);\r\n    verifyFileControllerInstance(factory, LogAggregationTFileController.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testLogAggregationFileControllerFactoryClassNotSet",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testLogAggregationFileControllerFactoryClassNotSet()\n{\r\n    Configuration conf = getConf();\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TestLogAggregationFileController\");\r\n    new LogAggregationFileControllerFactory(conf);\r\n    fail(\"TestLogAggregationFileController's class was not set, \" + \"but the factory creation did not fail.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "enableFileControllers",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void enableFileControllers(List<Class<? extends LogAggregationFileController>> fileControllers, List<String> fileControllerNames)\n{\r\n    Configuration conf = getConf();\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, StringUtils.join(fileControllerNames, \",\"));\r\n    for (int i = 0; i < fileControllers.size(); i++) {\r\n        Class<? extends LogAggregationFileController> fileController = fileControllers.get(i);\r\n        String controllerName = fileControllerNames.get(i);\r\n        conf.setClass(String.format(LOG_AGGREGATION_FILE_CONTROLLER_FMT, controllerName), fileController, LogAggregationFileController.class);\r\n        conf.set(String.format(LOG_AGGREGATION_REMOTE_APP_LOG_DIR_FMT, controllerName), REMOTE_LOG_ROOT + controllerName + \"/\");\r\n        conf.set(String.format(LOG_AGGREGATION_REMOTE_APP_LOG_DIR_SUFFIX_FMT, controllerName), controllerName);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testLogAggregationFileControllerFactory",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testLogAggregationFileControllerFactory() throws Exception\n{\r\n    enableFileControllers(ALL_FILE_CONTROLLERS, ALL_FILE_CONTROLLER_NAMES);\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(getConf());\r\n    List<LogAggregationFileController> list = factory.getConfiguredLogAggregationFileControllerList();\r\n    assertEquals(\"The expected number of LogAggregationFileController \" + \"is not 3!\", 3, list.size());\r\n    assertTrue(\"Test format is expected to be the first \" + \"LogAggregationFileController!\", list.get(0) instanceof TestLogAggregationFileController);\r\n    assertTrue(\"IFile format is expected to be the second \" + \"LogAggregationFileController!\", list.get(1) instanceof LogAggregationIndexedFileController);\r\n    assertTrue(\"TFile format is expected to be the first \" + \"LogAggregationFileController!\", list.get(2) instanceof LogAggregationTFileController);\r\n    assertTrue(\"Test format is expected to be used for writing!\", factory.getFileControllerForWrite() instanceof TestLogAggregationFileController);\r\n    verifyFileControllerInstance(factory, TestLogAggregationFileController.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testClassConfUsed",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testClassConfUsed()\n{\r\n    enableFileControllers(Collections.singletonList(LogAggregationTFileController.class), Collections.singletonList(\"TFile\"));\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(getConf());\r\n    LogAggregationFileController fc = factory.getFileControllerForWrite();\r\n    assertEquals(WRONG_ROOT_LOG_DIR_MSG, \"target/app-logs/TFile\", fc.getRemoteRootLogDir().toString());\r\n    assertEquals(WRONG_ROOT_LOG_DIR_SUFFIX_MSG, \"TFile\", fc.getRemoteRootLogDirSuffix());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testNodemanagerConfigurationIsUsed",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testNodemanagerConfigurationIsUsed()\n{\r\n    Configuration conf = getConf();\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TFile\");\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(conf);\r\n    LogAggregationFileController fc = factory.getFileControllerForWrite();\r\n    assertEquals(WRONG_ROOT_LOG_DIR_MSG, \"target/app-logs/default\", fc.getRemoteRootLogDir().toString());\r\n    assertEquals(WRONG_ROOT_LOG_DIR_SUFFIX_MSG, \"log-tfile\", fc.getRemoteRootLogDirSuffix());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "testDefaultConfUsed",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testDefaultConfUsed()\n{\r\n    Configuration conf = getConf();\r\n    conf.unset(YarnConfiguration.NM_REMOTE_APP_LOG_DIR);\r\n    conf.unset(YarnConfiguration.NM_REMOTE_APP_LOG_DIR_SUFFIX);\r\n    conf.set(YarnConfiguration.LOG_AGGREGATION_FILE_FORMATS, \"TFile\");\r\n    LogAggregationFileControllerFactory factory = new LogAggregationFileControllerFactory(getConf());\r\n    LogAggregationFileController fc = factory.getFileControllerForWrite();\r\n    assertEquals(WRONG_ROOT_LOG_DIR_MSG, \"/tmp/logs\", fc.getRemoteRootLogDir().toString());\r\n    assertEquals(WRONG_ROOT_LOG_DIR_SUFFIX_MSG, \"logs-tfile\", fc.getRemoteRootLogDirSuffix());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "cleanupTestDir",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void cleanupTestDir() throws Exception\n{\r\n    Path workDirPath = new Path(testWorkDir.getAbsolutePath());\r\n    LOG.info(\"Cleaning test directory [\" + workDirPath + \"]\");\r\n    fs.delete(workDirPath, true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testForCorruptedAggregatedLogs",
  "errType" : [ "Exception", "IOException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testForCorruptedAggregatedLogs() throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    File workDir = new File(testWorkDir, \"testReadAcontainerLogs1\");\r\n    Path remoteAppLogFile = new Path(workDir.getAbsolutePath(), \"aggregatedLogFile\");\r\n    Path srcFileRoot = new Path(workDir.getAbsolutePath(), \"srcFiles\");\r\n    ContainerId testContainerId = TestContainerId.newContainerId(1, 1, 1, 1);\r\n    Path t = new Path(srcFileRoot, testContainerId.getApplicationAttemptId().getApplicationId().toString());\r\n    Path srcFilePath = new Path(t, testContainerId.toString());\r\n    long numChars = 950000;\r\n    writeSrcFileAndALog(srcFilePath, \"stdout\", numChars, remoteAppLogFile, srcFileRoot, testContainerId);\r\n    LogReader logReader = new LogReader(conf, remoteAppLogFile);\r\n    LogKey rLogKey = new LogKey();\r\n    DataInputStream dis = logReader.next(rLogKey);\r\n    Writer writer = new StringWriter();\r\n    try {\r\n        LogReader.readAcontainerLogs(dis, writer);\r\n    } catch (Exception e) {\r\n        if (e.toString().contains(\"NumberFormatException\")) {\r\n            Assert.fail(\"Aggregated logs are corrupted.\");\r\n        }\r\n    }\r\n    URI logUri = URI.create(\"file:///\" + remoteAppLogFile.toUri().toString());\r\n    Files.write(Paths.get(logUri), \"corrupt_text\".getBytes(), StandardOpenOption.APPEND);\r\n    try {\r\n        logReader = new LogReader(conf, remoteAppLogFile);\r\n        Assert.fail(\"Expect IOException from reading corrupt aggregated logs.\");\r\n    } catch (IOException ioe) {\r\n        DataInputStream dIS = logReader.next(rLogKey);\r\n        Assert.assertNull(\"Input stream not available for reading\", dIS);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "writeSrcFileAndALog",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void writeSrcFileAndALog(Path srcFilePath, String fileName, final long length, Path remoteAppLogFile, Path srcFileRoot, ContainerId testContainerId) throws Exception\n{\r\n    File dir = new File(srcFilePath.toString());\r\n    if (!dir.exists()) {\r\n        if (!dir.mkdirs()) {\r\n            throw new IOException(\"Unable to create directory : \" + dir);\r\n        }\r\n    }\r\n    File outputFile = new File(new File(srcFilePath.toString()), fileName);\r\n    FileOutputStream os = new FileOutputStream(outputFile);\r\n    final OutputStreamWriter osw = new OutputStreamWriter(os, \"UTF8\");\r\n    final int ch = filler;\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    try (LogWriter logWriter = new LogWriter()) {\r\n        logWriter.initialize(new Configuration(), remoteAppLogFile, ugi);\r\n        LogKey logKey = new LogKey(testContainerId);\r\n        LogValue logValue = spy(new LogValue(Collections.singletonList(srcFileRoot.toString()), testContainerId, ugi.getShortUserName()));\r\n        final CountDownLatch latch = new CountDownLatch(1);\r\n        Thread t = new Thread() {\r\n\r\n            public void run() {\r\n                try {\r\n                    for (int i = 0; i < length / 3; i++) {\r\n                        osw.write(ch);\r\n                    }\r\n                    latch.countDown();\r\n                    for (int i = 0; i < (2 * length) / 3; i++) {\r\n                        osw.write(ch);\r\n                    }\r\n                    osw.close();\r\n                } catch (IOException e) {\r\n                    e.printStackTrace();\r\n                }\r\n            }\r\n        };\r\n        t.start();\r\n        latch.await();\r\n        logWriter.append(logKey, logValue);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testReadAcontainerLogs1",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testReadAcontainerLogs1() throws Exception\n{\r\n    testReadAcontainerLog(true);\r\n    testReadAcontainerLog(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testReadAcontainerLog",
  "errType" : null,
  "containingMethodsNum" : 38,
  "sourceCodeText" : "void testReadAcontainerLog(boolean logUploadedTime) throws Exception\n{\r\n    Configuration conf = new Configuration();\r\n    File workDir = new File(testWorkDir, \"testReadAcontainerLogs1\");\r\n    Path remoteAppLogFile = new Path(workDir.getAbsolutePath(), \"aggregatedLogFile\");\r\n    Path srcFileRoot = new Path(workDir.getAbsolutePath(), \"srcFiles\");\r\n    ContainerId testContainerId = TestContainerId.newContainerId(1, 1, 1, 1);\r\n    Path t = new Path(srcFileRoot, testContainerId.getApplicationAttemptId().getApplicationId().toString());\r\n    Path srcFilePath = new Path(t, testContainerId.toString());\r\n    int numChars = 80000;\r\n    Path subDir = new Path(srcFilePath, \"subDir\");\r\n    fs.mkdirs(subDir);\r\n    writeSrcFile(subDir, \"logs\", numChars);\r\n    writeSrcFile(srcFilePath, \"stderr\", numChars);\r\n    writeSrcFile(srcFilePath, \"stdout\", numChars);\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    try (LogWriter logWriter = new LogWriter()) {\r\n        logWriter.initialize(conf, remoteAppLogFile, ugi);\r\n        LogKey logKey = new LogKey(testContainerId);\r\n        LogValue logValue = new LogValue(Collections.singletonList(srcFileRoot.toString()), testContainerId, ugi.getShortUserName());\r\n        LogValue spyLogValue = spy(logValue);\r\n        File errorFile = new File((new Path(srcFilePath, \"stderr\")).toString());\r\n        doThrow(new IOException(\"Mock can not open FileInputStream\")).when(spyLogValue).secureOpenFile(errorFile);\r\n        logWriter.append(logKey, spyLogValue);\r\n    }\r\n    FileStatus fsStatus = fs.getFileStatus(remoteAppLogFile);\r\n    Assert.assertEquals(\"permissions on log aggregation file are wrong\", FsPermission.createImmutable((short) 0640), fsStatus.getPermission());\r\n    LogReader logReader = new LogReader(conf, remoteAppLogFile);\r\n    LogKey rLogKey = new LogKey();\r\n    DataInputStream dis = logReader.next(rLogKey);\r\n    Writer writer = new StringWriter();\r\n    if (logUploadedTime) {\r\n        LogReader.readAcontainerLogs(dis, writer, System.currentTimeMillis());\r\n    } else {\r\n        LogReader.readAcontainerLogs(dis, writer);\r\n    }\r\n    String s = writer.toString();\r\n    int expectedLength = \"LogType:stdout\".length() + (logUploadedTime ? (System.lineSeparator() + \"Log Upload Time:\" + Times.format(System.currentTimeMillis())).length() : 0) + (System.lineSeparator() + \"LogLength:\" + numChars).length() + (System.lineSeparator() + \"Log Contents:\" + System.lineSeparator()).length() + numChars + (\"\\n\").length() + (\"End of LogType:stdout\" + System.lineSeparator() + System.lineSeparator()).length();\r\n    Assert.assertTrue(\"LogType not matched\", s.contains(\"LogType:stdout\"));\r\n    Assert.assertTrue(\"log file:stderr should not be aggregated.\", !s.contains(\"LogType:stderr\"));\r\n    Assert.assertTrue(\"log file:logs should not be aggregated.\", !s.contains(\"LogType:logs\"));\r\n    Assert.assertTrue(\"LogLength not matched\", s.contains(\"LogLength:\" + numChars));\r\n    Assert.assertTrue(\"Log Contents not matched\", s.contains(\"Log Contents\"));\r\n    StringBuilder sb = new StringBuilder();\r\n    for (int i = 0; i < numChars; i++) {\r\n        sb.append(filler);\r\n    }\r\n    String expectedContent = sb.toString();\r\n    Assert.assertTrue(\"Log content incorrect\", s.contains(expectedContent));\r\n    Assert.assertEquals(expectedLength, s.length());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testZeroLengthLog",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testZeroLengthLog() throws IOException\n{\r\n    Configuration conf = new Configuration();\r\n    File workDir = new File(testWorkDir, \"testZeroLength\");\r\n    Path remoteAppLogFile = new Path(workDir.getAbsolutePath(), \"aggregatedLogFile\");\r\n    Path srcFileRoot = new Path(workDir.getAbsolutePath(), \"srcFiles\");\r\n    ContainerId testContainerId = TestContainerId.newContainerId(1, 1, 1, 1);\r\n    Path t = new Path(srcFileRoot, testContainerId.getApplicationAttemptId().getApplicationId().toString());\r\n    Path srcFilePath = new Path(t, testContainerId.toString());\r\n    writeSrcFile(srcFilePath, \"stdout\", 0);\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    try (LogWriter logWriter = new LogWriter()) {\r\n        logWriter.initialize(conf, remoteAppLogFile, ugi);\r\n        LogKey logKey = new LogKey(testContainerId);\r\n        LogValue logValue = new LogValue(Collections.singletonList(srcFileRoot.toString()), testContainerId, ugi.getShortUserName());\r\n        logWriter.append(logKey, logValue);\r\n    }\r\n    LogReader logReader = new LogReader(conf, remoteAppLogFile);\r\n    LogKey rLogKey = new LogKey();\r\n    DataInputStream dis = logReader.next(rLogKey);\r\n    Writer writer = new StringWriter();\r\n    LogReader.readAcontainerLogs(dis, writer);\r\n    Assert.assertEquals(\"LogType:stdout\\n\" + \"LogLength:0\\n\" + \"Log Contents:\\n\\n\" + \"End of LogType:stdout\\n\\n\", writer.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "testContainerLogsFileAccess",
  "errType" : null,
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void testContainerLogsFileAccess() throws IOException\n{\r\n    Assume.assumeTrue(NativeIO.isAvailable());\r\n    Configuration conf = new Configuration();\r\n    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, \"kerberos\");\r\n    UserGroupInformation.setConfiguration(conf);\r\n    File workDir = new File(testWorkDir, \"testContainerLogsFileAccess1\");\r\n    Path remoteAppLogFile = new Path(workDir.getAbsolutePath(), \"aggregatedLogFile\");\r\n    Path srcFileRoot = new Path(workDir.getAbsolutePath(), \"srcFiles\");\r\n    String data = \"Log File content for container : \";\r\n    ApplicationId applicationId = ApplicationId.newInstance(1, 1);\r\n    ApplicationAttemptId applicationAttemptId = ApplicationAttemptId.newInstance(applicationId, 1);\r\n    ContainerId testContainerId1 = ContainerId.newContainerId(applicationAttemptId, 1);\r\n    Path appDir = new Path(srcFileRoot, testContainerId1.getApplicationAttemptId().getApplicationId().toString());\r\n    Path srcFilePath1 = new Path(appDir, testContainerId1.toString());\r\n    String stdout = \"stdout\";\r\n    String stderr = \"stderr\";\r\n    writeSrcFile(srcFilePath1, stdout, data + testContainerId1.toString() + stdout);\r\n    writeSrcFile(srcFilePath1, stderr, data + testContainerId1.toString() + stderr);\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    try (LogWriter logWriter = new LogWriter()) {\r\n        logWriter.initialize(conf, remoteAppLogFile, ugi);\r\n        LogKey logKey = new LogKey(testContainerId1);\r\n        String randomUser = \"randomUser\";\r\n        LogValue logValue = spy(new LogValue(Collections.singletonList(srcFileRoot.toString()), testContainerId1, randomUser));\r\n        when(logValue.getUser()).thenReturn(randomUser).thenReturn(ugi.getShortUserName());\r\n        logWriter.append(logKey, logValue);\r\n    }\r\n    BufferedReader in = new BufferedReader(new FileReader(new File(remoteAppLogFile.toUri().getRawPath())));\r\n    String line;\r\n    StringBuffer sb = new StringBuffer(\"\");\r\n    while ((line = in.readLine()) != null) {\r\n        LOG.info(line);\r\n        sb.append(line);\r\n    }\r\n    line = sb.toString();\r\n    String expectedOwner = ugi.getShortUserName();\r\n    if (Path.WINDOWS) {\r\n        final String adminsGroupString = \"Administrators\";\r\n        if (Arrays.asList(ugi.getGroupNames()).contains(adminsGroupString)) {\r\n            expectedOwner = adminsGroupString;\r\n        }\r\n    }\r\n    String stdoutFile1 = StringUtils.join(File.separator, Arrays.asList(new String[] { workDir.getAbsolutePath(), \"srcFiles\", testContainerId1.getApplicationAttemptId().getApplicationId().toString(), testContainerId1.toString(), stderr }));\r\n    String stdoutFile2 = StringUtils.join(File.separator, Arrays.asList(new String[] { workDir.getAbsolutePath(), \"srcFiles\", testContainerId1.getApplicationAttemptId().getApplicationId().toString(), testContainerId1.toString(), stdout }));\r\n    String message2 = \"Owner '\" + expectedOwner + \"' for path \" + stdoutFile2 + \" did not match expected owner '\" + ugi.getShortUserName() + \"'\";\r\n    Assert.assertFalse(line.contains(message2));\r\n    Assert.assertFalse(line.contains(data + testContainerId1.toString() + stderr));\r\n    Assert.assertTrue(line.contains(data + testContainerId1.toString() + stdout));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "writeSrcFile",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeSrcFile(Path srcFilePath, String fileName, long length) throws IOException\n{\r\n    OutputStreamWriter osw = getOutputStreamWriter(srcFilePath, fileName);\r\n    int ch = filler;\r\n    for (int i = 0; i < length; i++) {\r\n        osw.write(ch);\r\n    }\r\n    osw.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "writeSrcFile",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeSrcFile(Path srcFilePath, String fileName, String data) throws IOException\n{\r\n    OutputStreamWriter osw = getOutputStreamWriter(srcFilePath, fileName);\r\n    osw.write(data);\r\n    osw.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation",
  "methodName" : "getOutputStreamWriter",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "OutputStreamWriter getOutputStreamWriter(Path srcFilePath, String fileName) throws IOException, FileNotFoundException, UnsupportedEncodingException\n{\r\n    File dir = new File(srcFilePath.toString());\r\n    if (!dir.exists()) {\r\n        if (!dir.mkdirs()) {\r\n            throw new IOException(\"Unable to create directory : \" + dir);\r\n        }\r\n    }\r\n    File outputFile = new File(new File(srcFilePath.toString()), fileName);\r\n    FileOutputStream os = new FileOutputStream(outputFile);\r\n    OutputStreamWriter osw = new OutputStreamWriter(os, \"UTF8\");\r\n    return osw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setup()\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION, 1.0f);\r\n    client = createTimelineClient(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void tearDown() throws Exception\n{\r\n    if (client != null) {\r\n        client.stop();\r\n    }\r\n    if (isSSLConfigured()) {\r\n        KeyStoreTestUtil.cleanupSSLConfig(keystoresDir, sslConfDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntities",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPostEntities() throws Exception\n{\r\n    mockEntityClientResponse(spyTimelineWriter, ClientResponse.Status.OK, false, false);\r\n    try {\r\n        TimelinePutResponse response = client.putEntities(generateEntity());\r\n        Assert.assertEquals(0, response.getErrors().size());\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Exception is not expected\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntitiesWithError",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testPostEntitiesWithError() throws Exception\n{\r\n    mockEntityClientResponse(spyTimelineWriter, ClientResponse.Status.OK, true, false);\r\n    try {\r\n        TimelinePutResponse response = client.putEntities(generateEntity());\r\n        Assert.assertEquals(1, response.getErrors().size());\r\n        Assert.assertEquals(\"test entity id\", response.getErrors().get(0).getEntityId());\r\n        Assert.assertEquals(\"test entity type\", response.getErrors().get(0).getEntityType());\r\n        Assert.assertEquals(TimelinePutResponse.TimelinePutError.IO_EXCEPTION, response.getErrors().get(0).getErrorCode());\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Exception is not expected\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostIncompleteEntities",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testPostIncompleteEntities() throws Exception\n{\r\n    try {\r\n        client.putEntities(new TimelineEntity());\r\n        Assert.fail(\"Exception should have been thrown\");\r\n    } catch (YarnException e) {\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntitiesNoResponse",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPostEntitiesNoResponse() throws Exception\n{\r\n    mockEntityClientResponse(spyTimelineWriter, ClientResponse.Status.INTERNAL_SERVER_ERROR, false, false);\r\n    try {\r\n        client.putEntities(generateEntity());\r\n        Assert.fail(\"Exception is expected\");\r\n    } catch (YarnException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Failed to get the response from the timeline server.\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntitiesConnectionRefused",
  "errType" : [ "RuntimeException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPostEntitiesConnectionRefused() throws Exception\n{\r\n    mockEntityClientResponse(spyTimelineWriter, null, false, true);\r\n    try {\r\n        client.putEntities(generateEntity());\r\n        Assert.fail(\"RuntimeException is expected\");\r\n    } catch (RuntimeException re) {\r\n        Assert.assertTrue(re instanceof ClientHandlerException);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPutDomain",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testPutDomain() throws Exception\n{\r\n    mockDomainClientResponse(spyTimelineWriter, ClientResponse.Status.OK, false);\r\n    try {\r\n        client.putDomain(generateDomain());\r\n    } catch (YarnException e) {\r\n        Assert.fail(\"Exception is not expected\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPutDomainNoResponse",
  "errType" : [ "YarnException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPutDomainNoResponse() throws Exception\n{\r\n    mockDomainClientResponse(spyTimelineWriter, ClientResponse.Status.FORBIDDEN, false);\r\n    try {\r\n        client.putDomain(generateDomain());\r\n        Assert.fail(\"Exception is expected\");\r\n    } catch (YarnException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Failed to get the response from the timeline server.\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPutDomainConnectionRefused",
  "errType" : [ "RuntimeException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPutDomainConnectionRefused() throws Exception\n{\r\n    mockDomainClientResponse(spyTimelineWriter, null, true);\r\n    try {\r\n        client.putDomain(generateDomain());\r\n        Assert.fail(\"RuntimeException is expected\");\r\n    } catch (RuntimeException re) {\r\n        Assert.assertTrue(re instanceof ClientHandlerException);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testCheckRetryCount",
  "errType" : [ "IllegalArgumentException", "IllegalArgumentException", "RuntimeException" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testCheckRetryCount() throws Exception\n{\r\n    try {\r\n        YarnConfiguration conf = new YarnConfiguration();\r\n        conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n        conf.setInt(YarnConfiguration.TIMELINE_SERVICE_CLIENT_MAX_RETRIES, -2);\r\n        createTimelineClient(conf);\r\n        Assert.fail();\r\n    } catch (IllegalArgumentException e) {\r\n        Assert.assertTrue(e.getMessage().contains(YarnConfiguration.TIMELINE_SERVICE_CLIENT_MAX_RETRIES));\r\n    }\r\n    try {\r\n        YarnConfiguration conf = new YarnConfiguration();\r\n        conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n        conf.setLong(YarnConfiguration.TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS, 0);\r\n        createTimelineClient(conf);\r\n        Assert.fail();\r\n    } catch (IllegalArgumentException e) {\r\n        Assert.assertTrue(e.getMessage().contains(YarnConfiguration.TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS));\r\n    }\r\n    int newMaxRetries = 5;\r\n    long newIntervalMs = 500;\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setInt(YarnConfiguration.TIMELINE_SERVICE_CLIENT_MAX_RETRIES, newMaxRetries);\r\n    conf.setLong(YarnConfiguration.TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS, newIntervalMs);\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    TimelineClientImpl client = createTimelineClient(conf);\r\n    try {\r\n        client.putEntities(generateEntity());\r\n        Assert.fail(\"Exception expected! \" + \"Timeline server should be off to run this test. \");\r\n    } catch (RuntimeException ce) {\r\n        Assert.assertTrue(\"Handler exception for reason other than retry: \" + ce.getMessage(), ce.getMessage().contains(\"Connection retries limit exceeded\"));\r\n        Assert.assertTrue(\"Retry filter didn't perform any retries! \", client.connector.connectionRetry.getRetired());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testDelegationTokenOperationsRetry",
  "errType" : [ "RuntimeException", "RuntimeException", "RuntimeException", "RuntimeException" ],
  "containingMethodsNum" : 25,
  "sourceCodeText" : "void testDelegationTokenOperationsRetry() throws Exception\n{\r\n    int newMaxRetries = 5;\r\n    long newIntervalMs = 500;\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setInt(YarnConfiguration.TIMELINE_SERVICE_CLIENT_MAX_RETRIES, newMaxRetries);\r\n    conf.setLong(YarnConfiguration.TIMELINE_SERVICE_CLIENT_RETRY_INTERVAL_MS, newIntervalMs);\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, \"kerberos\");\r\n    conf.set(YarnConfiguration.TIMELINE_HTTP_AUTH_TYPE, \"kerberos\");\r\n    UserGroupInformation.setConfiguration(conf);\r\n    TimelineClientImpl client = createTimelineClient(conf);\r\n    TimelineClientImpl clientFake = createTimelineClientFakeTimelineClientRetryOp(conf);\r\n    TestTimelineDelegationTokenSecretManager dtManager = new TestTimelineDelegationTokenSecretManager();\r\n    try {\r\n        dtManager.startThreads();\r\n        Thread.sleep(3000);\r\n        try {\r\n            client.getDelegationToken(UserGroupInformation.getCurrentUser().getShortUserName());\r\n            assertFail();\r\n        } catch (RuntimeException ce) {\r\n            assertException(client, ce);\r\n        }\r\n        try {\r\n            TimelineDelegationTokenIdentifier timelineDT = new TimelineDelegationTokenIdentifier(new Text(\"tester\"), new Text(\"tester\"), new Text(\"tester\"));\r\n            client.renewDelegationToken(new Token<TimelineDelegationTokenIdentifier>(timelineDT.getBytes(), dtManager.createPassword(timelineDT), timelineDT.getKind(), new Text(\"0.0.0.0:8188\")));\r\n            assertFail();\r\n        } catch (RuntimeException ce) {\r\n            assertException(client, ce);\r\n        }\r\n        try {\r\n            TimelineDelegationTokenIdentifier timelineDT = new TimelineDelegationTokenIdentifier(new Text(\"tester\"), new Text(\"tester\"), new Text(\"tester\"));\r\n            client.cancelDelegationToken(new Token<TimelineDelegationTokenIdentifier>(timelineDT.getBytes(), dtManager.createPassword(timelineDT), timelineDT.getKind(), new Text(\"0.0.0.0:8188\")));\r\n            assertFail();\r\n        } catch (RuntimeException ce) {\r\n            assertException(client, ce);\r\n        }\r\n        try {\r\n            TimelineDelegationTokenIdentifier timelineDT = new TimelineDelegationTokenIdentifier(new Text(\"tester\"), new Text(\"tester\"), new Text(\"tester\"));\r\n            clientFake.cancelDelegationToken(new Token<TimelineDelegationTokenIdentifier>(timelineDT.getBytes(), dtManager.createPassword(timelineDT), timelineDT.getKind(), new Text(\"0.0.0.0:8188\")));\r\n            assertFail();\r\n        } catch (RuntimeException ce) {\r\n            assertException(clientFake, ce);\r\n        }\r\n    } finally {\r\n        client.stop();\r\n        clientFake.stop();\r\n        dtManager.stopThreads();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 5,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testDelegationTokenDisabledOnSimpleAuth",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testDelegationTokenDisabledOnSimpleAuth() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.set(YarnConfiguration.TIMELINE_HTTP_AUTH_TYPE, \"simple\");\r\n    UserGroupInformation.setConfiguration(conf);\r\n    TimelineClientImpl tClient = createTimelineClient(conf);\r\n    TimelineConnector spyConnector = spy(tClient.connector);\r\n    tClient.connector = spyConnector;\r\n    try {\r\n        Token<TimelineDelegationTokenIdentifier> identifierToken = tClient.getDelegationToken(UserGroupInformation.getCurrentUser().getShortUserName());\r\n        Assert.assertNull(identifierToken);\r\n        Token<TimelineDelegationTokenIdentifier> dummyToken = new Token<>();\r\n        long renewTime = tClient.renewDelegationToken(dummyToken);\r\n        Assert.assertEquals(renewTime, -1);\r\n        tClient.cancelDelegationToken(dummyToken);\r\n        verify(spyConnector, never()).getDelegationTokenAuthenticatedURL();\r\n    } finally {\r\n        tClient.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "assertFail",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void assertFail()\n{\r\n    Assert.fail(\"Exception expected! \" + \"Timeline server should be off to run this test.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "assertException",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void assertException(TimelineClientImpl client, RuntimeException ce)\n{\r\n    Assert.assertTrue(\"Handler exception for reason other than retry: \" + ce.toString(), ce.getMessage().contains(\"Connection retries limit exceeded\"));\r\n    Assert.assertTrue(\"Retry filter didn't perform any retries! \", client.connector.connectionRetry.getRetired());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "mockEntityClientResponse",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "ClientResponse mockEntityClientResponse(TimelineWriter spyTimelineWriter, ClientResponse.Status status, boolean hasError, boolean hasRuntimeError)\n{\r\n    ClientResponse response = mock(ClientResponse.class);\r\n    if (hasRuntimeError) {\r\n        doThrow(new ClientHandlerException(new ConnectException())).when(spyTimelineWriter).doPostingObject(any(TimelineEntities.class), any());\r\n        return response;\r\n    }\r\n    doReturn(response).when(spyTimelineWriter).doPostingObject(any(TimelineEntities.class), any());\r\n    when(response.getStatusInfo()).thenReturn(status);\r\n    TimelinePutResponse.TimelinePutError error = new TimelinePutResponse.TimelinePutError();\r\n    error.setEntityId(\"test entity id\");\r\n    error.setEntityType(\"test entity type\");\r\n    error.setErrorCode(TimelinePutResponse.TimelinePutError.IO_EXCEPTION);\r\n    TimelinePutResponse putResponse = new TimelinePutResponse();\r\n    if (hasError) {\r\n        putResponse.addError(error);\r\n    }\r\n    when(response.getEntity(TimelinePutResponse.class)).thenReturn(putResponse);\r\n    return response;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "mockDomainClientResponse",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "ClientResponse mockDomainClientResponse(TimelineWriter spyTimelineWriter, ClientResponse.Status status, boolean hasRuntimeError)\n{\r\n    ClientResponse response = mock(ClientResponse.class);\r\n    if (hasRuntimeError) {\r\n        doThrow(new ClientHandlerException(new ConnectException())).when(spyTimelineWriter).doPostingObject(any(TimelineDomain.class), any(String.class));\r\n        return response;\r\n    }\r\n    doReturn(response).when(spyTimelineWriter).doPostingObject(any(TimelineDomain.class), any(String.class));\r\n    when(response.getStatusInfo()).thenReturn(status);\r\n    return response;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "generateEntity",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "TimelineEntity generateEntity()\n{\r\n    TimelineEntity entity = new TimelineEntity();\r\n    entity.setEntityId(\"entity id\");\r\n    entity.setEntityType(\"entity type\");\r\n    entity.setStartTime(System.currentTimeMillis());\r\n    for (int i = 0; i < 2; ++i) {\r\n        TimelineEvent event = new TimelineEvent();\r\n        event.setTimestamp(System.currentTimeMillis());\r\n        event.setEventType(\"test event type \" + i);\r\n        event.addEventInfo(\"key1\", \"val1\");\r\n        event.addEventInfo(\"key2\", \"val2\");\r\n        entity.addEvent(event);\r\n    }\r\n    entity.addRelatedEntity(\"test ref type 1\", \"test ref id 1\");\r\n    entity.addRelatedEntity(\"test ref type 2\", \"test ref id 2\");\r\n    entity.addPrimaryFilter(\"pkey1\", \"pval1\");\r\n    entity.addPrimaryFilter(\"pkey2\", \"pval2\");\r\n    entity.addOtherInfo(\"okey1\", \"oval1\");\r\n    entity.addOtherInfo(\"okey2\", \"oval2\");\r\n    entity.setDomainId(\"domain id 1\");\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "generateDomain",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "TimelineDomain generateDomain()\n{\r\n    TimelineDomain domain = new TimelineDomain();\r\n    domain.setId(\"namesapce id\");\r\n    domain.setDescription(\"domain description\");\r\n    domain.setOwner(\"domain owner\");\r\n    domain.setReaders(\"domain_reader\");\r\n    domain.setWriters(\"domain_writer\");\r\n    domain.setCreatedTime(0L);\r\n    domain.setModifiedTime(1L);\r\n    return domain;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "createTimelineClient",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineClientImpl createTimelineClient(YarnConfiguration conf)\n{\r\n    TimelineClientImpl client = new TimelineClientImpl() {\r\n\r\n        @Override\r\n        protected TimelineWriter createTimelineWriter(Configuration conf, UserGroupInformation authUgi, Client client, URI resURI) throws IOException {\r\n            TimelineWriter timelineWriter = new DirectTimelineWriter(authUgi, client, resURI);\r\n            spyTimelineWriter = spy(timelineWriter);\r\n            return spyTimelineWriter;\r\n        }\r\n    };\r\n    client.init(conf);\r\n    client.start();\r\n    return client;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "createTimelineClientFakeTimelineClientRetryOp",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "TimelineClientImpl createTimelineClientFakeTimelineClientRetryOp(YarnConfiguration conf)\n{\r\n    TimelineClientImpl client = new TimelineClientImpl() {\r\n\r\n        @Override\r\n        protected TimelineConnector createTimelineConnector() {\r\n            TimelineConnector connector = new TimelineConnector(true, authUgi, doAsUser, token) {\r\n\r\n                @Override\r\n                public TimelineClientRetryOp createRetryOpForOperateDelegationToken(final PrivilegedExceptionAction<?> action) throws IOException {\r\n                    TimelineClientRetryOpForOperateDelegationToken op = spy(new TimelineClientRetryOpForOperateDelegationToken(UserGroupInformation.getCurrentUser(), action));\r\n                    doThrow(new SocketTimeoutException(\"Test socketTimeoutException\")).when(op).run();\r\n                    return op;\r\n                }\r\n            };\r\n            addIfService(connector);\r\n            return connector;\r\n        }\r\n    };\r\n    client.init(conf);\r\n    client.start();\r\n    return client;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testTimelineClientCleanup",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testTimelineClientCleanup() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.setInt(YarnConfiguration.TIMELINE_SERVICE_CLIENT_MAX_RETRIES, 0);\r\n    conf.set(YarnConfiguration.YARN_HTTP_POLICY_KEY, Policy.HTTPS_ONLY.name());\r\n    setupSSLConfig(conf);\r\n    client = createTimelineClient(conf);\r\n    ThreadGroup threadGroup = Thread.currentThread().getThreadGroup();\r\n    while (threadGroup.getParent() != null) {\r\n        threadGroup = threadGroup.getParent();\r\n    }\r\n    Thread[] threads = new Thread[threadGroup.activeCount()];\r\n    threadGroup.enumerate(threads);\r\n    Thread reloaderThread = null;\r\n    for (Thread thread : threads) {\r\n        if ((thread.getName() != null) && (thread.getName().contains(SSL_MONITORING_THREAD_NAME))) {\r\n            reloaderThread = thread;\r\n        }\r\n    }\r\n    Assert.assertTrue(\"Reloader is not alive\", reloaderThread.isAlive());\r\n    client.close();\r\n    boolean reloaderStillAlive = true;\r\n    for (int i = 0; i < 10; i++) {\r\n        reloaderStillAlive = reloaderThread.isAlive();\r\n        if (!reloaderStillAlive) {\r\n            break;\r\n        }\r\n        Thread.sleep(1000);\r\n    }\r\n    Assert.assertFalse(\"Reloader is still alive\", reloaderStillAlive);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testTimelineConnectorDestroy",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testTimelineConnectorDestroy()\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    TimelineClientImpl client = createTimelineClient(conf);\r\n    Client mockJerseyClient = mock(Client.class);\r\n    client.connector.client = mockJerseyClient;\r\n    client.stop();\r\n    verify(mockJerseyClient, times(1)).destroy();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "setupSSLConfig",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setupSSLConfig(YarnConfiguration conf) throws Exception\n{\r\n    keystoresDir = TestGenericTestUtils.getTestDir().getAbsolutePath();\r\n    sslConfDir = KeyStoreTestUtil.getClasspathDir(TestTimelineClient.class);\r\n    KeyStoreTestUtil.setupSSLConfig(keystoresDir, sslConfDir, conf, false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "isSSLConfigured",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isSSLConfigured()\n{\r\n    return keystoresDir != null && sslConfDir != null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testCLCPBImplNullEnv",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testCLCPBImplNullEnv() throws IOException\n{\r\n    Map<String, LocalResource> localResources = Collections.emptyMap();\r\n    Map<String, String> environment = new HashMap<String, String>();\r\n    List<String> commands = Collections.emptyList();\r\n    Map<String, ByteBuffer> serviceData = Collections.emptyMap();\r\n    Credentials containerCreds = new Credentials();\r\n    DataOutputBuffer dob = new DataOutputBuffer();\r\n    containerCreds.writeTokenStorageToStream(dob);\r\n    ByteBuffer containerTokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\r\n    Map<ApplicationAccessType, String> acls = Collections.emptyMap();\r\n    environment.put(\"testCLCPBImplNullEnv\", null);\r\n    ContainerLaunchContext clc = ContainerLaunchContext.newInstance(localResources, environment, commands, serviceData, containerTokens, acls);\r\n    ContainerLaunchContext clcProto = new ContainerLaunchContextPBImpl(((ContainerLaunchContextPBImpl) clc).getProto());\r\n    Assert.assertEquals(\"\", clcProto.getEnvironment().get(\"testCLCPBImplNullEnv\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testCLCPBImplNullResourceURL",
  "errType" : [ "NullPointerException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testCLCPBImplNullResourceURL() throws IOException\n{\r\n    RecordFactory recordFactory = RecordFactoryProvider.getRecordFactory(null);\r\n    try {\r\n        LocalResource rsrc_alpha = recordFactory.newRecordInstance(LocalResource.class);\r\n        rsrc_alpha.setResource(null);\r\n        rsrc_alpha.setSize(-1);\r\n        rsrc_alpha.setVisibility(LocalResourceVisibility.APPLICATION);\r\n        rsrc_alpha.setType(LocalResourceType.FILE);\r\n        rsrc_alpha.setTimestamp(System.currentTimeMillis());\r\n        Map<String, LocalResource> localResources = new HashMap<String, LocalResource>();\r\n        localResources.put(\"null_url_resource\", rsrc_alpha);\r\n        ContainerLaunchContext containerLaunchContext = recordFactory.newRecordInstance(ContainerLaunchContext.class);\r\n        containerLaunchContext.setLocalResources(localResources);\r\n        Assert.fail(\"Setting an invalid local resource should be an error!\");\r\n    } catch (NullPointerException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Null resource URL for local resource\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testCLCPBImplNullResourceType",
  "errType" : [ "NullPointerException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testCLCPBImplNullResourceType() throws IOException\n{\r\n    RecordFactory recordFactory = RecordFactoryProvider.getRecordFactory(null);\r\n    try {\r\n        LocalResource resource = recordFactory.newRecordInstance(LocalResource.class);\r\n        resource.setResource(URL.fromPath(new Path(\".\")));\r\n        resource.setSize(-1);\r\n        resource.setVisibility(LocalResourceVisibility.APPLICATION);\r\n        resource.setType(null);\r\n        resource.setTimestamp(System.currentTimeMillis());\r\n        Map<String, LocalResource> localResources = new HashMap<String, LocalResource>();\r\n        localResources.put(\"null_type_resource\", resource);\r\n        ContainerLaunchContext containerLaunchContext = recordFactory.newRecordInstance(ContainerLaunchContext.class);\r\n        containerLaunchContext.setLocalResources(localResources);\r\n        Assert.fail(\"Setting an invalid local resource should be an error!\");\r\n    } catch (NullPointerException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Null resource type for local resource\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records\\impl\\pb",
  "methodName" : "testCLCPBImplNullResourceVisibility",
  "errType" : [ "NullPointerException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testCLCPBImplNullResourceVisibility() throws IOException\n{\r\n    RecordFactory recordFactory = RecordFactoryProvider.getRecordFactory(null);\r\n    try {\r\n        LocalResource resource = recordFactory.newRecordInstance(LocalResource.class);\r\n        resource.setResource(URL.fromPath(new Path(\".\")));\r\n        resource.setSize(-1);\r\n        resource.setVisibility(null);\r\n        resource.setType(LocalResourceType.FILE);\r\n        resource.setTimestamp(System.currentTimeMillis());\r\n        Map<String, LocalResource> localResources = new HashMap<String, LocalResource>();\r\n        localResources.put(\"null_visibility_resource\", resource);\r\n        ContainerLaunchContext containerLaunchContext = recordFactory.newRecordInstance(ContainerLaunchContext.class);\r\n        containerLaunchContext.setLocalResources(localResources);\r\n        Assert.fail(\"Setting an invalid local resource should be an error!\");\r\n    } catch (NullPointerException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"Null resource visibility for local resource\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "testPbRecordFactory",
  "errType" : [ "YarnRuntimeException", "YarnRuntimeException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testPbRecordFactory()\n{\r\n    RecordFactory pbRecordFactory = RecordFactoryPBImpl.get();\r\n    try {\r\n        AllocateResponse response = pbRecordFactory.newRecordInstance(AllocateResponse.class);\r\n        Assert.assertEquals(AllocateResponsePBImpl.class, response.getClass());\r\n    } catch (YarnRuntimeException e) {\r\n        e.printStackTrace();\r\n        Assert.fail(\"Failed to crete record\");\r\n    }\r\n    try {\r\n        AllocateRequest response = pbRecordFactory.newRecordInstance(AllocateRequest.class);\r\n        Assert.assertEquals(AllocateRequestPBImpl.class, response.getClass());\r\n    } catch (YarnRuntimeException e) {\r\n        e.printStackTrace();\r\n        Assert.fail(\"Failed to crete record\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\resourcetypes",
  "methodName" : "newResource",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "Resource newResource(long memory, int vCores, Map<String, String> customResources)\n{\r\n    Resource resource = RECORD_FACTORY.newRecordInstance(Resource.class);\r\n    resource.setMemorySize(memory);\r\n    resource.setVirtualCores(vCores);\r\n    if (customResources != null) {\r\n        for (Map.Entry<String, String> customResource : customResources.entrySet()) {\r\n            String resourceName = customResource.getKey();\r\n            ResourceInformation resourceInformation = createResourceInformation(resourceName, customResource.getValue());\r\n            resource.setResourceInformation(resourceName, resourceInformation);\r\n        }\r\n    }\r\n    return resource;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\resourcetypes",
  "methodName" : "createResourceInformation",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ResourceInformation createResourceInformation(String resourceName, String descriptor)\n{\r\n    ResourceValueAndUnit resourceValueAndUnit = getResourceValueAndUnit(descriptor);\r\n    return ResourceInformation.newInstance(resourceName, resourceValueAndUnit.unit, resourceValueAndUnit.value);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\resourcetypes",
  "methodName" : "getResourceValueAndUnit",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "ResourceValueAndUnit getResourceValueAndUnit(String val)\n{\r\n    Matcher matcher = RESOURCE_VALUE_AND_UNIT_PATTERN.matcher(val);\r\n    if (!matcher.find()) {\r\n        throw new RuntimeException(\"Invalid pattern of resource descriptor: \" + val);\r\n    } else if (matcher.groupCount() != 2) {\r\n        throw new RuntimeException(\"Capturing group count in string \" + val + \" is not 2!\");\r\n    }\r\n    long value = Long.parseLong(matcher.group(1));\r\n    return new ResourceValueAndUnit(value, matcher.group(2));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\resourcetypes",
  "methodName" : "extractCustomResources",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "Map<String, Long> extractCustomResources(Resource res)\n{\r\n    Map<String, Long> customResources = Maps.newHashMap();\r\n    for (int i = 0; i < res.getResources().length; i++) {\r\n        ResourceInformation ri = res.getResourceInformation(i);\r\n        if (!ri.getName().equals(ResourceInformation.MEMORY_URI) && !ri.getName().equals(ResourceInformation.VCORES_URI)) {\r\n            customResources.put(ri.getName(), ri.getValue());\r\n        }\r\n    }\r\n    return customResources;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\resourcetypes",
  "methodName" : "extractCustomResourcesAsStrings",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Map<String, String> extractCustomResourcesAsStrings(Resource res)\n{\r\n    Map<String, Long> resValues = extractCustomResources(res);\r\n    return convertCustomResources(resValues);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\resourcetypes",
  "methodName" : "convertCustomResources",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, String> convertCustomResources(Map<String, ? extends Number> customResources)\n{\r\n    return customResources.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> String.valueOf(e.getValue())));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testContainerId",
  "errType" : null,
  "containingMethodsNum" : 31,
  "sourceCodeText" : "void testContainerId()\n{\r\n    ContainerId c1 = newContainerId(1, 1, 10l, 1);\r\n    ContainerId c2 = newContainerId(1, 1, 10l, 2);\r\n    ContainerId c3 = newContainerId(1, 1, 10l, 1);\r\n    ContainerId c4 = newContainerId(1, 3, 10l, 1);\r\n    ContainerId c5 = newContainerId(1, 3, 8l, 1);\r\n    Assert.assertTrue(c1.equals(c3));\r\n    Assert.assertFalse(c1.equals(c2));\r\n    Assert.assertFalse(c1.equals(c4));\r\n    Assert.assertFalse(c1.equals(c5));\r\n    Assert.assertTrue(c1.compareTo(c3) == 0);\r\n    Assert.assertTrue(c1.compareTo(c2) < 0);\r\n    Assert.assertTrue(c1.compareTo(c4) < 0);\r\n    Assert.assertTrue(c1.compareTo(c5) > 0);\r\n    Assert.assertTrue(c1.hashCode() == c3.hashCode());\r\n    Assert.assertFalse(c1.hashCode() == c2.hashCode());\r\n    Assert.assertFalse(c1.hashCode() == c4.hashCode());\r\n    Assert.assertFalse(c1.hashCode() == c5.hashCode());\r\n    long ts = System.currentTimeMillis();\r\n    ContainerId c6 = newContainerId(36473, 4365472, ts, 25645811);\r\n    Assert.assertEquals(\"container_10_0001_01_000001\", c1.toString());\r\n    Assert.assertEquals(25645811, 0xffffffffffL & c6.getContainerId());\r\n    Assert.assertEquals(0, c6.getContainerId() >> 40);\r\n    Assert.assertEquals(\"container_\" + ts + \"_36473_4365472_25645811\", c6.toString());\r\n    ContainerId c7 = newContainerId(36473, 4365472, ts, 4298334883325L);\r\n    Assert.assertEquals(999799999997L, 0xffffffffffL & c7.getContainerId());\r\n    Assert.assertEquals(3, c7.getContainerId() >> 40);\r\n    Assert.assertEquals(\"container_e03_\" + ts + \"_36473_4365472_999799999997\", c7.toString());\r\n    ContainerId c8 = newContainerId(36473, 4365472, ts, 844424930131965L);\r\n    Assert.assertEquals(1099511627773L, 0xffffffffffL & c8.getContainerId());\r\n    Assert.assertEquals(767, c8.getContainerId() >> 40);\r\n    Assert.assertEquals(\"container_e767_\" + ts + \"_36473_4365472_1099511627773\", c8.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "newContainerId",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "ContainerId newContainerId(int appId, int appAttemptId, long timestamp, long containerId)\n{\r\n    ApplicationId applicationId = ApplicationId.newInstance(timestamp, appId);\r\n    ApplicationAttemptId applicationAttemptId = ApplicationAttemptId.newInstance(applicationId, appAttemptId);\r\n    return ContainerId.newContainerId(applicationAttemptId, containerId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newAppName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String newAppName()\n{\r\n    synchronized (NAMES) {\r\n        return NAMES.next();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newUserName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String newUserName()\n{\r\n    synchronized (USERS) {\r\n        return USERS.next();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newQueue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String newQueue()\n{\r\n    synchronized (QUEUES) {\r\n        return QUEUES.next();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newAppID",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ApplicationId newAppID(int i)\n{\r\n    return ApplicationId.newInstance(TS, i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn",
  "methodName" : "newAppState",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "YarnApplicationState newAppState()\n{\r\n    synchronized (STATES) {\r\n        return STATES.next();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    localFS = FileContext.getLocalFSFileContext();\r\n    localActiveDir = new File(\"target\", this.getClass().getSimpleName() + \"-activeDir\").getAbsoluteFile();\r\n    localFS.delete(new Path(localActiveDir.getAbsolutePath()), true);\r\n    localActiveDir.mkdir();\r\n    LOG.info(\"Created activeDir in \" + localActiveDir.getAbsolutePath());\r\n    authUgi = UserGroupInformation.getCurrentUser();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "getConfigurations",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "YarnConfiguration getConfigurations()\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);\r\n    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION, 1.5f);\r\n    conf.set(YarnConfiguration.TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_ACTIVE_DIR, localActiveDir.getAbsolutePath());\r\n    conf.set(YarnConfiguration.TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_SUMMARY_ENTITY_TYPES, \"summary_type\");\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void tearDown() throws Exception\n{\r\n    if (client != null) {\r\n        client.stop();\r\n    }\r\n    localFS.delete(new Path(localActiveDir.getAbsolutePath()), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntities",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testPostEntities() throws Exception\n{\r\n    client = createTimelineClient(getConfigurations());\r\n    verifyForPostEntities(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPostEntitiesToKeepUnderUserDir",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPostEntitiesToKeepUnderUserDir() throws Exception\n{\r\n    YarnConfiguration conf = getConfigurations();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_WITH_USER_DIR, true);\r\n    client = createTimelineClient(conf);\r\n    verifyForPostEntities(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "verifyForPostEntities",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void verifyForPostEntities(boolean storeInsideUserDir)\n{\r\n    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);\r\n    TimelineEntityGroupId groupId = TimelineEntityGroupId.newInstance(appId, \"1\");\r\n    TimelineEntityGroupId groupId2 = TimelineEntityGroupId.newInstance(appId, \"2\");\r\n    TimelineEntity[] entities = new TimelineEntity[2];\r\n    entities[0] = generateEntity(\"entity_type\");\r\n    entities[1] = generateEntity(\"summary_type\");\r\n    try {\r\n        client.putEntities(null, null, entities);\r\n        verify(spyTimelineWriter, times(1)).putEntities(entities);\r\n        reset(spyTimelineWriter);\r\n        ApplicationAttemptId attemptId1 = ApplicationAttemptId.newInstance(appId, 1);\r\n        client.putEntities(attemptId1, null, entities);\r\n        TimelineEntity[] entityTDB = new TimelineEntity[1];\r\n        entityTDB[0] = entities[0];\r\n        verify(spyTimelineWriter, times(1)).putEntities(entityTDB);\r\n        Assert.assertTrue(localFS.util().exists(new Path(getAppAttemptDir(attemptId1, storeInsideUserDir), \"summarylog-\" + attemptId1.toString())));\r\n        reset(spyTimelineWriter);\r\n        ApplicationAttemptId attemptId2 = ApplicationAttemptId.newInstance(appId, 2);\r\n        client.putEntities(attemptId2, groupId, entities);\r\n        client.putEntities(attemptId2, groupId2, entities);\r\n        verify(spyTimelineWriter, times(0)).putEntities(any(TimelineEntity[].class));\r\n        Assert.assertTrue(localFS.util().exists(new Path(getAppAttemptDir(attemptId2, storeInsideUserDir), \"summarylog-\" + attemptId2.toString())));\r\n        Assert.assertTrue(localFS.util().exists(new Path(getAppAttemptDir(attemptId2, storeInsideUserDir), \"entitylog-\" + groupId.toString())));\r\n        Assert.assertTrue(localFS.util().exists(new Path(getAppAttemptDir(attemptId2, storeInsideUserDir), \"entitylog-\" + groupId2.toString())));\r\n        reset(spyTimelineWriter);\r\n    } catch (Exception e) {\r\n        Assert.fail(\"Exception is not expected. \" + e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPutDomain",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testPutDomain()\n{\r\n    client = createTimelineClient(getConfigurations());\r\n    verifyForPutDomain(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "testPutDomainToKeepUnderUserDir",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testPutDomainToKeepUnderUserDir()\n{\r\n    YarnConfiguration conf = getConfigurations();\r\n    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENTITYGROUP_FS_STORE_WITH_USER_DIR, true);\r\n    client = createTimelineClient(conf);\r\n    verifyForPutDomain(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "verifyForPutDomain",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void verifyForPutDomain(boolean storeInsideUserDir)\n{\r\n    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);\r\n    ApplicationAttemptId attemptId1 = ApplicationAttemptId.newInstance(appId, 1);\r\n    try {\r\n        TimelineDomain domain = generateDomain();\r\n        client.putDomain(null, domain);\r\n        verify(spyTimelineWriter, times(1)).putDomain(domain);\r\n        reset(spyTimelineWriter);\r\n        client.putDomain(attemptId1, domain);\r\n        verify(spyTimelineWriter, times(0)).putDomain(domain);\r\n        Assert.assertTrue(localFS.util().exists(new Path(getAppAttemptDir(attemptId1, storeInsideUserDir), \"domainlog-\" + attemptId1.toString())));\r\n        reset(spyTimelineWriter);\r\n    } catch (Exception e) {\r\n        Assert.fail(\"Exception is not expected.\" + e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "getAppAttemptDir",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Path getAppAttemptDir(ApplicationAttemptId appAttemptId, boolean storeInsideUserDir)\n{\r\n    Path userDir = getUserDir(appAttemptId, storeInsideUserDir);\r\n    Path appDir = new Path(userDir, appAttemptId.getApplicationId().toString());\r\n    Path attemptDir = new Path(appDir, appAttemptId.toString());\r\n    return attemptDir;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "getUserDir",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Path getUserDir(ApplicationAttemptId appAttemptId, boolean storeInsideUserDir)\n{\r\n    if (!storeInsideUserDir) {\r\n        return new Path(localActiveDir.getAbsolutePath());\r\n    }\r\n    Path userDir = new Path(localActiveDir.getAbsolutePath(), authUgi.getShortUserName());\r\n    return userDir;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "generateEntity",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineEntity generateEntity(String type)\n{\r\n    TimelineEntity entity = new TimelineEntity();\r\n    entity.setEntityId(\"entity id\");\r\n    entity.setEntityType(type);\r\n    entity.setStartTime(System.currentTimeMillis());\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "generateDomain",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "TimelineDomain generateDomain()\n{\r\n    TimelineDomain domain = new TimelineDomain();\r\n    domain.setId(\"namesapce id\");\r\n    domain.setDescription(\"domain description\");\r\n    domain.setOwner(\"domain owner\");\r\n    domain.setReaders(\"domain_reader\");\r\n    domain.setWriters(\"domain_writer\");\r\n    domain.setCreatedTime(0L);\r\n    domain.setModifiedTime(1L);\r\n    return domain;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\client\\api\\impl",
  "methodName" : "createTimelineClient",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "TimelineClientImpl createTimelineClient(YarnConfiguration conf)\n{\r\n    TimelineClientImpl client = new TimelineClientImpl() {\r\n\r\n        @Override\r\n        protected TimelineWriter createTimelineWriter(Configuration conf, UserGroupInformation authUgi, Client client, URI resURI) throws IOException {\r\n            TimelineWriter timelineWriter = new FileSystemTimelineWriter(conf, authUgi, client, resURI) {\r\n\r\n                public ClientResponse doPostingObject(Object object, String path) {\r\n                    ClientResponse response = mock(ClientResponse.class);\r\n                    when(response.getStatusInfo()).thenReturn(ClientResponse.Status.OK);\r\n                    return response;\r\n                }\r\n            };\r\n            spyTimelineWriter = spy(timelineWriter);\r\n            return spyTimelineWriter;\r\n        }\r\n    };\r\n    client.init(conf);\r\n    client.start();\r\n    return client;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getPort",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int getPort(int port)\n{\r\n    Random rand = new Random();\r\n    int jerseyPort = port + rand.nextInt(1000);\r\n    try {\r\n        jerseyPort = ServerSocketUtil.getPort(jerseyPort, 10);\r\n    } catch (IOException e) {\r\n    }\r\n    return super.getPort(jerseyPort);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setupExtraResourceType",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setupExtraResourceType() throws Exception\n{\r\n    Configuration conf = new YarnConfiguration();\r\n    resourceTypesFile = TestResourceUtils.setupResourceTypes(conf, \"resource-types-3.xml\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "unsetExtraResourceType",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void unsetExtraResourceType()\n{\r\n    deleteResourceTypesFile();\r\n    ResourceUtils.resetResourceTypes();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "deleteResourceTypesFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void deleteResourceTypesFile()\n{\r\n    if (resourceTypesFile != null && !resourceTypesFile.isEmpty()) {\r\n        File resourceFile = new File(resourceTypesFile);\r\n        resourceFile.delete();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    setupExtraResourceType();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "teardown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void teardown()\n{\r\n    deleteResourceTypesFile();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "createResource",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Resource createResource(long memory, int vCores)\n{\r\n    return Resource.newInstance(memory, vCores);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "createResource",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Resource createResource(long memory, int vCores, long resource2)\n{\r\n    Resource ret = Resource.newInstance(memory, vCores);\r\n    ret.setResourceInformation(EXTRA_RESOURCE_TYPE, ResourceInformation.newInstance(EXTRA_RESOURCE_TYPE, resource2));\r\n    return ret;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareToWithUnboundedResource",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testCompareToWithUnboundedResource()\n{\r\n    unsetExtraResourceType();\r\n    Resource unboundedClone = Resources.clone(ExtendedResources.unbounded());\r\n    assertTrue(unboundedClone.compareTo(createResource(Long.MAX_VALUE, Integer.MAX_VALUE)) == 0);\r\n    assertTrue(unboundedClone.compareTo(createResource(Long.MAX_VALUE, 0)) > 0);\r\n    assertTrue(unboundedClone.compareTo(createResource(0, Integer.MAX_VALUE)) > 0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCompareToWithNoneResource",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testCompareToWithNoneResource()\n{\r\n    assertTrue(Resources.none().compareTo(createResource(0, 0)) == 0);\r\n    assertTrue(Resources.none().compareTo(createResource(1, 0)) < 0);\r\n    assertTrue(Resources.none().compareTo(createResource(0, 1)) < 0);\r\n    assertTrue(Resources.none().compareTo(createResource(0, 0, 0)) == 0);\r\n    assertTrue(Resources.none().compareTo(createResource(1, 0, 0)) < 0);\r\n    assertTrue(Resources.none().compareTo(createResource(0, 1, 0)) < 0);\r\n    assertTrue(Resources.none().compareTo(createResource(0, 0, 1)) < 0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testFitsIn",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testFitsIn()\n{\r\n    assertTrue(fitsIn(createResource(1, 1), createResource(2, 2)));\r\n    assertTrue(fitsIn(createResource(2, 2), createResource(2, 2)));\r\n    assertFalse(fitsIn(createResource(2, 2), createResource(1, 1)));\r\n    assertFalse(fitsIn(createResource(1, 2), createResource(2, 1)));\r\n    assertFalse(fitsIn(createResource(2, 1), createResource(1, 2)));\r\n    assertTrue(fitsIn(createResource(1, 1, 1), createResource(2, 2, 2)));\r\n    assertTrue(fitsIn(createResource(1, 1, 0), createResource(2, 2, 0)));\r\n    assertTrue(fitsIn(createResource(1, 1, 1), createResource(2, 2, 2)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testComponentwiseMin",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testComponentwiseMin()\n{\r\n    assertEquals(createResource(1, 1), componentwiseMin(createResource(1, 1), createResource(2, 2)));\r\n    assertEquals(createResource(1, 1), componentwiseMin(createResource(2, 2), createResource(1, 1)));\r\n    assertEquals(createResource(1, 1), componentwiseMin(createResource(1, 2), createResource(2, 1)));\r\n    assertEquals(createResource(1, 1, 1), componentwiseMin(createResource(1, 1, 1), createResource(2, 2, 2)));\r\n    assertEquals(createResource(1, 1, 0), componentwiseMin(createResource(2, 2, 2), createResource(1, 1)));\r\n    assertEquals(createResource(1, 1, 2), componentwiseMin(createResource(1, 2, 2), createResource(2, 1, 3)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testComponentwiseMax",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testComponentwiseMax()\n{\r\n    assertEquals(createResource(2, 2), componentwiseMax(createResource(1, 1), createResource(2, 2)));\r\n    assertEquals(createResource(2, 2), componentwiseMax(createResource(2, 2), createResource(1, 1)));\r\n    assertEquals(createResource(2, 2), componentwiseMax(createResource(1, 2), createResource(2, 1)));\r\n    assertEquals(createResource(2, 2, 2), componentwiseMax(createResource(1, 1, 1), createResource(2, 2, 2)));\r\n    assertEquals(createResource(2, 2, 2), componentwiseMax(createResource(2, 2, 2), createResource(1, 1)));\r\n    assertEquals(createResource(2, 2, 3), componentwiseMax(createResource(1, 2, 2), createResource(2, 1, 3)));\r\n    assertEquals(createResource(2, 2, 1), componentwiseMax(createResource(2, 2, 0), createResource(2, 1, 1)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testAdd",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testAdd()\n{\r\n    assertEquals(createResource(2, 3), add(createResource(1, 1), createResource(1, 2)));\r\n    assertEquals(createResource(3, 2), add(createResource(1, 1), createResource(2, 1)));\r\n    assertEquals(createResource(2, 2, 0), add(createResource(1, 1, 0), createResource(1, 1, 0)));\r\n    assertEquals(createResource(2, 2, 3), add(createResource(1, 1, 1), createResource(1, 1, 2)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testSubtract",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testSubtract()\n{\r\n    assertEquals(createResource(1, 0), subtract(createResource(2, 1), createResource(1, 1)));\r\n    assertEquals(createResource(0, 1), subtract(createResource(1, 2), createResource(1, 1)));\r\n    assertEquals(createResource(2, 2, 0), subtract(createResource(3, 3, 0), createResource(1, 1, 0)));\r\n    assertEquals(createResource(1, 1, 2), subtract(createResource(2, 2, 3), createResource(1, 1, 1)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testClone",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testClone()\n{\r\n    assertEquals(createResource(1, 1), Resources.clone(createResource(1, 1)));\r\n    assertEquals(createResource(1, 1, 0), Resources.clone(createResource(1, 1)));\r\n    assertEquals(createResource(1, 1), Resources.clone(createResource(1, 1, 0)));\r\n    assertEquals(createResource(1, 1, 2), Resources.clone(createResource(1, 1, 2)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMultiply",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testMultiply()\n{\r\n    assertEquals(createResource(4, 2), multiply(createResource(2, 1), 2));\r\n    assertEquals(createResource(4, 2, 0), multiply(createResource(2, 1), 2));\r\n    assertEquals(createResource(2, 4), multiply(createResource(1, 2), 2));\r\n    assertEquals(createResource(2, 4, 0), multiply(createResource(1, 2), 2));\r\n    assertEquals(createResource(6, 6, 0), multiply(createResource(3, 3, 0), 2));\r\n    assertEquals(createResource(4, 4, 6), multiply(createResource(2, 2, 3), 2));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMultiplyRoundUp",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testMultiplyRoundUp()\n{\r\n    final double by = 0.5;\r\n    final String memoryErrorMsg = \"Invalid memory size.\";\r\n    final String vcoreErrorMsg = \"Invalid virtual core number.\";\r\n    Resource resource = Resources.createResource(1, 1);\r\n    Resource result = Resources.multiplyAndRoundUp(resource, by);\r\n    assertEquals(memoryErrorMsg, result.getMemorySize(), 1);\r\n    assertEquals(vcoreErrorMsg, result.getVirtualCores(), 1);\r\n    resource = Resources.createResource(2, 2);\r\n    result = Resources.multiplyAndRoundUp(resource, by);\r\n    assertEquals(memoryErrorMsg, result.getMemorySize(), 1);\r\n    assertEquals(vcoreErrorMsg, result.getVirtualCores(), 1);\r\n    resource = Resources.createResource(0, 0);\r\n    result = Resources.multiplyAndRoundUp(resource, by);\r\n    assertEquals(memoryErrorMsg, result.getMemorySize(), 0);\r\n    assertEquals(vcoreErrorMsg, result.getVirtualCores(), 0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMultiplyAndRoundUpCustomResources",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testMultiplyAndRoundUpCustomResources()\n{\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(5, 2, 8), multiplyAndRoundUp(createResource(3, 1, 5), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(5, 2, 0), multiplyAndRoundUp(createResource(3, 1, 0), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(5, 5, 0), multiplyAndRoundUp(createResource(3, 3, 0), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(8, 3, 13), multiplyAndRoundUp(createResource(3, 1, 5), 2.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(8, 3, 0), multiplyAndRoundUp(createResource(3, 1, 0), 2.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(8, 8, 0), multiplyAndRoundUp(createResource(3, 3, 0), 2.5));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMultiplyAndRoundDown",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testMultiplyAndRoundDown()\n{\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(4, 1), multiplyAndRoundDown(createResource(3, 1), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(4, 1, 0), multiplyAndRoundDown(createResource(3, 1), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(1, 4), multiplyAndRoundDown(createResource(1, 3), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(1, 4, 0), multiplyAndRoundDown(createResource(1, 3), 1.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(7, 7, 0), multiplyAndRoundDown(createResource(3, 3, 0), 2.5));\r\n    assertEquals(INVALID_RESOURCE_MSG, createResource(2, 2, 7), multiplyAndRoundDown(createResource(1, 1, 3), 2.5));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testMultiplyAndAddTo",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testMultiplyAndAddTo() throws Exception\n{\r\n    unsetExtraResourceType();\r\n    setupExtraResourceType();\r\n    assertEquals(createResource(6, 4), multiplyAndAddTo(createResource(3, 1), createResource(2, 2), 1.5));\r\n    assertEquals(createResource(6, 4, 0), multiplyAndAddTo(createResource(3, 1), createResource(2, 2), 1.5));\r\n    assertEquals(createResource(4, 7), multiplyAndAddTo(createResource(1, 1), createResource(2, 4), 1.5));\r\n    assertEquals(createResource(4, 7, 0), multiplyAndAddTo(createResource(1, 1), createResource(2, 4), 1.5));\r\n    assertEquals(createResource(6, 4, 0), multiplyAndAddTo(createResource(3, 1, 0), createResource(2, 2, 0), 1.5));\r\n    assertEquals(createResource(6, 4, 6), multiplyAndAddTo(createResource(3, 1, 2), createResource(2, 2, 3), 1.5));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCreateResourceWithSameLongValue",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCreateResourceWithSameLongValue() throws Exception\n{\r\n    unsetExtraResourceType();\r\n    setupExtraResourceType();\r\n    Resource res = ResourceUtils.createResourceWithSameValue(11L);\r\n    assertEquals(11L, res.getMemorySize());\r\n    assertEquals(11, res.getVirtualCores());\r\n    assertEquals(11L, res.getResourceInformation(EXTRA_RESOURCE_TYPE).getValue());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCreateResourceWithSameIntValue",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCreateResourceWithSameIntValue() throws Exception\n{\r\n    unsetExtraResourceType();\r\n    setupExtraResourceType();\r\n    Resource res = ResourceUtils.createResourceWithSameValue(11);\r\n    assertEquals(11, res.getMemorySize());\r\n    assertEquals(11, res.getVirtualCores());\r\n    assertEquals(11, res.getResourceInformation(EXTRA_RESOURCE_TYPE).getValue());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCreateSimpleResourceWithSameLongValue",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testCreateSimpleResourceWithSameLongValue()\n{\r\n    Resource res = ResourceUtils.createResourceWithSameValue(11L);\r\n    assertEquals(11L, res.getMemorySize());\r\n    assertEquals(11, res.getVirtualCores());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util\\resource",
  "methodName" : "testCreateSimpleResourceWithSameIntValue",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testCreateSimpleResourceWithSameIntValue()\n{\r\n    Resource res = ResourceUtils.createResourceWithSameValue(11);\r\n    assertEquals(11, res.getMemorySize());\r\n    assertEquals(11, res.getVirtualCores());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlLong",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "long getXmlLong(Element element, String name)\n{\r\n    String val = getXmlString(element, name);\r\n    return Long.parseLong(val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlInt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getXmlInt(Element element, String name)\n{\r\n    String val = getXmlString(element, name);\r\n    return Integer.parseInt(val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlBoolean",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Boolean getXmlBoolean(Element element, String name)\n{\r\n    String val = getXmlString(element, name);\r\n    return Boolean.parseBoolean(val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlFloat",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "float getXmlFloat(Element element, String name)\n{\r\n    String val = getXmlString(element, name);\r\n    return Float.parseFloat(val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlStrings",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "List<String> getXmlStrings(Element element, String name)\n{\r\n    NodeList id = element.getElementsByTagName(name);\r\n    List<String> strings = new ArrayList<>();\r\n    int len = id.getLength();\r\n    if (id.getLength() == 0) {\r\n        return strings;\r\n    }\r\n    for (int i = 0; i < len; i++) {\r\n        Element line = (Element) id.item(i);\r\n        if (line == null) {\r\n            continue;\r\n        }\r\n        Node first = line.getFirstChild();\r\n        if (first == null) {\r\n            continue;\r\n        }\r\n        String val = first.getNodeValue();\r\n        if (val == null) {\r\n            continue;\r\n        }\r\n        strings.add(val);\r\n    }\r\n    return strings;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlString",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String getXmlString(Element element, String name)\n{\r\n    NodeList id = element.getElementsByTagName(name);\r\n    Element line = (Element) id.item(0);\r\n    if (line == null) {\r\n        return null;\r\n    }\r\n    Node first = line.getFirstChild();\r\n    if (first == null) {\r\n        return \"\";\r\n    }\r\n    String val = first.getNodeValue();\r\n    if (val == null) {\r\n        return \"\";\r\n    }\r\n    return val;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getPropertyValue",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "String getPropertyValue(Element element, String elementName, String propertyName)\n{\r\n    NodeList id = element.getElementsByTagName(elementName);\r\n    Element line = (Element) id.item(0);\r\n    if (line == null) {\r\n        return null;\r\n    }\r\n    NodeList properties = line.getChildNodes();\r\n    for (int i = 0; i < properties.getLength(); i++) {\r\n        Element property = (Element) properties.item(i);\r\n        if (getXmlString(property, \"name\").equals(propertyName)) {\r\n            return getXmlString(property, \"value\");\r\n        }\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getXmlAttrString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getXmlAttrString(Element element, String name)\n{\r\n    Attr at = element.getAttributeNode(name);\r\n    if (at != null) {\r\n        return at.getValue();\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "checkStringMatch",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void checkStringMatch(String print, String expected, String got)\n{\r\n    assertTrue(print + \" doesn't match, got: \" + got + \" expected: \" + expected, got.matches(expected));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "checkStringContains",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void checkStringContains(String print, String expected, String got)\n{\r\n    assertTrue(print + \" doesn't contain expected string, got: \" + got + \" expected: \" + expected, got.contains(expected));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "checkStringEqual",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void checkStringEqual(String print, String expected, String got)\n{\r\n    assertTrue(print + \" is not equal, got: \" + got + \" expected: \" + expected, got.equals(expected));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "assertResponseStatusCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void assertResponseStatusCode(StatusType expected, StatusType actual)\n{\r\n    assertResponseStatusCode(null, expected, actual);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "assertResponseStatusCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void assertResponseStatusCode(String errmsg, StatusType expected, StatusType actual)\n{\r\n    assertEquals(errmsg, expected.getStatusCode(), actual.getStatusCode());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\log",
  "methodName" : "render",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void render(Block html)\n{\r\n    super.render(html);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\log",
  "methodName" : "moreParams",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Map<String, String> moreParams()\n{\r\n    return params;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\log",
  "methodName" : "request",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "HttpServletRequest request()\n{\r\n    return request;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\log",
  "methodName" : "setRequest",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setRequest(HttpServletRequest request)\n{\r\n    this.request = request;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testDefaultRMWebUrl",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testDefaultRMWebUrl() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    String rmWebUrl = WebAppUtils.getRMWebAppURLWithScheme(conf);\r\n    Assert.assertNotSame(\"RM Web Url is not correct\", \"http://0.0.0.0:8088\", rmWebUrl);\r\n    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf.set(YarnConfiguration.RM_HA_IDS, \"rm1, rm2\");\r\n    conf.set(\"yarn.resourcemanager.webapp.address.rm1\", \"10.10.10.10:18088\");\r\n    conf.set(\"yarn.resourcemanager.webapp.address.rm2\", \"20.20.20.20:28088\");\r\n    String rmWebUrlinHA = WebAppUtils.getRMWebAppURLWithScheme(conf);\r\n    Assert.assertEquals(\"http://10.10.10.10:18088\", rmWebUrlinHA);\r\n    YarnConfiguration conf2 = new YarnConfiguration();\r\n    conf2.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf2.set(YarnConfiguration.RM_HA_IDS, \"rm1, rm2\");\r\n    conf2.set(\"yarn.resourcemanager.hostname.rm1\", \"30.30.30.30\");\r\n    conf2.set(\"yarn.resourcemanager.hostname.rm2\", \"40.40.40.40\");\r\n    String rmWebUrlinHA2 = WebAppUtils.getRMWebAppURLWithScheme(conf2);\r\n    Assert.assertEquals(\"http://30.30.30.30:8088\", rmWebUrlinHA2);\r\n    rmWebUrlinHA2 = WebAppUtils.getRMWebAppURLWithScheme(conf2, 0);\r\n    Assert.assertEquals(\"http://30.30.30.30:8088\", rmWebUrlinHA2);\r\n    rmWebUrlinHA2 = WebAppUtils.getRMWebAppURLWithScheme(conf2, 1);\r\n    Assert.assertEquals(\"http://40.40.40.40:8088\", rmWebUrlinHA2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testRMWebUrlSpecified",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testRMWebUrlSpecified() throws Exception\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.set(YarnConfiguration.RM_WEBAPP_ADDRESS, \"fortesting:24543\");\r\n    conf.set(YarnConfiguration.RM_ADDRESS, \"rmtesting:9999\");\r\n    String rmWebUrl = WebAppUtils.getRMWebAppURLWithScheme(conf);\r\n    String[] parts = rmWebUrl.split(\":\");\r\n    Assert.assertEquals(\"RM Web URL Port is incrrect\", 24543, Integer.parseInt(parts[parts.length - 1]));\r\n    Assert.assertNotSame(\"RM Web Url not resolved correctly. Should not be rmtesting\", \"http://rmtesting:24543\", rmWebUrl);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testGetSocketAddressForNMWithHA",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testGetSocketAddressForNMWithHA()\n{\r\n    YarnConfiguration conf = new YarnConfiguration();\r\n    conf.set(YarnConfiguration.NM_ADDRESS, \"0.0.0.0:1234\");\r\n    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf.set(YarnConfiguration.RM_HA_ID, \"rm1\");\r\n    assertTrue(HAUtil.isHAEnabled(conf));\r\n    InetSocketAddress addr = conf.getSocketAddr(YarnConfiguration.NM_ADDRESS, YarnConfiguration.DEFAULT_NM_ADDRESS, YarnConfiguration.DEFAULT_NM_PORT);\r\n    assertEquals(1234, addr.getPort());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testGetSocketAddr",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testGetSocketAddr() throws Exception\n{\r\n    YarnConfiguration conf;\r\n    InetSocketAddress resourceTrackerAddress;\r\n    conf = new YarnConfiguration();\r\n    resourceTrackerAddress = conf.getSocketAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT);\r\n    assertEquals(new InetSocketAddress(YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS.split(\":\")[0], YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT), resourceTrackerAddress);\r\n    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, \"10.0.0.1\");\r\n    resourceTrackerAddress = conf.getSocketAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT);\r\n    assertEquals(new InetSocketAddress(\"10.0.0.1\", YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT), resourceTrackerAddress);\r\n    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, \"10.0.0.2:5001\");\r\n    resourceTrackerAddress = conf.getSocketAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT);\r\n    assertEquals(new InetSocketAddress(\"10.0.0.2\", 5001), resourceTrackerAddress);\r\n    conf = new YarnConfiguration();\r\n    conf.set(YarnConfiguration.RM_BIND_HOST, \"10.0.0.3\");\r\n    resourceTrackerAddress = conf.getSocketAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT);\r\n    assertEquals(new InetSocketAddress(\"10.0.0.3\", YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT), resourceTrackerAddress);\r\n    conf.set(YarnConfiguration.RM_BIND_HOST, \"0.0.0.0\");\r\n    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, \"10.0.0.2\");\r\n    resourceTrackerAddress = conf.getSocketAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT);\r\n    assertEquals(new InetSocketAddress(\"0.0.0.0\", YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT), resourceTrackerAddress);\r\n    conf.set(YarnConfiguration.RM_BIND_HOST, \"0.0.0.0\");\r\n    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, \"10.0.0.2:5003\");\r\n    resourceTrackerAddress = conf.getSocketAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_PORT);\r\n    assertEquals(new InetSocketAddress(\"0.0.0.0\", 5003), resourceTrackerAddress);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testUpdateConnectAddr",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void testUpdateConnectAddr() throws Exception\n{\r\n    YarnConfiguration conf;\r\n    InetSocketAddress resourceTrackerConnectAddress;\r\n    InetSocketAddress serverAddress;\r\n    conf = new YarnConfiguration();\r\n    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, \"yo.yo.yo\");\r\n    serverAddress = new InetSocketAddress(YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS.split(\":\")[0], Integer.parseInt(YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS.split(\":\")[1]));\r\n    resourceTrackerConnectAddress = conf.updateConnectAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, serverAddress);\r\n    assertFalse(resourceTrackerConnectAddress.toString().startsWith(\"yo.yo.yo\"));\r\n    conf = new YarnConfiguration();\r\n    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, \"yo.yo.yo\");\r\n    conf.set(YarnConfiguration.RM_BIND_HOST, \"0.0.0.0\");\r\n    serverAddress = new InetSocketAddress(YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS.split(\":\")[0], Integer.parseInt(YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS.split(\":\")[1]));\r\n    resourceTrackerConnectAddress = conf.updateConnectAddr(YarnConfiguration.RM_BIND_HOST, YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS, YarnConfiguration.DEFAULT_RM_RESOURCE_TRACKER_ADDRESS, serverAddress);\r\n    assertTrue(resourceTrackerConnectAddress.toString().startsWith(\"yo.yo.yo\"));\r\n    conf = new YarnConfiguration();\r\n    conf.set(YarnConfiguration.NM_LOCALIZER_ADDRESS, \"yo.yo.yo\");\r\n    conf.set(YarnConfiguration.NM_BIND_HOST, \"0.0.0.0\");\r\n    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    conf.set(YarnConfiguration.RM_HA_ID, \"rm1\");\r\n    serverAddress = new InetSocketAddress(YarnConfiguration.DEFAULT_NM_LOCALIZER_ADDRESS.split(\":\")[0], Integer.parseInt(YarnConfiguration.DEFAULT_NM_LOCALIZER_ADDRESS.split(\":\")[1]));\r\n    InetSocketAddress localizerAddress = conf.updateConnectAddr(YarnConfiguration.NM_BIND_HOST, YarnConfiguration.NM_LOCALIZER_ADDRESS, YarnConfiguration.DEFAULT_NM_LOCALIZER_ADDRESS, serverAddress);\r\n    assertTrue(localizerAddress.toString().startsWith(\"yo.yo.yo\"));\r\n    assertNull(conf.get(HAUtil.addSuffix(YarnConfiguration.NM_LOCALIZER_ADDRESS, \"rm1\")));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "initInternal",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initInternal(Configuration conf)\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "initializeWriter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initializeWriter(LogAggregationFileControllerContext context) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "closeWriter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void closeWriter() throws LogAggregationDFSException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void write(AggregatedLogFormat.LogKey logKey, AggregatedLogFormat.LogValue logValue) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "postWrite",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void postWrite(LogAggregationFileControllerContext record) throws Exception\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "readAggregatedLogs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean readAggregatedLogs(ContainerLogsRequest logRequest, OutputStream os) throws IOException\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "readAggregatedLogsMeta",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "List<ContainerLogMeta> readAggregatedLogsMeta(ContainerLogsRequest logRequest) throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "renderAggregatedLogsBlock",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void renderAggregatedLogsBlock(HtmlBlock.Block html, View.ViewContext context)\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "getApplicationOwner",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getApplicationOwner(Path aggregatedLogPath, ApplicationId appId) throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\logaggregation\\filecontroller",
  "methodName" : "getApplicationAcls",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Map<ApplicationAccessType, String> getApplicationAcls(Path aggregatedLogPath, ApplicationId appId) throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getContext",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JAXBContext getContext(Class<?> objectType)\n{\r\n    return (types.contains(objectType)) ? context : null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testGetApplicationsRequest",
  "errType" : null,
  "containingMethodsNum" : 29,
  "sourceCodeText" : "void testGetApplicationsRequest()\n{\r\n    GetApplicationsRequest request = GetApplicationsRequest.newInstance();\r\n    EnumSet<YarnApplicationState> appStates = EnumSet.of(YarnApplicationState.ACCEPTED);\r\n    request.setApplicationStates(appStates);\r\n    Set<String> tags = new HashSet<String>();\r\n    tags.add(\"tag1\");\r\n    request.setApplicationTags(tags);\r\n    Set<String> types = new HashSet<String>();\r\n    types.add(\"type1\");\r\n    request.setApplicationTypes(types);\r\n    long startBegin = System.currentTimeMillis();\r\n    long startEnd = System.currentTimeMillis() + 1;\r\n    request.setStartRange(startBegin, startEnd);\r\n    long finishBegin = System.currentTimeMillis() + 2;\r\n    long finishEnd = System.currentTimeMillis() + 3;\r\n    request.setFinishRange(finishBegin, finishEnd);\r\n    long limit = 100L;\r\n    request.setLimit(limit);\r\n    Set<String> queues = new HashSet<String>();\r\n    queues.add(\"queue1\");\r\n    request.setQueues(queues);\r\n    Set<String> users = new HashSet<String>();\r\n    users.add(\"user1\");\r\n    request.setUsers(users);\r\n    ApplicationsRequestScope scope = ApplicationsRequestScope.ALL;\r\n    request.setScope(scope);\r\n    GetApplicationsRequest requestFromProto = new GetApplicationsRequestPBImpl(((GetApplicationsRequestPBImpl) request).getProto());\r\n    Assert.assertEquals(requestFromProto, request);\r\n    Assert.assertEquals(\"ApplicationStates from proto is not the same with original request\", requestFromProto.getApplicationStates(), appStates);\r\n    Assert.assertEquals(\"ApplicationTags from proto is not the same with original request\", requestFromProto.getApplicationTags(), tags);\r\n    Assert.assertEquals(\"ApplicationTypes from proto is not the same with original request\", requestFromProto.getApplicationTypes(), types);\r\n    Assert.assertEquals(\"StartRange from proto is not the same with original request\", requestFromProto.getStartRange(), Range.between(startBegin, startEnd));\r\n    Assert.assertEquals(\"FinishRange from proto is not the same with original request\", requestFromProto.getFinishRange(), Range.between(finishBegin, finishEnd));\r\n    Assert.assertEquals(\"Limit from proto is not the same with original request\", requestFromProto.getLimit(), limit);\r\n    Assert.assertEquals(\"Queues from proto is not the same with original request\", requestFromProto.getQueues(), queues);\r\n    Assert.assertEquals(\"Users from proto is not the same with original request\", requestFromProto.getUsers(), users);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testCreateInstance",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testCreateInstance()\n{\r\n    ResourceCalculatorProcessTree tree;\r\n    tree = ResourceCalculatorProcessTree.getResourceCalculatorProcessTree(\"1\", EmptyProcessTree.class, new Configuration());\r\n    assertNotNull(tree);\r\n    assertThat(tree, instanceOf(EmptyProcessTree.class));\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testCreatedInstanceConfigured",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testCreatedInstanceConfigured()\n{\r\n    ResourceCalculatorProcessTree tree;\r\n    Configuration conf = new Configuration();\r\n    tree = ResourceCalculatorProcessTree.getResourceCalculatorProcessTree(\"1\", EmptyProcessTree.class, conf);\r\n    assertNotNull(tree);\r\n    assertThat(tree.getConf(), sameInstance(conf));\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testScriptName",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testScriptName()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setClass(CommonConfigurationKeysPublic.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY, ScriptBasedMapping.class, DNSToSwitchMapping.class);\r\n    conf.set(CommonConfigurationKeysPublic.NET_TOPOLOGY_SCRIPT_FILE_NAME_KEY, \"testScript\");\r\n    RackResolver.init(conf);\r\n    Assert.assertEquals(RackResolver.getDnsToSwitchMapping().toString(), \"script-based mapping with script testScript\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "before",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void before()\n{\r\n    mgr = new DummyCommonNodeLabelsManager();\r\n    Configuration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.NODE_LABELS_ENABLED, true);\r\n    mgr.init(conf);\r\n    mgr.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "after",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void after()\n{\r\n    mgr.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testAddRemovelabel",
  "errType" : [ "Exception", "Exception", "IOException" ],
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void testAddRemovelabel() throws Exception\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"hello\"));\r\n    verifyNodeLabelAdded(Sets.newHashSet(\"hello\"), mgr.lastAddedlabels);\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"world\"));\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"hello1\", \"world1\"));\r\n    verifyNodeLabelAdded(Sets.newHashSet(\"hello1\", \"world1\"), mgr.lastAddedlabels);\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Sets.newHashSet(\"hello\", \"world\", \"hello1\", \"world1\")));\r\n    try {\r\n        mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"hello1\", false)));\r\n        Assert.fail(\"IOException not thrown on exclusivity change of labels\");\r\n    } catch (Exception e) {\r\n        Assert.assertTrue(\"IOException is expected when exclusivity is modified\", e instanceof IOException);\r\n    }\r\n    try {\r\n        mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"hello1\", true)));\r\n    } catch (Exception e) {\r\n        Assert.assertFalse(\"IOException not expected when no change in exclusivity\", e instanceof IOException);\r\n    }\r\n    for (String p : Arrays.asList(null, CommonNodeLabelsManager.NO_LABEL, \"xx\")) {\r\n        boolean caught = false;\r\n        try {\r\n            mgr.removeFromClusterNodeLabels(Arrays.asList(p));\r\n        } catch (IOException e) {\r\n            caught = true;\r\n        }\r\n        Assert.assertTrue(\"remove label should fail \" + \"when label is null/empty/non-existed\", caught);\r\n    }\r\n    mgr.removeFromClusterNodeLabels(Arrays.asList(\"hello\"));\r\n    assertCollectionEquals(Sets.newHashSet(\"hello\"), mgr.lastRemovedlabels);\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"world\", \"hello1\", \"world1\")));\r\n    mgr.removeFromClusterNodeLabels(Arrays.asList(\"hello1\", \"world1\", \"world\"));\r\n    Assert.assertTrue(mgr.lastRemovedlabels.containsAll(Sets.newHashSet(\"hello1\", \"world1\", \"world\")));\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().isEmpty());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testAddlabelWithCase",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testAddlabelWithCase() throws Exception\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"HeLlO\"));\r\n    verifyNodeLabelAdded(Sets.newHashSet(\"HeLlO\"), mgr.lastAddedlabels);\r\n    Assert.assertFalse(mgr.getClusterNodeLabelNames().containsAll(Arrays.asList(\"hello\")));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testAddlabelWithExclusivity",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testAddlabelWithExclusivity() throws Exception\n{\r\n    mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"a\", false), NodeLabel.newInstance(\"b\", true)));\r\n    Assert.assertFalse(mgr.isExclusiveNodeLabel(\"a\"));\r\n    Assert.assertTrue(mgr.isExclusiveNodeLabel(\"b\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testAddInvalidlabel",
  "errType" : [ "IOException", "IOException", "IOException", "IOException", "IOException", "IOException", "IOException", "IOException" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testAddInvalidlabel() throws IOException\n{\r\n    boolean caught = false;\r\n    try {\r\n        Set<String> set = new HashSet<String>();\r\n        set.add(null);\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(set);\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"null label should not add to repo\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(CommonNodeLabelsManager.NO_LABEL));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"empty label should not add to repo\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"-?\"));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"invalid label character should not add to repo\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(StringUtils.repeat(\"c\", 257)));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"too long label should not add to repo\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"-aaabbb\"));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"label cannot start with \\\"-\\\"\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"_aaabbb\"));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"label cannot start with \\\"_\\\"\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"a^aabbb\"));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"label cannot contains other chars like ^[] ...\", caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"aa[a]bbb\"));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"label cannot contains other chars like ^[] ...\", caught);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 8,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testAddReplaceRemoveLabelsOnNodes",
  "errType" : [ "IOException", "IOException" ],
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testAddReplaceRemoveLabelsOnNodes() throws Exception\n{\r\n    boolean caught = false;\r\n    try {\r\n        mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"node\"), toSet(\"label\")));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"trying to set a label to a node but \" + \"label doesn't exist in repository should fail\", caught);\r\n    try {\r\n        mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(CommonNodeLabelsManager.NO_LABEL), toSet(\"label\")));\r\n    } catch (IOException e) {\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(\"trying to add a empty node but succeeded\", caught);\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p3\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p2\"), toNodeId(\"n2\"), toSet(\"p3\")));\r\n    assertMapEquals(mgr.lastNodeToLabels, ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p3\")));\r\n    mgr.replaceLabelsOnNode((Map) ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\"), toNodeId(\"n1\"), toSet(\"p1\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p3\"), toNodeId(\"n3\"), toSet(\"p3\")));\r\n    assertMapEquals(mgr.lastNodeToLabels, ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\"), toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.removeLabelsFromNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p3\"), toNodeId(\"n3\"), toSet(\"p3\")));\r\n    assertMapEquals(mgr.lastNodeToLabels, ImmutableMap.of(toNodeId(\"n1\"), CommonNodeLabelsManager.EMPTY_STRING_SET));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p3\"), toNodeId(\"n3\"), toSet(\"p3\")));\r\n    assertMapEquals(mgr.lastNodeToLabels, ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.removeLabelsFromNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n2\"), toSet(\"p3\"), toNodeId(\"n3\"), toSet(\"p3\")));\r\n    Assert.assertEquals(0, mgr.getNodeLabels().size());\r\n    assertMapEquals(mgr.lastNodeToLabels, ImmutableMap.of(toNodeId(\"n1\"), CommonNodeLabelsManager.EMPTY_STRING_SET, toNodeId(\"n2\"), CommonNodeLabelsManager.EMPTY_STRING_SET, toNodeId(\"n3\"), CommonNodeLabelsManager.EMPTY_STRING_SET));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testRemovelabelWithNodes",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testRemovelabelWithNodes() throws Exception\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p3\")));\r\n    mgr.removeFromClusterNodeLabels(ImmutableSet.of(\"p1\"));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\"), toNodeId(\"n3\"), toSet(\"p3\")));\r\n    assertCollectionEquals(Arrays.asList(\"p1\"), mgr.lastRemovedlabels);\r\n    mgr.removeFromClusterNodeLabels(ImmutableSet.of(\"p2\", \"p3\"));\r\n    Assert.assertTrue(mgr.getNodeLabels().isEmpty());\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().isEmpty());\r\n    assertCollectionEquals(Arrays.asList(\"p2\", \"p3\"), mgr.lastRemovedlabels);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testTrimLabelsWhenAddRemoveNodeLabels",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testTrimLabelsWhenAddRemoveNodeLabels() throws IOException\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\" p1\"));\r\n    assertCollectionEquals(toSet(\"p1\"), mgr.getClusterNodeLabelNames());\r\n    mgr.removeFromClusterNodeLabels(toSet(\"p1 \"));\r\n    Assert.assertTrue(mgr.getClusterNodeLabelNames().isEmpty());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testTrimLabelsWhenModifyLabelsOnNodes",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testTrimLabelsWhenModifyLabelsOnNodes() throws IOException\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\" p1\", \"p2\"));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1 \")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\" p2\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p2\")));\r\n    mgr.removeLabelsFromNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"  p2 \")));\r\n    Assert.assertTrue(mgr.getNodeLabels().isEmpty());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testReplaceLabelsOnHostsShouldUpdateNodesBelongTo",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testReplaceLabelsOnHostsShouldUpdateNodesBelongTo() throws IOException\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1:1\"), toSet(\"p2\"), toNodeId(\"n1:2\"), toSet(\"p2\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n1:1\"), toSet(\"p2\"), toNodeId(\"n1:2\"), toSet(\"p2\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    assertMapEquals(mgr.getNodeLabels(), ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\"), toNodeId(\"n1:1\"), toSet(\"p1\"), toNodeId(\"n1:2\"), toSet(\"p1\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1:1\"), toSet(\"p2\")));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "assertNodeLabelsDisabledErrorMessage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void assertNodeLabelsDisabledErrorMessage(IOException e)\n{\r\n    Assert.assertEquals(CommonNodeLabelsManager.NODE_LABELS_NOT_ENABLED_ERR, e.getMessage());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testNodeLabelsDisabled",
  "errType" : [ "IOException", "IOException", "IOException", "IOException", "IOException" ],
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testNodeLabelsDisabled() throws IOException\n{\r\n    DummyCommonNodeLabelsManager mgr = new DummyCommonNodeLabelsManager();\r\n    Configuration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.NODE_LABELS_ENABLED, false);\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    boolean caught = false;\r\n    try {\r\n        mgr.addToCluserNodeLabelsWithDefaultExclusivity(ImmutableSet.of(\"x\"));\r\n    } catch (IOException e) {\r\n        assertNodeLabelsDisabledErrorMessage(e);\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(caught);\r\n    caught = false;\r\n    try {\r\n        mgr.removeFromClusterNodeLabels(ImmutableSet.of(\"x\"));\r\n    } catch (IOException e) {\r\n        assertNodeLabelsDisabledErrorMessage(e);\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(caught);\r\n    caught = false;\r\n    try {\r\n        mgr.addLabelsToNode(ImmutableMap.of(NodeId.newInstance(\"host\", 0), CommonNodeLabelsManager.EMPTY_STRING_SET));\r\n    } catch (IOException e) {\r\n        assertNodeLabelsDisabledErrorMessage(e);\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(caught);\r\n    caught = false;\r\n    try {\r\n        mgr.removeLabelsFromNode(ImmutableMap.of(NodeId.newInstance(\"host\", 0), CommonNodeLabelsManager.EMPTY_STRING_SET));\r\n    } catch (IOException e) {\r\n        assertNodeLabelsDisabledErrorMessage(e);\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(caught);\r\n    caught = false;\r\n    try {\r\n        mgr.replaceLabelsOnNode(ImmutableMap.of(NodeId.newInstance(\"host\", 0), CommonNodeLabelsManager.EMPTY_STRING_SET));\r\n    } catch (IOException e) {\r\n        assertNodeLabelsDisabledErrorMessage(e);\r\n        caught = true;\r\n    }\r\n    Assert.assertTrue(caught);\r\n    caught = false;\r\n    mgr.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 5,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testLabelsToNodes",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void testLabelsToNodes() throws IOException\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    Map<String, Set<NodeId>> labelsToNodes = mgr.getLabelsToNodes();\r\n    assertLabelsToNodesEquals(labelsToNodes, ImmutableMap.of(\"p1\", toSet(toNodeId(\"n1\"))));\r\n    assertLabelsToNodesEquals(labelsToNodes, transposeNodeToLabels(mgr.getNodeLabels()));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1:1\"), toSet(\"p2\"), toNodeId(\"n1:2\"), toSet(\"p2\")));\r\n    labelsToNodes = mgr.getLabelsToNodes();\r\n    assertLabelsToNodesEquals(labelsToNodes, ImmutableMap.of(\"p1\", toSet(toNodeId(\"n1\")), \"p2\", toSet(toNodeId(\"n1:1\"), toNodeId(\"n1:2\"))));\r\n    assertLabelsToNodesEquals(labelsToNodes, transposeNodeToLabels(mgr.getNodeLabels()));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    labelsToNodes = mgr.getLabelsToNodes();\r\n    assertLabelsToNodesEquals(labelsToNodes, ImmutableMap.of(\"p1\", toSet(toNodeId(\"n1\"), toNodeId(\"n1:1\"), toNodeId(\"n1:2\"))));\r\n    assertLabelsToNodesEquals(labelsToNodes, transposeNodeToLabels(mgr.getNodeLabels()));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1:1\"), toSet(\"p2\")));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p3\")));\r\n    labelsToNodes = mgr.getLabelsToNodes();\r\n    assertLabelsToNodesEquals(labelsToNodes, ImmutableMap.of(\"p1\", toSet(toNodeId(\"n1\"), toNodeId(\"n1:2\")), \"p2\", toSet(toNodeId(\"n1:1\")), \"p3\", toSet(toNodeId(\"n2\"))));\r\n    assertLabelsToNodesEquals(labelsToNodes, transposeNodeToLabels(mgr.getNodeLabels()));\r\n    mgr.removeLabelsFromNode(ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p3\")));\r\n    labelsToNodes = mgr.getLabelsToNodes();\r\n    assertLabelsToNodesEquals(labelsToNodes, ImmutableMap.of(\"p1\", toSet(toNodeId(\"n1\"), toNodeId(\"n1:2\")), \"p2\", toSet(toNodeId(\"n1:1\"))));\r\n    assertLabelsToNodesEquals(labelsToNodes, transposeNodeToLabels(mgr.getNodeLabels()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testLabelsToNodesForSelectedLabels",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testLabelsToNodesForSelectedLabels() throws IOException\n{\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1:1\"), toSet(\"p1\"), toNodeId(\"n1:2\"), toSet(\"p2\")));\r\n    Set<String> setlabels = new HashSet<String>(Arrays.asList(new String[] { \"p1\" }));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p1\", toSet(toNodeId(\"n1:1\"))));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p3\")));\r\n    assertTrue(mgr.getLabelsToNodes(setlabels).isEmpty());\r\n    setlabels = new HashSet<String>(Arrays.asList(new String[] { \"p2\", \"p3\" }));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p3\", toSet(toNodeId(\"n1\"), toNodeId(\"n1:1\"), toNodeId(\"n1:2\"))));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p2\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p2\", toSet(toNodeId(\"n2\")), \"p3\", toSet(toNodeId(\"n1\"), toNodeId(\"n1:1\"), toNodeId(\"n1:2\"))));\r\n    mgr.removeLabelsFromNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p3\")));\r\n    setlabels = new HashSet<String>(Arrays.asList(new String[] { \"p1\", \"p2\", \"p3\" }));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p2\", toSet(toNodeId(\"n2\"))));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n3\"), toSet(\"p1\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p1\", toSet(toNodeId(\"n3\")), \"p2\", toSet(toNodeId(\"n2\"))));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n2:2\"), toSet(\"p3\")));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p1\", toSet(toNodeId(\"n3\")), \"p2\", toSet(toNodeId(\"n2\")), \"p3\", toSet(toNodeId(\"n2:2\"))));\r\n    setlabels = new HashSet<String>(Arrays.asList(new String[] { \"p1\" }));\r\n    assertLabelsToNodesEquals(mgr.getLabelsToNodes(setlabels), ImmutableMap.of(\"p1\", toSet(toNodeId(\"n3\"))));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testNoMoreThanOneLabelExistedInOneHost",
  "errType" : [ "IOException", "IOException", "IOException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testNoMoreThanOneLabelExistedInOneHost() throws IOException\n{\r\n    boolean failed = false;\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    try {\r\n        mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\", \"p2\")));\r\n    } catch (IOException e) {\r\n        failed = true;\r\n    }\r\n    Assert.assertTrue(\"Should failed when set > 1 labels on a host\", failed);\r\n    try {\r\n        mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\", \"p2\")));\r\n    } catch (IOException e) {\r\n        failed = true;\r\n    }\r\n    Assert.assertTrue(\"Should failed when add > 1 labels on a host\", failed);\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    try {\r\n        mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p2\")));\r\n    } catch (IOException e) {\r\n        failed = true;\r\n    }\r\n    Assert.assertTrue(\"Should failed when #labels > 1 on a host after add\", failed);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "verifyNodeLabelAdded",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void verifyNodeLabelAdded(Set<String> expectedAddedLabelNames, Collection<NodeLabel> addedNodeLabels)\n{\r\n    Assert.assertEquals(expectedAddedLabelNames.size(), addedNodeLabels.size());\r\n    for (NodeLabel label : addedNodeLabels) {\r\n        Assert.assertTrue(expectedAddedLabelNames.contains(label.getName()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testReplaceLabelsOnNodeInDistributedMode",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testReplaceLabelsOnNodeInDistributedMode() throws Exception\n{\r\n    mgr.stop();\r\n    mgr = new DummyCommonNodeLabelsManager();\r\n    Configuration conf = new YarnConfiguration();\r\n    conf.setBoolean(YarnConfiguration.NODE_LABELS_ENABLED, true);\r\n    conf.set(YarnConfiguration.NODELABEL_CONFIGURATION_TYPE, YarnConfiguration.DISTRIBUTED_NODELABEL_CONFIGURATION_TYPE);\r\n    mgr.init(conf);\r\n    mgr.start();\r\n    mgr.addToCluserNodeLabelsWithDefaultExclusivity(toSet(\"p1\", \"p2\", \"p3\"));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    Set<String> labelsByNode = mgr.getLabelsByNode(toNodeId(\"n1\"));\r\n    Assert.assertNull(\"Labels are not expected to be written to the NodeLabelStore\", mgr.lastNodeToLabels);\r\n    Assert.assertNotNull(\"Updated labels should be available from the Mgr\", labelsByNode);\r\n    Assert.assertTrue(labelsByNode.contains(\"p1\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testLabelsInfoToNodes",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testLabelsInfoToNodes() throws IOException\n{\r\n    mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"p1\", false), NodeLabel.newInstance(\"p2\", true), NodeLabel.newInstance(\"p3\", true)));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p1\")));\r\n    Map<NodeLabel, Set<NodeId>> labelsToNodes = mgr.getLabelsInfoToNodes();\r\n    assertLabelsInfoToNodesEquals(labelsToNodes, ImmutableMap.of(NodeLabel.newInstance(\"p1\", false), toSet(toNodeId(\"n1\"))));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testGetNodeLabelsInfo",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testGetNodeLabelsInfo() throws IOException\n{\r\n    mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"p1\", false), NodeLabel.newInstance(\"p2\", true), NodeLabel.newInstance(\"p3\", false)));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p2\")));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n2\"), toSet(\"p3\")));\r\n    assertLabelInfoMapEquals(mgr.getNodeLabelsInfo(), ImmutableMap.of(toNodeId(\"n1\"), toSet(NodeLabel.newInstance(\"p2\", true)), toNodeId(\"n2\"), toSet(NodeLabel.newInstance(\"p3\", false))));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\nodelabels",
  "methodName" : "testRemoveNodeLabelsInfo",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testRemoveNodeLabelsInfo() throws IOException\n{\r\n    mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"p1\", true)));\r\n    mgr.addToCluserNodeLabels(Arrays.asList(NodeLabel.newInstance(\"p2\", true)));\r\n    mgr.addLabelsToNode(ImmutableMap.of(toNodeId(\"n1:1\"), toSet(\"p1\")));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), toSet(\"p2\")));\r\n    Map<String, Set<NodeId>> labelsToNodes = mgr.getLabelsToNodes();\r\n    assertLabelsToNodesEquals(labelsToNodes, ImmutableMap.of(\"p2\", toSet(toNodeId(\"n1:1\"), toNodeId(\"n1:0\"))));\r\n    mgr.replaceLabelsOnNode(ImmutableMap.of(toNodeId(\"n1\"), new HashSet()));\r\n    Map<String, Set<NodeId>> labelsToNodes2 = mgr.getLabelsToNodes();\r\n    Assert.assertEquals(labelsToNodes2.get(\"p2\"), null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testSubView",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testSubView() throws Exception\n{\r\n    Injector injector = WebAppTests.createMockInjector(this);\r\n    injector.getInstance(MainView.class).render();\r\n    PrintWriter out = injector.getInstance(HttpServletResponse.class).getWriter();\r\n    out.flush();\r\n    verify(out).print(\"sub1 text\");\r\n    verify(out).print(\"sub2 text\");\r\n    verify(out, times(16)).println();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "echo",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String echo(String s)\n{\r\n    return s;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testCreate",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testCreate()\n{\r\n    WebApp app = WebApps.$for(this).start();\r\n    app.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testCreateWithPort",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testCreateWithPort()\n{\r\n    WebApp app = WebApps.$for(this).at(0).start();\r\n    int port = app.getListenerAddress().getPort();\r\n    assertTrue(port > 0);\r\n    app.stop();\r\n    app = WebApps.$for(this).at(port).start();\r\n    assertEquals(port, app.getListenerAddress().getPort());\r\n    app.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testCreateWithBindAddressNonZeroPort",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCreateWithBindAddressNonZeroPort()\n{\r\n    WebApp app = WebApps.$for(this).at(\"0.0.0.0:50000\").start();\r\n    int port = app.getListenerAddress().getPort();\r\n    assertEquals(50000, port);\r\n    WebApp app2 = WebApps.$for(this).at(\"0.0.0.0:50000\").start();\r\n    app.stop();\r\n    app2.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testCreateWithNonZeroPort",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCreateWithNonZeroPort()\n{\r\n    WebApp app = WebApps.$for(this).at(50000).start();\r\n    int port = app.getListenerAddress().getPort();\r\n    assertEquals(50000, port);\r\n    WebApp app2 = WebApps.$for(this).at(50000).start();\r\n    app.stop();\r\n    app2.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testServePaths",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testServePaths()\n{\r\n    WebApp app = WebApps.$for(\"test\", this).start();\r\n    assertEquals(\"/test\", app.getRedirectPath());\r\n    String[] expectedPaths = { \"/test\", \"/test/*\" };\r\n    String[] pathSpecs = app.getServePathSpecs();\r\n    assertEquals(2, pathSpecs.length);\r\n    for (int i = 0; i < expectedPaths.length; i++) {\r\n        assertTrue(ArrayUtils.contains(pathSpecs, expectedPaths[i]));\r\n    }\r\n    app.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testServePathsNoName",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testServePathsNoName()\n{\r\n    WebApp app = WebApps.$for(\"\", this).start();\r\n    assertEquals(\"/\", app.getRedirectPath());\r\n    String[] expectedPaths = { \"/*\" };\r\n    String[] pathSpecs = app.getServePathSpecs();\r\n    assertEquals(1, pathSpecs.length);\r\n    for (int i = 0; i < expectedPaths.length; i++) {\r\n        assertTrue(ArrayUtils.contains(pathSpecs, expectedPaths[i]));\r\n    }\r\n    app.stop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testDefaultRoutes",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testDefaultRoutes() throws Exception\n{\r\n    WebApp app = WebApps.$for(\"test\", this).start();\r\n    String baseUrl = baseUrl(app);\r\n    try {\r\n        assertEquals(\"foo\", getContent(baseUrl + \"test/foo\").trim());\r\n        assertEquals(\"foo\", getContent(baseUrl + \"test/foo/index\").trim());\r\n        assertEquals(\"bar\", getContent(baseUrl + \"test/foo/bar\").trim());\r\n        assertEquals(\"default\", getContent(baseUrl + \"test\").trim());\r\n        assertEquals(\"default\", getContent(baseUrl + \"test/\").trim());\r\n        assertEquals(\"default\", getContent(baseUrl).trim());\r\n    } finally {\r\n        app.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testCustomRoutes",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testCustomRoutes() throws Exception\n{\r\n    WebApp app = WebApps.$for(\"test\", TestWebApp.class, this, \"ws\").start(new WebApp() {\r\n\r\n        @Override\r\n        public void setup() {\r\n            bind(MyTestJAXBContextResolver.class);\r\n            bind(MyTestWebService.class);\r\n            route(\"/:foo\", FooController.class);\r\n            route(\"/bar/foo\", FooController.class, \"bar\");\r\n            route(\"/foo/:foo\", DefaultController.class);\r\n            route(\"/foo/bar/:foo\", DefaultController.class, \"index\");\r\n        }\r\n    });\r\n    String baseUrl = baseUrl(app);\r\n    try {\r\n        assertEquals(\"foo\", getContent(baseUrl).trim());\r\n        assertEquals(\"foo\", getContent(baseUrl + \"test\").trim());\r\n        assertEquals(\"foo1\", getContent(baseUrl + \"test/1\").trim());\r\n        assertEquals(\"bar\", getContent(baseUrl + \"test/bar/foo\").trim());\r\n        assertEquals(\"default\", getContent(baseUrl + \"test/foo/bar\").trim());\r\n        assertEquals(\"default1\", getContent(baseUrl + \"test/foo/1\").trim());\r\n        assertEquals(\"default2\", getContent(baseUrl + \"test/foo/bar/2\").trim());\r\n        assertEquals(404, getResponseCode(baseUrl + \"test/goo\"));\r\n        assertEquals(200, getResponseCode(baseUrl + \"ws/v1/test\"));\r\n        assertTrue(getContent(baseUrl + \"ws/v1/test\").contains(\"myInfo\"));\r\n    } finally {\r\n        app.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testEncodedUrl",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testEncodedUrl() throws Exception\n{\r\n    WebApp app = WebApps.$for(\"test\", TestWebApp.class, this, \"ws\").start(new WebApp() {\r\n\r\n        @Override\r\n        public void setup() {\r\n            bind(MyTestJAXBContextResolver.class);\r\n            bind(MyTestWebService.class);\r\n            route(\"/:foo\", FooController.class);\r\n        }\r\n    });\r\n    String baseUrl = baseUrl(app);\r\n    try {\r\n        String rawPath = \"localhost:8080\";\r\n        String encodedUrl = baseUrl + \"test/\" + URLEncoder.encode(rawPath, \"UTF-8\");\r\n        assertEquals(\"foo\" + rawPath, getContent(encodedUrl).trim());\r\n        rawPath = \"@;%$\";\r\n        encodedUrl = baseUrl + \"test/\" + URLEncoder.encode(rawPath, \"UTF-8\");\r\n        assertEquals(\"foo\" + rawPath, getContent(encodedUrl).trim());\r\n    } finally {\r\n        app.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testRobotsText",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testRobotsText() throws Exception\n{\r\n    WebApp app = WebApps.$for(\"test\", TestWebApp.class, this, \"ws\").start(new WebApp() {\r\n\r\n        @Override\r\n        public void setup() {\r\n            bind(MyTestJAXBContextResolver.class);\r\n            bind(MyTestWebService.class);\r\n        }\r\n    });\r\n    String baseUrl = baseUrl(app);\r\n    try {\r\n        String[] robotsTxtOutput = getContent(baseUrl + RobotsTextPage.ROBOTS_TXT).trim().split(System.getProperty(\"line\" + \".separator\"));\r\n        assertEquals(2, robotsTxtOutput.length);\r\n        assertEquals(\"User-agent: *\", robotsTxtOutput[0]);\r\n        assertEquals(\"Disallow: /\", robotsTxtOutput[1]);\r\n    } finally {\r\n        app.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testYARNWebAppContext",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testYARNWebAppContext() throws Exception\n{\r\n    System.setProperty(\"hadoop.log.dir\", \"/Not/Existing/dir\");\r\n    WebApp app = WebApps.$for(\"test\", this).start(new WebApp() {\r\n\r\n        @Override\r\n        public void setup() {\r\n            route(\"/\", FooController.class);\r\n        }\r\n    });\r\n    String baseUrl = baseUrl(app);\r\n    try {\r\n        assertEquals(404, getResponseCode(baseUrl + \"logs\"));\r\n        assertEquals(\"foo\", getContent(baseUrl).trim());\r\n    } finally {\r\n        app.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "stopWebApp",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void stopWebApp(WebApp app)\n{\r\n    if (app != null) {\r\n        app.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "testPortRanges",
  "errType" : null,
  "containingMethodsNum" : 23,
  "sourceCodeText" : "void testPortRanges() throws Exception\n{\r\n    WebApp app = WebApps.$for(\"test\", this).start();\r\n    String baseUrl = baseUrl(app);\r\n    WebApp app1 = null;\r\n    WebApp app2 = null;\r\n    WebApp app3 = null;\r\n    WebApp app4 = null;\r\n    WebApp app5 = null;\r\n    try {\r\n        int port = ServerSocketUtil.waitForPort(48000, 60);\r\n        assertEquals(\"foo\", getContent(baseUrl + \"test/foo\").trim());\r\n        app1 = WebApps.$for(\"test\", this).at(port).start();\r\n        assertEquals(port, app1.getListenerAddress().getPort());\r\n        app2 = WebApps.$for(\"test\", this).at(\"0.0.0.0\", port, true).start();\r\n        assertTrue(app2.getListenerAddress().getPort() > port);\r\n        Configuration conf = new Configuration();\r\n        port = ServerSocketUtil.waitForPort(47000, 60);\r\n        app3 = WebApps.$for(\"test\", this).at(port).withPortRange(conf, \"abc\").start();\r\n        assertEquals(port, app3.getListenerAddress().getPort());\r\n        ServerSocketUtil.waitForPort(46000, 60);\r\n        conf.set(\"abc\", \"46000-46500\");\r\n        app4 = WebApps.$for(\"test\", this).at(port).withPortRange(conf, \"abc\").start();\r\n        assertEquals(46000, app4.getListenerAddress().getPort());\r\n        app5 = WebApps.$for(\"test\", this).withPortRange(conf, \"abc\").start();\r\n        assertTrue(app5.getListenerAddress().getPort() > 46000);\r\n    } finally {\r\n        stopWebApp(app);\r\n        stopWebApp(app1);\r\n        stopWebApp(app2);\r\n        stopWebApp(app3);\r\n        stopWebApp(app4);\r\n        stopWebApp(app5);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "baseUrl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String baseUrl(WebApp app)\n{\r\n    return \"http://localhost:\" + app.port() + \"/\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getContent",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String getContent(String url)\n{\r\n    try {\r\n        StringBuilder out = new StringBuilder();\r\n        InputStream in = new URL(url).openConnection().getInputStream();\r\n        byte[] buffer = new byte[64 * 1024];\r\n        int len = in.read(buffer);\r\n        while (len > 0) {\r\n            out.append(new String(buffer, 0, len));\r\n            len = in.read(buffer);\r\n        }\r\n        return out.toString();\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "getResponseCode",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getResponseCode(String url)\n{\r\n    try {\r\n        HttpURLConnection c = (HttpURLConnection) new URL(url).openConnection();\r\n        return c.getResponseCode();\r\n    } catch (Exception e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void main(String[] args) throws Exception\n{\r\n    WebApps.$for(\"test\", new TestWebApp()).at(8888).inDevMode().start().joinThread();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void setUp()\n{\r\n    conf = new Configuration();\r\n    conf.set(YarnConfiguration.RM_HA_IDS, RM_NODE_IDS_UNTRIMMED);\r\n    conf.set(YarnConfiguration.RM_HA_ID, RM1_NODE_ID_UNTRIMMED);\r\n    for (String confKey : YarnConfiguration.getServiceAddressConfKeys(conf)) {\r\n        conf.set(HAUtil.addSuffix(confKey, RM1_NODE_ID), RM1_ADDRESS_UNTRIMMED);\r\n        conf.set(HAUtil.addSuffix(confKey, RM2_NODE_ID), RM2_ADDRESS);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testGetRMServiceId",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testGetRMServiceId() throws Exception\n{\r\n    conf.set(YarnConfiguration.RM_HA_IDS, RM1_NODE_ID + \",\" + RM2_NODE_ID);\r\n    Collection<String> rmhaIds = HAUtil.getRMHAIds(conf);\r\n    assertEquals(2, rmhaIds.size());\r\n    String[] ids = rmhaIds.toArray(new String[0]);\r\n    assertEquals(RM1_NODE_ID, ids[0]);\r\n    assertEquals(RM2_NODE_ID, ids[1]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testGetRMId",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testGetRMId() throws Exception\n{\r\n    conf.set(YarnConfiguration.RM_HA_ID, RM1_NODE_ID);\r\n    assertEquals(\"Does not honor \" + YarnConfiguration.RM_HA_ID, RM1_NODE_ID, HAUtil.getRMHAId(conf));\r\n    conf.clear();\r\n    assertNull(\"Return null when \" + YarnConfiguration.RM_HA_ID + \" is not set\", HAUtil.getRMHAId(conf));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testVerifyAndSetConfiguration",
  "errType" : [ "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException", "YarnRuntimeException" ],
  "containingMethodsNum" : 41,
  "sourceCodeText" : "void testVerifyAndSetConfiguration() throws Exception\n{\r\n    Configuration myConf = new Configuration(conf);\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n    } catch (YarnRuntimeException e) {\r\n        fail(\"Should not throw any exceptions.\");\r\n    }\r\n    assertEquals(\"Should be saved as Trimmed collection\", StringUtils.getStringCollection(RM_NODE_IDS), HAUtil.getRMHAIds(myConf));\r\n    assertEquals(\"Should be saved as Trimmed string\", RM1_NODE_ID, HAUtil.getRMHAId(myConf));\r\n    for (String confKey : YarnConfiguration.getServiceAddressConfKeys(myConf)) {\r\n        assertEquals(\"RPC address not set for \" + confKey, RM1_ADDRESS, myConf.get(confKey));\r\n    }\r\n    myConf = new Configuration(conf);\r\n    myConf.set(YarnConfiguration.RM_HA_IDS, RM1_NODE_ID);\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n    } catch (YarnRuntimeException e) {\r\n        assertEquals(\"YarnRuntimeException by verifyAndSetRMHAIds()\", HAUtil.BAD_CONFIG_MESSAGE_PREFIX + HAUtil.getInvalidValueMessage(YarnConfiguration.RM_HA_IDS, myConf.get(YarnConfiguration.RM_HA_IDS) + \"\\nHA mode requires atleast two RMs\"), e.getMessage());\r\n    }\r\n    myConf = new Configuration(conf);\r\n    myConf.set(YarnConfiguration.RM_HA_IDS, RM1_NODE_ID + \",\" + RM2_NODE_ID);\r\n    for (String confKey : YarnConfiguration.getServiceAddressConfKeys(myConf)) {\r\n        myConf.set(HAUtil.addSuffix(confKey, RM1_NODE_ID), RM1_ADDRESS);\r\n        myConf.set(HAUtil.addSuffix(confKey, RM2_NODE_ID), RM2_ADDRESS);\r\n    }\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n    } catch (YarnRuntimeException e) {\r\n        assertEquals(\"YarnRuntimeException by getRMId()\", HAUtil.BAD_CONFIG_MESSAGE_PREFIX + HAUtil.getNeedToSetValueMessage(YarnConfiguration.RM_HA_ID), e.getMessage());\r\n    }\r\n    myConf = new Configuration(conf);\r\n    myConf.set(YarnConfiguration.RM_HA_ID, RM_INVALID_NODE_ID);\r\n    myConf.set(YarnConfiguration.RM_HA_IDS, RM_INVALID_NODE_ID + \",\" + RM1_NODE_ID);\r\n    for (String confKey : YarnConfiguration.getServiceAddressConfKeys(myConf)) {\r\n        myConf.set(confKey + RM_INVALID_NODE_ID, RM_INVALID_NODE_ID);\r\n    }\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n    } catch (YarnRuntimeException e) {\r\n        assertEquals(\"YarnRuntimeException by addSuffix()\", HAUtil.BAD_CONFIG_MESSAGE_PREFIX + HAUtil.getInvalidValueMessage(YarnConfiguration.RM_HA_ID, RM_INVALID_NODE_ID), e.getMessage());\r\n    }\r\n    myConf = new Configuration();\r\n    myConf.set(YarnConfiguration.RM_HA_ID, RM1_NODE_ID);\r\n    myConf.set(YarnConfiguration.RM_HA_IDS, RM1_NODE_ID + \",\" + RM2_NODE_ID);\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n        fail(\"Should throw YarnRuntimeException. by Configuration#set()\");\r\n    } catch (YarnRuntimeException e) {\r\n        String confKey = HAUtil.addSuffix(YarnConfiguration.RM_ADDRESS, RM1_NODE_ID);\r\n        assertEquals(\"YarnRuntimeException by Configuration#set()\", HAUtil.BAD_CONFIG_MESSAGE_PREFIX + HAUtil.getNeedToSetValueMessage(HAUtil.addSuffix(YarnConfiguration.RM_HOSTNAME, RM1_NODE_ID) + \" or \" + confKey), e.getMessage());\r\n    }\r\n    myConf = new Configuration(conf);\r\n    myConf.set(YarnConfiguration.RM_HA_IDS, RM2_NODE_ID + \",\" + RM3_NODE_ID);\r\n    myConf.set(YarnConfiguration.RM_HA_ID, RM1_NODE_ID_UNTRIMMED);\r\n    for (String confKey : YarnConfiguration.getServiceAddressConfKeys(myConf)) {\r\n        myConf.set(HAUtil.addSuffix(confKey, RM1_NODE_ID), RM1_ADDRESS_UNTRIMMED);\r\n        myConf.set(HAUtil.addSuffix(confKey, RM2_NODE_ID), RM2_ADDRESS);\r\n        myConf.set(HAUtil.addSuffix(confKey, RM3_NODE_ID), RM3_ADDRESS);\r\n    }\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n    } catch (YarnRuntimeException e) {\r\n        assertEquals(\"YarnRuntimeException by getRMId()'s validation\", HAUtil.BAD_CONFIG_MESSAGE_PREFIX + HAUtil.getRMHAIdNeedToBeIncludedMessage(\"[rm2, rm3]\", RM1_NODE_ID), e.getMessage());\r\n    }\r\n    myConf = new Configuration(conf);\r\n    myConf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    myConf.setBoolean(YarnConfiguration.AUTO_FAILOVER_ENABLED, true);\r\n    myConf.setBoolean(YarnConfiguration.AUTO_FAILOVER_EMBEDDED, false);\r\n    myConf.setBoolean(YarnConfiguration.CURATOR_LEADER_ELECTOR, false);\r\n    try {\r\n        HAUtil.verifyAndSetConfiguration(myConf);\r\n    } catch (YarnRuntimeException e) {\r\n        assertEquals(\"YarnRuntimeException by getRMId()'s validation\", HAUtil.BAD_CONFIG_MESSAGE_PREFIX + HAUtil.NO_LEADER_ELECTION_MESSAGE, e.getMessage());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 7,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\conf",
  "methodName" : "testGetConfKeyForRMInstance",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testGetConfKeyForRMInstance()\n{\r\n    assertTrue(\"RM instance id is not suffixed\", HAUtil.getConfKeyForRMInstance(YarnConfiguration.RM_ADDRESS, conf).contains(HAUtil.getRMHAId(conf)));\r\n    assertFalse(\"RM instance id is suffixed\", HAUtil.getConfKeyForRMInstance(YarnConfiguration.NM_ADDRESS, conf).contains(HAUtil.getRMHAId(conf)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\resource",
  "methodName" : "testTargetConstraint",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testTargetConstraint()\n{\r\n    AbstractConstraint sConstraintExpr = targetIn(NODE, allocationTag(\"hbase-m\"));\r\n    Assert.assertTrue(sConstraintExpr instanceof SingleConstraint);\r\n    PlacementConstraint sConstraint = PlacementConstraints.build(sConstraintExpr);\r\n    SpecializedConstraintTransformer specTransformer = new SpecializedConstraintTransformer(sConstraint);\r\n    PlacementConstraint tConstraint = specTransformer.transform();\r\n    AbstractConstraint tConstraintExpr = tConstraint.getConstraintExpr();\r\n    Assert.assertTrue(tConstraintExpr instanceof TargetConstraint);\r\n    SingleConstraint single = (SingleConstraint) sConstraintExpr;\r\n    TargetConstraint target = (TargetConstraint) tConstraintExpr;\r\n    Assert.assertEquals(single.toString(), target.toString());\r\n    Assert.assertEquals(single.getScope(), target.getScope());\r\n    Assert.assertEquals(TargetOperator.IN, target.getOp());\r\n    Assert.assertEquals(single.getTargetExpressions(), target.getTargetExpressions());\r\n    SingleConstraintTransformer singleTransformer = new SingleConstraintTransformer(tConstraint);\r\n    sConstraint = singleTransformer.transform();\r\n    sConstraintExpr = sConstraint.getConstraintExpr();\r\n    Assert.assertTrue(sConstraintExpr instanceof SingleConstraint);\r\n    single = (SingleConstraint) sConstraintExpr;\r\n    Assert.assertEquals(target.getScope(), single.getScope());\r\n    Assert.assertEquals(1, single.getMinCardinality());\r\n    Assert.assertEquals(Integer.MAX_VALUE, single.getMaxCardinality());\r\n    Assert.assertEquals(single.getTargetExpressions(), target.getTargetExpressions());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\resource",
  "methodName" : "testCardinalityConstraint",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testCardinalityConstraint()\n{\r\n    CardinalityConstraint cardinality = new CardinalityConstraint(RACK, 3, 10, new HashSet<>(Arrays.asList(\"hb\")));\r\n    PlacementConstraint cConstraint = PlacementConstraints.build(cardinality);\r\n    SingleConstraintTransformer singleTransformer = new SingleConstraintTransformer(cConstraint);\r\n    PlacementConstraint sConstraint = singleTransformer.transform();\r\n    AbstractConstraint sConstraintExpr = sConstraint.getConstraintExpr();\r\n    Assert.assertTrue(sConstraintExpr instanceof SingleConstraint);\r\n    SingleConstraint single = (SingleConstraint) sConstraintExpr;\r\n    Assert.assertEquals(single.toString(), cardinality.toString());\r\n    Assert.assertEquals(cardinality.getScope(), single.getScope());\r\n    Assert.assertEquals(cardinality.getMinCardinality(), single.getMinCardinality());\r\n    Assert.assertEquals(cardinality.getMaxCardinality(), single.getMaxCardinality());\r\n    Assert.assertEquals(new HashSet<>(Arrays.asList(PlacementTargets.allocationTag(\"hb\"))), single.getTargetExpressions());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\resource",
  "methodName" : "testTargetCardinalityConstraint",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testTargetCardinalityConstraint()\n{\r\n    AbstractConstraint constraintExpr = targetCardinality(RACK, 3, 10, allocationTag(\"zk\"));\r\n    Assert.assertTrue(constraintExpr instanceof SingleConstraint);\r\n    PlacementConstraint constraint = PlacementConstraints.build(constraintExpr);\r\n    SpecializedConstraintTransformer specTransformer = new SpecializedConstraintTransformer(constraint);\r\n    PlacementConstraint newConstraint = specTransformer.transform();\r\n    Assert.assertEquals(constraintExpr, newConstraint.getConstraintExpr());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\resource",
  "methodName" : "testCompositeConstraint",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void testCompositeConstraint()\n{\r\n    AbstractConstraint constraintExpr = or(targetIn(RACK, allocationTag(\"spark\")), maxCardinality(NODE, 3), targetCardinality(RACK, 2, 10, allocationTag(\"zk\")));\r\n    Assert.assertTrue(constraintExpr instanceof Or);\r\n    PlacementConstraint constraint = PlacementConstraints.build(constraintExpr);\r\n    Or orExpr = (Or) constraintExpr;\r\n    for (AbstractConstraint child : orExpr.getChildren()) {\r\n        Assert.assertTrue(child instanceof SingleConstraint);\r\n    }\r\n    SpecializedConstraintTransformer specTransformer = new SpecializedConstraintTransformer(constraint);\r\n    PlacementConstraint specConstraint = specTransformer.transform();\r\n    Or specOrExpr = (Or) specConstraint.getConstraintExpr();\r\n    List<AbstractConstraint> specChildren = specOrExpr.getChildren();\r\n    Assert.assertEquals(3, specChildren.size());\r\n    Assert.assertTrue(specChildren.get(0) instanceof TargetConstraint);\r\n    Assert.assertTrue(specChildren.get(1) instanceof SingleConstraint);\r\n    Assert.assertTrue(specChildren.get(2) instanceof SingleConstraint);\r\n    SingleConstraintTransformer singleTransformer = new SingleConstraintTransformer(specConstraint);\r\n    PlacementConstraint simConstraint = singleTransformer.transform();\r\n    Assert.assertTrue(simConstraint.getConstraintExpr() instanceof Or);\r\n    Or simOrExpr = (Or) specConstraint.getConstraintExpr();\r\n    for (AbstractConstraint child : simOrExpr.getChildren()) {\r\n        Assert.assertTrue(child instanceof SingleConstraint);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testTargetConstraintProtoConverter",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void testTargetConstraintProtoConverter()\n{\r\n    AbstractConstraint sConstraintExpr = targetIn(NODE, allocationTag(\"hbase-m\"));\r\n    Assert.assertTrue(sConstraintExpr instanceof SingleConstraint);\r\n    SingleConstraint single = (SingleConstraint) sConstraintExpr;\r\n    PlacementConstraint sConstraint = PlacementConstraints.build(sConstraintExpr);\r\n    PlacementConstraintToProtoConverter toProtoConverter = new PlacementConstraintToProtoConverter(sConstraint);\r\n    PlacementConstraintProto protoConstraint = toProtoConverter.convert();\r\n    Assert.assertTrue(protoConstraint.hasSimpleConstraint());\r\n    Assert.assertFalse(protoConstraint.hasCompositeConstraint());\r\n    SimplePlacementConstraintProto sProto = protoConstraint.getSimpleConstraint();\r\n    Assert.assertEquals(single.getScope(), sProto.getScope());\r\n    Assert.assertEquals(single.getMinCardinality(), sProto.getMinCardinality());\r\n    Assert.assertEquals(single.getMaxCardinality(), sProto.getMaxCardinality());\r\n    Assert.assertEquals(single.getTargetExpressions().size(), sProto.getTargetExpressionsList().size());\r\n    PlacementConstraintFromProtoConverter fromProtoConverter = new PlacementConstraintFromProtoConverter(protoConstraint);\r\n    PlacementConstraint newConstraint = fromProtoConverter.convert();\r\n    AbstractConstraint newConstraintExpr = newConstraint.getConstraintExpr();\r\n    Assert.assertTrue(newConstraintExpr instanceof SingleConstraint);\r\n    SingleConstraint newSingle = (SingleConstraint) newConstraintExpr;\r\n    Assert.assertEquals(single.getScope(), newSingle.getScope());\r\n    Assert.assertEquals(single.getMinCardinality(), newSingle.getMinCardinality());\r\n    Assert.assertEquals(single.getMaxCardinality(), newSingle.getMaxCardinality());\r\n    Assert.assertEquals(single.getTargetExpressions(), newSingle.getTargetExpressions());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testCardinalityConstraintProtoConverter",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testCardinalityConstraintProtoConverter()\n{\r\n    AbstractConstraint sConstraintExpr = cardinality(RACK, 3, 10);\r\n    Assert.assertTrue(sConstraintExpr instanceof SingleConstraint);\r\n    SingleConstraint single = (SingleConstraint) sConstraintExpr;\r\n    PlacementConstraint sConstraint = PlacementConstraints.build(sConstraintExpr);\r\n    PlacementConstraintToProtoConverter toProtoConverter = new PlacementConstraintToProtoConverter(sConstraint);\r\n    PlacementConstraintProto protoConstraint = toProtoConverter.convert();\r\n    compareSimpleConstraintToProto(single, protoConstraint);\r\n    PlacementConstraintFromProtoConverter fromProtoConverter = new PlacementConstraintFromProtoConverter(protoConstraint);\r\n    PlacementConstraint newConstraint = fromProtoConverter.convert();\r\n    AbstractConstraint newConstraintExpr = newConstraint.getConstraintExpr();\r\n    Assert.assertTrue(newConstraintExpr instanceof SingleConstraint);\r\n    SingleConstraint newSingle = (SingleConstraint) newConstraintExpr;\r\n    compareSimpleConstraints(single, newSingle);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testCompositeConstraintProtoConverter",
  "errType" : null,
  "containingMethodsNum" : 28,
  "sourceCodeText" : "void testCompositeConstraintProtoConverter()\n{\r\n    AbstractConstraint constraintExpr = or(targetIn(RACK, allocationTag(\"spark\")), maxCardinality(NODE, 3), targetCardinality(RACK, 2, 10, allocationTag(\"zk\")));\r\n    Assert.assertTrue(constraintExpr instanceof Or);\r\n    PlacementConstraint constraint = PlacementConstraints.build(constraintExpr);\r\n    Or orExpr = (Or) constraintExpr;\r\n    PlacementConstraintToProtoConverter toProtoConverter = new PlacementConstraintToProtoConverter(constraint);\r\n    PlacementConstraintProto protoConstraint = toProtoConverter.convert();\r\n    Assert.assertFalse(protoConstraint.hasSimpleConstraint());\r\n    Assert.assertTrue(protoConstraint.hasCompositeConstraint());\r\n    CompositePlacementConstraintProto cProto = protoConstraint.getCompositeConstraint();\r\n    Assert.assertEquals(CompositeType.OR, cProto.getCompositeType());\r\n    Assert.assertEquals(3, cProto.getChildConstraintsCount());\r\n    Assert.assertEquals(0, cProto.getTimedChildConstraintsCount());\r\n    Iterator<AbstractConstraint> orChildren = orExpr.getChildren().iterator();\r\n    Iterator<PlacementConstraintProto> orProtoChildren = cProto.getChildConstraintsList().iterator();\r\n    while (orChildren.hasNext() && orProtoChildren.hasNext()) {\r\n        AbstractConstraint orChild = orChildren.next();\r\n        PlacementConstraintProto orProtoChild = orProtoChildren.next();\r\n        compareSimpleConstraintToProto((SingleConstraint) orChild, orProtoChild);\r\n    }\r\n    PlacementConstraintFromProtoConverter fromProtoConverter = new PlacementConstraintFromProtoConverter(protoConstraint);\r\n    PlacementConstraint newConstraint = fromProtoConverter.convert();\r\n    AbstractConstraint newConstraintExpr = newConstraint.getConstraintExpr();\r\n    Assert.assertTrue(newConstraintExpr instanceof Or);\r\n    Or newOrExpr = (Or) newConstraintExpr;\r\n    Assert.assertEquals(3, newOrExpr.getChildren().size());\r\n    orChildren = orExpr.getChildren().iterator();\r\n    Iterator<AbstractConstraint> newOrChildren = newOrExpr.getChildren().iterator();\r\n    while (orChildren.hasNext() && newOrChildren.hasNext()) {\r\n        AbstractConstraint orChild = orChildren.next();\r\n        AbstractConstraint newOrChild = newOrChildren.next();\r\n        compareSimpleConstraints((SingleConstraint) orChild, (SingleConstraint) newOrChild);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "compareSimpleConstraintToProto",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void compareSimpleConstraintToProto(SingleConstraint constraint, PlacementConstraintProto proto)\n{\r\n    Assert.assertTrue(proto.hasSimpleConstraint());\r\n    Assert.assertFalse(proto.hasCompositeConstraint());\r\n    SimplePlacementConstraintProto sProto = proto.getSimpleConstraint();\r\n    Assert.assertEquals(constraint.getScope(), sProto.getScope());\r\n    Assert.assertEquals(constraint.getMinCardinality(), sProto.getMinCardinality());\r\n    Assert.assertEquals(constraint.getMaxCardinality(), sProto.getMaxCardinality());\r\n    Assert.assertEquals(constraint.getTargetExpressions().size(), sProto.getTargetExpressionsList().size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "compareSimpleConstraints",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void compareSimpleConstraints(SingleConstraint single, SingleConstraint newSingle)\n{\r\n    Assert.assertEquals(single.getScope(), newSingle.getScope());\r\n    Assert.assertEquals(single.getMinCardinality(), newSingle.getMinCardinality());\r\n    Assert.assertEquals(single.getMaxCardinality(), newSingle.getMaxCardinality());\r\n    Assert.assertEquals(single.getTargetExpressions(), newSingle.getTargetExpressions());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "initializeDummyHostnameResolution",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void initializeDummyHostnameResolution() throws Exception\n{\r\n    String previousIpAddress;\r\n    for (String hostName : dummyHostNames) {\r\n        if (null != (previousIpAddress = NetUtils.getStaticResolution(hostName))) {\r\n            savedStaticResolution.put(hostName, previousIpAddress);\r\n        }\r\n        NetUtils.addStaticResolution(hostName, anyIpAddress);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "restoreDummyHostnameResolution",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void restoreDummyHostnameResolution() throws Exception\n{\r\n    for (Map.Entry<String, String> hostnameToIpEntry : savedStaticResolution.entrySet()) {\r\n        NetUtils.addStaticResolution(hostnameToIpEntry.getKey(), hostnameToIpEntry.getValue());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "TestRMWebAppURLRemoteAndLocal",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void TestRMWebAppURLRemoteAndLocal() throws UnknownHostException\n{\r\n    Configuration configuration = new Configuration();\r\n    final String rmAddress = \"host1:8088\";\r\n    configuration.set(YarnConfiguration.RM_WEBAPP_ADDRESS, rmAddress);\r\n    final String rm1Address = \"host2:8088\";\r\n    final String rm2Address = \"host3:8088\";\r\n    configuration.set(YarnConfiguration.RM_WEBAPP_ADDRESS + \".\" + RM1_NODE_ID, rm1Address);\r\n    configuration.set(YarnConfiguration.RM_WEBAPP_ADDRESS + \".\" + RM2_NODE_ID, rm2Address);\r\n    configuration.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);\r\n    configuration.set(YarnConfiguration.RM_HA_IDS, RM1_NODE_ID + \",\" + RM2_NODE_ID);\r\n    String rmRemoteUrl = WebAppUtils.getResolvedRemoteRMWebAppURLWithoutScheme(configuration);\r\n    Assert.assertEquals(\"ResolvedRemoteRMWebAppUrl should resolve to the first HA RM address\", rm1Address, rmRemoteUrl);\r\n    String rmLocalUrl = WebAppUtils.getResolvedRMWebAppURLWithoutScheme(configuration);\r\n    Assert.assertEquals(\"ResolvedRMWebAppUrl should resolve to the default RM webapp address\", rmAddress, rmLocalUrl);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "testGetPassword",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testGetPassword() throws Exception\n{\r\n    Configuration conf = provisionCredentialsForSSL();\r\n    Assert.assertEquals(\"keypass\", WebAppUtils.getPassword(conf, WebAppUtils.WEB_APP_KEY_PASSWORD_KEY));\r\n    Assert.assertEquals(\"storepass\", WebAppUtils.getPassword(conf, WebAppUtils.WEB_APP_KEYSTORE_PASSWORD_KEY));\r\n    Assert.assertEquals(\"trustpass\", WebAppUtils.getPassword(conf, WebAppUtils.WEB_APP_TRUSTSTORE_PASSWORD_KEY));\r\n    Assert.assertEquals(null, WebAppUtils.getPassword(conf, \"invalid-alias\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "testLoadSslConfiguration",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testLoadSslConfiguration() throws Exception\n{\r\n    Configuration conf = provisionCredentialsForSSL();\r\n    TestBuilder builder = (TestBuilder) new TestBuilder();\r\n    builder = (TestBuilder) WebAppUtils.loadSslConfiguration(builder, conf);\r\n    String keypass = \"keypass\";\r\n    String storepass = \"storepass\";\r\n    String trustpass = \"trustpass\";\r\n    assertEquals(keypass, ((TestBuilder) builder).keypass);\r\n    assertEquals(storepass, ((TestBuilder) builder).keystorePassword);\r\n    assertEquals(trustpass, ((TestBuilder) builder).truststorePassword);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "provisionCredentialsForSSL",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "Configuration provisionCredentialsForSSL() throws IOException, Exception\n{\r\n    File testDir = new File(System.getProperty(\"test.build.data\", \"target/test-dir\"));\r\n    Configuration conf = new Configuration();\r\n    final Path jksPath = new Path(testDir.toString(), \"test.jks\");\r\n    final String ourUrl = JavaKeyStoreProvider.SCHEME_NAME + \"://file\" + jksPath.toUri();\r\n    File file = new File(testDir, \"test.jks\");\r\n    file.delete();\r\n    conf.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, ourUrl);\r\n    CredentialProvider provider = CredentialProviderFactory.getProviders(conf).get(0);\r\n    char[] keypass = { 'k', 'e', 'y', 'p', 'a', 's', 's' };\r\n    char[] storepass = { 's', 't', 'o', 'r', 'e', 'p', 'a', 's', 's' };\r\n    char[] trustpass = { 't', 'r', 'u', 's', 't', 'p', 'a', 's', 's' };\r\n    assertEquals(null, provider.getCredentialEntry(WebAppUtils.WEB_APP_KEY_PASSWORD_KEY));\r\n    assertEquals(null, provider.getCredentialEntry(WebAppUtils.WEB_APP_KEYSTORE_PASSWORD_KEY));\r\n    assertEquals(null, provider.getCredentialEntry(WebAppUtils.WEB_APP_TRUSTSTORE_PASSWORD_KEY));\r\n    try {\r\n        provider.createCredentialEntry(WebAppUtils.WEB_APP_KEY_PASSWORD_KEY, keypass);\r\n        provider.createCredentialEntry(WebAppUtils.WEB_APP_KEYSTORE_PASSWORD_KEY, storepass);\r\n        provider.createCredentialEntry(WebAppUtils.WEB_APP_TRUSTSTORE_PASSWORD_KEY, trustpass);\r\n        provider.flush();\r\n    } catch (Exception e) {\r\n        e.printStackTrace();\r\n        throw e;\r\n    }\r\n    assertArrayEquals(keypass, provider.getCredentialEntry(WebAppUtils.WEB_APP_KEY_PASSWORD_KEY).getCredential());\r\n    assertArrayEquals(storepass, provider.getCredentialEntry(WebAppUtils.WEB_APP_KEYSTORE_PASSWORD_KEY).getCredential());\r\n    assertArrayEquals(trustpass, provider.getCredentialEntry(WebAppUtils.WEB_APP_TRUSTSTORE_PASSWORD_KEY).getCredential());\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "testAppendQueryParams",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testAppendQueryParams() throws Exception\n{\r\n    HttpServletRequest request = Mockito.mock(HttpServletRequest.class);\r\n    String targetUri = \"/test/path\";\r\n    Mockito.when(request.getCharacterEncoding()).thenReturn(null);\r\n    Map<String, String> paramResultMap = new HashMap<>();\r\n    paramResultMap.put(\"param1=x\", targetUri + \"?\" + \"param1=x\");\r\n    paramResultMap.put(\"param1=x&param2=y\", targetUri + \"?\" + \"param1=x&param2=y\");\r\n    paramResultMap.put(\"param1=x&param2=y&param3=x+y\", targetUri + \"?\" + \"param1=x&param2=y&param3=x+y\");\r\n    for (Map.Entry<String, String> entry : paramResultMap.entrySet()) {\r\n        Mockito.when(request.getQueryString()).thenReturn(entry.getKey());\r\n        String uri = WebAppUtils.appendQueryParams(request, targetUri);\r\n        Assert.assertEquals(entry.getValue(), uri);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\util",
  "methodName" : "testGetHtmlEscapedURIWithQueryString",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testGetHtmlEscapedURIWithQueryString() throws Exception\n{\r\n    HttpServletRequest request = Mockito.mock(HttpServletRequest.class);\r\n    String targetUri = \"/test/path\";\r\n    Mockito.when(request.getCharacterEncoding()).thenReturn(null);\r\n    Mockito.when(request.getRequestURI()).thenReturn(targetUri);\r\n    Map<String, String> paramResultMap = new HashMap<>();\r\n    paramResultMap.put(\"param1=x\", targetUri + \"?\" + \"param1=x\");\r\n    paramResultMap.put(\"param1=x&param2=y\", targetUri + \"?\" + \"param1=x&amp;param2=y\");\r\n    paramResultMap.put(\"param1=x&param2=y&param3=x+y\", targetUri + \"?\" + \"param1=x&amp;param2=y&amp;param3=x+y\");\r\n    for (Map.Entry<String, String> entry : paramResultMap.entrySet()) {\r\n        Mockito.when(request.getQueryString()).thenReturn(entry.getKey());\r\n        String uri = WebAppUtils.getHtmlEscapedURIWithQueryString(request);\r\n        Assert.assertEquals(entry.getValue(), uri);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    file = File.createTempFile(\"docker-client-config\", \"test\");\r\n    file.deleteOnExit();\r\n    BufferedWriter bw = new BufferedWriter(new FileWriter(file));\r\n    bw.write(JSON);\r\n    bw.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testReadCredentialsFromConfigFile",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testReadCredentialsFromConfigFile() throws Exception\n{\r\n    Credentials credentials = DockerClientConfigHandler.readCredentialsFromConfigFile(new Path(file.toURI()), conf, APPLICATION_ID);\r\n    Token token1 = credentials.getToken(new Text(\"https://index.docker.io/v1/-\" + APPLICATION_ID));\r\n    assertEquals(DockerCredentialTokenIdentifier.KIND, token1.getKind());\r\n    assertEquals(\"foobarbaz\", new String(token1.getPassword()));\r\n    DockerCredentialTokenIdentifier ti1 = (DockerCredentialTokenIdentifier) token1.decodeIdentifier();\r\n    assertEquals(\"https://index.docker.io/v1/\", ti1.getRegistryUrl());\r\n    assertEquals(APPLICATION_ID, ti1.getApplicationId());\r\n    Token token2 = credentials.getToken(new Text(\"registry.example.com-\" + APPLICATION_ID));\r\n    assertEquals(DockerCredentialTokenIdentifier.KIND, token2.getKind());\r\n    assertEquals(\"bazbarfoo\", new String(token2.getPassword()));\r\n    DockerCredentialTokenIdentifier ti2 = (DockerCredentialTokenIdentifier) token2.decodeIdentifier();\r\n    assertEquals(\"registry.example.com\", ti2.getRegistryUrl());\r\n    assertEquals(APPLICATION_ID, ti2.getApplicationId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testGetCredentialsFromTokensByteBuffer",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void testGetCredentialsFromTokensByteBuffer() throws Exception\n{\r\n    Credentials credentials = DockerClientConfigHandler.readCredentialsFromConfigFile(new Path(file.toURI()), conf, APPLICATION_ID);\r\n    DataOutputBuffer dob = new DataOutputBuffer();\r\n    credentials.writeTokenStorageToStream(dob);\r\n    ByteBuffer tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\r\n    Credentials credentialsOut = DockerClientConfigHandler.getCredentialsFromTokensByteBuffer(tokens);\r\n    assertEquals(credentials.numberOfTokens(), credentialsOut.numberOfTokens());\r\n    for (Token<? extends TokenIdentifier> tkIn : credentials.getAllTokens()) {\r\n        DockerCredentialTokenIdentifier ti = (DockerCredentialTokenIdentifier) tkIn.decodeIdentifier();\r\n        Token tkOut = credentialsOut.getToken(new Text(ti.getRegistryUrl() + \"-\" + ti.getApplicationId()));\r\n        assertEquals(tkIn.getKind(), tkOut.getKind());\r\n        assertEquals(new String(tkIn.getIdentifier()), new String(tkOut.getIdentifier()));\r\n        assertEquals(new String(tkIn.getPassword()), new String(tkOut.getPassword()));\r\n        assertEquals(tkIn.getService(), tkOut.getService());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\security",
  "methodName" : "testWriteDockerCredentialsToPath",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testWriteDockerCredentialsToPath() throws Exception\n{\r\n    File outFile = File.createTempFile(\"docker-client-config\", \"out\");\r\n    outFile.deleteOnExit();\r\n    Credentials credentials = DockerClientConfigHandler.readCredentialsFromConfigFile(new Path(file.toURI()), conf, APPLICATION_ID);\r\n    assertTrue(DockerClientConfigHandler.writeDockerCredentialsToPath(outFile, credentials));\r\n    assertTrue(outFile.exists());\r\n    String fileContents = FileUtils.readFileToString(outFile);\r\n    assertTrue(fileContents.contains(\"auths\"));\r\n    assertTrue(fileContents.contains(\"registry.example.com\"));\r\n    assertTrue(fileContents.contains(\"https://index.docker.io/v1/\"));\r\n    assertTrue(fileContents.contains(\"foobarbaz\"));\r\n    assertTrue(fileContents.contains(\"bazbarfoo\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records",
  "methodName" : "testResourceUtilization",
  "errType" : null,
  "containingMethodsNum" : 28,
  "sourceCodeText" : "void testResourceUtilization()\n{\r\n    ResourceUtilization u1 = ResourceUtilization.newInstance(10, 20, 0.5f);\r\n    ResourceUtilization u2 = ResourceUtilization.newInstance(u1);\r\n    ResourceUtilization u3 = ResourceUtilization.newInstance(10, 20, 0.5f);\r\n    ResourceUtilization u4 = ResourceUtilization.newInstance(20, 20, 0.5f);\r\n    ResourceUtilization u5 = ResourceUtilization.newInstance(30, 40, 0.8f);\r\n    Assert.assertEquals(u1, u2);\r\n    Assert.assertEquals(u1, u3);\r\n    Assert.assertNotEquals(u1, u4);\r\n    Assert.assertNotEquals(u2, u5);\r\n    Assert.assertNotEquals(u4, u5);\r\n    Assert.assertTrue(u1.hashCode() == u2.hashCode());\r\n    Assert.assertTrue(u1.hashCode() == u3.hashCode());\r\n    Assert.assertFalse(u1.hashCode() == u4.hashCode());\r\n    Assert.assertFalse(u2.hashCode() == u5.hashCode());\r\n    Assert.assertFalse(u4.hashCode() == u5.hashCode());\r\n    Assert.assertTrue(u1.getPhysicalMemory() == 10);\r\n    Assert.assertFalse(u1.getVirtualMemory() == 10);\r\n    Assert.assertTrue(u1.getCPU() == 0.5f);\r\n    Assert.assertEquals(\"<pmem:10, vmem:\" + u1.getVirtualMemory() + \", vCores:0.5>\", u1.toString());\r\n    u1.addTo(10, 0, 0.0f);\r\n    Assert.assertNotEquals(u1, u2);\r\n    Assert.assertEquals(u1, u4);\r\n    u1.addTo(10, 20, 0.3f);\r\n    Assert.assertEquals(u1, u5);\r\n    u1.subtractFrom(10, 20, 0.3f);\r\n    Assert.assertEquals(u1, u4);\r\n    u1.subtractFrom(10, 0, 0.0f);\r\n    Assert.assertEquals(u1, u3);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api\\records",
  "methodName" : "testResourceUtilizationWithCustomResource",
  "errType" : null,
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void testResourceUtilizationWithCustomResource()\n{\r\n    Map<String, Float> customResources = new HashMap<>();\r\n    customResources.put(ResourceInformation.GPU_URI, 5.0f);\r\n    ResourceUtilization u1 = ResourceUtilization.newInstance(10, 20, 0.5f, customResources);\r\n    ResourceUtilization u2 = ResourceUtilization.newInstance(u1);\r\n    ResourceUtilization u3 = ResourceUtilization.newInstance(10, 20, 0.5f, customResources);\r\n    ResourceUtilization u4 = ResourceUtilization.newInstance(20, 20, 0.5f, customResources);\r\n    ResourceUtilization u5 = ResourceUtilization.newInstance(30, 40, 0.8f, customResources);\r\n    Assert.assertEquals(u1, u2);\r\n    Assert.assertEquals(u1, u3);\r\n    Assert.assertNotEquals(u1, u4);\r\n    Assert.assertNotEquals(u2, u5);\r\n    Assert.assertNotEquals(u4, u5);\r\n    Assert.assertTrue(u1.hashCode() == u2.hashCode());\r\n    Assert.assertTrue(u1.hashCode() == u3.hashCode());\r\n    Assert.assertFalse(u1.hashCode() == u4.hashCode());\r\n    Assert.assertFalse(u2.hashCode() == u5.hashCode());\r\n    Assert.assertFalse(u4.hashCode() == u5.hashCode());\r\n    Assert.assertTrue(u1.getPhysicalMemory() == 10);\r\n    Assert.assertFalse(u1.getVirtualMemory() == 10);\r\n    Assert.assertTrue(u1.getCPU() == 0.5f);\r\n    Assert.assertTrue(u1.getCustomResource(ResourceInformation.GPU_URI) == 5.0f);\r\n    Assert.assertEquals(\"<pmem:10, vmem:\" + u1.getVirtualMemory() + \", vCores:0.5, yarn.io/gpu:5.0>\", u1.toString());\r\n    u1.addTo(10, 0, 0.0f);\r\n    Assert.assertNotEquals(u1, u2);\r\n    Assert.assertEquals(u1, u4);\r\n    u1.addTo(10, 20, 0.3f);\r\n    Assert.assertEquals(u1, u5);\r\n    u1.subtractFrom(10, 20, 0.3f);\r\n    Assert.assertEquals(u1, u4);\r\n    u1.subtractFrom(10, 0, 0.0f);\r\n    Assert.assertEquals(u1, u3);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testNormal",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testNormal()\n{\r\n    String[] res = parseSelector(\"#id.class\");\r\n    assertEquals(\"id\", res[S_ID]);\r\n    assertEquals(\"class\", res[S_CLASS]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testMultiClass",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testMultiClass()\n{\r\n    String[] res = parseSelector(\"#id.class1.class2\");\r\n    assertEquals(\"id\", res[S_ID]);\r\n    assertEquals(\"class1 class2\", res[S_CLASS]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testMissingId",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testMissingId()\n{\r\n    String[] res = parseSelector(\".class\");\r\n    assertNull(res[S_ID]);\r\n    assertEquals(\"class\", res[S_CLASS]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testMissingClass",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testMissingClass()\n{\r\n    String[] res = parseSelector(\"#id\");\r\n    assertEquals(\"id\", res[S_ID]);\r\n    assertNull(res[S_CLASS]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\webapp\\hamlet2",
  "methodName" : "testMissingAll",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testMissingAll()\n{\r\n    parseSelector(\"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "getRogueTaskPID",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getRogueTaskPID()\n{\r\n    File f = new File(pidFile);\r\n    while (!f.exists()) {\r\n        try {\r\n            Thread.sleep(500);\r\n        } catch (InterruptedException ie) {\r\n            break;\r\n        }\r\n    }\r\n    return getPidFromPidFile(pidFile);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setup() throws IOException\n{\r\n    assumeTrue(Shell.LINUX);\r\n    FileContext.getLocalFSFileContext().delete(new Path(TEST_ROOT_DIR.getAbsolutePath()), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testProcessTree",
  "errType" : [ "Exception", "InterruptedException", "InterruptedException" ],
  "containingMethodsNum" : 44,
  "sourceCodeText" : "void testProcessTree() throws Exception\n{\r\n    try {\r\n        Assert.assertTrue(ProcfsBasedProcessTree.isAvailable());\r\n    } catch (Exception e) {\r\n        LOG.info(StringUtils.stringifyException(e));\r\n        Assert.assertTrue(\"ProcfsBaseProcessTree should be available on Linux\", false);\r\n        return;\r\n    }\r\n    Random rm = new Random();\r\n    File tempFile = new File(TEST_ROOT_DIR, getClass().getName() + \"_shellScript_\" + rm.nextInt() + \".sh\");\r\n    tempFile.deleteOnExit();\r\n    shellScript = TEST_ROOT_DIR + File.separator + tempFile.getName();\r\n    tempFile = new File(TEST_ROOT_DIR, getClass().getName() + \"_pidFile_\" + rm.nextInt() + \".pid\");\r\n    tempFile.deleteOnExit();\r\n    pidFile = TEST_ROOT_DIR + File.separator + tempFile.getName();\r\n    lowestDescendant = TEST_ROOT_DIR + File.separator + \"lowestDescendantPidFile\";\r\n    lostDescendant = TEST_ROOT_DIR + File.separator + \"lostDescendantPidFile\";\r\n    File file = new File(shellScript);\r\n    FileUtils.writeStringToFile(file, \"# rogue task\\n\" + \"sleep 1\\n\" + \"echo hello\\n\" + \"if [ $1 -ne 0 ]\\n\" + \"then\\n\" + \" sh \" + shellScript + \" $(($1-1))\\n\" + \"else\\n\" + \" echo $$ > \" + lowestDescendant + \"\\n\" + \"(sleep 300&\\n\" + \"echo $! > \" + lostDescendant + \")\\n\" + \" while true\\n do\\n\" + \"  sleep 5\\n\" + \" done\\n\" + \"fi\", StandardCharsets.UTF_8);\r\n    Thread t = new RogueTaskThread();\r\n    t.start();\r\n    String pid = getRogueTaskPID();\r\n    LOG.info(\"Root process pid: \" + pid);\r\n    ProcfsBasedProcessTree p = createProcessTree(pid);\r\n    p.updateProcessTree();\r\n    LOG.info(\"ProcessTree: \" + p);\r\n    File leaf = new File(lowestDescendant);\r\n    while (!leaf.exists()) {\r\n        try {\r\n            Thread.sleep(500);\r\n        } catch (InterruptedException ie) {\r\n            break;\r\n        }\r\n    }\r\n    p.updateProcessTree();\r\n    LOG.info(\"ProcessTree: \" + p);\r\n    String lostpid = getPidFromPidFile(lostDescendant);\r\n    LOG.info(\"Orphaned pid: \" + lostpid);\r\n    Assert.assertTrue(\"Child process owned by init escaped process tree.\", p.contains(lostpid));\r\n    String processTreeDump = p.getProcessTreeDump();\r\n    destroyProcessTree(pid);\r\n    boolean isAlive = true;\r\n    for (int tries = 100; tries > 0; tries--) {\r\n        if (isSetsidAvailable()) {\r\n            isAlive = isAnyProcessInTreeAlive(p);\r\n        } else {\r\n            isAlive = isAlive(pid);\r\n        }\r\n        if (!isAlive) {\r\n            break;\r\n        }\r\n        Thread.sleep(100);\r\n    }\r\n    if (isAlive) {\r\n        fail(\"ProcessTree shouldn't be alive\");\r\n    }\r\n    LOG.info(\"Process-tree dump follows: \\n\" + processTreeDump);\r\n    Assert.assertTrue(\"Process-tree dump doesn't start with a proper header\", processTreeDump.startsWith(\"\\t|- PID PPID PGRPID SESSID CMD_NAME \" + \"USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) \" + \"RSSMEM_USAGE(PAGES) FULL_CMD_LINE\\n\"));\r\n    for (int i = N; i >= 0; i--) {\r\n        String cmdLineDump = \"\\\\|- [0-9]+ [0-9]+ [0-9]+ [0-9]+ \\\\(sh\\\\)\" + \" [0-9]+ [0-9]+ [0-9]+ [0-9]+ sh \" + shellScript + \" \" + i;\r\n        Pattern pat = Pattern.compile(cmdLineDump);\r\n        Matcher mat = pat.matcher(processTreeDump);\r\n        Assert.assertTrue(\"Process-tree dump doesn't contain the cmdLineDump of \" + i + \"th process!\", mat.find());\r\n    }\r\n    try {\r\n        t.join(2000);\r\n        LOG.info(\"RogueTaskThread successfully joined.\");\r\n    } catch (InterruptedException ie) {\r\n        LOG.info(\"Interrupted while joining RogueTaskThread.\");\r\n    }\r\n    p.updateProcessTree();\r\n    Assert.assertFalse(\"ProcessTree must have been gone\", isAlive(pid));\r\n    Assert.assertTrue(\"vmem for the gone-process is \" + p.getVirtualMemorySize() + \" . It should be UNAVAILABLE(-1).\", p.getVirtualMemorySize() == UNAVAILABLE);\r\n    Assert.assertEquals(\"[ ]\", p.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createProcessTree",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ProcfsBasedProcessTree createProcessTree(String pid)\n{\r\n    return new ProcfsBasedProcessTree(pid);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createProcessTree",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ProcfsBasedProcessTree createProcessTree(String pid, String procfsRootDir, Clock clock)\n{\r\n    return new ProcfsBasedProcessTree(pid, procfsRootDir, clock);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "destroyProcessTree",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void destroyProcessTree(String pid) throws IOException\n{\r\n    sendSignal(\"-\" + pid, 9);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "getPidFromPidFile",
  "errType" : [ "FileNotFoundException", "IOException", "IOException", "IOException" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "String getPidFromPidFile(String pidFileName)\n{\r\n    BufferedReader pidFile = null;\r\n    FileReader fReader = null;\r\n    String pid = null;\r\n    try {\r\n        fReader = new FileReader(pidFileName);\r\n        pidFile = new BufferedReader(fReader);\r\n    } catch (FileNotFoundException f) {\r\n        LOG.debug(\"PidFile doesn't exist : {}\", pidFileName);\r\n        return pid;\r\n    }\r\n    try {\r\n        pid = pidFile.readLine();\r\n    } catch (IOException i) {\r\n        LOG.error(\"Failed to read from \" + pidFileName);\r\n    } finally {\r\n        try {\r\n            if (fReader != null) {\r\n                fReader.close();\r\n            }\r\n            try {\r\n                if (pidFile != null) {\r\n                    pidFile.close();\r\n                }\r\n            } catch (IOException i) {\r\n                LOG.warn(\"Error closing the stream \" + pidFile);\r\n            }\r\n        } catch (IOException i) {\r\n            LOG.warn(\"Error closing the stream \" + fReader);\r\n        }\r\n    }\r\n    return pid;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 4,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "constructMemoryMappingInfo",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "ProcessSmapMemoryInfo constructMemoryMappingInfo(String address, String[] entries)\n{\r\n    ProcessSmapMemoryInfo info = new ProcessSmapMemoryInfo(address);\r\n    info.setMemInfo(MemInfo.SIZE.name(), entries[0]);\r\n    info.setMemInfo(MemInfo.RSS.name(), entries[1]);\r\n    info.setMemInfo(MemInfo.PSS.name(), entries[2]);\r\n    info.setMemInfo(MemInfo.SHARED_CLEAN.name(), entries[3]);\r\n    info.setMemInfo(MemInfo.SHARED_DIRTY.name(), entries[4]);\r\n    info.setMemInfo(MemInfo.PRIVATE_CLEAN.name(), entries[5]);\r\n    info.setMemInfo(MemInfo.PRIVATE_DIRTY.name(), entries[6]);\r\n    info.setMemInfo(MemInfo.REFERENCED.name(), entries[7]);\r\n    info.setMemInfo(MemInfo.ANONYMOUS.name(), entries[8]);\r\n    info.setMemInfo(MemInfo.ANON_HUGE_PAGES.name(), entries[9]);\r\n    info.setMemInfo(MemInfo.SWAP.name(), entries[10]);\r\n    info.setMemInfo(MemInfo.KERNEL_PAGE_SIZE.name(), entries[11]);\r\n    info.setMemInfo(MemInfo.MMU_PAGE_SIZE.name(), entries[12]);\r\n    return info;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "createMemoryMappingInfo",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void createMemoryMappingInfo(ProcessTreeSmapMemInfo[] procMemInfo)\n{\r\n    for (int i = 0; i < procMemInfo.length; i++) {\r\n        List<ProcessSmapMemoryInfo> memoryMappingList = procMemInfo[i].getMemoryInfoList();\r\n        memoryMappingList.add(constructMemoryMappingInfo(\"7f56c177c000-7f56c177d000 \" + \"rw-p 00010000 08:02 40371558                   \" + \"/grid/0/jdk1.7.0_25/jre/lib/amd64/libnio.so\", new String[] { \"4\", \"4\", \"25\", \"4\", \"25\", \"15\", \"10\", \"4\", \"10\", \"0\", \"0\", \"4\", \"4\" }));\r\n        memoryMappingList.add(constructMemoryMappingInfo(\"7fb09382e000-7fb09382f000 r--s 00003000 \" + \"08:02 25953545\", new String[] { \"4\", \"4\", \"25\", \"4\", \"0\", \"15\", \"10\", \"4\", \"10\", \"0\", \"0\", \"4\", \"4\" }));\r\n        memoryMappingList.add(constructMemoryMappingInfo(\"7e8790000-7e8b80000 r-xs 00000000 00:00 0\", new String[] { \"4\", \"4\", \"25\", \"4\", \"0\", \"15\", \"10\", \"4\", \"10\", \"0\", \"0\", \"4\", \"4\" }));\r\n        memoryMappingList.add(constructMemoryMappingInfo(\"7da677000-7e0dcf000 rw-p 00000000 00:00 0\", new String[] { \"4\", \"4\", \"25\", \"4\", \"50\", \"15\", \"10\", \"4\", \"10\", \"0\", \"0\", \"4\", \"4\" }));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testCpuAndMemoryForProcessTree",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testCpuAndMemoryForProcessTree() throws IOException\n{\r\n    String[] pids = { \"100\", \"200\", \"300\", \"400\" };\r\n    ControlledClock testClock = new ControlledClock();\r\n    testClock.setTime(0);\r\n    File procfsRootDir = new File(TEST_ROOT_DIR, \"proc\");\r\n    try {\r\n        setupProcfsRootDir(procfsRootDir);\r\n        setupPidDirs(procfsRootDir, pids);\r\n        ProcessStatInfo[] procInfos = new ProcessStatInfo[4];\r\n        procInfos[0] = new ProcessStatInfo(new String[] { \"100\", \"proc1\", \"1\", \"100\", \"100\", \"100000\", \"100\", \"1000\", \"200\" });\r\n        procInfos[1] = new ProcessStatInfo(new String[] { \"200\", \"process two\", \"100\", \"100\", \"100\", \"200000\", \"200\", \"2000\", \"400\" });\r\n        procInfos[2] = new ProcessStatInfo(new String[] { \"300\", \"proc(3)\", \"200\", \"100\", \"100\", \"300000\", \"300\", \"3000\", \"600\" });\r\n        procInfos[3] = new ProcessStatInfo(new String[] { \"400\", \"proc4\", \"1\", \"400\", \"400\", \"400000\", \"400\", \"4000\", \"800\" });\r\n        ProcessTreeSmapMemInfo[] memInfo = new ProcessTreeSmapMemInfo[4];\r\n        memInfo[0] = new ProcessTreeSmapMemInfo(\"100\");\r\n        memInfo[1] = new ProcessTreeSmapMemInfo(\"200\");\r\n        memInfo[2] = new ProcessTreeSmapMemInfo(\"300\");\r\n        memInfo[3] = new ProcessTreeSmapMemInfo(\"400\");\r\n        createMemoryMappingInfo(memInfo);\r\n        writeStatFiles(procfsRootDir, pids, procInfos, memInfo);\r\n        Configuration conf = new Configuration();\r\n        ProcfsBasedProcessTree processTree = createProcessTree(\"100\", procfsRootDir.getAbsolutePath(), testClock);\r\n        processTree.setConf(conf);\r\n        processTree.updateProcessTree();\r\n        Assert.assertEquals(\"Virtual memory does not match\", 600000L, processTree.getVirtualMemorySize());\r\n        long cumuRssMem = ProcfsBasedProcessTree.PAGE_SIZE > 0 ? 600L * ProcfsBasedProcessTree.PAGE_SIZE : ResourceCalculatorProcessTree.UNAVAILABLE;\r\n        Assert.assertEquals(\"rss memory does not match\", cumuRssMem, processTree.getRssMemorySize());\r\n        long cumuCpuTime = ProcfsBasedProcessTree.JIFFY_LENGTH_IN_MILLIS > 0 ? 7200L * ProcfsBasedProcessTree.JIFFY_LENGTH_IN_MILLIS : 0L;\r\n        Assert.assertEquals(\"Cumulative cpu time does not match\", cumuCpuTime, processTree.getCumulativeCpuTime());\r\n        Assert.assertEquals(\"Percent CPU time should be set to -1 initially\", -1.0, processTree.getCpuUsagePercent(), 0.01);\r\n        setSmapsInProceTree(processTree, true);\r\n        Assert.assertEquals(\"rss memory does not match\", (20 * KB_TO_BYTES * 3), processTree.getRssMemorySize());\r\n        procInfos[0] = new ProcessStatInfo(new String[] { \"100\", \"proc1\", \"1\", \"100\", \"100\", \"100000\", \"100\", \"2000\", \"300\" });\r\n        procInfos[1] = new ProcessStatInfo(new String[] { \"200\", \"process two\", \"100\", \"100\", \"100\", \"200000\", \"200\", \"3000\", \"500\" });\r\n        writeStatFiles(procfsRootDir, pids, procInfos, memInfo);\r\n        long elapsedTimeBetweenUpdatesMsec = 200000;\r\n        testClock.setTime(elapsedTimeBetweenUpdatesMsec);\r\n        processTree.updateProcessTree();\r\n        long prevCumuCpuTime = cumuCpuTime;\r\n        cumuCpuTime = ProcfsBasedProcessTree.JIFFY_LENGTH_IN_MILLIS > 0 ? 9400L * ProcfsBasedProcessTree.JIFFY_LENGTH_IN_MILLIS : 0L;\r\n        Assert.assertEquals(\"Cumulative cpu time does not match\", cumuCpuTime, processTree.getCumulativeCpuTime());\r\n        double expectedCpuUsagePercent = (ProcfsBasedProcessTree.JIFFY_LENGTH_IN_MILLIS > 0) ? (cumuCpuTime - prevCumuCpuTime) * 100.0 / elapsedTimeBetweenUpdatesMsec : 0;\r\n        Assert.assertEquals(11, expectedCpuUsagePercent, 0.001);\r\n        Assert.assertEquals(\"Percent CPU time is not correct expected \" + expectedCpuUsagePercent, expectedCpuUsagePercent, processTree.getCpuUsagePercent(), 0.01);\r\n    } finally {\r\n        FileUtil.fullyDelete(procfsRootDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setSmapsInProceTree",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setSmapsInProceTree(ProcfsBasedProcessTree processTree, boolean enableFlag)\n{\r\n    Configuration conf = processTree.getConf();\r\n    if (conf == null) {\r\n        conf = new Configuration();\r\n    }\r\n    conf.setBoolean(YarnConfiguration.PROCFS_USE_SMAPS_BASED_RSS_ENABLED, enableFlag);\r\n    processTree.setConf(conf);\r\n    processTree.updateProcessTree();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testMemForOlderProcesses",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testMemForOlderProcesses() throws IOException\n{\r\n    testMemForOlderProcesses(false);\r\n    testMemForOlderProcesses(true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testMemForOlderProcesses",
  "errType" : null,
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void testMemForOlderProcesses(boolean smapEnabled) throws IOException\n{\r\n    String[] pids = { \"100\", \"200\", \"300\", \"400\" };\r\n    File procfsRootDir = new File(TEST_ROOT_DIR, \"proc\");\r\n    try {\r\n        setupProcfsRootDir(procfsRootDir);\r\n        setupPidDirs(procfsRootDir, pids);\r\n        ProcessStatInfo[] procInfos = new ProcessStatInfo[4];\r\n        procInfos[0] = new ProcessStatInfo(new String[] { \"100\", \"proc1\", \"1\", \"100\", \"100\", \"100000\", \"100\" });\r\n        procInfos[1] = new ProcessStatInfo(new String[] { \"200\", \"process two\", \"100\", \"100\", \"100\", \"200000\", \"200\" });\r\n        procInfos[2] = new ProcessStatInfo(new String[] { \"300\", \"proc(3)\", \"1\", \"300\", \"300\", \"300000\", \"300\" });\r\n        procInfos[3] = new ProcessStatInfo(new String[] { \"400\", \"proc4\", \"100\", \"100\", \"100\", \"400000\", \"400\" });\r\n        ProcessTreeSmapMemInfo[] memInfo = new ProcessTreeSmapMemInfo[4];\r\n        memInfo[0] = new ProcessTreeSmapMemInfo(\"100\");\r\n        memInfo[1] = new ProcessTreeSmapMemInfo(\"200\");\r\n        memInfo[2] = new ProcessTreeSmapMemInfo(\"300\");\r\n        memInfo[3] = new ProcessTreeSmapMemInfo(\"400\");\r\n        createMemoryMappingInfo(memInfo);\r\n        writeStatFiles(procfsRootDir, pids, procInfos, memInfo);\r\n        ProcfsBasedProcessTree processTree = createProcessTree(\"100\", procfsRootDir.getAbsolutePath(), SystemClock.getInstance());\r\n        setSmapsInProceTree(processTree, smapEnabled);\r\n        Assert.assertEquals(\"Virtual memory does not match\", 700000L, processTree.getVirtualMemorySize());\r\n        String[] newPids = { \"500\" };\r\n        setupPidDirs(procfsRootDir, newPids);\r\n        ProcessStatInfo[] newProcInfos = new ProcessStatInfo[1];\r\n        newProcInfos[0] = new ProcessStatInfo(new String[] { \"500\", \"proc5\", \"100\", \"100\", \"100\", \"500000\", \"500\" });\r\n        ProcessTreeSmapMemInfo[] newMemInfos = new ProcessTreeSmapMemInfo[1];\r\n        newMemInfos[0] = new ProcessTreeSmapMemInfo(\"500\");\r\n        createMemoryMappingInfo(newMemInfos);\r\n        writeStatFiles(procfsRootDir, newPids, newProcInfos, newMemInfos);\r\n        processTree.updateProcessTree();\r\n        Assert.assertEquals(\"vmem does not include new process\", 1200000L, processTree.getVirtualMemorySize());\r\n        if (!smapEnabled) {\r\n            long cumuRssMem = ProcfsBasedProcessTree.PAGE_SIZE > 0 ? 1200L * ProcfsBasedProcessTree.PAGE_SIZE : ResourceCalculatorProcessTree.UNAVAILABLE;\r\n            Assert.assertEquals(\"rssmem does not include new process\", cumuRssMem, processTree.getRssMemorySize());\r\n        } else {\r\n            Assert.assertEquals(\"rssmem does not include new process\", 20 * KB_TO_BYTES * 4, processTree.getRssMemorySize());\r\n        }\r\n        Assert.assertEquals(\"vmem shouldn't have included new process\", 700000L, processTree.getVirtualMemorySize(1));\r\n        if (!smapEnabled) {\r\n            long cumuRssMem = ProcfsBasedProcessTree.PAGE_SIZE > 0 ? 700L * ProcfsBasedProcessTree.PAGE_SIZE : ResourceCalculatorProcessTree.UNAVAILABLE;\r\n            Assert.assertEquals(\"rssmem shouldn't have included new process\", cumuRssMem, processTree.getRssMemorySize(1));\r\n        } else {\r\n            Assert.assertEquals(\"rssmem shouldn't have included new process\", 20 * KB_TO_BYTES * 3, processTree.getRssMemorySize(1));\r\n        }\r\n        newPids = new String[] { \"600\" };\r\n        setupPidDirs(procfsRootDir, newPids);\r\n        newProcInfos = new ProcessStatInfo[1];\r\n        newProcInfos[0] = new ProcessStatInfo(new String[] { \"600\", \"proc6\", \"100\", \"100\", \"100\", \"600000\", \"600\" });\r\n        newMemInfos = new ProcessTreeSmapMemInfo[1];\r\n        newMemInfos[0] = new ProcessTreeSmapMemInfo(\"600\");\r\n        createMemoryMappingInfo(newMemInfos);\r\n        writeStatFiles(procfsRootDir, newPids, newProcInfos, newMemInfos);\r\n        processTree.updateProcessTree();\r\n        Assert.assertEquals(\"vmem shouldn't have included new processes\", 700000L, processTree.getVirtualMemorySize(2));\r\n        if (!smapEnabled) {\r\n            long cumuRssMem = ProcfsBasedProcessTree.PAGE_SIZE > 0 ? 700L * ProcfsBasedProcessTree.PAGE_SIZE : ResourceCalculatorProcessTree.UNAVAILABLE;\r\n            Assert.assertEquals(\"rssmem shouldn't have included new processes\", cumuRssMem, processTree.getRssMemorySize(2));\r\n        } else {\r\n            Assert.assertEquals(\"rssmem shouldn't have included new processes\", 20 * KB_TO_BYTES * 3, processTree.getRssMemorySize(2));\r\n        }\r\n        Assert.assertEquals(\"vmem shouldn't have included new processes\", 1200000L, processTree.getVirtualMemorySize(1));\r\n        if (!smapEnabled) {\r\n            long cumuRssMem = ProcfsBasedProcessTree.PAGE_SIZE > 0 ? 1200L * ProcfsBasedProcessTree.PAGE_SIZE : ResourceCalculatorProcessTree.UNAVAILABLE;\r\n            Assert.assertEquals(\"rssmem shouldn't have included new processes\", cumuRssMem, processTree.getRssMemorySize(1));\r\n        } else {\r\n            Assert.assertEquals(\"rssmem shouldn't have included new processes\", 20 * KB_TO_BYTES * 4, processTree.getRssMemorySize(1));\r\n        }\r\n        Assert.assertEquals(\"Getting non-zero vmem for processes older than 3 iterations\", 0, processTree.getVirtualMemorySize(3));\r\n        Assert.assertEquals(\"Getting non-zero rssmem for processes older than 3 iterations\", 0, processTree.getRssMemorySize(3));\r\n    } finally {\r\n        FileUtil.fullyDelete(procfsRootDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testDestroyProcessTree",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testDestroyProcessTree() throws IOException\n{\r\n    String pid = \"100\";\r\n    File procfsRootDir = new File(TEST_ROOT_DIR, \"proc\");\r\n    try {\r\n        setupProcfsRootDir(procfsRootDir);\r\n        createProcessTree(pid, procfsRootDir.getAbsolutePath(), SystemClock.getInstance());\r\n        Assert.assertTrue(ProcfsBasedProcessTree.checkPidPgrpidForMatch(pid, procfsRootDir.getAbsolutePath()));\r\n    } finally {\r\n        FileUtil.fullyDelete(procfsRootDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testProcessTreeDump",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testProcessTreeDump() throws IOException\n{\r\n    String[] pids = { \"100\", \"200\", \"300\", \"400\", \"500\", \"600\" };\r\n    File procfsRootDir = new File(TEST_ROOT_DIR, \"proc\");\r\n    try {\r\n        setupProcfsRootDir(procfsRootDir);\r\n        setupPidDirs(procfsRootDir, pids);\r\n        int numProcesses = pids.length;\r\n        ProcessStatInfo[] procInfos = new ProcessStatInfo[numProcesses];\r\n        procInfos[0] = new ProcessStatInfo(new String[] { \"100\", \"proc1\", \"1\", \"100\", \"100\", \"100000\", \"100\", \"1000\", \"200\" });\r\n        procInfos[1] = new ProcessStatInfo(new String[] { \"200\", \"process two\", \"100\", \"100\", \"100\", \"200000\", \"200\", \"2000\", \"400\" });\r\n        procInfos[2] = new ProcessStatInfo(new String[] { \"300\", \"proc(3)\", \"200\", \"100\", \"100\", \"300000\", \"300\", \"3000\", \"600\" });\r\n        procInfos[3] = new ProcessStatInfo(new String[] { \"400\", \"proc4\", \"200\", \"100\", \"100\", \"400000\", \"400\", \"4000\", \"800\" });\r\n        procInfos[4] = new ProcessStatInfo(new String[] { \"500\", \"proc5\", \"400\", \"100\", \"100\", \"400000\", \"400\", \"4000\", \"800\" });\r\n        procInfos[5] = new ProcessStatInfo(new String[] { \"600\", \"proc6\", \"1\", \"1\", \"1\", \"400000\", \"400\", \"4000\", \"800\" });\r\n        ProcessTreeSmapMemInfo[] memInfos = new ProcessTreeSmapMemInfo[6];\r\n        memInfos[0] = new ProcessTreeSmapMemInfo(\"100\");\r\n        memInfos[1] = new ProcessTreeSmapMemInfo(\"200\");\r\n        memInfos[2] = new ProcessTreeSmapMemInfo(\"300\");\r\n        memInfos[3] = new ProcessTreeSmapMemInfo(\"400\");\r\n        memInfos[4] = new ProcessTreeSmapMemInfo(\"500\");\r\n        memInfos[5] = new ProcessTreeSmapMemInfo(\"600\");\r\n        String[] cmdLines = new String[numProcesses];\r\n        cmdLines[0] = \"proc1 arg1 arg2\";\r\n        cmdLines[1] = \"process two arg3 arg4\";\r\n        cmdLines[2] = \"proc(3) arg5 arg6\";\r\n        cmdLines[3] = \"proc4 arg7 arg8\";\r\n        cmdLines[4] = \"proc5 arg9 arg10\";\r\n        cmdLines[5] = \"proc6 arg11 arg12\";\r\n        createMemoryMappingInfo(memInfos);\r\n        writeStatFiles(procfsRootDir, pids, procInfos, memInfos);\r\n        writeCmdLineFiles(procfsRootDir, pids, cmdLines);\r\n        ProcfsBasedProcessTree processTree = createProcessTree(\"100\", procfsRootDir.getAbsolutePath(), SystemClock.getInstance());\r\n        processTree.updateProcessTree();\r\n        String processTreeDump = processTree.getProcessTreeDump();\r\n        LOG.info(\"Process-tree dump follows: \\n\" + processTreeDump);\r\n        Assert.assertTrue(\"Process-tree dump doesn't start with a proper header\", processTreeDump.startsWith(\"\\t|- PID PPID PGRPID SESSID CMD_NAME \" + \"USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) \" + \"RSSMEM_USAGE(PAGES) FULL_CMD_LINE\\n\"));\r\n        for (int i = 0; i < 5; i++) {\r\n            ProcessStatInfo p = procInfos[i];\r\n            Assert.assertTrue(\"Process-tree dump doesn't contain the cmdLineDump of process \" + p.pid, processTreeDump.contains(\"\\t|- \" + p.pid + \" \" + p.ppid + \" \" + p.pgrpId + \" \" + p.session + \" (\" + p.name + \") \" + p.utime + \" \" + p.stime + \" \" + p.vmem + \" \" + p.rssmemPage + \" \" + cmdLines[i]));\r\n        }\r\n        ProcessStatInfo p = procInfos[5];\r\n        Assert.assertFalse(\"Process-tree dump shouldn't contain the cmdLineDump of process \" + p.pid, processTreeDump.contains(\"\\t|- \" + p.pid + \" \" + p.ppid + \" \" + p.pgrpId + \" \" + p.session + \" (\" + p.name + \") \" + p.utime + \" \" + p.stime + \" \" + p.vmem + \" \" + cmdLines[5]));\r\n    } finally {\r\n        FileUtil.fullyDelete(procfsRootDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "isSetsidAvailable",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean isSetsidAvailable()\n{\r\n    ShellCommandExecutor shexec = null;\r\n    boolean setsidSupported = true;\r\n    try {\r\n        String[] args = { \"setsid\", \"bash\", \"-c\", \"echo $$\" };\r\n        shexec = new ShellCommandExecutor(args);\r\n        shexec.execute();\r\n    } catch (IOException ioe) {\r\n        LOG.warn(\"setsid is not available on this machine. So not using it.\");\r\n        setsidSupported = false;\r\n    } finally {\r\n        LOG.info(\"setsid exited with exit code \" + shexec.getExitCode());\r\n    }\r\n    return setsidSupported;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "isAlive",
  "errType" : [ "IOException", "ExitCodeException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean isAlive(String pid)\n{\r\n    try {\r\n        final String sigpid = isSetsidAvailable() ? \"-\" + pid : pid;\r\n        try {\r\n            sendSignal(sigpid, 0);\r\n        } catch (ExitCodeException e) {\r\n            return false;\r\n        }\r\n        return true;\r\n    } catch (IOException ignored) {\r\n    }\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "sendSignal",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void sendSignal(String pid, int signal) throws IOException\n{\r\n    ShellCommandExecutor shexec = null;\r\n    String[] arg = { \"kill\", \"-\" + signal, \"--\", pid };\r\n    shexec = new ShellCommandExecutor(arg);\r\n    shexec.execute();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "isAnyProcessInTreeAlive",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean isAnyProcessInTreeAlive(ProcfsBasedProcessTree processTree)\n{\r\n    for (String pId : processTree.getCurrentProcessIDs()) {\r\n        if (isAlive(pId)) {\r\n            return true;\r\n        }\r\n    }\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setupProcfsRootDir",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setupProcfsRootDir(File procfsRootDir) throws IOException\n{\r\n    if (procfsRootDir.exists()) {\r\n        Assert.assertTrue(FileUtil.fullyDelete(procfsRootDir));\r\n    }\r\n    Assert.assertTrue(procfsRootDir.mkdirs());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setupPidDirs",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setupPidDirs(File procfsRootDir, String[] pids) throws IOException\n{\r\n    for (String pid : pids) {\r\n        File pidDir = new File(procfsRootDir, pid);\r\n        FileUtils.forceMkdir(pidDir);\r\n        LOG.info(\"created pid dir: \" + pidDir);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "writeStatFiles",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void writeStatFiles(File procfsRootDir, String[] pids, ProcessStatInfo[] procs, ProcessTreeSmapMemInfo[] smaps) throws IOException\n{\r\n    for (int i = 0; i < pids.length; i++) {\r\n        File statFile = new File(new File(procfsRootDir, pids[i]), ProcfsBasedProcessTree.PROCFS_STAT_FILE);\r\n        BufferedWriter bw = null;\r\n        try {\r\n            FileWriter fw = new FileWriter(statFile);\r\n            bw = new BufferedWriter(fw);\r\n            bw.write(procs[i].getStatLine());\r\n            LOG.info(\"wrote stat file for \" + pids[i] + \" with contents: \" + procs[i].getStatLine());\r\n        } finally {\r\n            if (bw != null) {\r\n                bw.close();\r\n            }\r\n        }\r\n        if (smaps != null) {\r\n            File smapFile = new File(new File(procfsRootDir, pids[i]), ProcfsBasedProcessTree.SMAPS);\r\n            bw = null;\r\n            try {\r\n                FileWriter fw = new FileWriter(smapFile);\r\n                bw = new BufferedWriter(fw);\r\n                bw.write(smaps[i].toString());\r\n                bw.flush();\r\n                LOG.info(\"wrote smap file for \" + pids[i] + \" with contents: \" + smaps[i].toString());\r\n            } finally {\r\n                if (bw != null) {\r\n                    bw.close();\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "writeCmdLineFiles",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeCmdLineFiles(File procfsRootDir, String[] pids, String[] cmdLines) throws IOException\n{\r\n    for (int i = 0; i < pids.length; i++) {\r\n        File statFile = new File(new File(procfsRootDir, pids[i]), ProcfsBasedProcessTree.PROCFS_CMDLINE_FILE);\r\n        BufferedWriter bw = null;\r\n        try {\r\n            bw = new BufferedWriter(new FileWriter(statFile));\r\n            bw.write(cmdLines[i]);\r\n            LOG.info(\"wrote command-line file for \" + pids[i] + \" with contents: \" + cmdLines[i]);\r\n        } finally {\r\n            if (bw != null) {\r\n                bw.close();\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testMapCastToHashMap",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void testMapCastToHashMap()\n{\r\n    Map<String, String> nullMap = null;\r\n    Assert.assertNull(TimelineServiceHelper.mapCastToHashMap(nullMap));\r\n    Map<String, String> emptyHashMap = new HashMap<String, String>();\r\n    Assert.assertEquals(TimelineServiceHelper.mapCastToHashMap(emptyHashMap).size(), 0);\r\n    Map<String, String> emptyTreeMap = new TreeMap<String, String>();\r\n    Assert.assertEquals(TimelineServiceHelper.mapCastToHashMap(emptyTreeMap).size(), 0);\r\n    Map<String, String> firstHashMap = new HashMap<String, String>();\r\n    String key = \"KEY\";\r\n    String value = \"VALUE\";\r\n    firstHashMap.put(key, value);\r\n    Assert.assertEquals(TimelineServiceHelper.mapCastToHashMap(firstHashMap), firstHashMap);\r\n    Map<String, String> firstTreeMap = new TreeMap<String, String>();\r\n    firstTreeMap.put(key, value);\r\n    HashMap<String, String> alternateHashMap = TimelineServiceHelper.mapCastToHashMap(firstTreeMap);\r\n    Assert.assertEquals(firstTreeMap.size(), alternateHashMap.size());\r\n    assertThat(alternateHashMap.get(key)).isEqualTo(value);\r\n    Map<String, Set<String>> complicatedHashMap = new HashMap<String, Set<String>>();\r\n    Set<String> hashSet = new HashSet<String>();\r\n    hashSet.add(value);\r\n    complicatedHashMap.put(key, hashSet);\r\n    Assert.assertEquals(TimelineServiceHelper.mapCastToHashMap(complicatedHashMap), complicatedHashMap);\r\n    Map<String, Set<String>> complicatedTreeMap = new TreeMap<String, Set<String>>();\r\n    complicatedTreeMap.put(key, hashSet);\r\n    Assert.assertEquals(TimelineServiceHelper.mapCastToHashMap(complicatedTreeMap).get(key), hashSet);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setUp()\n{\r\n    RackResolver.reset();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testCaching",
  "errType" : [ "UnknownHostException" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testCaching()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setClass(CommonConfigurationKeysPublic.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY, MyResolver.class, DNSToSwitchMapping.class);\r\n    RackResolver.init(conf);\r\n    try {\r\n        InetAddress iaddr = InetAddress.getByName(\"host1\");\r\n        MyResolver.resolvedHost1 = iaddr.getHostAddress();\r\n    } catch (UnknownHostException e) {\r\n    }\r\n    Node node = RackResolver.resolve(\"host1\");\r\n    Assert.assertEquals(\"/rack1\", node.getNetworkLocation());\r\n    node = RackResolver.resolve(\"host1\");\r\n    Assert.assertEquals(\"/rack1\", node.getNetworkLocation());\r\n    node = RackResolver.resolve(invalidHost);\r\n    Assert.assertEquals(NetworkTopology.DEFAULT_RACK, node.getNetworkLocation());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\util",
  "methodName" : "testMultipleHosts",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testMultipleHosts()\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setClass(CommonConfigurationKeysPublic.NET_TOPOLOGY_NODE_SWITCH_MAPPING_IMPL_KEY, MultipleResolver.class, DNSToSwitchMapping.class);\r\n    RackResolver.init(conf);\r\n    List<Node> nodes = RackResolver.resolve(Arrays.asList(\"host1\", invalidHost, \"host2\"));\r\n    Assert.assertEquals(\"/rack1\", nodes.get(0).getNetworkLocation());\r\n    Assert.assertEquals(NetworkTopology.DEFAULT_RACK, nodes.get(1).getNetworkLocation());\r\n    Assert.assertEquals(\"/rack2\", nodes.get(2).getNetworkLocation());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "testApplicationAttemptId",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "void testApplicationAttemptId()\n{\r\n    ApplicationAttemptId a1 = createAppAttemptId(10l, 1, 1);\r\n    ApplicationAttemptId a2 = createAppAttemptId(10l, 1, 2);\r\n    ApplicationAttemptId a3 = createAppAttemptId(10l, 2, 1);\r\n    ApplicationAttemptId a4 = createAppAttemptId(8l, 1, 4);\r\n    ApplicationAttemptId a5 = createAppAttemptId(10l, 1, 1);\r\n    Assert.assertTrue(a1.equals(a5));\r\n    Assert.assertFalse(a1.equals(a2));\r\n    Assert.assertFalse(a1.equals(a3));\r\n    Assert.assertFalse(a1.equals(a4));\r\n    Assert.assertTrue(a1.compareTo(a5) == 0);\r\n    Assert.assertTrue(a1.compareTo(a2) < 0);\r\n    Assert.assertTrue(a1.compareTo(a3) < 0);\r\n    Assert.assertTrue(a1.compareTo(a4) > 0);\r\n    Assert.assertTrue(a1.hashCode() == a5.hashCode());\r\n    Assert.assertFalse(a1.hashCode() == a2.hashCode());\r\n    Assert.assertFalse(a1.hashCode() == a3.hashCode());\r\n    Assert.assertFalse(a1.hashCode() == a4.hashCode());\r\n    long ts = System.currentTimeMillis();\r\n    ApplicationAttemptId a6 = createAppAttemptId(ts, 543627, 33492611);\r\n    Assert.assertEquals(\"appattempt_10_0001_000001\", a1.toString());\r\n    Assert.assertEquals(\"appattempt_\" + ts + \"_543627_33492611\", a6.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "createAppAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ApplicationAttemptId createAppAttemptId(long clusterTimeStamp, int id, int attemptId)\n{\r\n    ApplicationId appId = ApplicationId.newInstance(clusterTimeStamp, id);\r\n    return ApplicationAttemptId.newInstance(appId, attemptId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-common\\src\\test\\java\\org\\apache\\hadoop\\yarn\\api",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void main(String[] args) throws Exception\n{\r\n    TestApplicationAttemptId t = new TestApplicationAttemptId();\r\n    t.testApplicationAttemptId();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]