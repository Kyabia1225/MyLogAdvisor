[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BaseTableRW<?> getTable()\n{\r\n    return FLOW_RUN_TABLE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void validateParams()\n{\r\n    if (getContext() == null) {\r\n        throw new NullPointerException(\"context shouldn't be null\");\r\n    }\r\n    if (getDataToRetrieve() == null) {\r\n        throw new NullPointerException(\"data to retrieve shouldn't be null\");\r\n    }\r\n    if (getContext().getClusterId() == null) {\r\n        throw new NullPointerException(\"clusterId shouldn't be null\");\r\n    }\r\n    if (getContext().getUserId() == null) {\r\n        throw new NullPointerException(\"userId shouldn't be null\");\r\n    }\r\n    if (getContext().getFlowName() == null) {\r\n        throw new NullPointerException(\"flowName shouldn't be null\");\r\n    }\r\n    if (isSingleEntityRead()) {\r\n        if (getContext().getFlowRunId() == null) {\r\n            throw new NullPointerException(\"flowRunId shouldn't be null\");\r\n        }\r\n    }\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (!isSingleEntityRead() && fieldsToRetrieve != null) {\r\n        for (Field field : fieldsToRetrieve) {\r\n            if (field != Field.ALL && field != Field.METRICS) {\r\n                throw new BadRequestException(\"Invalid field \" + field + \" specified while querying flow runs.\");\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "augmentParams",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void augmentParams(Configuration hbaseConf, Connection conn)\n{\r\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\r\n    if (!isSingleEntityRead()) {\r\n        createFiltersIfNull();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFilters() throws IOException\n{\r\n    FilterList listBasedOnFilters = new FilterList();\r\n    Long createdTimeBegin = getFilters().getCreatedTimeBegin();\r\n    Long createdTimeEnd = getFilters().getCreatedTimeEnd();\r\n    if (createdTimeBegin != 0 || createdTimeEnd != Long.MAX_VALUE) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createSingleColValueFiltersByRange(FlowRunColumn.MIN_START_TIME, createdTimeBegin, createdTimeEnd));\r\n    }\r\n    TimelineFilterList metricFilters = getFilters().getMetricFilters();\r\n    if (metricFilters != null && !metricFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(FlowRunColumnPrefix.METRIC, metricFilters));\r\n    }\r\n    return listBasedOnFilters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFixedColumns",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "FilterList updateFixedColumns()\n{\r\n    FilterList columnsList = new FilterList(Operator.MUST_PASS_ONE);\r\n    for (FlowRunColumn column : FlowRunColumn.values()) {\r\n        columnsList.addFilter(new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(column.getColumnQualifierBytes())));\r\n    }\r\n    return columnsList;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFields(Set<String> cfsInFields) throws IOException\n{\r\n    FilterList list = new FilterList(Operator.MUST_PASS_ONE);\r\n    FamilyFilter infoColumnFamily = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(FlowRunColumnFamily.INFO.getBytes()));\r\n    TimelineDataToRetrieve dataToRetrieve = getDataToRetrieve();\r\n    if (!isSingleEntityRead() && !hasField(dataToRetrieve.getFieldsToRetrieve(), Field.METRICS)) {\r\n        FilterList infoColFamilyList = new FilterList(Operator.MUST_PASS_ONE);\r\n        infoColFamilyList.addFilter(infoColumnFamily);\r\n        cfsInFields.add(Bytes.toString(FlowRunColumnFamily.INFO.getBytes()));\r\n        infoColFamilyList.addFilter(new QualifierFilter(CompareOp.NOT_EQUAL, new BinaryPrefixComparator(FlowRunColumnPrefix.METRIC.getColumnPrefixBytes(\"\"))));\r\n        list.addFilter(infoColFamilyList);\r\n    } else {\r\n        TimelineFilterList metricsToRetrieve = dataToRetrieve.getMetricsToRetrieve();\r\n        if (metricsToRetrieve != null && !metricsToRetrieve.getFilterList().isEmpty()) {\r\n            FilterList infoColFamilyList = new FilterList();\r\n            infoColFamilyList.addFilter(infoColumnFamily);\r\n            cfsInFields.add(Bytes.toString(FlowRunColumnFamily.INFO.getBytes()));\r\n            FilterList columnsList = updateFixedColumns();\r\n            columnsList.addFilter(TimelineFilterUtils.createHBaseFilterList(FlowRunColumnPrefix.METRIC, metricsToRetrieve));\r\n            infoColFamilyList.addFilter(columnsList);\r\n            list.addFilter(infoColFamilyList);\r\n        }\r\n    }\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    TimelineReaderContext context = getContext();\r\n    FlowRunRowKey flowRunRowKey = new FlowRunRowKey(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId());\r\n    byte[] rowKey = flowRunRowKey.getRowKey();\r\n    Get get = new Get(rowKey);\r\n    get.setMaxVersions(Integer.MAX_VALUE);\r\n    if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n        get.setFilter(filterList);\r\n    }\r\n    return getTable().getResult(hbaseConf, conn, get);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResults",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 20,
  "sourceCodeText" : "ResultScanner getResults(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    Scan scan = new Scan();\r\n    TimelineReaderContext context = getContext();\r\n    RowKeyPrefix<FlowRunRowKey> flowRunRowKeyPrefix = null;\r\n    if (getFilters().getFromId() == null) {\r\n        flowRunRowKeyPrefix = new FlowRunRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName());\r\n        scan.setRowPrefixFilter(flowRunRowKeyPrefix.getRowKeyPrefix());\r\n    } else {\r\n        FlowRunRowKey flowRunRowKey = null;\r\n        try {\r\n            flowRunRowKey = FlowRunRowKey.parseRowKeyFromString(getFilters().getFromId());\r\n        } catch (IllegalArgumentException e) {\r\n            throw new BadRequestException(\"Invalid filter fromid is provided.\");\r\n        }\r\n        if (!context.getClusterId().equals(flowRunRowKey.getClusterId())) {\r\n            throw new BadRequestException(\"fromid doesn't belong to clusterId=\" + context.getClusterId());\r\n        }\r\n        scan.withStartRow(flowRunRowKey.getRowKey());\r\n        flowRunRowKeyPrefix = new FlowRunRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName());\r\n        scan.withStopRow(HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(flowRunRowKeyPrefix.getRowKeyPrefix()));\r\n    }\r\n    FilterList newList = new FilterList();\r\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\r\n    if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n        newList.addFilter(filterList);\r\n    }\r\n    scan.setFilter(newList);\r\n    scan.setMaxVersions(Integer.MAX_VALUE);\r\n    return getTable().getResultScanner(hbaseConf, conn, scan);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntity",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "TimelineEntity parseEntity(Result result) throws IOException\n{\r\n    FlowRunEntity flowRun = new FlowRunEntity();\r\n    FlowRunRowKey rowKey = FlowRunRowKey.parseRowKey(result.getRow());\r\n    flowRun.setRunId(rowKey.getFlowRunId());\r\n    flowRun.setUser(rowKey.getUserId());\r\n    flowRun.setName(rowKey.getFlowName());\r\n    Long startTime = (Long) ColumnRWHelper.readResult(result, FlowRunColumn.MIN_START_TIME);\r\n    if (startTime != null) {\r\n        flowRun.setStartTime(startTime.longValue());\r\n    }\r\n    Long endTime = (Long) ColumnRWHelper.readResult(result, FlowRunColumn.MAX_END_TIME);\r\n    if (endTime != null) {\r\n        flowRun.setMaxEndTime(endTime.longValue());\r\n    }\r\n    String version = (String) ColumnRWHelper.readResult(result, FlowRunColumn.FLOW_VERSION);\r\n    if (version != null) {\r\n        flowRun.setVersion(version);\r\n    }\r\n    if (isSingleEntityRead() || hasField(getDataToRetrieve().getFieldsToRetrieve(), Field.METRICS)) {\r\n        readMetrics(flowRun, result, FlowRunColumnPrefix.METRIC);\r\n    }\r\n    flowRun.setId(flowRun.getId());\r\n    flowRun.getInfo().put(TimelineReaderUtils.FROMID_KEY, rowKey.getRowKeyAsString());\r\n    return flowRun;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "serviceInit",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void serviceInit(Configuration conf) throws Exception\n{\r\n    super.serviceInit(conf);\r\n    Configuration hbaseConf = HBaseTimelineStorageUtils.getTimelineServiceHBaseConf(conf);\r\n    conn = ConnectionFactory.createConnection(hbaseConf);\r\n    entityTable = new EntityTableRW().getTableMutator(hbaseConf, conn);\r\n    appToFlowTable = new AppToFlowTableRW().getTableMutator(hbaseConf, conn);\r\n    applicationTable = new ApplicationTableRW().getTableMutator(hbaseConf, conn);\r\n    flowRunTable = new FlowRunTableRW().getTableMutator(hbaseConf, conn);\r\n    flowActivityTable = new FlowActivityTableRW().getTableMutator(hbaseConf, conn);\r\n    subApplicationTable = new SubApplicationTableRW().getTableMutator(hbaseConf, conn);\r\n    domainTable = new DomainTableRW().getTableMutator(hbaseConf, conn);\r\n    UserGroupInformation ugi = UserGroupInformation.isSecurityEnabled() ? UserGroupInformation.getLoginUser() : UserGroupInformation.getCurrentUser();\r\n    storageMonitor = new HBaseStorageMonitor(conf);\r\n    LOG.info(\"Initialized HBaseTimelineWriterImpl UGI to \" + ugi);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "serviceStart",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void serviceStart() throws Exception\n{\r\n    super.serviceStart();\r\n    storageMonitor.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 29,
  "sourceCodeText" : "TimelineWriteResponse write(TimelineCollectorContext context, TimelineEntities data, UserGroupInformation callerUgi) throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    TimelineWriteResponse putStatus = new TimelineWriteResponse();\r\n    String clusterId = context.getClusterId();\r\n    String userId = context.getUserId();\r\n    String flowName = context.getFlowName();\r\n    String flowVersion = context.getFlowVersion();\r\n    long flowRunId = context.getFlowRunId();\r\n    String appId = context.getAppId();\r\n    String subApplicationUser = callerUgi.getShortUserName();\r\n    if ((flowName == null) || (appId == null) || (clusterId == null) || (userId == null)) {\r\n        LOG.warn(\"Found null for one of: flowName=\" + flowName + \" appId=\" + appId + \" userId=\" + userId + \" clusterId=\" + clusterId + \" . Not proceeding with writing to hbase\");\r\n        return putStatus;\r\n    }\r\n    for (TimelineEntity te : data.getEntities()) {\r\n        if (te == null) {\r\n            continue;\r\n        }\r\n        boolean isApplication = ApplicationEntity.isApplicationEntity(te);\r\n        byte[] rowKey;\r\n        if (isApplication) {\r\n            ApplicationRowKey applicationRowKey = new ApplicationRowKey(clusterId, userId, flowName, flowRunId, appId);\r\n            rowKey = applicationRowKey.getRowKey();\r\n            store(rowKey, te, flowVersion, Tables.APPLICATION_TABLE);\r\n        } else {\r\n            EntityRowKey entityRowKey = new EntityRowKey(clusterId, userId, flowName, flowRunId, appId, te.getType(), te.getIdPrefix(), te.getId());\r\n            rowKey = entityRowKey.getRowKey();\r\n            store(rowKey, te, flowVersion, Tables.ENTITY_TABLE);\r\n        }\r\n        if (!isApplication && SubApplicationEntity.isSubApplicationEntity(te)) {\r\n            SubApplicationRowKey subApplicationRowKey = new SubApplicationRowKey(subApplicationUser, clusterId, te.getType(), te.getIdPrefix(), te.getId(), userId);\r\n            rowKey = subApplicationRowKey.getRowKey();\r\n            store(rowKey, te, flowVersion, Tables.SUBAPPLICATION_TABLE);\r\n        }\r\n        if (isApplication) {\r\n            TimelineEvent event = ApplicationEntity.getApplicationEvent(te, ApplicationMetricsConstants.CREATED_EVENT_TYPE);\r\n            FlowRunRowKey flowRunRowKey = new FlowRunRowKey(clusterId, userId, flowName, flowRunId);\r\n            if (event != null) {\r\n                onApplicationCreated(flowRunRowKey, clusterId, appId, userId, flowVersion, te, event.getTimestamp());\r\n            }\r\n            storeFlowMetricsAppRunning(flowRunRowKey, appId, te);\r\n            event = ApplicationEntity.getApplicationEvent(te, ApplicationMetricsConstants.FINISHED_EVENT_TYPE);\r\n            if (event != null) {\r\n                onApplicationFinished(flowRunRowKey, flowVersion, appId, te, event.getTimestamp());\r\n            }\r\n        }\r\n    }\r\n    return putStatus;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "TimelineWriteResponse write(TimelineCollectorContext context, TimelineDomain domain) throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    TimelineWriteResponse putStatus = new TimelineWriteResponse();\r\n    String clusterId = context.getClusterId();\r\n    String domainId = domain.getId();\r\n    if (clusterId == null) {\r\n        LOG.warn(\"Found null for clusterId. Not proceeding with writing to hbase\");\r\n        return putStatus;\r\n    }\r\n    DomainRowKey domainRowKey = new DomainRowKey(clusterId, domainId);\r\n    byte[] rowKey = domainRowKey.getRowKey();\r\n    ColumnRWHelper.store(rowKey, domainTable, DomainColumn.CREATED_TIME, null, domain.getCreatedTime());\r\n    ColumnRWHelper.store(rowKey, domainTable, DomainColumn.DESCRIPTION, null, domain.getDescription());\r\n    ColumnRWHelper.store(rowKey, domainTable, DomainColumn.MODIFICATION_TIME, null, domain.getModifiedTime());\r\n    ColumnRWHelper.store(rowKey, domainTable, DomainColumn.OWNER, null, domain.getOwner());\r\n    ColumnRWHelper.store(rowKey, domainTable, DomainColumn.READERS, null, domain.getReaders());\r\n    ColumnRWHelper.store(rowKey, domainTable, DomainColumn.WRITERS, null, domain.getWriters());\r\n    return putStatus;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "onApplicationCreated",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void onApplicationCreated(FlowRunRowKey flowRunRowKey, String clusterId, String appId, String userId, String flowVersion, TimelineEntity te, long appCreatedTimeStamp) throws IOException\n{\r\n    String flowName = flowRunRowKey.getFlowName();\r\n    Long flowRunId = flowRunRowKey.getFlowRunId();\r\n    AppToFlowRowKey appToFlowRowKey = new AppToFlowRowKey(appId);\r\n    byte[] rowKey = appToFlowRowKey.getRowKey();\r\n    ColumnRWHelper.store(rowKey, appToFlowTable, AppToFlowColumnPrefix.FLOW_NAME, clusterId, null, flowName);\r\n    ColumnRWHelper.store(rowKey, appToFlowTable, AppToFlowColumnPrefix.FLOW_RUN_ID, clusterId, null, flowRunId);\r\n    ColumnRWHelper.store(rowKey, appToFlowTable, AppToFlowColumnPrefix.USER_ID, clusterId, null, userId);\r\n    storeAppCreatedInFlowRunTable(flowRunRowKey, appId, te);\r\n    byte[] flowActivityRowKeyBytes = new FlowActivityRowKey(flowRunRowKey.getClusterId(), appCreatedTimeStamp, flowRunRowKey.getUserId(), flowName).getRowKey();\r\n    byte[] qualifier = longKeyConverter.encode(flowRunRowKey.getFlowRunId());\r\n    ColumnRWHelper.store(flowActivityRowKeyBytes, flowActivityTable, FlowActivityColumnPrefix.RUN_ID, qualifier, null, flowVersion, AggregationCompactionDimension.APPLICATION_ID.getAttribute(appId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeAppCreatedInFlowRunTable",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void storeAppCreatedInFlowRunTable(FlowRunRowKey flowRunRowKey, String appId, TimelineEntity te) throws IOException\n{\r\n    byte[] rowKey = flowRunRowKey.getRowKey();\r\n    ColumnRWHelper.store(rowKey, flowRunTable, FlowRunColumn.MIN_START_TIME, null, te.getCreatedTime(), AggregationCompactionDimension.APPLICATION_ID.getAttribute(appId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "onApplicationFinished",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void onApplicationFinished(FlowRunRowKey flowRunRowKey, String flowVersion, String appId, TimelineEntity te, long appFinishedTimeStamp) throws IOException\n{\r\n    storeAppFinishedInFlowRunTable(flowRunRowKey, appId, te, appFinishedTimeStamp);\r\n    byte[] rowKey = new FlowActivityRowKey(flowRunRowKey.getClusterId(), appFinishedTimeStamp, flowRunRowKey.getUserId(), flowRunRowKey.getFlowName()).getRowKey();\r\n    byte[] qualifier = longKeyConverter.encode(flowRunRowKey.getFlowRunId());\r\n    ColumnRWHelper.store(rowKey, flowActivityTable, FlowActivityColumnPrefix.RUN_ID, qualifier, null, flowVersion, AggregationCompactionDimension.APPLICATION_ID.getAttribute(appId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeAppFinishedInFlowRunTable",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void storeAppFinishedInFlowRunTable(FlowRunRowKey flowRunRowKey, String appId, TimelineEntity te, long appFinishedTimeStamp) throws IOException\n{\r\n    byte[] rowKey = flowRunRowKey.getRowKey();\r\n    Attribute attributeAppId = AggregationCompactionDimension.APPLICATION_ID.getAttribute(appId);\r\n    ColumnRWHelper.store(rowKey, flowRunTable, FlowRunColumn.MAX_END_TIME, null, appFinishedTimeStamp, attributeAppId);\r\n    Set<TimelineMetric> metrics = te.getMetrics();\r\n    if (metrics != null) {\r\n        storeFlowMetrics(rowKey, metrics, attributeAppId, AggregationOperation.SUM_FINAL.getAttribute());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeFlowMetricsAppRunning",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void storeFlowMetricsAppRunning(FlowRunRowKey flowRunRowKey, String appId, TimelineEntity te) throws IOException\n{\r\n    Set<TimelineMetric> metrics = te.getMetrics();\r\n    if (metrics != null) {\r\n        byte[] rowKey = flowRunRowKey.getRowKey();\r\n        storeFlowMetrics(rowKey, metrics, AggregationCompactionDimension.APPLICATION_ID.getAttribute(appId), AggregationOperation.SUM.getAttribute());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeFlowMetrics",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void storeFlowMetrics(byte[] rowKey, Set<TimelineMetric> metrics, Attribute... attributes) throws IOException\n{\r\n    for (TimelineMetric metric : metrics) {\r\n        byte[] metricColumnQualifier = stringKeyConverter.encode(metric.getId());\r\n        Map<Long, Number> timeseries = metric.getValues();\r\n        for (Map.Entry<Long, Number> timeseriesEntry : timeseries.entrySet()) {\r\n            Long timestamp = timeseriesEntry.getKey();\r\n            ColumnRWHelper.store(rowKey, flowRunTable, FlowRunColumnPrefix.METRIC, metricColumnQualifier, timestamp, timeseriesEntry.getValue(), attributes);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeRelations",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void storeRelations(byte[] rowKey, Map<String, Set<String>> connectedEntities, ColumnPrefix<T> columnPrefix, TypedBufferedMutator<T> table) throws IOException\n{\r\n    if (connectedEntities != null) {\r\n        for (Map.Entry<String, Set<String>> connectedEntity : connectedEntities.entrySet()) {\r\n            String compoundValue = Separator.VALUES.joinEncoded(connectedEntity.getValue());\r\n            ColumnRWHelper.store(rowKey, table, columnPrefix, stringKeyConverter.encode(connectedEntity.getKey()), null, compoundValue);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "store",
  "errType" : null,
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void store(byte[] rowKey, TimelineEntity te, String flowVersion, Tables table) throws IOException\n{\r\n    switch(table) {\r\n        case APPLICATION_TABLE:\r\n            ColumnRWHelper.store(rowKey, applicationTable, ApplicationColumn.ID, null, te.getId());\r\n            ColumnRWHelper.store(rowKey, applicationTable, ApplicationColumn.CREATED_TIME, null, te.getCreatedTime());\r\n            ColumnRWHelper.store(rowKey, applicationTable, ApplicationColumn.FLOW_VERSION, null, flowVersion);\r\n            storeInfo(rowKey, te.getInfo(), flowVersion, ApplicationColumnPrefix.INFO, applicationTable);\r\n            storeMetrics(rowKey, te.getMetrics(), ApplicationColumnPrefix.METRIC, applicationTable);\r\n            storeEvents(rowKey, te.getEvents(), ApplicationColumnPrefix.EVENT, applicationTable);\r\n            storeConfig(rowKey, te.getConfigs(), ApplicationColumnPrefix.CONFIG, applicationTable);\r\n            storeRelations(rowKey, te.getIsRelatedToEntities(), ApplicationColumnPrefix.IS_RELATED_TO, applicationTable);\r\n            storeRelations(rowKey, te.getRelatesToEntities(), ApplicationColumnPrefix.RELATES_TO, applicationTable);\r\n            break;\r\n        case ENTITY_TABLE:\r\n            ColumnRWHelper.store(rowKey, entityTable, EntityColumn.ID, null, te.getId());\r\n            ColumnRWHelper.store(rowKey, entityTable, EntityColumn.TYPE, null, te.getType());\r\n            ColumnRWHelper.store(rowKey, entityTable, EntityColumn.CREATED_TIME, null, te.getCreatedTime());\r\n            ColumnRWHelper.store(rowKey, entityTable, EntityColumn.FLOW_VERSION, null, flowVersion);\r\n            storeInfo(rowKey, te.getInfo(), flowVersion, EntityColumnPrefix.INFO, entityTable);\r\n            storeMetrics(rowKey, te.getMetrics(), EntityColumnPrefix.METRIC, entityTable);\r\n            storeEvents(rowKey, te.getEvents(), EntityColumnPrefix.EVENT, entityTable);\r\n            storeConfig(rowKey, te.getConfigs(), EntityColumnPrefix.CONFIG, entityTable);\r\n            storeRelations(rowKey, te.getIsRelatedToEntities(), EntityColumnPrefix.IS_RELATED_TO, entityTable);\r\n            storeRelations(rowKey, te.getRelatesToEntities(), EntityColumnPrefix.RELATES_TO, entityTable);\r\n            break;\r\n        case SUBAPPLICATION_TABLE:\r\n            ColumnRWHelper.store(rowKey, subApplicationTable, SubApplicationColumn.ID, null, te.getId());\r\n            ColumnRWHelper.store(rowKey, subApplicationTable, SubApplicationColumn.TYPE, null, te.getType());\r\n            ColumnRWHelper.store(rowKey, subApplicationTable, SubApplicationColumn.CREATED_TIME, null, te.getCreatedTime());\r\n            ColumnRWHelper.store(rowKey, subApplicationTable, SubApplicationColumn.FLOW_VERSION, null, flowVersion);\r\n            storeInfo(rowKey, te.getInfo(), flowVersion, SubApplicationColumnPrefix.INFO, subApplicationTable);\r\n            storeMetrics(rowKey, te.getMetrics(), SubApplicationColumnPrefix.METRIC, subApplicationTable);\r\n            storeEvents(rowKey, te.getEvents(), SubApplicationColumnPrefix.EVENT, subApplicationTable);\r\n            storeConfig(rowKey, te.getConfigs(), SubApplicationColumnPrefix.CONFIG, subApplicationTable);\r\n            storeRelations(rowKey, te.getIsRelatedToEntities(), SubApplicationColumnPrefix.IS_RELATED_TO, subApplicationTable);\r\n            storeRelations(rowKey, te.getRelatesToEntities(), SubApplicationColumnPrefix.RELATES_TO, subApplicationTable);\r\n            break;\r\n        default:\r\n            LOG.info(\"Invalid table name provided.\");\r\n            break;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeInfo",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void storeInfo(byte[] rowKey, Map<String, Object> info, String flowVersion, ColumnPrefix<T> columnPrefix, TypedBufferedMutator<T> table) throws IOException\n{\r\n    if (info != null) {\r\n        for (Map.Entry<String, Object> entry : info.entrySet()) {\r\n            ColumnRWHelper.store(rowKey, table, columnPrefix, stringKeyConverter.encode(entry.getKey()), null, entry.getValue());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeConfig",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void storeConfig(byte[] rowKey, Map<String, String> config, ColumnPrefix<T> columnPrefix, TypedBufferedMutator<T> table) throws IOException\n{\r\n    if (config != null) {\r\n        for (Map.Entry<String, String> entry : config.entrySet()) {\r\n            byte[] configKey = stringKeyConverter.encode(entry.getKey());\r\n            ColumnRWHelper.store(rowKey, table, columnPrefix, configKey, null, entry.getValue());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeMetrics",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void storeMetrics(byte[] rowKey, Set<TimelineMetric> metrics, ColumnPrefix<T> columnPrefix, TypedBufferedMutator<T> table) throws IOException\n{\r\n    if (metrics != null) {\r\n        for (TimelineMetric metric : metrics) {\r\n            byte[] metricColumnQualifier = stringKeyConverter.encode(metric.getId());\r\n            Map<Long, Number> timeseries = metric.getValues();\r\n            for (Map.Entry<Long, Number> timeseriesEntry : timeseries.entrySet()) {\r\n                Long timestamp = timeseriesEntry.getKey();\r\n                ColumnRWHelper.store(rowKey, table, columnPrefix, metricColumnQualifier, timestamp, timeseriesEntry.getValue());\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "storeEvents",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void storeEvents(byte[] rowKey, Set<TimelineEvent> events, ColumnPrefix<T> columnPrefix, TypedBufferedMutator<T> table) throws IOException\n{\r\n    if (events != null) {\r\n        for (TimelineEvent event : events) {\r\n            if (event != null) {\r\n                String eventId = event.getId();\r\n                if (eventId != null) {\r\n                    long eventTimestamp = event.getTimestamp();\r\n                    if (eventTimestamp == TimelineEvent.INVALID_TIMESTAMP) {\r\n                        LOG.warn(\"timestamp is not set for event \" + eventId + \"! Using the current timestamp\");\r\n                        eventTimestamp = System.currentTimeMillis();\r\n                    }\r\n                    Map<String, Object> eventInfo = event.getInfo();\r\n                    if ((eventInfo == null) || (eventInfo.size() == 0)) {\r\n                        byte[] columnQualifierBytes = new EventColumnName(eventId, eventTimestamp, null).getColumnQualifier();\r\n                        ColumnRWHelper.store(rowKey, table, columnPrefix, columnQualifierBytes, null, Separator.EMPTY_BYTES);\r\n                    } else {\r\n                        for (Map.Entry<String, Object> info : eventInfo.entrySet()) {\r\n                            byte[] columnQualifierBytes = new EventColumnName(eventId, eventTimestamp, info.getKey()).getColumnQualifier();\r\n                            ColumnRWHelper.store(rowKey, table, columnPrefix, columnQualifierBytes, null, info.getValue());\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "aggregate",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TimelineWriteResponse aggregate(TimelineEntity data, TimelineAggregationTrack track) throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "flush",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void flush() throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    entityTable.flush();\r\n    appToFlowTable.flush();\r\n    applicationTable.flush();\r\n    flowRunTable.flush();\r\n    flowActivityTable.flush();\r\n    subApplicationTable.flush();\r\n    domainTable.flush();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "serviceStop",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void serviceStop() throws Exception\n{\r\n    boolean isStorageUp = true;\r\n    try {\r\n        storageMonitor.checkStorageIsUp();\r\n    } catch (IOException e) {\r\n        LOG.warn(\"Failed to close the timeline tables as Hbase is down\", e);\r\n        isStorageUp = false;\r\n    }\r\n    if (isStorageUp) {\r\n        if (entityTable != null) {\r\n            LOG.info(\"closing the entity table\");\r\n            entityTable.close();\r\n        }\r\n        if (appToFlowTable != null) {\r\n            LOG.info(\"closing the app_flow table\");\r\n            appToFlowTable.close();\r\n        }\r\n        if (applicationTable != null) {\r\n            LOG.info(\"closing the application table\");\r\n            applicationTable.close();\r\n        }\r\n        if (flowRunTable != null) {\r\n            LOG.info(\"closing the flow run table\");\r\n            flowRunTable.close();\r\n        }\r\n        if (flowActivityTable != null) {\r\n            LOG.info(\"closing the flowActivityTable table\");\r\n            flowActivityTable.close();\r\n        }\r\n        if (subApplicationTable != null) {\r\n            subApplicationTable.close();\r\n        }\r\n        if (domainTable != null) {\r\n            domainTable.close();\r\n        }\r\n        if (conn != null) {\r\n            LOG.info(\"closing the hbase Connection\");\r\n            conn.close();\r\n        }\r\n    }\r\n    storageMonitor.stop();\r\n    super.serviceStop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "getTimelineStorageMonitor",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TimelineStorageMonitor getTimelineStorageMonitor()\n{\r\n    return storageMonitor;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\domain",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor domainTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor mappCF = new HColumnDescriptor(DomainColumnFamily.INFO.getBytes());\r\n    mappCF.setBloomFilterType(BloomType.ROWCOL);\r\n    domainTableDescp.addFamily(mappCF);\r\n    domainTableDescp.setRegionSplitPolicyClassName(\"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\r\n    domainTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\", TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\r\n    admin.createTable(domainTableDescp, TimelineHBaseSchemaConstants.getUsernameSplits());\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getPutTimestamp",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "long getPutTimestamp(Long timestamp, boolean supplementTs, Attribute[] attributes)\n{\r\n    if (timestamp == null) {\r\n        timestamp = System.currentTimeMillis();\r\n    }\r\n    if (!supplementTs) {\r\n        return timestamp;\r\n    } else {\r\n        String appId = getAppIdFromAttributes(attributes);\r\n        long supplementedTS = TimestampGenerator.getSupplementedTimestamp(timestamp, appId);\r\n        return supplementedTS;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getAppIdFromAttributes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getAppIdFromAttributes(Attribute[] attributes)\n{\r\n    if (attributes == null) {\r\n        return null;\r\n    }\r\n    String appId = null;\r\n    for (Attribute attribute : attributes) {\r\n        if (AggregationCompactionDimension.APPLICATION_ID.toString().equals(attribute.getName())) {\r\n            appId = Bytes.toString(attribute.getValue());\r\n        }\r\n    }\r\n    return appId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "store",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void store(byte[] rowKey, TypedBufferedMutator<?> tableMutator, Column<?> column, Long timestamp, Object inputValue, Attribute... attributes) throws IOException\n{\r\n    store(rowKey, tableMutator, column.getColumnFamilyBytes(), column.getColumnQualifierBytes(), timestamp, column.supplementCellTimestamp(), inputValue, column.getValueConverter(), column.getCombinedAttrsWithAggr(attributes));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "store",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void store(byte[] rowKey, TypedBufferedMutator<?> tableMutator, byte[] columnFamilyBytes, byte[] columnQualifier, Long timestamp, boolean supplementTs, Object inputValue, ValueConverter converter, Attribute... attributes) throws IOException\n{\r\n    if ((rowKey == null) || (columnQualifier == null) || (inputValue == null)) {\r\n        return;\r\n    }\r\n    Put p = new Put(rowKey);\r\n    timestamp = getPutTimestamp(timestamp, supplementTs, attributes);\r\n    p.addColumn(columnFamilyBytes, columnQualifier, timestamp, converter.encodeValue(inputValue));\r\n    if ((attributes != null) && (attributes.length > 0)) {\r\n        for (Attribute attribute : attributes) {\r\n            p.setAttribute(attribute.getName(), attribute.getValue());\r\n        }\r\n    }\r\n    tableMutator.mutate(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResult",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Object readResult(Result result, byte[] columnFamilyBytes, byte[] columnQualifierBytes, ValueConverter converter) throws IOException\n{\r\n    if (result == null || columnQualifierBytes == null) {\r\n        return null;\r\n    }\r\n    byte[] value = result.getValue(columnFamilyBytes, columnQualifierBytes);\r\n    return converter.decodeValue(value);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResult",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Object readResult(Result result, Column<?> column) throws IOException\n{\r\n    return readResult(result, column.getColumnFamilyBytes(), column.getColumnQualifierBytes(), column.getValueConverter());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResult",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Object readResult(Result result, ColumnPrefix<?> columnPrefix, String qualifier) throws IOException\n{\r\n    byte[] columnQualifier = ColumnHelper.getColumnQualifier(columnPrefix.getColumnPrefixInBytes(), qualifier);\r\n    return readResult(result, columnPrefix.getColumnFamilyBytes(), columnQualifier, columnPrefix.getValueConverter());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResults",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<K, Object> readResults(Result result, ColumnPrefix<?> columnPrefix, KeyConverter<K> keyConverter) throws IOException\n{\r\n    return readResults(result, columnPrefix.getColumnFamilyBytes(), columnPrefix.getColumnPrefixInBytes(), keyConverter, columnPrefix.getValueConverter());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResultsWithTimestamps",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "NavigableMap<K, NavigableMap<Long, V>> readResultsWithTimestamps(Result result, ColumnPrefix<?> columnPrefix, KeyConverter<K> keyConverter) throws IOException\n{\r\n    return readResultsWithTimestamps(result, columnPrefix.getColumnFamilyBytes(), columnPrefix.getColumnPrefixInBytes(), keyConverter, columnPrefix.getValueConverter(), columnPrefix.supplementCellTimeStamp());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResultsWithTimestamps",
  "errType" : [ "IllegalArgumentException", "IllegalArgumentException" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "NavigableMap<K, NavigableMap<Long, V>> readResultsWithTimestamps(Result result, byte[] columnFamilyBytes, byte[] columnPrefixBytes, KeyConverter<K> keyConverter, ValueConverter valueConverter, boolean supplementTs) throws IOException\n{\r\n    NavigableMap<K, NavigableMap<Long, V>> results = new TreeMap<>();\r\n    if (result != null) {\r\n        NavigableMap<byte[], NavigableMap<byte[], NavigableMap<Long, byte[]>>> resultMap = result.getMap();\r\n        NavigableMap<byte[], NavigableMap<Long, byte[]>> columnCellMap = resultMap.get(columnFamilyBytes);\r\n        if (columnCellMap != null) {\r\n            for (Map.Entry<byte[], NavigableMap<Long, byte[]>> entry : columnCellMap.entrySet()) {\r\n                K converterColumnKey = null;\r\n                if (columnPrefixBytes == null) {\r\n                    LOG.debug(\"null prefix was specified; returning all columns\");\r\n                    try {\r\n                        converterColumnKey = keyConverter.decode(entry.getKey());\r\n                    } catch (IllegalArgumentException iae) {\r\n                        LOG.error(\"Illegal column found, skipping this column.\", iae);\r\n                        continue;\r\n                    }\r\n                } else {\r\n                    byte[][] columnNameParts = Separator.QUALIFIERS.split(entry.getKey(), 2);\r\n                    byte[] actualColumnPrefixBytes = columnNameParts[0];\r\n                    if (Bytes.equals(columnPrefixBytes, actualColumnPrefixBytes) && columnNameParts.length == 2) {\r\n                        try {\r\n                            converterColumnKey = keyConverter.decode(columnNameParts[1]);\r\n                        } catch (IllegalArgumentException iae) {\r\n                            LOG.error(\"Illegal column found, skipping this column.\", iae);\r\n                            continue;\r\n                        }\r\n                    }\r\n                }\r\n                if (converterColumnKey != null) {\r\n                    NavigableMap<Long, V> cellResults = new TreeMap<Long, V>();\r\n                    NavigableMap<Long, byte[]> cells = entry.getValue();\r\n                    if (cells != null) {\r\n                        for (Map.Entry<Long, byte[]> cell : cells.entrySet()) {\r\n                            V value = (V) valueConverter.decodeValue(cell.getValue());\r\n                            Long ts = supplementTs ? TimestampGenerator.getTruncatedTimestamp(cell.getKey()) : cell.getKey();\r\n                            cellResults.put(ts, value);\r\n                        }\r\n                    }\r\n                    results.put(converterColumnKey, cellResults);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return results;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "readResults",
  "errType" : [ "IllegalArgumentException", "IllegalArgumentException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "Map<K, Object> readResults(Result result, byte[] columnFamilyBytes, byte[] columnPrefixBytes, KeyConverter<K> keyConverter, ValueConverter valueConverter) throws IOException\n{\r\n    Map<K, Object> results = new HashMap<K, Object>();\r\n    if (result != null) {\r\n        Map<byte[], byte[]> columns = result.getFamilyMap(columnFamilyBytes);\r\n        for (Map.Entry<byte[], byte[]> entry : columns.entrySet()) {\r\n            byte[] columnKey = entry.getKey();\r\n            if (columnKey != null && columnKey.length > 0) {\r\n                K converterColumnKey = null;\r\n                if (columnPrefixBytes == null) {\r\n                    try {\r\n                        converterColumnKey = keyConverter.decode(columnKey);\r\n                    } catch (IllegalArgumentException iae) {\r\n                        LOG.error(\"Illegal column found, skipping this column.\", iae);\r\n                        continue;\r\n                    }\r\n                } else {\r\n                    byte[][] columnNameParts = Separator.QUALIFIERS.split(columnKey, 2);\r\n                    if (columnNameParts.length > 0) {\r\n                        byte[] actualColumnPrefixBytes = columnNameParts[0];\r\n                        if (Bytes.equals(columnPrefixBytes, actualColumnPrefixBytes) && columnNameParts.length == 2) {\r\n                            try {\r\n                                converterColumnKey = keyConverter.decode(columnNameParts[1]);\r\n                            } catch (IllegalArgumentException iae) {\r\n                                LOG.error(\"Illegal column found, skipping this column.\", iae);\r\n                                continue;\r\n                            }\r\n                        }\r\n                    }\r\n                }\r\n                if (converterColumnKey != null) {\r\n                    Object value = valueConverter.decodeValue(entry.getValue());\r\n                    results.put(converterColumnKey, value);\r\n                }\r\n            }\r\n        }\r\n    }\r\n    return results;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "store",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void store(byte[] rowKey, TypedBufferedMutator<?> tableMutator, ColumnPrefix<?> columnPrefix, byte[] qualifier, Long timestamp, Object inputValue, Attribute... attributes) throws IOException\n{\r\n    if (qualifier == null) {\r\n        throw new IOException(\"Cannot store column with null qualifier in \" + tableMutator.getName().getNameAsString());\r\n    }\r\n    byte[] columnQualifier = columnPrefix.getColumnPrefixBytes(qualifier);\r\n    Attribute[] combinedAttributes = columnPrefix.getCombinedAttrsWithAggr(attributes);\r\n    store(rowKey, tableMutator, columnPrefix.getColumnFamilyBytes(), columnQualifier, timestamp, columnPrefix.supplementCellTimeStamp(), inputValue, columnPrefix.getValueConverter(), combinedAttributes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "store",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void store(byte[] rowKey, TypedBufferedMutator<?> tableMutator, ColumnPrefix<?> columnPrefix, String qualifier, Long timestamp, Object inputValue, Attribute... attributes) throws IOException\n{\r\n    if (qualifier == null) {\r\n        throw new IOException(\"Cannot store column with null qualifier in \" + tableMutator.getName().getNameAsString());\r\n    }\r\n    byte[] columnQualifier = columnPrefix.getColumnPrefixBytes(qualifier);\r\n    Attribute[] combinedAttributes = columnPrefix.getCombinedAttrsWithAggr(attributes);\r\n    store(rowKey, tableMutator, columnPrefix.getColumnFamilyBytes(), columnQualifier, timestamp, columnPrefix.supplementCellTimeStamp(), inputValue, columnPrefix.getValueConverter(), combinedAttributes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BaseTableRW<?> getTable()\n{\r\n    return ENTITY_TABLE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFilters() throws IOException\n{\r\n    FilterList listBasedOnFilters = new FilterList();\r\n    TimelineEntityFilters filters = getFilters();\r\n    long createdTimeBegin = filters.getCreatedTimeBegin();\r\n    long createdTimeEnd = filters.getCreatedTimeEnd();\r\n    if (createdTimeBegin != 0 || createdTimeEnd != Long.MAX_VALUE) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createSingleColValueFiltersByRange(EntityColumn.CREATED_TIME, createdTimeBegin, createdTimeEnd));\r\n    }\r\n    TimelineFilterList metricFilters = filters.getMetricFilters();\r\n    if (metricFilters != null && !metricFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(EntityColumnPrefix.METRIC, metricFilters));\r\n    }\r\n    TimelineFilterList configFilters = filters.getConfigFilters();\r\n    if (configFilters != null && !configFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(EntityColumnPrefix.CONFIG, configFilters));\r\n    }\r\n    TimelineFilterList infoFilters = filters.getInfoFilters();\r\n    if (infoFilters != null && !infoFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(EntityColumnPrefix.INFO, infoFilters));\r\n    }\r\n    return listBasedOnFilters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "fetchPartialEventCols",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean fetchPartialEventCols(TimelineFilterList eventFilters, EnumSet<Field> fieldsToRetrieve)\n{\r\n    return (eventFilters != null && !eventFilters.getFilterList().isEmpty() && !hasField(fieldsToRetrieve, Field.EVENTS));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "fetchPartialRelatesToCols",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean fetchPartialRelatesToCols(TimelineFilterList relatesTo, EnumSet<Field> fieldsToRetrieve)\n{\r\n    return (relatesTo != null && !relatesTo.getFilterList().isEmpty() && !hasField(fieldsToRetrieve, Field.RELATES_TO));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "fetchPartialIsRelatedToCols",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean fetchPartialIsRelatedToCols(TimelineFilterList isRelatedTo, EnumSet<Field> fieldsToRetrieve)\n{\r\n    return (isRelatedTo != null && !isRelatedTo.getFilterList().isEmpty() && !hasField(fieldsToRetrieve, Field.IS_RELATED_TO));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "fetchPartialColsFromInfoFamily",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean fetchPartialColsFromInfoFamily()\n{\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    TimelineEntityFilters filters = getFilters();\r\n    return fetchPartialEventCols(filters.getEventFilters(), fieldsToRetrieve) || fetchPartialRelatesToCols(filters.getRelatesTo(), fieldsToRetrieve) || fetchPartialIsRelatedToCols(filters.getIsRelatedTo(), fieldsToRetrieve);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "needCreateFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "boolean needCreateFilterListBasedOnFields()\n{\r\n    TimelineDataToRetrieve dataToRetrieve = getDataToRetrieve();\r\n    boolean flag = !dataToRetrieve.getFieldsToRetrieve().contains(Field.ALL) || (dataToRetrieve.getConfsToRetrieve() != null && !dataToRetrieve.getConfsToRetrieve().getFilterList().isEmpty()) || (dataToRetrieve.getMetricsToRetrieve() != null && !dataToRetrieve.getMetricsToRetrieve().getFilterList().isEmpty());\r\n    if (!flag && !isSingleEntityRead()) {\r\n        TimelineEntityFilters filters = getFilters();\r\n        flag = (filters.getEventFilters() != null && !filters.getEventFilters().getFilterList().isEmpty()) || (filters.getIsRelatedTo() != null && !filters.getIsRelatedTo().getFilterList().isEmpty()) || (filters.getRelatesTo() != null && !filters.getRelatesTo().getFilterList().isEmpty());\r\n    }\r\n    return flag;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFixedColumns",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void updateFixedColumns(FilterList list)\n{\r\n    for (EntityColumn column : EntityColumn.values()) {\r\n        list.addFilter(new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(column.getColumnQualifierBytes())));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createFilterListForColsOfInfoFamily",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "FilterList createFilterListForColsOfInfoFamily() throws IOException\n{\r\n    FilterList infoFamilyColsFilter = new FilterList(Operator.MUST_PASS_ONE);\r\n    updateFixedColumns(infoFamilyColsFilter);\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (hasField(fieldsToRetrieve, Field.INFO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, EntityColumnPrefix.INFO));\r\n    }\r\n    TimelineFilterList relatesTo = getFilters().getRelatesTo();\r\n    if (hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, EntityColumnPrefix.RELATES_TO));\r\n    } else if (relatesTo != null && !relatesTo.getFilterList().isEmpty()) {\r\n        Set<String> relatesToCols = TimelineFilterUtils.fetchColumnsFromFilterList(relatesTo);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(EntityColumnPrefix.RELATES_TO, relatesToCols));\r\n    }\r\n    TimelineFilterList isRelatedTo = getFilters().getIsRelatedTo();\r\n    if (hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, EntityColumnPrefix.IS_RELATED_TO));\r\n    } else if (isRelatedTo != null && !isRelatedTo.getFilterList().isEmpty()) {\r\n        Set<String> isRelatedToCols = TimelineFilterUtils.fetchColumnsFromFilterList(isRelatedTo);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(EntityColumnPrefix.IS_RELATED_TO, isRelatedToCols));\r\n    }\r\n    TimelineFilterList eventFilters = getFilters().getEventFilters();\r\n    if (hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, EntityColumnPrefix.EVENT));\r\n    } else if (eventFilters != null && !eventFilters.getFilterList().isEmpty()) {\r\n        Set<String> eventCols = TimelineFilterUtils.fetchColumnsFromFilterList(eventFilters);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(EntityColumnPrefix.EVENT, eventCols));\r\n    }\r\n    return infoFamilyColsFilter;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "excludeFieldsFromInfoColFamily",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void excludeFieldsFromInfoColFamily(FilterList infoColFamilyList)\n{\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (!hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, EntityColumnPrefix.EVENT));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.INFO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, EntityColumnPrefix.INFO));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, EntityColumnPrefix.IS_RELATED_TO));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, EntityColumnPrefix.RELATES_TO));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFilterForConfsAndMetricsToRetrieve",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void updateFilterForConfsAndMetricsToRetrieve(FilterList listBasedOnFields, Set<String> cfsInFields) throws IOException\n{\r\n    TimelineDataToRetrieve dataToRetrieve = getDataToRetrieve();\r\n    if (dataToRetrieve.getFieldsToRetrieve().contains(Field.CONFIGS)) {\r\n        listBasedOnFields.addFilter(TimelineFilterUtils.createFilterForConfsOrMetricsToRetrieve(dataToRetrieve.getConfsToRetrieve(), EntityColumnFamily.CONFIGS, EntityColumnPrefix.CONFIG));\r\n        cfsInFields.add(Bytes.toString(EntityColumnFamily.CONFIGS.getBytes()));\r\n    }\r\n    if (dataToRetrieve.getFieldsToRetrieve().contains(Field.METRICS)) {\r\n        listBasedOnFields.addFilter(TimelineFilterUtils.createFilterForConfsOrMetricsToRetrieve(dataToRetrieve.getMetricsToRetrieve(), EntityColumnFamily.METRICS, EntityColumnPrefix.METRIC));\r\n        cfsInFields.add(Bytes.toString(EntityColumnFamily.METRICS.getBytes()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFields(Set<String> cfsInFields) throws IOException\n{\r\n    if (!needCreateFilterListBasedOnFields()) {\r\n        return null;\r\n    }\r\n    FilterList listBasedOnFields = new FilterList(Operator.MUST_PASS_ONE);\r\n    FilterList infoColFamilyList = new FilterList();\r\n    FamilyFilter infoColumnFamily = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(EntityColumnFamily.INFO.getBytes()));\r\n    infoColFamilyList.addFilter(infoColumnFamily);\r\n    if (!isSingleEntityRead() && fetchPartialColsFromInfoFamily()) {\r\n        infoColFamilyList.addFilter(createFilterListForColsOfInfoFamily());\r\n    } else {\r\n        excludeFieldsFromInfoColFamily(infoColFamilyList);\r\n    }\r\n    listBasedOnFields.addFilter(infoColFamilyList);\r\n    cfsInFields.add(Bytes.toString(EntityColumnFamily.INFO.getBytes()));\r\n    updateFilterForConfsAndMetricsToRetrieve(listBasedOnFields, cfsInFields);\r\n    return listBasedOnFields;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void validateParams()\n{\r\n    if (getContext() == null) {\r\n        throw new NullPointerException(\"context shouldn't be null\");\r\n    }\r\n    if (getDataToRetrieve() == null) {\r\n        throw new NullPointerException(\"data to retrieve shouldn't be null\");\r\n    }\r\n    if (getContext().getClusterId() == null) {\r\n        throw new NullPointerException(\"clusterId shouldn't be null\");\r\n    }\r\n    if (getContext().getAppId() == null) {\r\n        throw new NullPointerException(\"appId shouldn't be null\");\r\n    }\r\n    if (getContext().getEntityType() == null) {\r\n        throw new NullPointerException(\"entityType shouldn't be null\");\r\n    }\r\n    if (isSingleEntityRead()) {\r\n        if (getContext().getEntityId() == null) {\r\n            throw new NullPointerException(\"entityId shouldn't be null\");\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "augmentParams",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void augmentParams(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    defaultAugmentParams(hbaseConf, conn);\r\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\r\n    if (!isSingleEntityRead()) {\r\n        createFiltersIfNull();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 18,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    TimelineReaderContext context = getContext();\r\n    Result result = null;\r\n    if (context.getEntityIdPrefix() != null) {\r\n        byte[] rowKey = new EntityRowKey(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId(), context.getAppId(), context.getEntityType(), context.getEntityIdPrefix(), context.getEntityId()).getRowKey();\r\n        Get get = new Get(rowKey);\r\n        setMetricsTimeRange(get);\r\n        get.setMaxVersions(getDataToRetrieve().getMetricsLimit());\r\n        if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n            get.setFilter(filterList);\r\n        }\r\n        result = getTable().getResult(hbaseConf, conn, get);\r\n    } else {\r\n        FilterList filter = new FilterList(Operator.MUST_PASS_ALL);\r\n        if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n            filter.addFilter(filterList);\r\n        }\r\n        FilterList newFilter = new FilterList();\r\n        newFilter.addFilter(TimelineFilterUtils.createHBaseSingleColValueFilter(EntityColumn.ID, context.getEntityId(), CompareOp.EQUAL));\r\n        newFilter.addFilter(new PageFilter(1));\r\n        filter.addFilter(newFilter);\r\n        ResultScanner results = getResults(hbaseConf, conn, filter);\r\n        try {\r\n            Iterator<Result> iterator = results.iterator();\r\n            if (iterator.hasNext()) {\r\n                result = iterator.next();\r\n            }\r\n        } finally {\r\n            results.close();\r\n        }\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "setMetricsTimeRange",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTimeRange(Query query)\n{\r\n    HBaseTimelineStorageUtils.setMetricsTimeRange(query, EntityColumnFamily.METRICS.getBytes(), getDataToRetrieve().getMetricsTimeBegin(), getDataToRetrieve().getMetricsTimeEnd());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResults",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 27,
  "sourceCodeText" : "ResultScanner getResults(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    Scan scan = new Scan();\r\n    TimelineReaderContext context = getContext();\r\n    RowKeyPrefix<EntityRowKey> entityRowKeyPrefix = null;\r\n    if (getFilters() == null || getFilters().getFromId() == null) {\r\n        entityRowKeyPrefix = new EntityRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId(), context.getAppId(), context.getEntityType(), null, null);\r\n        scan.setRowPrefixFilter(entityRowKeyPrefix.getRowKeyPrefix());\r\n    } else {\r\n        EntityRowKey entityRowKey = null;\r\n        try {\r\n            entityRowKey = EntityRowKey.parseRowKeyFromString(getFilters().getFromId());\r\n        } catch (IllegalArgumentException e) {\r\n            throw new BadRequestException(\"Invalid filter fromid is provided.\");\r\n        }\r\n        if (!context.getClusterId().equals(entityRowKey.getClusterId())) {\r\n            throw new BadRequestException(\"fromid doesn't belong to clusterId=\" + context.getClusterId());\r\n        }\r\n        scan.withStartRow(entityRowKey.getRowKey());\r\n        entityRowKeyPrefix = new EntityRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId(), context.getAppId(), context.getEntityType(), null, null);\r\n        scan.withStopRow(HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(entityRowKeyPrefix.getRowKeyPrefix()));\r\n        filterList.addFilter(new PageFilter(getFilters().getLimit()));\r\n    }\r\n    setMetricsTimeRange(scan);\r\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\r\n    if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n        scan.setFilter(filterList);\r\n    }\r\n    return getTable().getResultScanner(hbaseConf, conn, scan);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntity",
  "errType" : null,
  "containingMethodsNum" : 40,
  "sourceCodeText" : "TimelineEntity parseEntity(Result result) throws IOException\n{\r\n    if (result == null || result.isEmpty()) {\r\n        return null;\r\n    }\r\n    TimelineEntity entity = new TimelineEntity();\r\n    EntityRowKey parseRowKey = EntityRowKey.parseRowKey(result.getRow());\r\n    entity.setType(parseRowKey.getEntityType());\r\n    entity.setId(parseRowKey.getEntityId());\r\n    entity.setIdPrefix(parseRowKey.getEntityIdPrefix().longValue());\r\n    TimelineEntityFilters filters = getFilters();\r\n    Long createdTime = (Long) ColumnRWHelper.readResult(result, EntityColumn.CREATED_TIME);\r\n    entity.setCreatedTime(createdTime);\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    boolean checkIsRelatedTo = !isSingleEntityRead() && filters.getIsRelatedTo() != null && filters.getIsRelatedTo().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.IS_RELATED_TO) || checkIsRelatedTo) {\r\n        readRelationship(entity, result, EntityColumnPrefix.IS_RELATED_TO, true);\r\n        if (checkIsRelatedTo && !TimelineStorageUtils.matchIsRelatedTo(entity, filters.getIsRelatedTo())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n            entity.getIsRelatedToEntities().clear();\r\n        }\r\n    }\r\n    boolean checkRelatesTo = !isSingleEntityRead() && filters.getRelatesTo() != null && filters.getRelatesTo().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.RELATES_TO) || checkRelatesTo) {\r\n        readRelationship(entity, result, EntityColumnPrefix.RELATES_TO, false);\r\n        if (checkRelatesTo && !TimelineStorageUtils.matchRelatesTo(entity, filters.getRelatesTo())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n            entity.getRelatesToEntities().clear();\r\n        }\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.INFO)) {\r\n        readKeyValuePairs(entity, result, EntityColumnPrefix.INFO, false);\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.CONFIGS)) {\r\n        readKeyValuePairs(entity, result, EntityColumnPrefix.CONFIG, true);\r\n    }\r\n    boolean checkEvents = !isSingleEntityRead() && filters.getEventFilters() != null && filters.getEventFilters().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.EVENTS) || checkEvents) {\r\n        readEvents(entity, result, EntityColumnPrefix.EVENT);\r\n        if (checkEvents && !TimelineStorageUtils.matchEventFilters(entity, filters.getEventFilters())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n            entity.getEvents().clear();\r\n        }\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.METRICS)) {\r\n        readMetrics(entity, result, EntityColumnPrefix.METRIC);\r\n    }\r\n    entity.getInfo().put(TimelineReaderUtils.FROMID_KEY, parseRowKey.getRowKeyAsString());\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readKeyValuePairs",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void readKeyValuePairs(TimelineEntity entity, Result result, ColumnPrefix<T> prefix, boolean isConfig) throws IOException\n{\r\n    Map<String, Object> columns = ColumnRWHelper.readResults(result, prefix, stringKeyConverter);\r\n    if (isConfig) {\r\n        for (Map.Entry<String, Object> column : columns.entrySet()) {\r\n            entity.addConfig(column.getKey(), column.getValue().toString());\r\n        }\r\n    } else {\r\n        entity.addInfo(columns);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createSingleEntityReader",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineEntityReader createSingleEntityReader(TimelineReaderContext context, TimelineDataToRetrieve dataToRetrieve)\n{\r\n    if (TimelineEntityType.YARN_APPLICATION.matches(context.getEntityType())) {\r\n        return new ApplicationEntityReader(context, dataToRetrieve);\r\n    } else if (TimelineEntityType.YARN_FLOW_RUN.matches(context.getEntityType())) {\r\n        return new FlowRunEntityReader(context, dataToRetrieve);\r\n    } else if (TimelineEntityType.YARN_FLOW_ACTIVITY.matches(context.getEntityType())) {\r\n        return new FlowActivityEntityReader(context, dataToRetrieve);\r\n    } else {\r\n        return new GenericEntityReader(context, dataToRetrieve);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createMultipleEntitiesReader",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TimelineEntityReader createMultipleEntitiesReader(TimelineReaderContext context, TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve)\n{\r\n    if (TimelineEntityType.YARN_APPLICATION.matches(context.getEntityType())) {\r\n        return new ApplicationEntityReader(context, filters, dataToRetrieve);\r\n    } else if (TimelineEntityType.YARN_FLOW_ACTIVITY.matches(context.getEntityType())) {\r\n        return new FlowActivityEntityReader(context, filters, dataToRetrieve);\r\n    } else if (TimelineEntityType.YARN_FLOW_RUN.matches(context.getEntityType())) {\r\n        return new FlowRunEntityReader(context, filters, dataToRetrieve);\r\n    } else {\r\n        if (context.getDoAsUser() != null) {\r\n            return new SubApplicationEntityReader(context, filters, dataToRetrieve);\r\n        }\r\n        return new GenericEntityReader(context, filters, dataToRetrieve);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createEntityTypeReader",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "EntityTypeReader createEntityTypeReader(TimelineReaderContext context)\n{\r\n    return new EntityTypeReader(context);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\flow",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor flowActivityTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor infoCF = new HColumnDescriptor(FlowActivityColumnFamily.INFO.getBytes());\r\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\r\n    flowActivityTableDescp.addFamily(infoCF);\r\n    infoCF.setMinVersions(1);\r\n    infoCF.setMaxVersions(DEFAULT_METRICS_MAX_VERSIONS);\r\n    admin.createTable(flowActivityTableDescp);\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void initialize(Configuration conf) throws Exception\n{\r\n    monitorHBaseConf = HBaseTimelineStorageUtils.getTimelineServiceHBaseConf(conf);\r\n    monitorHBaseConf.setInt(\"hbase.client.retries.number\", 3);\r\n    monitorHBaseConf.setLong(\"hbase.client.pause\", 1000);\r\n    long monitorInterval = conf.getLong(YarnConfiguration.TIMELINE_SERVICE_READER_STORAGE_MONITOR_INTERVAL_MS, YarnConfiguration.DEFAULT_TIMELINE_SERVICE_STORAGE_MONITOR_INTERVAL_MS);\r\n    monitorHBaseConf.setLong(\"hbase.rpc.timeout\", monitorInterval);\r\n    monitorHBaseConf.setLong(\"hbase.client.scanner.timeout.period\", monitorInterval);\r\n    monitorHBaseConf.setInt(\"zookeeper.recovery.retry\", 1);\r\n    monitorConn = ConnectionFactory.createConnection(monitorHBaseConf);\r\n    String clusterId = conf.get(YarnConfiguration.RM_CLUSTER_ID, YarnConfiguration.DEFAULT_RM_CLUSTER_ID);\r\n    TimelineReaderContext monitorContext = new TimelineReaderContext(clusterId, null, null, null, null, TimelineEntityType.YARN_FLOW_ACTIVITY.toString(), null, null);\r\n    reader = TimelineEntityReaderFactory.createMultipleEntitiesReader(monitorContext, MONITOR_FILTERS, DATA_TO_RETRIEVE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "healthCheck",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void healthCheck() throws Exception\n{\r\n    reader.readEntities(monitorHBaseConf, monitorConn);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "start",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void start()\n{\r\n    super.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "stop",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void stop() throws Exception\n{\r\n    super.stop();\r\n    monitorConn.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getTableMutator",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBufferedMutator<T> getTableMutator(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    TableName tableName = this.getTableName(hbaseConf);\r\n    BufferedMutator bufferedMutator = conn.getBufferedMutator(tableName);\r\n    TypedBufferedMutator<T> table = new TypedBufferedMutator<T>(bufferedMutator);\r\n    return table;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getResultScanner",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ResultScanner getResultScanner(Configuration hbaseConf, Connection conn, Scan scan) throws IOException\n{\r\n    Table table = conn.getTable(getTableName(hbaseConf));\r\n    return table.getScanner(scan);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, Get get) throws IOException\n{\r\n    Table table = conn.getTable(getTableName(hbaseConf));\r\n    return table.get(get);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getTableName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TableName getTableName(Configuration conf, String tableName)\n{\r\n    String tableSchemaPrefix = conf.get(YarnConfiguration.TIMELINE_SERVICE_HBASE_SCHEMA_PREFIX_NAME, YarnConfiguration.DEFAULT_TIMELINE_SERVICE_HBASE_SCHEMA_PREFIX);\r\n    return TableName.valueOf(tableSchemaPrefix + tableName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getTableName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TableName getTableName(Configuration conf)\n{\r\n    String tableName = conf.get(tableNameConfName, defaultTableName);\r\n    return getTableName(conf, tableName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getTableName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TableName getTableName(Configuration conf, String tableNameInConf, String defaultTableName)\n{\r\n    String tableName = conf.get(tableNameInConf, defaultTableName);\r\n    return getTableName(conf, tableName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\apptoflow",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor appToFlowTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor mappCF = new HColumnDescriptor(AppToFlowColumnFamily.MAPPING.getBytes());\r\n    mappCF.setBloomFilterType(BloomType.ROWCOL);\r\n    appToFlowTableDescp.addFamily(mappCF);\r\n    admin.createTable(appToFlowTableDescp);\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "createTimelineSchema",
  "errType" : null,
  "containingMethodsNum" : 34,
  "sourceCodeText" : "void createTimelineSchema(String[] args) throws Exception\n{\r\n    LOG.info(\"Starting the schema creation\");\r\n    Configuration hbaseConf = HBaseTimelineStorageUtils.getTimelineServiceHBaseConf(new YarnConfiguration());\r\n    String[] otherArgs = new GenericOptionsParser(hbaseConf, args).getRemainingArgs();\r\n    CommandLine commandLine = parseArgs(otherArgs);\r\n    if (commandLine.hasOption(HELP_SHORT)) {\r\n        printUsage();\r\n    } else if (commandLine.hasOption(CREATE_TABLES_SHORT)) {\r\n        String entityTableName = commandLine.getOptionValue(ENTITY_TABLE_NAME_SHORT);\r\n        if (StringUtils.isNotBlank(entityTableName)) {\r\n            hbaseConf.set(EntityTableRW.TABLE_NAME_CONF_NAME, entityTableName);\r\n        }\r\n        String entityTableMetricsTTL = commandLine.getOptionValue(ENTITY_METRICS_TTL_OPTION_SHORT);\r\n        if (StringUtils.isNotBlank(entityTableMetricsTTL)) {\r\n            int entityMetricsTTL = Integer.parseInt(entityTableMetricsTTL);\r\n            new EntityTableRW().setMetricsTTL(entityMetricsTTL, hbaseConf);\r\n        }\r\n        String appToflowTableName = commandLine.getOptionValue(APP_TO_FLOW_TABLE_NAME_SHORT);\r\n        if (StringUtils.isNotBlank(appToflowTableName)) {\r\n            hbaseConf.set(AppToFlowTableRW.TABLE_NAME_CONF_NAME, appToflowTableName);\r\n        }\r\n        String applicationTableName = commandLine.getOptionValue(APP_TABLE_NAME_SHORT);\r\n        if (StringUtils.isNotBlank(applicationTableName)) {\r\n            hbaseConf.set(ApplicationTableRW.TABLE_NAME_CONF_NAME, applicationTableName);\r\n        }\r\n        String applicationTableMetricsTTL = commandLine.getOptionValue(APP_METRICS_TTL_OPTION_SHORT);\r\n        if (StringUtils.isNotBlank(applicationTableMetricsTTL)) {\r\n            int appMetricsTTL = Integer.parseInt(applicationTableMetricsTTL);\r\n            new ApplicationTableRW().setMetricsTTL(appMetricsTTL, hbaseConf);\r\n        }\r\n        String subApplicationTableName = commandLine.getOptionValue(SUB_APP_TABLE_NAME_SHORT);\r\n        if (StringUtils.isNotBlank(subApplicationTableName)) {\r\n            hbaseConf.set(SubApplicationTableRW.TABLE_NAME_CONF_NAME, subApplicationTableName);\r\n        }\r\n        String subApplicationTableMetricsTTL = commandLine.getOptionValue(SUB_APP_METRICS_TTL_OPTION_SHORT);\r\n        if (StringUtils.isNotBlank(subApplicationTableMetricsTTL)) {\r\n            int subAppMetricsTTL = Integer.parseInt(subApplicationTableMetricsTTL);\r\n            new SubApplicationTableRW().setMetricsTTL(subAppMetricsTTL, hbaseConf);\r\n        }\r\n        final boolean skipExisting = commandLine.hasOption(SKIP_EXISTING_TABLE_OPTION_SHORT);\r\n        createAllSchemas(hbaseConf, skipExisting);\r\n    } else {\r\n        printUsage();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "parseArgs",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 31,
  "sourceCodeText" : "CommandLine parseArgs(String[] args) throws ParseException\n{\r\n    Options options = new Options();\r\n    Option o = new Option(HELP_SHORT, \"help\", false, \"print help information\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(CREATE_TABLES_SHORT, \"create\", false, \"a mandatory option to create hbase tables\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(ENTITY_TABLE_NAME_SHORT, \"entityTableName\", true, \"entity table name\");\r\n    o.setArgName(\"entityTableName\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(ENTITY_METRICS_TTL_OPTION_SHORT, \"entityMetricsTTL\", true, \"TTL for metrics column family\");\r\n    o.setArgName(\"entityMetricsTTL\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(APP_TO_FLOW_TABLE_NAME_SHORT, \"appToflowTableName\", true, \"app to flow table name\");\r\n    o.setArgName(\"appToflowTableName\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(APP_TABLE_NAME_SHORT, \"applicationTableName\", true, \"application table name\");\r\n    o.setArgName(\"applicationTableName\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(APP_METRICS_TTL_OPTION_SHORT, \"applicationMetricsTTL\", true, \"TTL for metrics column family\");\r\n    o.setArgName(\"applicationMetricsTTL\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(SUB_APP_TABLE_NAME_SHORT, \"subApplicationTableName\", true, \"subApplication table name\");\r\n    o.setArgName(\"subApplicationTableName\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(SUB_APP_METRICS_TTL_OPTION_SHORT, \"subApplicationMetricsTTL\", true, \"TTL for metrics column family\");\r\n    o.setArgName(\"subApplicationMetricsTTL\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    o = new Option(SKIP_EXISTING_TABLE_OPTION_SHORT, \"skipExistingTable\", false, \"skip existing Hbase tables and continue to create new tables\");\r\n    o.setRequired(false);\r\n    options.addOption(o);\r\n    CommandLineParser parser = new PosixParser();\r\n    CommandLine commandLine = null;\r\n    try {\r\n        commandLine = parser.parse(options, args);\r\n    } catch (Exception e) {\r\n        LOG.error(\"ERROR: \" + e.getMessage() + \"\\n\");\r\n        HelpFormatter formatter = new HelpFormatter();\r\n        formatter.printHelp(NAME + \" \", options, true);\r\n        System.exit(-1);\r\n    }\r\n    return commandLine;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void printUsage()\n{\r\n    StringBuilder usage = new StringBuilder(\"Command Usage: \\n\");\r\n    usage.append(\"TimelineSchemaCreator [-help] Display help info\" + \" for all commands. Or\\n\").append(\"TimelineSchemaCreator -create [OPTIONAL_OPTIONS]\" + \" Create hbase tables.\\n\\n\").append(\"The Optional options for creating tables include: \\n\").append(\"[-entityTableName <Entity Table Name>] \" + \"The name of the Entity table\\n\").append(\"[-entityMetricsTTL <Entity Table Metrics TTL>]\" + \" TTL for metrics in the Entity table\\n\").append(\"[-appToflowTableName <AppToflow Table Name>]\" + \" The name of the AppToFlow table\\n\").append(\"[-applicationTableName <Application Table Name>]\" + \" The name of the Application table\\n\").append(\"[-applicationMetricsTTL <Application Table Metrics TTL>]\" + \" TTL for metrics in the Application table\\n\").append(\"[-subApplicationTableName <SubApplication Table Name>]\" + \" The name of the SubApplication table\\n\").append(\"[-subApplicationMetricsTTL \" + \" <SubApplication Table Metrics TTL>]\" + \" TTL for metrics in the SubApplication table\\n\").append(\"[-skipExistingTable] Whether to skip existing\" + \" hbase tables\\n\");\r\n    System.out.println(usage.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "createAllSchemas",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void createAllSchemas(Configuration hbaseConf, boolean skipExisting)\n{\r\n    List<Exception> exceptions = new ArrayList<>();\r\n    try {\r\n        if (skipExisting) {\r\n            LOG.info(\"Will skip existing tables and continue on htable creation \" + \"exceptions!\");\r\n        }\r\n        createAllTables(hbaseConf, skipExisting);\r\n        LOG.info(\"Successfully created HBase schema. \");\r\n    } catch (IOException e) {\r\n        LOG.error(\"Error in creating hbase tables: \", e);\r\n        exceptions.add(e);\r\n    }\r\n    if (exceptions.size() > 0) {\r\n        LOG.warn(\"Schema creation finished with the following exceptions\");\r\n        for (Exception e : exceptions) {\r\n            LOG.warn(e.getMessage());\r\n        }\r\n        System.exit(-1);\r\n    } else {\r\n        LOG.info(\"Schema creation finished successfully\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "createAllTables",
  "errType" : [ "IOException", "IOException", "IOException", "IOException", "IOException", "IOException", "IOException" ],
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void createAllTables(Configuration hbaseConf, boolean skipExisting) throws IOException\n{\r\n    Connection conn = null;\r\n    try {\r\n        conn = ConnectionFactory.createConnection(hbaseConf);\r\n        Admin admin = conn.getAdmin();\r\n        if (admin == null) {\r\n            throw new IOException(\"Cannot create table since admin is null\");\r\n        }\r\n        try {\r\n            new EntityTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n        try {\r\n            new AppToFlowTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n        try {\r\n            new ApplicationTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n        try {\r\n            new FlowRunTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n        try {\r\n            new FlowActivityTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n        try {\r\n            new SubApplicationTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n        try {\r\n            new DomainTableRW().createTable(admin, hbaseConf);\r\n        } catch (IOException e) {\r\n            if (skipExisting) {\r\n                LOG.warn(\"Skip and continue on: \" + e.getMessage());\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n    } finally {\r\n        if (conn != null) {\r\n            conn.close();\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 8,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\subapplication",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor subAppTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor infoCF = new HColumnDescriptor(SubApplicationColumnFamily.INFO.getBytes());\r\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\r\n    subAppTableDescp.addFamily(infoCF);\r\n    HColumnDescriptor configCF = new HColumnDescriptor(SubApplicationColumnFamily.CONFIGS.getBytes());\r\n    configCF.setBloomFilterType(BloomType.ROWCOL);\r\n    configCF.setBlockCacheEnabled(true);\r\n    subAppTableDescp.addFamily(configCF);\r\n    HColumnDescriptor metricsCF = new HColumnDescriptor(SubApplicationColumnFamily.METRICS.getBytes());\r\n    subAppTableDescp.addFamily(metricsCF);\r\n    metricsCF.setBlockCacheEnabled(true);\r\n    metricsCF.setMinVersions(1);\r\n    metricsCF.setMaxVersions(hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\r\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME, DEFAULT_METRICS_TTL));\r\n    subAppTableDescp.setRegionSplitPolicyClassName(\"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\r\n    subAppTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\", TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\r\n    admin.createTable(subAppTableDescp, TimelineHBaseSchemaConstants.getUsernameSplits());\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\subapplication",
  "methodName" : "setMetricsTTL",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTTL(int metricsTTL, Configuration hbaseConf)\n{\r\n    hbaseConf.setInt(METRICS_TTL_CONF_NAME, metricsTTL);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readEntityTypes",
  "errType" : null,
  "containingMethodsNum" : 24,
  "sourceCodeText" : "Set<String> readEntityTypes(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    validateParams();\r\n    augmentParams(hbaseConf, conn);\r\n    Set<String> types = new TreeSet<>();\r\n    TimelineReaderContext context = getContext();\r\n    EntityRowKeyPrefix prefix = new EntityRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId(), context.getAppId());\r\n    byte[] currRowKey = prefix.getRowKeyPrefix();\r\n    byte[] nextRowKey = prefix.getRowKeyPrefix();\r\n    nextRowKey[nextRowKey.length - 1]++;\r\n    FilterList typeFilterList = new FilterList();\r\n    typeFilterList.addFilter(new FirstKeyOnlyFilter());\r\n    typeFilterList.addFilter(new KeyOnlyFilter());\r\n    typeFilterList.addFilter(new PageFilter(1));\r\n    LOG.debug(\"FilterList created for scan is - {}\", typeFilterList);\r\n    int counter = 0;\r\n    while (true) {\r\n        try (ResultScanner results = getResult(hbaseConf, conn, typeFilterList, currRowKey, nextRowKey)) {\r\n            TimelineEntity entity = parseEntityForType(results.next());\r\n            if (entity == null) {\r\n                break;\r\n            }\r\n            ++counter;\r\n            if (!types.add(entity.getType())) {\r\n                LOG.warn(\"Failed to add type \" + entity.getType() + \" to the result set because there is a duplicated copy. \");\r\n            }\r\n            String currType = entity.getType();\r\n            if (LOG.isDebugEnabled()) {\r\n                LOG.debug(\"Current row key: \" + Arrays.toString(currRowKey));\r\n                LOG.debug(\"New entity type discovered: \" + currType);\r\n            }\r\n            currRowKey = getNextRowKey(prefix.getRowKeyPrefix(), currType);\r\n        }\r\n    }\r\n    LOG.debug(\"Scanned {} records for {} types\", counter, types.size());\r\n    return types;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void validateParams()\n{\r\n    if (getContext() == null) {\r\n        throw new NullPointerException(\"context shouldn't be null\");\r\n    }\r\n    if (getContext().getClusterId() == null) {\r\n        throw new NullPointerException(\"clusterId shouldn't be null\");\r\n    }\r\n    if (getContext().getAppId() == null) {\r\n        throw new NullPointerException(\"appId shouldn't be null\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getNextRowKey",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "byte[] getNextRowKey(byte[] currRowKeyPrefix, String entityType)\n{\r\n    if (currRowKeyPrefix == null || entityType == null) {\r\n        return null;\r\n    }\r\n    byte[] entityTypeEncoded = Separator.QUALIFIERS.join(Separator.encode(entityType, Separator.SPACE, Separator.TAB, Separator.QUALIFIERS), Separator.EMPTY_BYTES);\r\n    byte[] currRowKey = new byte[currRowKeyPrefix.length + entityTypeEncoded.length];\r\n    System.arraycopy(currRowKeyPrefix, 0, currRowKey, 0, currRowKeyPrefix.length);\r\n    System.arraycopy(entityTypeEncoded, 0, currRowKey, currRowKeyPrefix.length, entityTypeEncoded.length);\r\n    return HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(currRowKey);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ResultScanner getResult(Configuration hbaseConf, Connection conn, FilterList filterList, byte[] startPrefix, byte[] endPrefix) throws IOException\n{\r\n    Scan scan = new Scan().withStartRow(startPrefix).withStopRow(endPrefix).setFilter(filterList).setSmall(true);\r\n    return ENTITY_TABLE.getResultScanner(hbaseConf, conn, scan);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntityForType",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineEntity parseEntityForType(Result result) throws IOException\n{\r\n    if (result == null || result.isEmpty()) {\r\n        return null;\r\n    }\r\n    TimelineEntity entity = new TimelineEntity();\r\n    EntityRowKey newRowKey = EntityRowKey.parseRowKey(result.getRow());\r\n    entity.setType(newRowKey.getEntityType());\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "getHBaseOperator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Operator getHBaseOperator(TimelineFilterList.Operator op)\n{\r\n    switch(op) {\r\n        case AND:\r\n            return Operator.MUST_PASS_ALL;\r\n        case OR:\r\n            return Operator.MUST_PASS_ONE;\r\n        default:\r\n            throw new IllegalArgumentException(\"Invalid operator\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "getHBaseCompareOp",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CompareOp getHBaseCompareOp(TimelineCompareOp op)\n{\r\n    switch(op) {\r\n        case LESS_THAN:\r\n            return CompareOp.LESS;\r\n        case LESS_OR_EQUAL:\r\n            return CompareOp.LESS_OR_EQUAL;\r\n        case EQUAL:\r\n            return CompareOp.EQUAL;\r\n        case NOT_EQUAL:\r\n            return CompareOp.NOT_EQUAL;\r\n        case GREATER_OR_EQUAL:\r\n            return CompareOp.GREATER_OR_EQUAL;\r\n        case GREATER_THAN:\r\n            return CompareOp.GREATER;\r\n        default:\r\n            throw new IllegalArgumentException(\"Invalid compare operator\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createHBaseColQualPrefixFilter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Filter createHBaseColQualPrefixFilter(ColumnPrefix<T> colPrefix, TimelinePrefixFilter filter)\n{\r\n    return new QualifierFilter(getHBaseCompareOp(filter.getCompareOp()), new BinaryPrefixComparator(colPrefix.getColumnPrefixBytes(filter.getPrefix())));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createHBaseQualifierFilter",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Filter createHBaseQualifierFilter(CompareOp compareOp, ColumnPrefix<T> columnPrefix)\n{\r\n    return new QualifierFilter(compareOp, new BinaryPrefixComparator(columnPrefix.getColumnPrefixBytes(\"\")));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createFilterForConfsOrMetricsToRetrieve",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Filter createFilterForConfsOrMetricsToRetrieve(TimelineFilterList confsOrMetricToRetrieve, ColumnFamily<T> columnFamily, ColumnPrefix<T> columnPrefix) throws IOException\n{\r\n    Filter familyFilter = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(columnFamily.getBytes()));\r\n    if (confsOrMetricToRetrieve != null && !confsOrMetricToRetrieve.getFilterList().isEmpty()) {\r\n        FilterList filter = new FilterList(familyFilter);\r\n        filter.addFilter(createHBaseFilterList(columnPrefix, confsOrMetricToRetrieve));\r\n        return filter;\r\n    } else {\r\n        return familyFilter;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createSingleColValueFiltersByRange",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "FilterList createSingleColValueFiltersByRange(Column<T> column, Object startValue, Object endValue) throws IOException\n{\r\n    FilterList list = new FilterList();\r\n    Filter singleColValFilterStart = createHBaseSingleColValueFilter(column.getColumnFamilyBytes(), column.getColumnQualifierBytes(), column.getValueConverter().encodeValue(startValue), CompareOp.GREATER_OR_EQUAL, true);\r\n    list.addFilter(singleColValFilterStart);\r\n    Filter singleColValFilterEnd = createHBaseSingleColValueFilter(column.getColumnFamilyBytes(), column.getColumnQualifierBytes(), column.getValueConverter().encodeValue(endValue), CompareOp.LESS_OR_EQUAL, true);\r\n    list.addFilter(singleColValFilterEnd);\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createHBaseSingleColValueFilter",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Filter createHBaseSingleColValueFilter(Column<T> column, Object value, CompareOp op) throws IOException\n{\r\n    Filter singleColValFilter = createHBaseSingleColValueFilter(column.getColumnFamilyBytes(), column.getColumnQualifierBytes(), column.getValueConverter().encodeValue(value), op, true);\r\n    return singleColValFilter;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createHBaseSingleColValueFilter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "SingleColumnValueFilter createHBaseSingleColValueFilter(byte[] columnFamily, byte[] columnQualifier, byte[] value, CompareOp compareOp, boolean filterIfMissing) throws IOException\n{\r\n    SingleColumnValueFilter singleColValFilter = new SingleColumnValueFilter(columnFamily, columnQualifier, compareOp, new BinaryComparator(value));\r\n    singleColValFilter.setLatestVersionOnly(true);\r\n    singleColValFilter.setFilterIfMissing(filterIfMissing);\r\n    return singleColValFilter;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "fetchColumnsFromFilterList",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "Set<String> fetchColumnsFromFilterList(TimelineFilterList filterList)\n{\r\n    Set<String> strSet = new HashSet<String>();\r\n    for (TimelineFilter filter : filterList.getFilterList()) {\r\n        switch(filter.getFilterType()) {\r\n            case LIST:\r\n                strSet.addAll(fetchColumnsFromFilterList((TimelineFilterList) filter));\r\n                break;\r\n            case KEY_VALUES:\r\n                strSet.add(((TimelineKeyValuesFilter) filter).getKey());\r\n                break;\r\n            case EXISTS:\r\n                strSet.add(((TimelineExistsFilter) filter).getValue());\r\n                break;\r\n            default:\r\n                LOG.info(\"Unexpected filter type \" + filter.getFilterType());\r\n                break;\r\n        }\r\n    }\r\n    return strSet;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\reader\\filter",
  "methodName" : "createHBaseFilterList",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "FilterList createHBaseFilterList(ColumnPrefix<T> colPrefix, TimelineFilterList filterList) throws IOException\n{\r\n    FilterList list = new FilterList(getHBaseOperator(filterList.getOperator()));\r\n    for (TimelineFilter filter : filterList.getFilterList()) {\r\n        switch(filter.getFilterType()) {\r\n            case LIST:\r\n                list.addFilter(createHBaseFilterList(colPrefix, (TimelineFilterList) filter));\r\n                break;\r\n            case PREFIX:\r\n                list.addFilter(createHBaseColQualPrefixFilter(colPrefix, (TimelinePrefixFilter) filter));\r\n                break;\r\n            case COMPARE:\r\n                TimelineCompareFilter compareFilter = (TimelineCompareFilter) filter;\r\n                list.addFilter(createHBaseSingleColValueFilter(colPrefix.getColumnFamilyBytes(), colPrefix.getColumnPrefixBytes(compareFilter.getKey()), colPrefix.getValueConverter().encodeValue(compareFilter.getValue()), getHBaseCompareOp(compareFilter.getCompareOp()), compareFilter.getKeyMustExist()));\r\n                break;\r\n            case KEY_VALUE:\r\n                TimelineKeyValueFilter kvFilter = (TimelineKeyValueFilter) filter;\r\n                list.addFilter(createHBaseSingleColValueFilter(colPrefix.getColumnFamilyBytes(), colPrefix.getColumnPrefixBytes(kvFilter.getKey()), colPrefix.getValueConverter().encodeValue(kvFilter.getValue()), getHBaseCompareOp(kvFilter.getCompareOp()), kvFilter.getKeyMustExist()));\r\n                break;\r\n            default:\r\n                LOG.info(\"Unexpected filter type \" + filter.getFilterType());\r\n                break;\r\n        }\r\n    }\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getUsernameSplits",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "byte[][] getUsernameSplits()\n{\r\n    byte[][] kloon = USERNAME_SPLITS.clone();\r\n    for (int row = 0; row < USERNAME_SPLITS.length; row++) {\r\n        kloon[row] = Bytes.copy(USERNAME_SPLITS[row]);\r\n    }\r\n    return kloon;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TableName getName()\n{\r\n    return bufferedMutator.getName();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getConfiguration",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Configuration getConfiguration()\n{\r\n    return bufferedMutator.getConfiguration();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "mutate",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mutate(Mutation mutation) throws IOException\n{\r\n    bufferedMutator.mutate(mutation);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "mutate",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mutate(List<? extends Mutation> mutations) throws IOException\n{\r\n    bufferedMutator.mutate(mutations);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    bufferedMutator.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "flush",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void flush() throws IOException\n{\r\n    bufferedMutator.flush();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getWriteBufferSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getWriteBufferSize()\n{\r\n    return bufferedMutator.getWriteBufferSize();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BaseTableRW<?> getTable()\n{\r\n    return APPLICATION_TABLE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFilters() throws IOException\n{\r\n    TimelineEntityFilters filters = getFilters();\r\n    FilterList listBasedOnFilters = new FilterList();\r\n    long createdTimeBegin = filters.getCreatedTimeBegin();\r\n    long createdTimeEnd = filters.getCreatedTimeEnd();\r\n    if (createdTimeBegin != 0 || createdTimeEnd != Long.MAX_VALUE) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createSingleColValueFiltersByRange(ApplicationColumn.CREATED_TIME, createdTimeBegin, createdTimeEnd));\r\n    }\r\n    TimelineFilterList metricFilters = filters.getMetricFilters();\r\n    if (metricFilters != null && !metricFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(ApplicationColumnPrefix.METRIC, metricFilters));\r\n    }\r\n    TimelineFilterList configFilters = filters.getConfigFilters();\r\n    if (configFilters != null && !configFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(ApplicationColumnPrefix.CONFIG, configFilters));\r\n    }\r\n    TimelineFilterList infoFilters = filters.getInfoFilters();\r\n    if (infoFilters != null && !infoFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(ApplicationColumnPrefix.INFO, infoFilters));\r\n    }\r\n    return listBasedOnFilters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFixedColumns",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void updateFixedColumns(FilterList list)\n{\r\n    for (ApplicationColumn column : ApplicationColumn.values()) {\r\n        list.addFilter(new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(column.getColumnQualifierBytes())));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createFilterListForColsOfInfoFamily",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "FilterList createFilterListForColsOfInfoFamily() throws IOException\n{\r\n    FilterList infoFamilyColsFilter = new FilterList(Operator.MUST_PASS_ONE);\r\n    updateFixedColumns(infoFamilyColsFilter);\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (hasField(fieldsToRetrieve, Field.INFO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, ApplicationColumnPrefix.INFO));\r\n    }\r\n    TimelineFilterList relatesTo = getFilters().getRelatesTo();\r\n    if (hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, ApplicationColumnPrefix.RELATES_TO));\r\n    } else if (relatesTo != null && !relatesTo.getFilterList().isEmpty()) {\r\n        Set<String> relatesToCols = TimelineFilterUtils.fetchColumnsFromFilterList(relatesTo);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(ApplicationColumnPrefix.RELATES_TO, relatesToCols));\r\n    }\r\n    TimelineFilterList isRelatedTo = getFilters().getIsRelatedTo();\r\n    if (hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, ApplicationColumnPrefix.IS_RELATED_TO));\r\n    } else if (isRelatedTo != null && !isRelatedTo.getFilterList().isEmpty()) {\r\n        Set<String> isRelatedToCols = TimelineFilterUtils.fetchColumnsFromFilterList(isRelatedTo);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(ApplicationColumnPrefix.IS_RELATED_TO, isRelatedToCols));\r\n    }\r\n    TimelineFilterList eventFilters = getFilters().getEventFilters();\r\n    if (hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, ApplicationColumnPrefix.EVENT));\r\n    } else if (eventFilters != null && !eventFilters.getFilterList().isEmpty()) {\r\n        Set<String> eventCols = TimelineFilterUtils.fetchColumnsFromFilterList(eventFilters);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(ApplicationColumnPrefix.EVENT, eventCols));\r\n    }\r\n    return infoFamilyColsFilter;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "excludeFieldsFromInfoColFamily",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void excludeFieldsFromInfoColFamily(FilterList infoColFamilyList)\n{\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (!hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, ApplicationColumnPrefix.EVENT));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.INFO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, ApplicationColumnPrefix.INFO));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, ApplicationColumnPrefix.IS_RELATED_TO));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, ApplicationColumnPrefix.RELATES_TO));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFilterForConfsAndMetricsToRetrieve",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void updateFilterForConfsAndMetricsToRetrieve(FilterList listBasedOnFields, Set<String> cfsInFields) throws IOException\n{\r\n    TimelineDataToRetrieve dataToRetrieve = getDataToRetrieve();\r\n    if (dataToRetrieve.getFieldsToRetrieve().contains(Field.CONFIGS)) {\r\n        listBasedOnFields.addFilter(TimelineFilterUtils.createFilterForConfsOrMetricsToRetrieve(dataToRetrieve.getConfsToRetrieve(), ApplicationColumnFamily.CONFIGS, ApplicationColumnPrefix.CONFIG));\r\n        cfsInFields.add(Bytes.toString(ApplicationColumnFamily.CONFIGS.getBytes()));\r\n    }\r\n    if (dataToRetrieve.getFieldsToRetrieve().contains(Field.METRICS)) {\r\n        listBasedOnFields.addFilter(TimelineFilterUtils.createFilterForConfsOrMetricsToRetrieve(dataToRetrieve.getMetricsToRetrieve(), ApplicationColumnFamily.METRICS, ApplicationColumnPrefix.METRIC));\r\n        cfsInFields.add(Bytes.toString(ApplicationColumnFamily.METRICS.getBytes()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFields(Set<String> cfsInFields) throws IOException\n{\r\n    if (!needCreateFilterListBasedOnFields()) {\r\n        return null;\r\n    }\r\n    FilterList listBasedOnFields = new FilterList(Operator.MUST_PASS_ONE);\r\n    FilterList infoColFamilyList = new FilterList();\r\n    FamilyFilter infoColumnFamily = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(ApplicationColumnFamily.INFO.getBytes()));\r\n    infoColFamilyList.addFilter(infoColumnFamily);\r\n    if (!isSingleEntityRead() && fetchPartialColsFromInfoFamily()) {\r\n        infoColFamilyList.addFilter(createFilterListForColsOfInfoFamily());\r\n    } else {\r\n        excludeFieldsFromInfoColFamily(infoColFamilyList);\r\n    }\r\n    listBasedOnFields.addFilter(infoColFamilyList);\r\n    cfsInFields.add(Bytes.toString(ApplicationColumnFamily.INFO.getBytes()));\r\n    updateFilterForConfsAndMetricsToRetrieve(listBasedOnFields, cfsInFields);\r\n    return listBasedOnFields;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    TimelineReaderContext context = getContext();\r\n    ApplicationRowKey applicationRowKey = new ApplicationRowKey(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId(), context.getAppId());\r\n    byte[] rowKey = applicationRowKey.getRowKey();\r\n    Get get = new Get(rowKey);\r\n    setMetricsTimeRange(get);\r\n    get.setMaxVersions(getDataToRetrieve().getMetricsLimit());\r\n    if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n        get.setFilter(filterList);\r\n    }\r\n    return getTable().getResult(hbaseConf, conn, get);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void validateParams()\n{\r\n    if (getContext() == null) {\r\n        throw new NullPointerException(\"context shouldn't be null\");\r\n    }\r\n    if (getDataToRetrieve() == null) {\r\n        throw new NullPointerException(\"data to retrieve shouldn't be null\");\r\n    }\r\n    if (getContext().getClusterId() == null) {\r\n        throw new NullPointerException(\"clusterId shouldn't be null\");\r\n    }\r\n    if (getContext().getEntityType() == null) {\r\n        throw new NullPointerException(\"entityType shouldn't be null\");\r\n    }\r\n    if (isSingleEntityRead()) {\r\n        if (getContext().getAppId() == null) {\r\n            throw new NullPointerException(\"appId shouldn't be null\");\r\n        }\r\n    } else {\r\n        if (getContext().getUserId() == null) {\r\n            throw new NullPointerException(\"userId shouldn't be null\");\r\n        }\r\n        if (getContext().getFlowName() == null) {\r\n            throw new NullPointerException(\"flowName shouldn't be null\");\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "augmentParams",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void augmentParams(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    if (isSingleEntityRead()) {\r\n        defaultAugmentParams(hbaseConf, conn);\r\n    }\r\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\r\n    if (!isSingleEntityRead()) {\r\n        createFiltersIfNull();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "setMetricsTimeRange",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTimeRange(Query query)\n{\r\n    HBaseTimelineStorageUtils.setMetricsTimeRange(query, ApplicationColumnFamily.METRICS.getBytes(), getDataToRetrieve().getMetricsTimeBegin(), getDataToRetrieve().getMetricsTimeEnd());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResults",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 23,
  "sourceCodeText" : "ResultScanner getResults(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    Scan scan = new Scan();\r\n    TimelineReaderContext context = getContext();\r\n    RowKeyPrefix<ApplicationRowKey> applicationRowKeyPrefix = null;\r\n    if (getFilters().getFromId() == null) {\r\n        applicationRowKeyPrefix = new ApplicationRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId());\r\n        scan.setRowPrefixFilter(applicationRowKeyPrefix.getRowKeyPrefix());\r\n    } else {\r\n        ApplicationRowKey applicationRowKey = null;\r\n        try {\r\n            applicationRowKey = ApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\r\n        } catch (IllegalArgumentException e) {\r\n            throw new BadRequestException(\"Invalid filter fromid is provided.\");\r\n        }\r\n        if (!context.getClusterId().equals(applicationRowKey.getClusterId())) {\r\n            throw new BadRequestException(\"fromid doesn't belong to clusterId=\" + context.getClusterId());\r\n        }\r\n        scan.withStartRow(applicationRowKey.getRowKey());\r\n        applicationRowKeyPrefix = new ApplicationRowKeyPrefix(context.getClusterId(), context.getUserId(), context.getFlowName(), context.getFlowRunId());\r\n        scan.withStopRow(HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(applicationRowKeyPrefix.getRowKeyPrefix()));\r\n    }\r\n    FilterList newList = new FilterList();\r\n    newList.addFilter(new PageFilter(getFilters().getLimit()));\r\n    if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n        newList.addFilter(filterList);\r\n    }\r\n    scan.setFilter(newList);\r\n    setMetricsTimeRange(scan);\r\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\r\n    return getTable().getResultScanner(hbaseConf, conn, scan);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntity",
  "errType" : null,
  "containingMethodsNum" : 40,
  "sourceCodeText" : "TimelineEntity parseEntity(Result result) throws IOException\n{\r\n    if (result == null || result.isEmpty()) {\r\n        return null;\r\n    }\r\n    TimelineEntity entity = new TimelineEntity();\r\n    entity.setType(TimelineEntityType.YARN_APPLICATION.toString());\r\n    String entityId = ColumnRWHelper.readResult(result, ApplicationColumn.ID).toString();\r\n    entity.setId(entityId);\r\n    TimelineEntityFilters filters = getFilters();\r\n    Long createdTime = (Long) ColumnRWHelper.readResult(result, ApplicationColumn.CREATED_TIME);\r\n    entity.setCreatedTime(createdTime);\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    boolean checkIsRelatedTo = !isSingleEntityRead() && filters.getIsRelatedTo() != null && filters.getIsRelatedTo().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.IS_RELATED_TO) || checkIsRelatedTo) {\r\n        readRelationship(entity, result, ApplicationColumnPrefix.IS_RELATED_TO, true);\r\n        if (checkIsRelatedTo && !TimelineStorageUtils.matchIsRelatedTo(entity, filters.getIsRelatedTo())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n            entity.getIsRelatedToEntities().clear();\r\n        }\r\n    }\r\n    boolean checkRelatesTo = !isSingleEntityRead() && filters.getRelatesTo() != null && filters.getRelatesTo().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.RELATES_TO) || checkRelatesTo) {\r\n        readRelationship(entity, result, ApplicationColumnPrefix.RELATES_TO, false);\r\n        if (checkRelatesTo && !TimelineStorageUtils.matchRelatesTo(entity, filters.getRelatesTo())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n            entity.getRelatesToEntities().clear();\r\n        }\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.INFO)) {\r\n        readKeyValuePairs(entity, result, ApplicationColumnPrefix.INFO, false);\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.CONFIGS)) {\r\n        readKeyValuePairs(entity, result, ApplicationColumnPrefix.CONFIG, true);\r\n    }\r\n    boolean checkEvents = !isSingleEntityRead() && filters.getEventFilters() != null && filters.getEventFilters().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.EVENTS) || checkEvents) {\r\n        readEvents(entity, result, ApplicationColumnPrefix.EVENT);\r\n        if (checkEvents && !TimelineStorageUtils.matchEventFilters(entity, filters.getEventFilters())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n            entity.getEvents().clear();\r\n        }\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.METRICS)) {\r\n        readMetrics(entity, result, ApplicationColumnPrefix.METRIC);\r\n    }\r\n    ApplicationRowKey rowKey = ApplicationRowKey.parseRowKey(result.getRow());\r\n    entity.getInfo().put(TimelineReaderUtils.FROMID_KEY, rowKey.getRowKeyAsString());\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\entity",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor entityTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor infoCF = new HColumnDescriptor(EntityColumnFamily.INFO.getBytes());\r\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\r\n    entityTableDescp.addFamily(infoCF);\r\n    HColumnDescriptor configCF = new HColumnDescriptor(EntityColumnFamily.CONFIGS.getBytes());\r\n    configCF.setBloomFilterType(BloomType.ROWCOL);\r\n    configCF.setBlockCacheEnabled(true);\r\n    entityTableDescp.addFamily(configCF);\r\n    HColumnDescriptor metricsCF = new HColumnDescriptor(EntityColumnFamily.METRICS.getBytes());\r\n    entityTableDescp.addFamily(metricsCF);\r\n    metricsCF.setBlockCacheEnabled(true);\r\n    metricsCF.setMinVersions(1);\r\n    metricsCF.setMaxVersions(hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\r\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME, DEFAULT_METRICS_TTL));\r\n    entityTableDescp.setRegionSplitPolicyClassName(\"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\r\n    entityTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\", TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\r\n    admin.createTable(entityTableDescp, TimelineHBaseSchemaConstants.getUsernameSplits());\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\entity",
  "methodName" : "setMetricsTTL",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTTL(int metricsTTL, Configuration hbaseConf)\n{\r\n    hbaseConf.setInt(METRICS_TTL_CONF_NAME, metricsTTL);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFields(Set<String> cfsInFields) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFilters() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createFilterList",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "FilterList createFilterList() throws IOException\n{\r\n    FilterList listBasedOnFilters = constructFilterListBasedOnFilters();\r\n    boolean hasListBasedOnFilters = listBasedOnFilters != null && !listBasedOnFilters.getFilters().isEmpty();\r\n    Set<String> cfsInListBasedOnFields = new HashSet<>(0);\r\n    FilterList listBasedOnFields = constructFilterListBasedOnFields(cfsInListBasedOnFields);\r\n    boolean hasListBasedOnFields = listBasedOnFields != null && !listBasedOnFields.getFilters().isEmpty();\r\n    if (hasListBasedOnFilters && hasListBasedOnFields) {\r\n        FilterList list = new FilterList();\r\n        list.addFilter(listBasedOnFilters);\r\n        Set<String> cfsInListBasedOnFilters = new HashSet<>(0);\r\n        extractColumnFamiliesFromFiltersBasedOnFilters(listBasedOnFilters, cfsInListBasedOnFilters);\r\n        cfsInListBasedOnFilters.removeAll(cfsInListBasedOnFields);\r\n        if (!cfsInListBasedOnFilters.isEmpty()) {\r\n            for (String cf : cfsInListBasedOnFilters) {\r\n                listBasedOnFields.addFilter(new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(Bytes.toBytes(cf))));\r\n            }\r\n        }\r\n        list.addFilter(listBasedOnFields);\r\n        return list;\r\n    } else if (hasListBasedOnFilters) {\r\n        return listBasedOnFilters;\r\n    } else if (hasListBasedOnFields) {\r\n        return listBasedOnFields;\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "extractColumnFamiliesFromFiltersBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void extractColumnFamiliesFromFiltersBasedOnFilters(Filter hbaseFilterBasedOnTLSFilter, Set<String> columnFamilies)\n{\r\n    if (hbaseFilterBasedOnTLSFilter instanceof SingleColumnValueFilter) {\r\n        byte[] cf = ((SingleColumnValueFilter) hbaseFilterBasedOnTLSFilter).getFamily();\r\n        columnFamilies.add(Bytes.toString(cf));\r\n    } else if (hbaseFilterBasedOnTLSFilter instanceof FilterList) {\r\n        FilterList filterListBase = (FilterList) hbaseFilterBasedOnTLSFilter;\r\n        for (Filter fs : filterListBase.getFilters()) {\r\n            extractColumnFamiliesFromFiltersBasedOnFilters(fs, columnFamilies);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getDataToRetrieve",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TimelineDataToRetrieve getDataToRetrieve()\n{\r\n    return dataToRetrieve;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getFilters",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TimelineEntityFilters getFilters()\n{\r\n    return filters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createFiltersIfNull",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void createFiltersIfNull()\n{\r\n    if (filters == null) {\r\n        filters = new TimelineEntityFilters.Builder().build();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readEntity",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "TimelineEntity readEntity(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    validateParams();\r\n    augmentParams(hbaseConf, conn);\r\n    FilterList filterList = constructFilterListBasedOnFields(new HashSet<>(0));\r\n    if (filterList != null) {\r\n        LOG.debug(\"FilterList created for get is - {}\", filterList);\r\n    }\r\n    Result result = getResult(hbaseConf, conn, filterList);\r\n    if (result == null || result.isEmpty()) {\r\n        LOG.info(\"Cannot find matching entity of type \" + getContext().getEntityType());\r\n        return null;\r\n    }\r\n    return parseEntity(result);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readEntities",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "Set<TimelineEntity> readEntities(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    validateParams();\r\n    augmentParams(hbaseConf, conn);\r\n    Set<TimelineEntity> entities = new LinkedHashSet<>();\r\n    FilterList filterList = createFilterList();\r\n    if (filterList != null) {\r\n        LOG.debug(\"FilterList created for scan is - {}\", filterList);\r\n    }\r\n    ResultScanner results = getResults(hbaseConf, conn, filterList);\r\n    try {\r\n        for (Result result : results) {\r\n            TimelineEntity entity = parseEntity(result);\r\n            if (entity == null) {\r\n                continue;\r\n            }\r\n            entities.add(entity);\r\n            if (entities.size() == filters.getLimit()) {\r\n                break;\r\n            }\r\n        }\r\n        return entities;\r\n    } finally {\r\n        results.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BaseTableRW<?> getTable()\n{\r\n    return table;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResults",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ResultScanner getResults(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntity",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TimelineEntity parseEntity(Result result) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readMetrics",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void readMetrics(TimelineEntity entity, Result result, ColumnPrefix<?> columnPrefix) throws IOException\n{\r\n    NavigableMap<String, NavigableMap<Long, Number>> metricsResult = ColumnRWHelper.readResultsWithTimestamps(result, columnPrefix, stringKeyConverter);\r\n    for (Map.Entry<String, NavigableMap<Long, Number>> metricResult : metricsResult.entrySet()) {\r\n        TimelineMetric metric = new TimelineMetric();\r\n        metric.setId(metricResult.getKey());\r\n        TimelineMetric.Type metricType = metricResult.getValue().size() > 1 ? TimelineMetric.Type.TIME_SERIES : TimelineMetric.Type.SINGLE_VALUE;\r\n        metric.setType(metricType);\r\n        metric.addValues(metricResult.getValue());\r\n        entity.addMetric(metric);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "isSingleEntityRead",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isSingleEntityRead()\n{\r\n    return singleEntityRead;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "setTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTable(BaseTableRW<?> baseTable)\n{\r\n    this.table = baseTable;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "hasField",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean hasField(EnumSet<Field> fieldsToRetrieve, Field requiredField)\n{\r\n    return fieldsToRetrieve.contains(Field.ALL) || fieldsToRetrieve.contains(requiredField);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createFiltersFromColumnQualifiers",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "FilterList createFiltersFromColumnQualifiers(ColumnPrefix<T> colPrefix, Set<String> columns)\n{\r\n    FilterList list = new FilterList(Operator.MUST_PASS_ONE);\r\n    for (String column : columns) {\r\n        byte[] compoundColQual = createColQualifierPrefix(colPrefix, column);\r\n        list.addFilter(new QualifierFilter(CompareOp.EQUAL, new BinaryPrefixComparator(colPrefix.getColumnPrefixBytes(compoundColQual))));\r\n    }\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createColQualifierPrefix",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "byte[] createColQualifierPrefix(ColumnPrefix<T> colPrefix, String column)\n{\r\n    if (colPrefix == ApplicationColumnPrefix.EVENT || colPrefix == EntityColumnPrefix.EVENT) {\r\n        return new EventColumnName(column, null, null).getColumnQualifier();\r\n    } else {\r\n        return stringKeyConverter.encode(column);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readRelationship",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void readRelationship(TimelineEntity entity, Result result, ColumnPrefix<T> prefix, boolean isRelatedTo) throws IOException\n{\r\n    Map<String, Object> columns = ColumnRWHelper.readResults(result, prefix, stringKeyConverter);\r\n    for (Map.Entry<String, Object> column : columns.entrySet()) {\r\n        for (String id : Separator.VALUES.splitEncoded(column.getValue().toString())) {\r\n            if (isRelatedTo) {\r\n                entity.addIsRelatedToEntity(column.getKey(), id);\r\n            } else {\r\n                entity.addRelatesToEntity(column.getKey(), id);\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "readEvents",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void readEvents(TimelineEntity entity, Result result, ColumnPrefix<T> prefix) throws IOException\n{\r\n    Map<String, TimelineEvent> eventsMap = new HashMap<>();\r\n    Map<EventColumnName, Object> eventsResult = ColumnRWHelper.readResults(result, prefix, new EventColumnNameConverter());\r\n    for (Map.Entry<EventColumnName, Object> eventResult : eventsResult.entrySet()) {\r\n        EventColumnName eventColumnName = eventResult.getKey();\r\n        String key = eventColumnName.getId() + Long.toString(eventColumnName.getTimestamp());\r\n        TimelineEvent event = eventsMap.get(key);\r\n        if (event == null) {\r\n            event = new TimelineEvent();\r\n            event.setId(eventColumnName.getId());\r\n            event.setTimestamp(eventColumnName.getTimestamp());\r\n            eventsMap.put(key, event);\r\n        }\r\n        if (eventColumnName.getInfoKey() != null) {\r\n            event.addInfo(eventColumnName.getInfoKey(), eventResult.getValue());\r\n        }\r\n    }\r\n    Set<TimelineEvent> eventsSet = new HashSet<>(eventsMap.values());\r\n    entity.addEvents(eventsSet);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\flow",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor flowRunTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor infoCF = new HColumnDescriptor(FlowRunColumnFamily.INFO.getBytes());\r\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\r\n    flowRunTableDescp.addFamily(infoCF);\r\n    infoCF.setMinVersions(1);\r\n    infoCF.setMaxVersions(DEFAULT_METRICS_MAX_VERSIONS);\r\n    String coprocessorJarPathStr = hbaseConf.get(YarnConfiguration.FLOW_RUN_COPROCESSOR_JAR_HDFS_LOCATION, YarnConfiguration.DEFAULT_HDFS_LOCATION_FLOW_RUN_COPROCESSOR_JAR);\r\n    Path coprocessorJarPath = new Path(coprocessorJarPathStr);\r\n    LOG.info(\"CoprocessorJarPath=\" + coprocessorJarPath.toString());\r\n    flowRunTableDescp.addCoprocessor(\"org.apache.hadoop.yarn.server.timelineservice.storage.\" + \"flow.FlowRunCoprocessor\", coprocessorJarPath, Coprocessor.PRIORITY_USER, null);\r\n    admin.createTable(flowRunTableDescp);\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\application",
  "methodName" : "createTable",
  "errType" : null,
  "containingMethodsNum" : 20,
  "sourceCodeText" : "void createTable(Admin admin, Configuration hbaseConf) throws IOException\n{\r\n    TableName table = getTableName(hbaseConf);\r\n    if (admin.tableExists(table)) {\r\n        throw new IOException(\"Table \" + table.getNameAsString() + \" already exists.\");\r\n    }\r\n    HTableDescriptor applicationTableDescp = new HTableDescriptor(table);\r\n    HColumnDescriptor infoCF = new HColumnDescriptor(ApplicationColumnFamily.INFO.getBytes());\r\n    infoCF.setBloomFilterType(BloomType.ROWCOL);\r\n    applicationTableDescp.addFamily(infoCF);\r\n    HColumnDescriptor configCF = new HColumnDescriptor(ApplicationColumnFamily.CONFIGS.getBytes());\r\n    configCF.setBloomFilterType(BloomType.ROWCOL);\r\n    configCF.setBlockCacheEnabled(true);\r\n    applicationTableDescp.addFamily(configCF);\r\n    HColumnDescriptor metricsCF = new HColumnDescriptor(ApplicationColumnFamily.METRICS.getBytes());\r\n    applicationTableDescp.addFamily(metricsCF);\r\n    metricsCF.setBlockCacheEnabled(true);\r\n    metricsCF.setMinVersions(1);\r\n    metricsCF.setMaxVersions(hbaseConf.getInt(METRICS_MAX_VERSIONS, DEFAULT_METRICS_MAX_VERSIONS));\r\n    metricsCF.setTimeToLive(hbaseConf.getInt(METRICS_TTL_CONF_NAME, DEFAULT_METRICS_TTL));\r\n    applicationTableDescp.setRegionSplitPolicyClassName(\"org.apache.hadoop.hbase.regionserver.KeyPrefixRegionSplitPolicy\");\r\n    applicationTableDescp.setValue(\"KeyPrefixRegionSplitPolicy.prefix_length\", TimelineHBaseSchemaConstants.USERNAME_SPLIT_KEY_PREFIX_LENGTH);\r\n    admin.createTable(applicationTableDescp, TimelineHBaseSchemaConstants.getUsernameSplits());\r\n    LOG.info(\"Status of table creation for \" + table.getNameAsString() + \"=\" + admin.tableExists(table));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\application",
  "methodName" : "setMetricsTTL",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTTL(int metricsTTL, Configuration hbaseConf)\n{\r\n    hbaseConf.setInt(METRICS_TTL_CONF_NAME, metricsTTL);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getContext",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TimelineReaderContext getContext()\n{\r\n    return context;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "lookupFlowContext",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "FlowContext lookupFlowContext(AppToFlowRowKey appToFlowRowKey, String clusterId, Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    byte[] rowKey = appToFlowRowKey.getRowKey();\r\n    Get get = new Get(rowKey);\r\n    Result result = appToFlowTable.getResult(hbaseConf, conn, get);\r\n    if (result != null && !result.isEmpty()) {\r\n        Object flowName = ColumnRWHelper.readResult(result, AppToFlowColumnPrefix.FLOW_NAME, clusterId);\r\n        Object flowRunId = ColumnRWHelper.readResult(result, AppToFlowColumnPrefix.FLOW_RUN_ID, clusterId);\r\n        Object userId = ColumnRWHelper.readResult(result, AppToFlowColumnPrefix.USER_ID, clusterId);\r\n        if (flowName == null || userId == null || flowRunId == null) {\r\n            throw new NotFoundException(\"Unable to find the context flow name, and flow run id, \" + \"and user id for clusterId=\" + clusterId + \", appId=\" + appToFlowRowKey.getAppId());\r\n        }\r\n        return new FlowContext((String) userId, (String) flowName, ((Number) flowRunId).longValue());\r\n    } else {\r\n        throw new NotFoundException(\"Unable to find the context flow name, and flow run id, \" + \"and user id for clusterId=\" + clusterId + \", appId=\" + appToFlowRowKey.getAppId());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "augmentParams",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void augmentParams(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    defaultAugmentParams(hbaseConf, conn);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "defaultAugmentParams",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void defaultAugmentParams(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    if (context.getFlowName() == null || context.getFlowRunId() == null || context.getUserId() == null) {\r\n        AppToFlowRowKey appToFlowRowKey = new AppToFlowRowKey(context.getAppId());\r\n        FlowContext flowContext = lookupFlowContext(appToFlowRowKey, context.getClusterId(), hbaseConf, conn);\r\n        context.setFlowName(flowContext.flowName);\r\n        context.setFlowRunId(flowContext.flowRunId);\r\n        context.setUserId(flowContext.userId);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void validateParams()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BaseTableRW<?> getTable()\n{\r\n    return SUB_APPLICATION_TABLE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFilters() throws IOException\n{\r\n    FilterList listBasedOnFilters = new FilterList();\r\n    TimelineEntityFilters filters = getFilters();\r\n    long createdTimeBegin = filters.getCreatedTimeBegin();\r\n    long createdTimeEnd = filters.getCreatedTimeEnd();\r\n    if (createdTimeBegin != 0 || createdTimeEnd != Long.MAX_VALUE) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createSingleColValueFiltersByRange(SubApplicationColumn.CREATED_TIME, createdTimeBegin, createdTimeEnd));\r\n    }\r\n    TimelineFilterList metricFilters = filters.getMetricFilters();\r\n    if (metricFilters != null && !metricFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(SubApplicationColumnPrefix.METRIC, metricFilters));\r\n    }\r\n    TimelineFilterList configFilters = filters.getConfigFilters();\r\n    if (configFilters != null && !configFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(SubApplicationColumnPrefix.CONFIG, configFilters));\r\n    }\r\n    TimelineFilterList infoFilters = filters.getInfoFilters();\r\n    if (infoFilters != null && !infoFilters.getFilterList().isEmpty()) {\r\n        listBasedOnFilters.addFilter(TimelineFilterUtils.createHBaseFilterList(SubApplicationColumnPrefix.INFO, infoFilters));\r\n    }\r\n    return listBasedOnFilters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFixedColumns",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void updateFixedColumns(FilterList list)\n{\r\n    for (SubApplicationColumn column : SubApplicationColumn.values()) {\r\n        list.addFilter(new QualifierFilter(CompareOp.EQUAL, new BinaryComparator(column.getColumnQualifierBytes())));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "createFilterListForColsOfInfoFamily",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "FilterList createFilterListForColsOfInfoFamily() throws IOException\n{\r\n    FilterList infoFamilyColsFilter = new FilterList(Operator.MUST_PASS_ONE);\r\n    updateFixedColumns(infoFamilyColsFilter);\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (hasField(fieldsToRetrieve, Field.INFO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, SubApplicationColumnPrefix.INFO));\r\n    }\r\n    TimelineFilterList relatesTo = getFilters().getRelatesTo();\r\n    if (hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, SubApplicationColumnPrefix.RELATES_TO));\r\n    } else if (relatesTo != null && !relatesTo.getFilterList().isEmpty()) {\r\n        Set<String> relatesToCols = TimelineFilterUtils.fetchColumnsFromFilterList(relatesTo);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(SubApplicationColumnPrefix.RELATES_TO, relatesToCols));\r\n    }\r\n    TimelineFilterList isRelatedTo = getFilters().getIsRelatedTo();\r\n    if (hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, SubApplicationColumnPrefix.IS_RELATED_TO));\r\n    } else if (isRelatedTo != null && !isRelatedTo.getFilterList().isEmpty()) {\r\n        Set<String> isRelatedToCols = TimelineFilterUtils.fetchColumnsFromFilterList(isRelatedTo);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(SubApplicationColumnPrefix.IS_RELATED_TO, isRelatedToCols));\r\n    }\r\n    TimelineFilterList eventFilters = getFilters().getEventFilters();\r\n    if (hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n        infoFamilyColsFilter.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.EQUAL, SubApplicationColumnPrefix.EVENT));\r\n    } else if (eventFilters != null && !eventFilters.getFilterList().isEmpty()) {\r\n        Set<String> eventCols = TimelineFilterUtils.fetchColumnsFromFilterList(eventFilters);\r\n        infoFamilyColsFilter.addFilter(createFiltersFromColumnQualifiers(SubApplicationColumnPrefix.EVENT, eventCols));\r\n    }\r\n    return infoFamilyColsFilter;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "excludeFieldsFromInfoColFamily",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void excludeFieldsFromInfoColFamily(FilterList infoColFamilyList)\n{\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    if (!hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, SubApplicationColumnPrefix.EVENT));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.INFO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, SubApplicationColumnPrefix.INFO));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, SubApplicationColumnPrefix.IS_RELATED_TO));\r\n    }\r\n    if (!hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n        infoColFamilyList.addFilter(TimelineFilterUtils.createHBaseQualifierFilter(CompareOp.NOT_EQUAL, SubApplicationColumnPrefix.RELATES_TO));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "updateFilterForConfsAndMetricsToRetrieve",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void updateFilterForConfsAndMetricsToRetrieve(FilterList listBasedOnFields, Set<String> cfsInFields) throws IOException\n{\r\n    TimelineDataToRetrieve dataToRetrieve = getDataToRetrieve();\r\n    if (dataToRetrieve.getFieldsToRetrieve().contains(Field.CONFIGS)) {\r\n        listBasedOnFields.addFilter(TimelineFilterUtils.createFilterForConfsOrMetricsToRetrieve(dataToRetrieve.getConfsToRetrieve(), SubApplicationColumnFamily.CONFIGS, SubApplicationColumnPrefix.CONFIG));\r\n        cfsInFields.add(Bytes.toString(SubApplicationColumnFamily.CONFIGS.getBytes()));\r\n    }\r\n    if (dataToRetrieve.getFieldsToRetrieve().contains(Field.METRICS)) {\r\n        listBasedOnFields.addFilter(TimelineFilterUtils.createFilterForConfsOrMetricsToRetrieve(dataToRetrieve.getMetricsToRetrieve(), SubApplicationColumnFamily.METRICS, SubApplicationColumnPrefix.METRIC));\r\n        cfsInFields.add(Bytes.toString(SubApplicationColumnFamily.METRICS.getBytes()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFields(Set<String> cfsInFields) throws IOException\n{\r\n    if (!needCreateFilterListBasedOnFields()) {\r\n        return null;\r\n    }\r\n    FilterList listBasedOnFields = new FilterList(Operator.MUST_PASS_ONE);\r\n    FilterList infoColFamilyList = new FilterList();\r\n    FamilyFilter infoColumnFamily = new FamilyFilter(CompareOp.EQUAL, new BinaryComparator(SubApplicationColumnFamily.INFO.getBytes()));\r\n    infoColFamilyList.addFilter(infoColumnFamily);\r\n    if (fetchPartialColsFromInfoFamily()) {\r\n        infoColFamilyList.addFilter(createFilterListForColsOfInfoFamily());\r\n    } else {\r\n        excludeFieldsFromInfoColFamily(infoColFamilyList);\r\n    }\r\n    listBasedOnFields.addFilter(infoColFamilyList);\r\n    cfsInFields.add(Bytes.toString(SubApplicationColumnFamily.INFO.getBytes()));\r\n    updateFilterForConfsAndMetricsToRetrieve(listBasedOnFields, cfsInFields);\r\n    return listBasedOnFields;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void validateParams()\n{\r\n    if (getContext() == null) {\r\n        throw new NullPointerException(\"context shouldn't be null\");\r\n    }\r\n    if (getDataToRetrieve() == null) {\r\n        throw new NullPointerException(\"data to retrieve shouldn't be null\");\r\n    }\r\n    if (getContext().getClusterId() == null) {\r\n        throw new NullPointerException(\"clusterId shouldn't be null\");\r\n    }\r\n    if (getContext().getDoAsUser() == null) {\r\n        throw new NullPointerException(\"DoAsUser shouldn't be null\");\r\n    }\r\n    if (getContext().getEntityType() == null) {\r\n        throw new NullPointerException(\"entityType shouldn't be null\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "augmentParams",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void augmentParams(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    getDataToRetrieve().addFieldsBasedOnConfsAndMetricsToRetrieve();\r\n    createFiltersIfNull();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "setMetricsTimeRange",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTimeRange(Query query)\n{\r\n    HBaseTimelineStorageUtils.setMetricsTimeRange(query, SubApplicationColumnFamily.METRICS.getBytes(), getDataToRetrieve().getMetricsTimeBegin(), getDataToRetrieve().getMetricsTimeEnd());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResults",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 22,
  "sourceCodeText" : "ResultScanner getResults(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    Scan scan = new Scan();\r\n    TimelineReaderContext context = getContext();\r\n    if (context.getDoAsUser() == null) {\r\n        throw new BadRequestException(\"Invalid user!\");\r\n    }\r\n    RowKeyPrefix<SubApplicationRowKey> subApplicationRowKeyPrefix = null;\r\n    if (getFilters() == null || getFilters().getFromId() == null) {\r\n        subApplicationRowKeyPrefix = new SubApplicationRowKeyPrefix(context.getDoAsUser(), context.getClusterId(), context.getEntityType(), null, null, null);\r\n        scan.setRowPrefixFilter(subApplicationRowKeyPrefix.getRowKeyPrefix());\r\n    } else {\r\n        SubApplicationRowKey entityRowKey = null;\r\n        try {\r\n            entityRowKey = SubApplicationRowKey.parseRowKeyFromString(getFilters().getFromId());\r\n        } catch (IllegalArgumentException e) {\r\n            throw new BadRequestException(\"Invalid filter fromid is provided.\");\r\n        }\r\n        if (!context.getClusterId().equals(entityRowKey.getClusterId())) {\r\n            throw new BadRequestException(\"fromid doesn't belong to clusterId=\" + context.getClusterId());\r\n        }\r\n        scan.withStartRow(entityRowKey.getRowKey());\r\n        subApplicationRowKeyPrefix = new SubApplicationRowKeyPrefix(context.getDoAsUser(), context.getClusterId(), context.getEntityType(), null, null, null);\r\n        scan.withStopRow(HBaseTimelineStorageUtils.calculateTheClosestNextRowKeyForPrefix(subApplicationRowKeyPrefix.getRowKeyPrefix()));\r\n        filterList.addFilter(new PageFilter(getFilters().getLimit()));\r\n    }\r\n    setMetricsTimeRange(scan);\r\n    scan.setMaxVersions(getDataToRetrieve().getMetricsLimit());\r\n    if (filterList != null && !filterList.getFilters().isEmpty()) {\r\n        scan.setFilter(filterList);\r\n    }\r\n    return getTable().getResultScanner(hbaseConf, conn, scan);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"we don't support a single entity query\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntity",
  "errType" : null,
  "containingMethodsNum" : 39,
  "sourceCodeText" : "TimelineEntity parseEntity(Result result) throws IOException\n{\r\n    if (result == null || result.isEmpty()) {\r\n        return null;\r\n    }\r\n    TimelineEntity entity = new TimelineEntity();\r\n    SubApplicationRowKey parseRowKey = SubApplicationRowKey.parseRowKey(result.getRow());\r\n    entity.setType(parseRowKey.getEntityType());\r\n    entity.setId(parseRowKey.getEntityId());\r\n    entity.setIdPrefix(parseRowKey.getEntityIdPrefix().longValue());\r\n    TimelineEntityFilters filters = getFilters();\r\n    Long createdTime = (Long) ColumnRWHelper.readResult(result, SubApplicationColumn.CREATED_TIME);\r\n    entity.setCreatedTime(createdTime);\r\n    EnumSet<Field> fieldsToRetrieve = getDataToRetrieve().getFieldsToRetrieve();\r\n    boolean checkIsRelatedTo = filters.getIsRelatedTo() != null && filters.getIsRelatedTo().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.IS_RELATED_TO) || checkIsRelatedTo) {\r\n        readRelationship(entity, result, SubApplicationColumnPrefix.IS_RELATED_TO, true);\r\n        if (checkIsRelatedTo && !TimelineStorageUtils.matchIsRelatedTo(entity, filters.getIsRelatedTo())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.IS_RELATED_TO)) {\r\n            entity.getIsRelatedToEntities().clear();\r\n        }\r\n    }\r\n    boolean checkRelatesTo = !isSingleEntityRead() && filters.getRelatesTo() != null && filters.getRelatesTo().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.RELATES_TO) || checkRelatesTo) {\r\n        readRelationship(entity, result, SubApplicationColumnPrefix.RELATES_TO, false);\r\n        if (checkRelatesTo && !TimelineStorageUtils.matchRelatesTo(entity, filters.getRelatesTo())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.RELATES_TO)) {\r\n            entity.getRelatesToEntities().clear();\r\n        }\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.INFO)) {\r\n        readKeyValuePairs(entity, result, SubApplicationColumnPrefix.INFO, false);\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.CONFIGS)) {\r\n        readKeyValuePairs(entity, result, SubApplicationColumnPrefix.CONFIG, true);\r\n    }\r\n    boolean checkEvents = !isSingleEntityRead() && filters.getEventFilters() != null && filters.getEventFilters().getFilterList().size() > 0;\r\n    if (hasField(fieldsToRetrieve, Field.EVENTS) || checkEvents) {\r\n        readEvents(entity, result, SubApplicationColumnPrefix.EVENT);\r\n        if (checkEvents && !TimelineStorageUtils.matchEventFilters(entity, filters.getEventFilters())) {\r\n            return null;\r\n        }\r\n        if (!hasField(fieldsToRetrieve, Field.EVENTS)) {\r\n            entity.getEvents().clear();\r\n        }\r\n    }\r\n    if (hasField(fieldsToRetrieve, Field.METRICS)) {\r\n        readMetrics(entity, result, SubApplicationColumnPrefix.METRIC);\r\n    }\r\n    entity.getInfo().put(TimelineReaderUtils.FROMID_KEY, parseRowKey.getRowKeyAsString());\r\n    return entity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "getTimelineServiceHBaseConf",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "Configuration getTimelineServiceHBaseConf(Configuration conf) throws IOException\n{\r\n    if (conf == null) {\r\n        throw new NullPointerException();\r\n    }\r\n    Configuration hbaseConf;\r\n    String timelineServiceHBaseConfFilePath = conf.get(YarnConfiguration.TIMELINE_SERVICE_HBASE_CONFIGURATION_FILE);\r\n    if (timelineServiceHBaseConfFilePath != null && timelineServiceHBaseConfFilePath.length() > 0) {\r\n        LOG.info(\"Using hbase configuration at \" + timelineServiceHBaseConfFilePath);\r\n        hbaseConf = new Configuration(conf);\r\n        Configuration plainHBaseConf = new Configuration(false);\r\n        Path hbaseConfigPath = new Path(timelineServiceHBaseConfFilePath);\r\n        try (FileSystem fs = FileSystem.newInstance(hbaseConfigPath.toUri(), conf);\r\n            FSDataInputStream in = fs.open(hbaseConfigPath)) {\r\n            plainHBaseConf.addResource(in);\r\n            HBaseConfiguration.merge(hbaseConf, plainHBaseConf);\r\n        }\r\n    } else {\r\n        hbaseConf = HBaseConfiguration.create(conf);\r\n    }\r\n    return hbaseConf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "calculateTheClosestNextRowKeyForPrefix",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] calculateTheClosestNextRowKeyForPrefix(byte[] rowKeyPrefix)\n{\r\n    int offset = rowKeyPrefix.length;\r\n    while (offset > 0) {\r\n        if (rowKeyPrefix[offset - 1] != (byte) 0xFF) {\r\n            break;\r\n        }\r\n        offset--;\r\n    }\r\n    if (offset == 0) {\r\n        return HConstants.EMPTY_END_ROW;\r\n    }\r\n    byte[] newStopRow = Arrays.copyOfRange(rowKeyPrefix, 0, offset);\r\n    newStopRow[newStopRow.length - 1]++;\r\n    return newStopRow;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\common",
  "methodName" : "setMetricsTimeRange",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setMetricsTimeRange(Query query, byte[] metricsCf, long tsBegin, long tsEnd)\n{\r\n    if (tsBegin != 0 || tsEnd != Long.MAX_VALUE) {\r\n        query.setColumnFamilyTimeRange(metricsCf, tsBegin, ((tsEnd == Long.MAX_VALUE) ? Long.MAX_VALUE : (tsEnd + 1)));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getTable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BaseTableRW<?> getTable()\n{\r\n    return FLOW_ACTIVITY_TABLE;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "validateParams",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void validateParams()\n{\r\n    String clusterId = getContext().getClusterId();\r\n    if (clusterId == null) {\r\n        throw new NullPointerException(\"clusterId shouldn't be null\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "augmentParams",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void augmentParams(Configuration hbaseConf, Connection conn) throws IOException\n{\r\n    createFiltersIfNull();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFilters",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFilters() throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "constructFilterListBasedOnFields",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FilterList constructFilterListBasedOnFields(Set<String> cfsInFields)\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResult",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Result getResult(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"we don't support a single entity query\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "getResults",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 14,
  "sourceCodeText" : "ResultScanner getResults(Configuration hbaseConf, Connection conn, FilterList filterList) throws IOException\n{\r\n    Scan scan = new Scan();\r\n    String clusterId = getContext().getClusterId();\r\n    if (getFilters().getFromId() == null && getFilters().getCreatedTimeBegin() == 0L && getFilters().getCreatedTimeEnd() == Long.MAX_VALUE) {\r\n        scan.setRowPrefixFilter(new FlowActivityRowKeyPrefix(clusterId).getRowKeyPrefix());\r\n    } else if (getFilters().getFromId() != null) {\r\n        FlowActivityRowKey key = null;\r\n        try {\r\n            key = FlowActivityRowKey.parseRowKeyFromString(getFilters().getFromId());\r\n        } catch (IllegalArgumentException e) {\r\n            throw new BadRequestException(\"Invalid filter fromid is provided.\");\r\n        }\r\n        if (!clusterId.equals(key.getClusterId())) {\r\n            throw new BadRequestException(\"fromid doesn't belong to clusterId=\" + clusterId);\r\n        }\r\n        scan.withStartRow(key.getRowKey());\r\n        scan.withStopRow(new FlowActivityRowKeyPrefix(clusterId, (getFilters().getCreatedTimeBegin() <= 0 ? 0 : (getFilters().getCreatedTimeBegin() - 1))).getRowKeyPrefix());\r\n    } else {\r\n        scan.withStartRow(new FlowActivityRowKeyPrefix(clusterId, getFilters().getCreatedTimeEnd()).getRowKeyPrefix());\r\n        scan.withStopRow(new FlowActivityRowKeyPrefix(clusterId, (getFilters().getCreatedTimeBegin() <= 0 ? 0 : (getFilters().getCreatedTimeBegin() - 1))).getRowKeyPrefix());\r\n    }\r\n    scan.setFilter(new PageFilter(getFilters().getLimit()));\r\n    return getTable().getResultScanner(hbaseConf, conn, scan);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage\\reader",
  "methodName" : "parseEntity",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "TimelineEntity parseEntity(Result result) throws IOException\n{\r\n    FlowActivityRowKey rowKey = FlowActivityRowKey.parseRowKey(result.getRow());\r\n    Long time = rowKey.getDayTimestamp();\r\n    String user = rowKey.getUserId();\r\n    String flowName = rowKey.getFlowName();\r\n    FlowActivityEntity flowActivity = new FlowActivityEntity(getContext().getClusterId(), time, user, flowName);\r\n    flowActivity.setId(flowActivity.getId());\r\n    Map<Long, Object> runIdsMap = ColumnRWHelper.readResults(result, FlowActivityColumnPrefix.RUN_ID, longKeyConverter);\r\n    for (Map.Entry<Long, Object> e : runIdsMap.entrySet()) {\r\n        Long runId = e.getKey();\r\n        String version = (String) e.getValue();\r\n        FlowRunEntity flowRun = new FlowRunEntity();\r\n        flowRun.setUser(user);\r\n        flowRun.setName(flowName);\r\n        flowRun.setRunId(runId);\r\n        flowRun.setVersion(version);\r\n        flowRun.setId(flowRun.getId());\r\n        flowActivity.addFlowRun(flowRun);\r\n    }\r\n    flowActivity.getInfo().put(TimelineReaderUtils.FROMID_KEY, rowKey.getRowKeyAsString());\r\n    return flowActivity;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "serviceInit",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void serviceInit(Configuration conf) throws Exception\n{\r\n    super.serviceInit(conf);\r\n    hbaseConf = HBaseTimelineStorageUtils.getTimelineServiceHBaseConf(conf);\r\n    conn = ConnectionFactory.createConnection(hbaseConf);\r\n    storageMonitor = new HBaseStorageMonitor(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "serviceStart",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void serviceStart() throws Exception\n{\r\n    super.serviceStart();\r\n    storageMonitor.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "serviceStop",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void serviceStop() throws Exception\n{\r\n    if (conn != null) {\r\n        LOG.info(\"closing the hbase Connection\");\r\n        conn.close();\r\n    }\r\n    storageMonitor.stop();\r\n    super.serviceStop();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "getEntity",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TimelineEntity getEntity(TimelineReaderContext context, TimelineDataToRetrieve dataToRetrieve) throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    TimelineEntityReader reader = TimelineEntityReaderFactory.createSingleEntityReader(context, dataToRetrieve);\r\n    return reader.readEntity(hbaseConf, conn);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "getEntities",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Set<TimelineEntity> getEntities(TimelineReaderContext context, TimelineEntityFilters filters, TimelineDataToRetrieve dataToRetrieve) throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    TimelineEntityReader reader = TimelineEntityReaderFactory.createMultipleEntitiesReader(context, filters, dataToRetrieve);\r\n    return reader.readEntities(hbaseConf, conn);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "getEntityTypes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Set<String> getEntityTypes(TimelineReaderContext context) throws IOException\n{\r\n    storageMonitor.checkStorageIsUp();\r\n    EntityTypeReader reader = new EntityTypeReader(context);\r\n    return reader.readEntityTypes(hbaseConf, conn);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "getHealthStatus",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TimelineHealth getHealthStatus()\n{\r\n    try {\r\n        storageMonitor.checkStorageIsUp();\r\n        return new TimelineHealth(TimelineHealth.TimelineHealthStatus.RUNNING, \"\");\r\n    } catch (IOException e) {\r\n        return new TimelineHealth(TimelineHealth.TimelineHealthStatus.READER_CONNECTION_FAILURE, \"HBase connection is down\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-server\\hadoop-yarn-server-timelineservice-hbase\\hadoop-yarn-server-timelineservice-hbase-client\\src\\main\\java\\org\\apache\\hadoop\\yarn\\server\\timelineservice\\storage",
  "methodName" : "getTimelineStorageMonitor",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TimelineStorageMonitor getTimelineStorageMonitor()\n{\r\n    return storageMonitor;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]