[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "main",
  "errType" : [ "Throwable", "IllegalArgumentException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    boolean result = false;\r\n    try {\r\n        Client client = new Client();\r\n        LOG.info(\"Initializing Client\");\r\n        try {\r\n            boolean doRun = client.init(args);\r\n            if (!doRun) {\r\n                System.exit(0);\r\n            }\r\n        } catch (IllegalArgumentException e) {\r\n            System.err.println(e.getLocalizedMessage());\r\n            client.printUsage();\r\n            System.exit(-1);\r\n        }\r\n        result = client.run();\r\n    } catch (Throwable t) {\r\n        LOG.error(\"Error running Client\", t);\r\n        System.exit(1);\r\n    }\r\n    if (result) {\r\n        LOG.info(\"Application completed successfully\");\r\n        System.exit(0);\r\n    }\r\n    LOG.error(\"Application failed to complete successfully\");\r\n    System.exit(2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void printUsage()\n{\r\n    new HelpFormatter().printHelp(\"Client\", opts);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "init",
  "errType" : [ "Exception", "NumberFormatException" ],
  "containingMethodsNum" : 107,
  "sourceCodeText" : "boolean init(String[] args) throws ParseException\n{\r\n    CommandLine cliParser = new GnuParser().parse(opts, args);\r\n    if (args.length == 0) {\r\n        throw new IllegalArgumentException(\"No args specified for client to initialize\");\r\n    }\r\n    if (cliParser.hasOption(\"log_properties\")) {\r\n        String log4jPath = cliParser.getOptionValue(\"log_properties\");\r\n        try {\r\n            Log4jPropertyHelper.updateLog4jConfiguration(Client.class, log4jPath);\r\n        } catch (Exception e) {\r\n            LOG.warn(\"Can not set up custom log4j properties. \" + e);\r\n        }\r\n    }\r\n    if (cliParser.hasOption(\"rolling_log_pattern\")) {\r\n        rollingFilesPattern = cliParser.getOptionValue(\"rolling_log_pattern\");\r\n    }\r\n    if (cliParser.hasOption(\"help\")) {\r\n        printUsage();\r\n        return false;\r\n    }\r\n    if (cliParser.hasOption(\"debug\")) {\r\n        debugFlag = true;\r\n    }\r\n    if (cliParser.hasOption(\"keep_containers_across_application_attempts\")) {\r\n        LOG.info(\"keep_containers_across_application_attempts\");\r\n        keepContainers = true;\r\n    }\r\n    if (cliParser.hasOption(\"placement_spec\")) {\r\n        placementSpec = cliParser.getOptionValue(\"placement_spec\");\r\n        PlacementSpec.parse(this.placementSpec);\r\n    }\r\n    appName = cliParser.getOptionValue(\"appname\", \"DistributedShell\");\r\n    amPriority = Integer.parseInt(cliParser.getOptionValue(\"priority\", \"0\"));\r\n    amQueue = cliParser.getOptionValue(\"queue\", \"default\");\r\n    amMemory = Integer.parseInt(cliParser.getOptionValue(\"master_memory\", \"-1\"));\r\n    amVCores = Integer.parseInt(cliParser.getOptionValue(\"master_vcores\", \"-1\"));\r\n    if (cliParser.hasOption(\"master_resources\")) {\r\n        Map<String, Long> masterResources = parseResourcesString(cliParser.getOptionValue(\"master_resources\"));\r\n        for (Map.Entry<String, Long> entry : masterResources.entrySet()) {\r\n            if (entry.getKey().equals(ResourceInformation.MEMORY_URI)) {\r\n                amMemory = entry.getValue();\r\n            } else if (entry.getKey().equals(ResourceInformation.VCORES_URI)) {\r\n                amVCores = entry.getValue().intValue();\r\n            } else {\r\n                amResources.put(entry.getKey(), entry.getValue());\r\n            }\r\n        }\r\n    }\r\n    amResourceProfile = cliParser.getOptionValue(\"master_resource_profile\", \"\");\r\n    if (!cliParser.hasOption(\"jar\")) {\r\n        throw new IllegalArgumentException(\"No jar file specified for application master\");\r\n    }\r\n    appMasterJar = cliParser.getOptionValue(\"jar\");\r\n    if (!cliParser.hasOption(\"shell_command\") && !cliParser.hasOption(\"shell_script\")) {\r\n        throw new IllegalArgumentException(\"No shell command or shell script specified to be executed by application master\");\r\n    } else if (cliParser.hasOption(\"shell_command\") && cliParser.hasOption(\"shell_script\")) {\r\n        throw new IllegalArgumentException(\"Can not specify shell_command option \" + \"and shell_script option at the same time\");\r\n    } else if (cliParser.hasOption(\"shell_command\")) {\r\n        shellCommand = cliParser.getOptionValue(\"shell_command\");\r\n    } else {\r\n        shellScriptPath = cliParser.getOptionValue(\"shell_script\");\r\n    }\r\n    if (cliParser.hasOption(\"shell_args\")) {\r\n        shellArgs = cliParser.getOptionValues(\"shell_args\");\r\n    }\r\n    if (cliParser.hasOption(\"shell_env\")) {\r\n        String[] envs = cliParser.getOptionValues(\"shell_env\");\r\n        for (String env : envs) {\r\n            env = env.trim();\r\n            int index = env.indexOf('=');\r\n            if (index == -1) {\r\n                shellEnv.put(env, \"\");\r\n                continue;\r\n            }\r\n            String key = env.substring(0, index);\r\n            String val = \"\";\r\n            if (index < (env.length() - 1)) {\r\n                val = env.substring(index + 1);\r\n            }\r\n            shellEnv.put(key, val);\r\n        }\r\n    }\r\n    shellCmdPriority = Integer.parseInt(cliParser.getOptionValue(\"shell_cmd_priority\", \"0\"));\r\n    if (cliParser.hasOption(\"container_type\")) {\r\n        String containerTypeStr = cliParser.getOptionValue(\"container_type\");\r\n        if (Arrays.stream(ExecutionType.values()).noneMatch(executionType -> executionType.toString().equals(containerTypeStr))) {\r\n            throw new IllegalArgumentException(\"Invalid container_type: \" + containerTypeStr);\r\n        }\r\n        containerType = ExecutionType.valueOf(containerTypeStr);\r\n    }\r\n    if (cliParser.hasOption(\"promote_opportunistic_after_start\")) {\r\n        autoPromoteContainers = true;\r\n    }\r\n    if (cliParser.hasOption(\"enforce_execution_type\")) {\r\n        enforceExecType = true;\r\n    }\r\n    containerMemory = Integer.parseInt(cliParser.getOptionValue(\"container_memory\", \"-1\"));\r\n    containerVirtualCores = Integer.parseInt(cliParser.getOptionValue(\"container_vcores\", \"-1\"));\r\n    if (cliParser.hasOption(\"container_resources\")) {\r\n        Map<String, Long> resources = parseResourcesString(cliParser.getOptionValue(\"container_resources\"));\r\n        for (Map.Entry<String, Long> entry : resources.entrySet()) {\r\n            if (entry.getKey().equals(ResourceInformation.MEMORY_URI)) {\r\n                containerMemory = entry.getValue();\r\n            } else if (entry.getKey().equals(ResourceInformation.VCORES_URI)) {\r\n                containerVirtualCores = entry.getValue().intValue();\r\n            } else {\r\n                containerResources.put(entry.getKey(), entry.getValue());\r\n            }\r\n        }\r\n    }\r\n    containerResourceProfile = cliParser.getOptionValue(\"container_resource_profile\", \"\");\r\n    numContainers = Integer.parseInt(cliParser.getOptionValue(\"num_containers\", \"1\"));\r\n    if (numContainers < 1) {\r\n        throw new IllegalArgumentException(\"Invalid no. of containers specified,\" + \" exiting. Specified numContainer=\" + numContainers);\r\n    }\r\n    nodeLabelExpression = cliParser.getOptionValue(\"node_label_expression\", null);\r\n    clientTimeout = Integer.parseInt(cliParser.getOptionValue(\"timeout\", \"600000\"));\r\n    attemptFailuresValidityInterval = Long.parseLong(cliParser.getOptionValue(\"attempt_failures_validity_interval\", \"-1\"));\r\n    log4jPropFile = cliParser.getOptionValue(\"log_properties\", \"\");\r\n    if (cliParser.hasOption(\"domain\")) {\r\n        domainId = cliParser.getOptionValue(\"domain\");\r\n        toCreateDomain = cliParser.hasOption(\"create\");\r\n        if (cliParser.hasOption(\"view_acls\")) {\r\n            viewACLs = cliParser.getOptionValue(\"view_acls\");\r\n        }\r\n        if (cliParser.hasOption(\"modify_acls\")) {\r\n            modifyACLs = cliParser.getOptionValue(\"modify_acls\");\r\n        }\r\n    }\r\n    if (cliParser.hasOption(\"container_retry_policy\")) {\r\n        containerRetryOptions.add(\"--container_retry_policy \" + cliParser.getOptionValue(\"container_retry_policy\"));\r\n    }\r\n    if (cliParser.hasOption(\"container_retry_error_codes\")) {\r\n        containerRetryOptions.add(\"--container_retry_error_codes \" + cliParser.getOptionValue(\"container_retry_error_codes\"));\r\n    }\r\n    if (cliParser.hasOption(\"container_max_retries\")) {\r\n        containerRetryOptions.add(\"--container_max_retries \" + cliParser.getOptionValue(\"container_max_retries\"));\r\n    }\r\n    if (cliParser.hasOption(\"container_retry_interval\")) {\r\n        containerRetryOptions.add(\"--container_retry_interval \" + cliParser.getOptionValue(\"container_retry_interval\"));\r\n    }\r\n    if (cliParser.hasOption(\"container_failures_validity_interval\")) {\r\n        containerRetryOptions.add(\"--container_failures_validity_interval \" + cliParser.getOptionValue(\"container_failures_validity_interval\"));\r\n    }\r\n    if (cliParser.hasOption(\"flow_name\")) {\r\n        flowName = cliParser.getOptionValue(\"flow_name\");\r\n    }\r\n    if (cliParser.hasOption(\"flow_version\")) {\r\n        flowVersion = cliParser.getOptionValue(\"flow_version\");\r\n    }\r\n    if (cliParser.hasOption(\"flow_run_id\")) {\r\n        try {\r\n            flowRunId = Long.parseLong(cliParser.getOptionValue(\"flow_run_id\"));\r\n        } catch (NumberFormatException e) {\r\n            throw new IllegalArgumentException(\"Flow run is not a valid long value\", e);\r\n        }\r\n    }\r\n    if (cliParser.hasOption(\"docker_client_config\")) {\r\n        dockerClientConfig = cliParser.getOptionValue(\"docker_client_config\");\r\n    }\r\n    if (cliParser.hasOption(\"application_tags\")) {\r\n        String applicationTagsStr = cliParser.getOptionValue(\"application_tags\");\r\n        String[] appTags = applicationTagsStr.split(\",\");\r\n        for (String appTag : appTags) {\r\n            this.applicationTags.add(appTag.trim());\r\n        }\r\n    }\r\n    if (cliParser.hasOption(\"localize_files\")) {\r\n        String filesStr = cliParser.getOptionValue(\"localize_files\");\r\n        if (filesStr.contains(\",\")) {\r\n            String[] files = filesStr.split(\",\");\r\n            filesToLocalize = Arrays.asList(files);\r\n        } else {\r\n            filesToLocalize.add(filesStr);\r\n        }\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "run",
  "errType" : [ "YARNFeatureNotEnabledException", "IOException" ],
  "containingMethodsNum" : 130,
  "sourceCodeText" : "boolean run() throws IOException, YarnException\n{\r\n    LOG.info(\"Running Client\");\r\n    isRunning.set(true);\r\n    yarnClient.start();\r\n    clientStartTime = System.currentTimeMillis();\r\n    YarnClusterMetrics clusterMetrics = yarnClient.getYarnClusterMetrics();\r\n    LOG.info(\"Got Cluster metric info from ASM\" + \", numNodeManagers=\" + clusterMetrics.getNumNodeManagers());\r\n    List<NodeReport> clusterNodeReports = yarnClient.getNodeReports(NodeState.RUNNING);\r\n    LOG.info(\"Got Cluster node info from ASM\");\r\n    for (NodeReport node : clusterNodeReports) {\r\n        LOG.info(\"Got node report from ASM for\" + \", nodeId=\" + node.getNodeId() + \", nodeAddress=\" + node.getHttpAddress() + \", nodeRackName=\" + node.getRackName() + \", nodeNumContainers=\" + node.getNumContainers());\r\n    }\r\n    QueueInfo queueInfo = yarnClient.getQueueInfo(this.amQueue);\r\n    if (queueInfo == null) {\r\n        throw new IllegalArgumentException(String.format(\"Queue %s not present in scheduler configuration.\", this.amQueue));\r\n    }\r\n    LOG.info(\"Queue info\" + \", queueName=\" + queueInfo.getQueueName() + \", queueCurrentCapacity=\" + queueInfo.getCurrentCapacity() + \", queueMaxCapacity=\" + queueInfo.getMaximumCapacity() + \", queueApplicationCount=\" + queueInfo.getApplications().size() + \", queueChildQueueCount=\" + queueInfo.getChildQueues().size());\r\n    List<QueueUserACLInfo> listAclInfo = yarnClient.getQueueAclsInfo();\r\n    for (QueueUserACLInfo aclInfo : listAclInfo) {\r\n        for (QueueACL userAcl : aclInfo.getUserAcls()) {\r\n            LOG.info(\"User ACL Info for Queue\" + \", queueName=\" + aclInfo.getQueueName() + \", userAcl=\" + userAcl.name());\r\n        }\r\n    }\r\n    if (domainId != null && domainId.length() > 0 && toCreateDomain) {\r\n        prepareTimelineDomain();\r\n    }\r\n    Map<String, Resource> profiles;\r\n    try {\r\n        profiles = yarnClient.getResourceProfiles();\r\n    } catch (YARNFeatureNotEnabledException re) {\r\n        profiles = null;\r\n    }\r\n    List<String> appProfiles = new ArrayList<>(2);\r\n    appProfiles.add(amResourceProfile);\r\n    appProfiles.add(containerResourceProfile);\r\n    for (String appProfile : appProfiles) {\r\n        if (appProfile != null && !appProfile.isEmpty()) {\r\n            if (profiles == null) {\r\n                String message = \"Resource profiles is not enabled\";\r\n                LOG.error(message);\r\n                throw new IOException(message);\r\n            }\r\n            if (!profiles.containsKey(appProfile)) {\r\n                String message = \"Unknown resource profile '\" + appProfile + \"'. Valid resource profiles are \" + profiles.keySet();\r\n                LOG.error(message);\r\n                throw new IOException(message);\r\n            }\r\n        }\r\n    }\r\n    YarnClientApplication app = yarnClient.createApplication();\r\n    GetNewApplicationResponse appResponse = app.getNewApplicationResponse();\r\n    long maxMem = appResponse.getMaximumResourceCapability().getMemorySize();\r\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\r\n    if (amMemory > maxMem) {\r\n        LOG.info(\"AM memory specified above max threshold of cluster. Using max value.\" + \", specified=\" + amMemory + \", max=\" + maxMem);\r\n        amMemory = maxMem;\r\n    }\r\n    int maxVCores = appResponse.getMaximumResourceCapability().getVirtualCores();\r\n    LOG.info(\"Max virtual cores capability of resources in this cluster \" + maxVCores);\r\n    if (amVCores > maxVCores) {\r\n        LOG.info(\"AM virtual cores specified above max threshold of cluster. \" + \"Using max value.\" + \", specified=\" + amVCores + \", max=\" + maxVCores);\r\n        amVCores = maxVCores;\r\n    }\r\n    ApplicationSubmissionContext appContext = app.getApplicationSubmissionContext();\r\n    applicationId = appContext.getApplicationId();\r\n    List<ResourceTypeInfo> resourceTypes = yarnClient.getResourceTypeInfo();\r\n    setAMResourceCapability(appContext, profiles, resourceTypes);\r\n    setContainerResources(profiles, resourceTypes);\r\n    appContext.setKeepContainersAcrossApplicationAttempts(keepContainers);\r\n    appContext.setApplicationName(appName);\r\n    if (attemptFailuresValidityInterval >= 0) {\r\n        appContext.setAttemptFailuresValidityInterval(attemptFailuresValidityInterval);\r\n    }\r\n    Set<String> tags = new HashSet<String>();\r\n    if (applicationTags != null) {\r\n        tags.addAll(applicationTags);\r\n    }\r\n    if (flowName != null) {\r\n        tags.add(TimelineUtils.generateFlowNameTag(flowName));\r\n    }\r\n    if (flowVersion != null) {\r\n        tags.add(TimelineUtils.generateFlowVersionTag(flowVersion));\r\n    }\r\n    if (flowRunId != 0) {\r\n        tags.add(TimelineUtils.generateFlowRunIdTag(flowRunId));\r\n    }\r\n    appContext.setApplicationTags(tags);\r\n    Map<String, LocalResource> localResources = new HashMap<String, LocalResource>();\r\n    LOG.info(\"Copy App Master jar from local filesystem and add to local environment\");\r\n    FileSystem fs = FileSystem.get(conf);\r\n    addToLocalResources(fs, appMasterJar, appMasterJarPath, applicationId.toString(), localResources, null);\r\n    if (!log4jPropFile.isEmpty()) {\r\n        addToLocalResources(fs, log4jPropFile, log4jPath, applicationId.toString(), localResources, null);\r\n    }\r\n    StringBuilder localizableFiles = new StringBuilder();\r\n    filesToLocalize.stream().forEach(path -> {\r\n        File f = new File(path);\r\n        if (!f.exists()) {\r\n            throw new UncheckedIOException(new IOException(path + \" does not exist\"));\r\n        }\r\n        if (!f.canRead()) {\r\n            throw new UncheckedIOException(new IOException(path + \" cannot be read\"));\r\n        }\r\n        if (f.isDirectory()) {\r\n            throw new UncheckedIOException(new IOException(path + \" is a directory\"));\r\n        }\r\n        try {\r\n            String fileName = f.getName();\r\n            uploadFile(fs, path, fileName, applicationId.toString());\r\n            if (localizableFiles.length() == 0) {\r\n                localizableFiles.append(fileName);\r\n            } else {\r\n                localizableFiles.append(\",\").append(fileName);\r\n            }\r\n        } catch (IOException e) {\r\n            throw new UncheckedIOException(\"Cannot upload file: \" + path, e);\r\n        }\r\n    });\r\n    String hdfsShellScriptLocation = \"\";\r\n    long hdfsShellScriptLen = 0;\r\n    long hdfsShellScriptTimestamp = 0;\r\n    if (!shellScriptPath.isEmpty()) {\r\n        Path shellSrc = new Path(shellScriptPath);\r\n        String shellPathSuffix = ApplicationMaster.getRelativePath(appName, applicationId.toString(), SCRIPT_PATH);\r\n        Path shellDst = new Path(fs.getHomeDirectory(), shellPathSuffix);\r\n        fs.copyFromLocalFile(false, true, shellSrc, shellDst);\r\n        hdfsShellScriptLocation = shellDst.toUri().toString();\r\n        FileStatus shellFileStatus = fs.getFileStatus(shellDst);\r\n        hdfsShellScriptLen = shellFileStatus.getLen();\r\n        hdfsShellScriptTimestamp = shellFileStatus.getModificationTime();\r\n    }\r\n    if (!shellCommand.isEmpty()) {\r\n        addToLocalResources(fs, null, shellCommandPath, applicationId.toString(), localResources, shellCommand);\r\n    }\r\n    if (shellArgs.length > 0) {\r\n        addToLocalResources(fs, null, shellArgsPath, applicationId.toString(), localResources, StringUtils.join(shellArgs, \" \"));\r\n    }\r\n    LOG.info(\"Set the environment for the application master\");\r\n    Map<String, String> env = new HashMap<String, String>();\r\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION, hdfsShellScriptLocation);\r\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP, Long.toString(hdfsShellScriptTimestamp));\r\n    env.put(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN, Long.toString(hdfsShellScriptLen));\r\n    if (domainId != null && domainId.length() > 0) {\r\n        env.put(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN, domainId);\r\n    }\r\n    StringBuilder classPathEnv = new StringBuilder(Environment.CLASSPATH.$$()).append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./*\");\r\n    for (String c : conf.getStrings(YarnConfiguration.YARN_APPLICATION_CLASSPATH, YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH)) {\r\n        classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(c.trim());\r\n    }\r\n    classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(\"./log4j.properties\");\r\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\r\n        classPathEnv.append(ApplicationConstants.CLASS_PATH_SEPARATOR).append(System.getProperty(\"java.class.path\"));\r\n    }\r\n    env.put(\"CLASSPATH\", classPathEnv.toString());\r\n    Vector<CharSequence> vargs = new Vector<CharSequence>(30);\r\n    LOG.info(\"Setting up app master command\");\r\n    vargs.add(\"\\\"\" + Environment.JAVA_HOME.$$() + \"/bin/java\\\"\");\r\n    vargs.add(\"-Xmx\" + amMemory + \"m\");\r\n    vargs.add(appMasterMainClass);\r\n    if (containerType != null) {\r\n        vargs.add(\"--container_type \" + String.valueOf(containerType));\r\n    }\r\n    if (autoPromoteContainers) {\r\n        vargs.add(\"--promote_opportunistic_after_start\");\r\n    }\r\n    if (enforceExecType) {\r\n        vargs.add(\"--enforce_execution_type\");\r\n    }\r\n    if (containerMemory > 0) {\r\n        vargs.add(\"--container_memory \" + String.valueOf(containerMemory));\r\n    }\r\n    if (containerVirtualCores > 0) {\r\n        vargs.add(\"--container_vcores \" + String.valueOf(containerVirtualCores));\r\n    }\r\n    if (!containerResources.isEmpty()) {\r\n        Joiner.MapJoiner joiner = Joiner.on(',').withKeyValueSeparator(\"=\");\r\n        vargs.add(\"--container_resources \" + joiner.join(containerResources));\r\n    }\r\n    if (containerResourceProfile != null && !containerResourceProfile.isEmpty()) {\r\n        vargs.add(\"--container_resource_profile \" + containerResourceProfile);\r\n    }\r\n    vargs.add(\"--num_containers \" + String.valueOf(numContainers));\r\n    if (placementSpec != null && placementSpec.length() > 0) {\r\n        String encodedSpec = Base64.getEncoder().encodeToString(placementSpec.getBytes(StandardCharsets.UTF_8));\r\n        LOG.info(\"Encode placement spec: \" + encodedSpec);\r\n        vargs.add(\"--placement_spec \" + encodedSpec);\r\n    }\r\n    if (null != nodeLabelExpression) {\r\n        appContext.setNodeLabelExpression(nodeLabelExpression);\r\n    }\r\n    vargs.add(\"--priority \" + String.valueOf(shellCmdPriority));\r\n    if (keepContainers) {\r\n        vargs.add(\"--keep_containers_across_application_attempts\");\r\n    }\r\n    for (Map.Entry<String, String> entry : shellEnv.entrySet()) {\r\n        vargs.add(\"--shell_env \" + entry.getKey() + \"=\" + entry.getValue());\r\n    }\r\n    if (debugFlag) {\r\n        vargs.add(\"--debug\");\r\n    }\r\n    if (localizableFiles.length() > 0) {\r\n        vargs.add(\"--localized_files \" + localizableFiles.toString());\r\n    }\r\n    vargs.add(\"--appname \" + appName);\r\n    vargs.add(\"--homedir \" + fs.getHomeDirectory());\r\n    vargs.addAll(containerRetryOptions);\r\n    vargs.add(\"1>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stdout\");\r\n    vargs.add(\"2>\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + \"/AppMaster.stderr\");\r\n    StringBuilder command = new StringBuilder();\r\n    for (CharSequence str : vargs) {\r\n        command.append(str).append(\" \");\r\n    }\r\n    LOG.info(\"Completed setting up app master command \" + command.toString());\r\n    List<String> commands = new ArrayList<String>();\r\n    commands.add(command.toString());\r\n    ContainerLaunchContext amContainer = ContainerLaunchContext.newInstance(localResources, env, commands, null, null, null);\r\n    Credentials rmCredentials = null;\r\n    if (UserGroupInformation.isSecurityEnabled()) {\r\n        rmCredentials = new Credentials();\r\n        String tokenRenewer = YarnClientUtils.getRmPrincipal(conf);\r\n        if (tokenRenewer == null || tokenRenewer.length() == 0) {\r\n            throw new IOException(\"Can't get Master Kerberos principal for the RM to use as renewer\");\r\n        }\r\n        final Token<?>[] tokens = fs.addDelegationTokens(tokenRenewer, rmCredentials);\r\n        if (tokens != null) {\r\n            for (Token<?> token : tokens) {\r\n                LOG.info(\"Got dt for \" + fs.getUri() + \"; \" + token);\r\n            }\r\n        }\r\n    }\r\n    Credentials dockerCredentials = null;\r\n    if (dockerClientConfig != null) {\r\n        dockerCredentials = DockerClientConfigHandler.readCredentialsFromConfigFile(new Path(dockerClientConfig), conf, applicationId.toString());\r\n    }\r\n    if (rmCredentials != null || dockerCredentials != null) {\r\n        DataOutputBuffer dob = new DataOutputBuffer();\r\n        if (rmCredentials != null) {\r\n            rmCredentials.writeTokenStorageToStream(dob);\r\n        }\r\n        if (dockerCredentials != null) {\r\n            dockerCredentials.writeTokenStorageToStream(dob);\r\n        }\r\n        ByteBuffer tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\r\n        amContainer.setTokens(tokens);\r\n    }\r\n    appContext.setAMContainerSpec(amContainer);\r\n    Priority pri = Priority.newInstance(amPriority);\r\n    appContext.setPriority(pri);\r\n    appContext.setQueue(amQueue);\r\n    specifyLogAggregationContext(appContext);\r\n    LOG.info(\"Submitting application to ASM\");\r\n    yarnClient.submitApplication(appContext);\r\n    return monitorApplication(applicationId);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "specifyLogAggregationContext",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void specifyLogAggregationContext(ApplicationSubmissionContext appContext)\n{\r\n    if (!rollingFilesPattern.isEmpty()) {\r\n        LogAggregationContext logAggregationContext = LogAggregationContext.newInstance(null, null, rollingFilesPattern, \"\");\r\n        appContext.setLogAggregationContext(logAggregationContext);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "monitorApplication",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "boolean monitorApplication(ApplicationId appId) throws YarnException, IOException\n{\r\n    boolean res = false;\r\n    boolean needForceKill = false;\r\n    while (isRunning.get()) {\r\n        try {\r\n            synchronized (objectLock) {\r\n                objectLock.wait(APP_MONITOR_INTERVAL);\r\n            }\r\n            needForceKill = stopSignalReceived.get();\r\n        } catch (InterruptedException e) {\r\n            LOG.warn(\"Thread sleep in monitoring loop interrupted\");\r\n            break;\r\n        } finally {\r\n            if (needForceKill) {\r\n                break;\r\n            }\r\n        }\r\n        ApplicationReport report = yarnClient.getApplicationReport(appId);\r\n        LOG.info(\"Got application report from ASM for\" + \", appId=\" + appId.getId() + \", clientToAMToken=\" + report.getClientToAMToken() + \", appDiagnostics=\" + report.getDiagnostics() + \", appMasterHost=\" + report.getHost() + \", appQueue=\" + report.getQueue() + \", appMasterRpcPort=\" + report.getRpcPort() + \", appStartTime=\" + report.getStartTime() + \", yarnAppState=\" + report.getYarnApplicationState().toString() + \", distributedFinalState=\" + report.getFinalApplicationStatus().toString() + \", appTrackingUrl=\" + report.getTrackingUrl() + \", appUser=\" + report.getUser());\r\n        YarnApplicationState state = report.getYarnApplicationState();\r\n        FinalApplicationStatus dsStatus = report.getFinalApplicationStatus();\r\n        if (YarnApplicationState.FINISHED == state) {\r\n            if (FinalApplicationStatus.SUCCEEDED == dsStatus) {\r\n                LOG.info(\"Application has completed successfully. \" + \"Breaking monitoring loop\");\r\n                res = true;\r\n            } else {\r\n                LOG.info(\"Application did finished unsuccessfully. \" + \"YarnState={}, DSFinalStatus={}. Breaking monitoring loop\", state, dsStatus);\r\n            }\r\n            break;\r\n        } else if (YarnApplicationState.KILLED == state || YarnApplicationState.FAILED == state) {\r\n            LOG.info(\"Application did not finish. YarnState={}, DSFinalStatus={}. \" + \"Breaking monitoring loop\", state, dsStatus);\r\n            break;\r\n        }\r\n        if (clientTimeout > 0 && System.currentTimeMillis() > (clientStartTime + clientTimeout)) {\r\n            LOG.info(\"Reached client specified timeout for application. \" + \"Killing application\");\r\n            needForceKill = true;\r\n            break;\r\n        }\r\n    }\r\n    if (needForceKill) {\r\n        forceKillApplication(appId);\r\n    }\r\n    isRunning.set(false);\r\n    return res;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "forceKillApplication",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void forceKillApplication(ApplicationId appId) throws YarnException, IOException\n{\r\n    yarnClient.killApplication(appId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "addToLocalResources",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void addToLocalResources(FileSystem fs, String fileSrcPath, String fileDstPath, String appId, Map<String, LocalResource> localResources, String resources) throws IOException\n{\r\n    String suffix = ApplicationMaster.getRelativePath(appName, appId, fileDstPath);\r\n    Path dst = new Path(fs.getHomeDirectory(), suffix);\r\n    if (fileSrcPath == null) {\r\n        try (FSDataOutputStream ostream = FileSystem.create(fs, dst, new FsPermission((short) 0710))) {\r\n            ostream.writeUTF(resources);\r\n        }\r\n    } else {\r\n        fs.copyFromLocalFile(new Path(fileSrcPath), dst);\r\n    }\r\n    FileStatus scFileStatus = fs.getFileStatus(dst);\r\n    LocalResource scRsrc = LocalResource.newInstance(URL.fromURI(dst.toUri()), LocalResourceType.FILE, LocalResourceVisibility.APPLICATION, scFileStatus.getLen(), scFileStatus.getModificationTime());\r\n    localResources.put(fileDstPath, scRsrc);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "uploadFile",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void uploadFile(FileSystem fs, String fileSrcPath, String fileDstPath, String appId) throws IOException\n{\r\n    String relativePath = ApplicationMaster.getRelativePath(appName, appId, fileDstPath);\r\n    Path dst = new Path(fs.getHomeDirectory(), relativePath);\r\n    LOG.info(\"Uploading file: \" + fileSrcPath + \" to \" + dst);\r\n    fs.copyFromLocalFile(new Path(fileSrcPath), dst);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getAppId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ApplicationId getAppId()\n{\r\n    return applicationId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "prepareTimelineDomain",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void prepareTimelineDomain()\n{\r\n    TimelineClient timelineClient = null;\r\n    if (conf.getBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, YarnConfiguration.DEFAULT_TIMELINE_SERVICE_ENABLED)) {\r\n        timelineClient = TimelineClient.createTimelineClient();\r\n        timelineClient.init(conf);\r\n        timelineClient.start();\r\n    } else {\r\n        LOG.warn(\"Cannot put the domain \" + domainId + \" because the timeline service is not enabled\");\r\n        return;\r\n    }\r\n    try {\r\n        TimelineDomain domain = new TimelineDomain();\r\n        domain.setId(domainId);\r\n        domain.setReaders(viewACLs != null && viewACLs.length() > 0 ? viewACLs : \" \");\r\n        domain.setWriters(modifyACLs != null && modifyACLs.length() > 0 ? modifyACLs : \" \");\r\n        timelineClient.putDomain(domain);\r\n        LOG.info(\"Put the timeline domain: \" + TimelineUtils.dumpTimelineRecordtoJSON(domain));\r\n    } catch (Exception e) {\r\n        LOG.error(\"Error when putting the timeline domain\", e);\r\n    } finally {\r\n        timelineClient.stop();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "setAMResourceCapability",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void setAMResourceCapability(ApplicationSubmissionContext appContext, Map<String, Resource> profiles, List<ResourceTypeInfo> resourceTypes) throws IllegalArgumentException, IOException, YarnException\n{\r\n    if (amMemory < -1 || amMemory == 0) {\r\n        throw new IllegalArgumentException(\"Invalid memory specified for\" + \" application master, exiting. Specified memory=\" + amMemory);\r\n    }\r\n    if (amVCores < -1 || amVCores == 0) {\r\n        throw new IllegalArgumentException(\"Invalid virtual cores specified for\" + \" application master, exiting. \" + \"Specified virtual cores=\" + amVCores);\r\n    }\r\n    Resource capability = Resource.newInstance(0, 0);\r\n    if (!amResourceProfile.isEmpty()) {\r\n        if (!profiles.containsKey(amResourceProfile)) {\r\n            throw new IllegalArgumentException(\"Failed to find specified resource profile for application master=\" + amResourceProfile);\r\n        }\r\n        capability = Resources.clone(profiles.get(amResourceProfile));\r\n    }\r\n    if (appContext.getAMContainerResourceRequests() == null) {\r\n        List<ResourceRequest> amResourceRequests = new ArrayList<ResourceRequest>();\r\n        amResourceRequests.add(ResourceRequest.newInstance(Priority.newInstance(amPriority), \"*\", Resources.clone(Resources.none()), 1));\r\n        appContext.setAMContainerResourceRequests(amResourceRequests);\r\n    }\r\n    validateResourceTypes(amResources.keySet(), resourceTypes);\r\n    for (Map.Entry<String, Long> entry : amResources.entrySet()) {\r\n        capability.setResourceValue(entry.getKey(), entry.getValue());\r\n    }\r\n    if (amMemory == -1) {\r\n        amMemory = DEFAULT_AM_MEMORY;\r\n        LOG.warn(\"AM Memory not specified, use \" + DEFAULT_AM_MEMORY + \" mb as AM memory\");\r\n    }\r\n    if (amVCores == -1) {\r\n        amVCores = DEFAULT_AM_VCORES;\r\n        LOG.warn(\"AM vcore not specified, use \" + DEFAULT_AM_VCORES + \" mb as AM vcores\");\r\n    }\r\n    capability.setMemorySize(amMemory);\r\n    capability.setVirtualCores(amVCores);\r\n    appContext.getAMContainerResourceRequests().get(0).setCapability(capability);\r\n    LOG.warn(\"AM Resource capability=\" + capability);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "setContainerResources",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setContainerResources(Map<String, Resource> profiles, List<ResourceTypeInfo> resourceTypes) throws IllegalArgumentException\n{\r\n    if (containerMemory < -1 || containerMemory == 0) {\r\n        throw new IllegalArgumentException(\"Container memory '\" + containerMemory + \"' has to be greated than 0\");\r\n    }\r\n    if (containerVirtualCores < -1 || containerVirtualCores == 0) {\r\n        throw new IllegalArgumentException(\"Container vcores '\" + containerVirtualCores + \"' has to be greated than 0\");\r\n    }\r\n    validateResourceTypes(containerResources.keySet(), resourceTypes);\r\n    if (profiles == null) {\r\n        containerMemory = containerMemory == -1 ? DEFAULT_CONTAINER_MEMORY : containerMemory;\r\n        containerVirtualCores = containerVirtualCores == -1 ? DEFAULT_CONTAINER_VCORES : containerVirtualCores;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "validateResourceTypes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void validateResourceTypes(Iterable<String> resourceNames, List<ResourceTypeInfo> resourceTypes)\n{\r\n    for (String resourceName : resourceNames) {\r\n        if (!resourceTypes.stream().anyMatch(e -> e.getName().equals(resourceName))) {\r\n            throw new ResourceNotFoundException(\"Unknown resource: \" + resourceName);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "parseResourcesString",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "Map<String, Long> parseResourcesString(String resourcesStr)\n{\r\n    Map<String, Long> resources = new HashMap<>();\r\n    if (resourcesStr.startsWith(\"[\")) {\r\n        resourcesStr = resourcesStr.substring(1);\r\n    }\r\n    if (resourcesStr.endsWith(\"]\")) {\r\n        resourcesStr = resourcesStr.substring(0, resourcesStr.length() - 1);\r\n    }\r\n    for (String resource : resourcesStr.trim().split(\",\")) {\r\n        resource = resource.trim();\r\n        if (!resource.matches(\"^[^=]+=\\\\d+\\\\s?\\\\w*$\")) {\r\n            throw new IllegalArgumentException(\"\\\"\" + resource + \"\\\" is not a \" + \"valid resource type/amount pair. \" + \"Please provide key=amount pairs separated by commas.\");\r\n        }\r\n        String[] splits = resource.split(\"=\");\r\n        String key = splits[0], value = splits[1];\r\n        String units = ResourceUtils.getUnits(value);\r\n        String valueWithoutUnit = value.substring(0, value.length() - units.length()).trim();\r\n        Long resourceValue = Long.valueOf(valueWithoutUnit);\r\n        if (!units.isEmpty()) {\r\n            resourceValue = UnitsConversionUtil.convert(units, \"Mi\", resourceValue);\r\n        }\r\n        if (key.equals(\"memory\")) {\r\n            key = ResourceInformation.MEMORY_URI;\r\n        }\r\n        resources.put(key, resourceValue);\r\n    }\r\n    return resources;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "sendStopSignal",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void sendStopSignal()\n{\r\n    LOG.info(\"Sending stop Signal to Client\");\r\n    stopSignalReceived.set(true);\r\n    synchronized (objectLock) {\r\n        objectLock.notifyAll();\r\n    }\r\n    int waitCount = 0;\r\n    LOG.info(\"Waiting for Client to exit loop\");\r\n    while (isRunning.get()) {\r\n        try {\r\n            Thread.sleep(50);\r\n        } catch (InterruptedException ie) {\r\n        } finally {\r\n            if (++waitCount > 2000) {\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    LOG.info(\"Stopping yarnClient within the DS Client\");\r\n    yarnClient.stop();\r\n    LOG.info(\"done stopping Client\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getContainerStartTimes",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ConcurrentMap<ContainerId, Long> getContainerStartTimes()\n{\r\n    return containerStartTimes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "main",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    boolean result = false;\r\n    ApplicationMaster appMaster = null;\r\n    try {\r\n        appMaster = new ApplicationMaster();\r\n        LOG.info(\"Initializing ApplicationMaster\");\r\n        boolean doRun = appMaster.init(args);\r\n        if (!doRun) {\r\n            System.exit(0);\r\n        }\r\n        appMaster.run();\r\n        result = appMaster.finish();\r\n    } catch (Throwable t) {\r\n        LOG.error(\"Error running ApplicationMaster\", t);\r\n        LogManager.shutdown();\r\n        ExitUtil.terminate(1, t);\r\n    } finally {\r\n        if (appMaster != null) {\r\n            appMaster.cleanup();\r\n        }\r\n    }\r\n    if (result) {\r\n        LOG.info(\"Application Master completed successfully. exiting\");\r\n        System.exit(0);\r\n    } else {\r\n        LOG.error(\"Application Master failed. exiting\");\r\n        System.exit(2);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "dumpOutDebugInfo",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void dumpOutDebugInfo()\n{\r\n    LOG.info(\"Dump debug output\");\r\n    Map<String, String> envs = System.getenv();\r\n    for (Map.Entry<String, String> env : envs.entrySet()) {\r\n        LOG.info(\"System env: key=\" + env.getKey() + \", val=\" + env.getValue());\r\n        System.out.println(\"System env: key=\" + env.getKey() + \", val=\" + env.getValue());\r\n    }\r\n    BufferedReader buf = null;\r\n    try {\r\n        String lines = Shell.WINDOWS ? Shell.execCommand(\"cmd\", \"/c\", \"dir\") : Shell.execCommand(\"ls\", \"-al\");\r\n        buf = new BufferedReader(new StringReader(lines));\r\n        String line = \"\";\r\n        while ((line = buf.readLine()) != null) {\r\n            LOG.info(\"System CWD content: \" + line);\r\n            System.out.println(\"System CWD content: \" + line);\r\n        }\r\n    } catch (IOException e) {\r\n        e.printStackTrace();\r\n    } finally {\r\n        IOUtils.cleanupWithLogger(LOG, buf);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "init",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 115,
  "sourceCodeText" : "boolean init(String[] args) throws ParseException, IOException\n{\r\n    Options opts = new Options();\r\n    opts.addOption(\"appname\", true, \"Application Name. Default value - DistributedShell\");\r\n    opts.addOption(\"app_attempt_id\", true, \"App Attempt ID. Not to be used unless for testing purposes\");\r\n    opts.addOption(\"shell_env\", true, \"Environment for shell script. Specified as env_key=env_val pairs\");\r\n    opts.addOption(\"container_type\", true, \"Container execution type, GUARANTEED or OPPORTUNISTIC\");\r\n    opts.addOption(\"promote_opportunistic_after_start\", false, \"Flag to indicate whether to automatically promote opportunistic\" + \" containers to guaranteed.\");\r\n    opts.addOption(\"enforce_execution_type\", false, \"Flag to indicate whether to enforce execution type of containers\");\r\n    opts.addOption(\"container_memory\", true, \"Amount of memory in MB to be requested to run the shell command\");\r\n    opts.addOption(\"container_vcores\", true, \"Amount of virtual cores to be requested to run the shell command\");\r\n    opts.addOption(\"container_resources\", true, \"Amount of resources to be requested to run the shell command. \" + \"Specified as resource type=value pairs separated by commas. \" + \"E.g. -container_resources memory-mb=512,vcores=1\");\r\n    opts.addOption(\"container_resource_profile\", true, \"Resource profile to be requested to run the shell command\");\r\n    opts.addOption(\"num_containers\", true, \"No. of containers on which the shell command needs to be executed\");\r\n    opts.addOption(\"priority\", true, \"Application Priority. Default 0\");\r\n    opts.addOption(\"container_retry_policy\", true, \"Retry policy when container fails to run, \" + \"0: NEVER_RETRY, 1: RETRY_ON_ALL_ERRORS, \" + \"2: RETRY_ON_SPECIFIC_ERROR_CODES\");\r\n    opts.addOption(\"container_retry_error_codes\", true, \"When retry policy is set to RETRY_ON_SPECIFIC_ERROR_CODES, error \" + \"codes is specified with this option, \" + \"e.g. --container_retry_error_codes 1,2,3\");\r\n    opts.addOption(\"container_max_retries\", true, \"If container could retry, it specifies max retires\");\r\n    opts.addOption(\"container_retry_interval\", true, \"Interval between each retry, unit is milliseconds\");\r\n    opts.addOption(\"container_failures_validity_interval\", true, \"Failures which are out of the time window will not be added to\" + \" the number of container retry attempts\");\r\n    opts.addOption(\"placement_spec\", true, \"Placement specification\");\r\n    opts.addOption(\"debug\", false, \"Dump out debug information\");\r\n    opts.addOption(\"keep_containers_across_application_attempts\", false, \"Flag to indicate whether to keep containers across application \" + \"attempts.\" + \" If the flag is true, running containers will not be killed when\" + \" application attempt fails and these containers will be \" + \"retrieved by\" + \" the new application attempt \");\r\n    opts.addOption(\"localized_files\", true, \"List of localized files\");\r\n    opts.addOption(\"homedir\", true, \"Home Directory of Job Owner\");\r\n    opts.addOption(\"help\", false, \"Print usage\");\r\n    CommandLine cliParser = new GnuParser().parse(opts, args);\r\n    if (args.length == 0) {\r\n        printUsage(opts);\r\n        throw new IllegalArgumentException(\"No args specified for application master to initialize\");\r\n    }\r\n    if (fileExist(log4jPath)) {\r\n        try {\r\n            Log4jPropertyHelper.updateLog4jConfiguration(ApplicationMaster.class, log4jPath);\r\n        } catch (Exception e) {\r\n            LOG.warn(\"Can not set up custom log4j properties. \" + e);\r\n        }\r\n    }\r\n    appName = cliParser.getOptionValue(\"appname\", \"DistributedShell\");\r\n    if (cliParser.hasOption(\"help\")) {\r\n        printUsage(opts);\r\n        return false;\r\n    }\r\n    if (cliParser.hasOption(\"debug\")) {\r\n        dumpOutDebugInfo();\r\n    }\r\n    homeDirectory = cliParser.hasOption(\"homedir\") ? new Path(cliParser.getOptionValue(\"homedir\")) : new Path(\"/user/\" + System.getenv(ApplicationConstants.Environment.USER.name()));\r\n    if (cliParser.hasOption(\"placement_spec\")) {\r\n        String placementSpec = cliParser.getOptionValue(\"placement_spec\");\r\n        String decodedSpec = getDecodedPlacementSpec(placementSpec);\r\n        LOG.info(\"Placement Spec received [{}]\", decodedSpec);\r\n        this.numTotalContainers = 0;\r\n        int globalNumOfContainers = Integer.parseInt(cliParser.getOptionValue(\"num_containers\", \"0\"));\r\n        parsePlacementSpecs(decodedSpec, globalNumOfContainers);\r\n        LOG.info(\"Total num containers requested [{}]\", numTotalContainers);\r\n        if (numTotalContainers == 0) {\r\n            throw new IllegalArgumentException(\"Cannot run distributed shell with no containers\");\r\n        }\r\n    }\r\n    Map<String, String> envs = System.getenv();\r\n    if (!envs.containsKey(Environment.CONTAINER_ID.name())) {\r\n        if (cliParser.hasOption(\"app_attempt_id\")) {\r\n            String appIdStr = cliParser.getOptionValue(\"app_attempt_id\", \"\");\r\n            appAttemptID = ApplicationAttemptId.fromString(appIdStr);\r\n        } else {\r\n            throw new IllegalArgumentException(\"Application Attempt Id not set in the environment\");\r\n        }\r\n    } else {\r\n        ContainerId containerId = ContainerId.fromString(envs.get(Environment.CONTAINER_ID.name()));\r\n        appAttemptID = containerId.getApplicationAttemptId();\r\n        appId = appAttemptID.getApplicationId();\r\n    }\r\n    if (!envs.containsKey(ApplicationConstants.APP_SUBMIT_TIME_ENV)) {\r\n        throw new RuntimeException(ApplicationConstants.APP_SUBMIT_TIME_ENV + \" not set in the environment\");\r\n    }\r\n    if (!envs.containsKey(Environment.NM_HOST.name())) {\r\n        throw new RuntimeException(Environment.NM_HOST.name() + \" not set in the environment\");\r\n    }\r\n    if (!envs.containsKey(Environment.NM_HTTP_PORT.name())) {\r\n        throw new RuntimeException(Environment.NM_HTTP_PORT + \" not set in the environment\");\r\n    }\r\n    if (!envs.containsKey(Environment.NM_PORT.name())) {\r\n        throw new RuntimeException(Environment.NM_PORT.name() + \" not set in the environment\");\r\n    }\r\n    LOG.info(\"Application master for app\" + \", appId=\" + appAttemptID.getApplicationId().getId() + \", clustertimestamp=\" + appAttemptID.getApplicationId().getClusterTimestamp() + \", attemptId=\" + appAttemptID.getAttemptId());\r\n    if (!fileExist(shellCommandPath) && envs.get(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION).isEmpty()) {\r\n        throw new IllegalArgumentException(\"No shell command or shell script specified to be executed by application master\");\r\n    }\r\n    if (fileExist(shellCommandPath)) {\r\n        shellCommand = readContent(shellCommandPath);\r\n    }\r\n    if (fileExist(shellArgsPath)) {\r\n        shellArgs = readContent(shellArgsPath);\r\n    }\r\n    if (cliParser.hasOption(\"shell_env\")) {\r\n        String[] shellEnvs = cliParser.getOptionValues(\"shell_env\");\r\n        for (String env : shellEnvs) {\r\n            env = env.trim();\r\n            int index = env.indexOf('=');\r\n            if (index == -1) {\r\n                shellEnv.put(env, \"\");\r\n                continue;\r\n            }\r\n            String key = env.substring(0, index);\r\n            String val = \"\";\r\n            if (index < (env.length() - 1)) {\r\n                val = env.substring(index + 1);\r\n            }\r\n            shellEnv.put(key, val);\r\n        }\r\n    }\r\n    if (envs.containsKey(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION)) {\r\n        scriptPath = envs.get(DSConstants.DISTRIBUTEDSHELLSCRIPTLOCATION);\r\n        if (envs.containsKey(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP)) {\r\n            shellScriptPathTimestamp = Long.parseLong(envs.get(DSConstants.DISTRIBUTEDSHELLSCRIPTTIMESTAMP));\r\n        }\r\n        if (envs.containsKey(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN)) {\r\n            shellScriptPathLen = Long.parseLong(envs.get(DSConstants.DISTRIBUTEDSHELLSCRIPTLEN));\r\n        }\r\n        if (!scriptPath.isEmpty() && (shellScriptPathTimestamp <= 0 || shellScriptPathLen <= 0)) {\r\n            LOG.error(\"Illegal values in env for shell script path\" + \", path=\" + scriptPath + \", len=\" + shellScriptPathLen + \", timestamp=\" + shellScriptPathTimestamp);\r\n            throw new IllegalArgumentException(\"Illegal values in env for shell script path\");\r\n        }\r\n    }\r\n    if (envs.containsKey(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN)) {\r\n        domainId = envs.get(DSConstants.DISTRIBUTEDSHELLTIMELINEDOMAIN);\r\n    }\r\n    if (cliParser.hasOption(\"container_type\")) {\r\n        String containerTypeStr = cliParser.getOptionValue(\"container_type\");\r\n        if (Arrays.stream(ExecutionType.values()).noneMatch(executionType -> executionType.toString().equals(containerTypeStr))) {\r\n            throw new IllegalArgumentException(\"Invalid container_type: \" + containerTypeStr);\r\n        }\r\n        containerType = ExecutionType.valueOf(containerTypeStr);\r\n    }\r\n    if (cliParser.hasOption(\"promote_opportunistic_after_start\")) {\r\n        autoPromoteContainers = true;\r\n    }\r\n    if (cliParser.hasOption(\"enforce_execution_type\")) {\r\n        enforceExecType = true;\r\n    }\r\n    containerMemory = Integer.parseInt(cliParser.getOptionValue(\"container_memory\", \"-1\"));\r\n    containerVirtualCores = Integer.parseInt(cliParser.getOptionValue(\"container_vcores\", \"-1\"));\r\n    containerResources = new HashMap<>();\r\n    if (cliParser.hasOption(\"container_resources\")) {\r\n        Map<String, Long> resources = Client.parseResourcesString(cliParser.getOptionValue(\"container_resources\"));\r\n        for (Map.Entry<String, Long> entry : resources.entrySet()) {\r\n            containerResources.put(entry.getKey(), entry.getValue());\r\n        }\r\n    }\r\n    containerResourceProfile = cliParser.getOptionValue(\"container_resource_profile\", \"\");\r\n    keepContainersAcrossAttempts = cliParser.hasOption(\"keep_containers_across_application_attempts\");\r\n    if (this.placementSpecs == null) {\r\n        numTotalContainers = Integer.parseInt(cliParser.getOptionValue(\"num_containers\", \"1\"));\r\n    }\r\n    if (numTotalContainers == 0) {\r\n        throw new IllegalArgumentException(\"Cannot run distributed shell with no containers\");\r\n    }\r\n    requestPriority = Integer.parseInt(cliParser.getOptionValue(\"priority\", \"0\"));\r\n    containerRetryPolicy = ContainerRetryPolicy.values()[Integer.parseInt(cliParser.getOptionValue(\"container_retry_policy\", \"0\"))];\r\n    if (cliParser.hasOption(\"container_retry_error_codes\")) {\r\n        containerRetryErrorCodes = new HashSet<>();\r\n        for (String errorCode : cliParser.getOptionValue(\"container_retry_error_codes\").split(\",\")) {\r\n            containerRetryErrorCodes.add(Integer.parseInt(errorCode));\r\n        }\r\n    }\r\n    containerMaxRetries = Integer.parseInt(cliParser.getOptionValue(\"container_max_retries\", \"0\"));\r\n    containrRetryInterval = Integer.parseInt(cliParser.getOptionValue(\"container_retry_interval\", \"0\"));\r\n    containerFailuresValidityInterval = Long.parseLong(cliParser.getOptionValue(\"container_failures_validity_interval\", \"-1\"));\r\n    if (!YarnConfiguration.timelineServiceEnabled(conf)) {\r\n        timelineClient = null;\r\n        timelineV2Client = null;\r\n        LOG.warn(\"Timeline service is not enabled\");\r\n    }\r\n    if (cliParser.hasOption(\"localized_files\")) {\r\n        String localizedFilesArg = cliParser.getOptionValue(\"localized_files\");\r\n        if (localizedFilesArg.contains(\",\")) {\r\n            String[] files = localizedFilesArg.split(\",\");\r\n            localizableFiles = Arrays.asList(files);\r\n        } else {\r\n            localizableFiles.add(localizedFilesArg);\r\n        }\r\n    }\r\n    return true;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "parsePlacementSpecs",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void parsePlacementSpecs(String decodedSpec, int globalNumOfContainers)\n{\r\n    Map<String, PlacementSpec> pSpecs = PlacementSpec.parse(decodedSpec);\r\n    this.placementSpecs = new HashMap<>();\r\n    for (PlacementSpec pSpec : pSpecs.values()) {\r\n        if (Strings.isNullOrEmpty(pSpec.sourceTag) && pSpec.getNumContainers() == 0 && globalNumOfContainers > 0) {\r\n            pSpec.setNumContainers(globalNumOfContainers);\r\n        }\r\n        this.numTotalContainers += pSpec.getNumContainers();\r\n        this.placementSpecs.put(pSpec.sourceTag, pSpec);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getDecodedPlacementSpec",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getDecodedPlacementSpec(String placementSpecifications)\n{\r\n    Base64.Decoder decoder = Base64.getDecoder();\r\n    byte[] decodedBytes = decoder.decode(placementSpecifications.getBytes(StandardCharsets.UTF_8));\r\n    String decodedSpec = new String(decodedBytes, StandardCharsets.UTF_8);\r\n    LOG.info(\"Decode placement spec: \" + decodedSpec);\r\n    return decodedSpec;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void printUsage(Options opts)\n{\r\n    new HelpFormatter().printHelp(\"ApplicationMaster\", opts);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "cleanup",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void cleanup()\n{\r\n    try {\r\n        appSubmitterUgi.doAs(new PrivilegedExceptionAction<Void>() {\r\n\r\n            @Override\r\n            public Void run() throws IOException {\r\n                FileSystem fs = FileSystem.get(conf);\r\n                Path dst = new Path(homeDirectory, getRelativePath(appName, appId.toString(), \"\"));\r\n                fs.delete(dst, true);\r\n                return null;\r\n            }\r\n        });\r\n    } catch (Exception e) {\r\n        LOG.warn(\"Failed to remove application staging directory\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "run",
  "errType" : null,
  "containingMethodsNum" : 55,
  "sourceCodeText" : "void run() throws YarnException, IOException, InterruptedException\n{\r\n    LOG.info(\"Starting ApplicationMaster\");\r\n    Credentials credentials = UserGroupInformation.getCurrentUser().getCredentials();\r\n    DataOutputBuffer dob = new DataOutputBuffer();\r\n    credentials.writeTokenStorageToStream(dob);\r\n    Iterator<Token<?>> iter = credentials.getAllTokens().iterator();\r\n    LOG.info(\"Executing with tokens:\");\r\n    while (iter.hasNext()) {\r\n        Token<?> token = iter.next();\r\n        LOG.info(token.toString());\r\n        if (token.getKind().equals(AMRMTokenIdentifier.KIND_NAME)) {\r\n            iter.remove();\r\n        }\r\n    }\r\n    allTokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\r\n    String appSubmitterUserName = System.getenv(ApplicationConstants.Environment.USER.name());\r\n    appSubmitterUgi = UserGroupInformation.createRemoteUser(appSubmitterUserName);\r\n    appSubmitterUgi.addCredentials(credentials);\r\n    AMRMClientAsync.AbstractCallbackHandler allocListener = new RMCallbackHandler();\r\n    amRMClient = AMRMClientAsync.createAMRMClientAsync(1000, allocListener);\r\n    amRMClient.init(conf);\r\n    amRMClient.start();\r\n    containerListener = createNMCallbackHandler();\r\n    nmClientAsync = new NMClientAsyncImpl(containerListener);\r\n    nmClientAsync.init(conf);\r\n    nmClientAsync.start();\r\n    startTimelineClient(conf);\r\n    if (timelineServiceV2Enabled) {\r\n        amRMClient.registerTimelineV2Client(timelineV2Client);\r\n        publishApplicationAttemptEventOnTimelineServiceV2(DSEvent.DS_APP_ATTEMPT_START);\r\n    }\r\n    if (timelineServiceV1Enabled) {\r\n        publishApplicationAttemptEvent(timelineClient, appAttemptID.toString(), DSEvent.DS_APP_ATTEMPT_START, domainId, appSubmitterUgi);\r\n    }\r\n    appMasterHostname = NetUtils.getHostname();\r\n    Map<Set<String>, PlacementConstraint> placementConstraintMap = null;\r\n    if (this.placementSpecs != null) {\r\n        placementConstraintMap = new HashMap<>();\r\n        for (PlacementSpec spec : this.placementSpecs.values()) {\r\n            if (spec.constraint != null) {\r\n                Set<String> allocationTags = Strings.isNullOrEmpty(spec.sourceTag) ? Collections.emptySet() : Collections.singleton(spec.sourceTag);\r\n                placementConstraintMap.put(allocationTags, spec.constraint);\r\n            }\r\n        }\r\n    }\r\n    RegisterApplicationMasterResponse response = amRMClient.registerApplicationMaster(appMasterHostname, appMasterRpcPort, appMasterTrackingUrl, placementConstraintMap);\r\n    resourceProfiles = response.getResourceProfiles();\r\n    ResourceUtils.reinitializeResources(response.getResourceTypes());\r\n    long maxMem = response.getMaximumResourceCapability().getMemorySize();\r\n    LOG.info(\"Max mem capability of resources in this cluster \" + maxMem);\r\n    int maxVCores = response.getMaximumResourceCapability().getVirtualCores();\r\n    LOG.info(\"Max vcores capability of resources in this cluster \" + maxVCores);\r\n    if (containerMemory > maxMem) {\r\n        LOG.info(\"Container memory specified above max threshold of cluster.\" + \" Using max value.\" + \", specified=\" + containerMemory + \", max=\" + maxMem);\r\n        containerMemory = maxMem;\r\n    }\r\n    if (containerVirtualCores > maxVCores) {\r\n        LOG.info(\"Container virtual cores specified above max threshold of cluster.\" + \" Using max value.\" + \", specified=\" + containerVirtualCores + \", max=\" + maxVCores);\r\n        containerVirtualCores = maxVCores;\r\n    }\r\n    List<Container> previousAMRunningContainers = response.getContainersFromPreviousAttempts();\r\n    LOG.info(appAttemptID + \" received \" + previousAMRunningContainers.size() + \" previous attempts' running containers on AM registration.\");\r\n    for (Container container : previousAMRunningContainers) {\r\n        launchedContainers.add(container.getId());\r\n    }\r\n    numAllocatedContainers.addAndGet(previousAMRunningContainers.size());\r\n    int numTotalContainersToRequest = numTotalContainers - previousAMRunningContainers.size();\r\n    if (this.placementSpecs == null) {\r\n        LOG.info(\"placementSpecs null\");\r\n        for (int i = 0; i < numTotalContainersToRequest; ++i) {\r\n            ContainerRequest containerAsk = setupContainerAskForRM();\r\n            amRMClient.addContainerRequest(containerAsk);\r\n        }\r\n    } else {\r\n        LOG.info(\"placementSpecs to create req:\" + placementSpecs);\r\n        List<SchedulingRequest> schedReqs = new ArrayList<>();\r\n        for (PlacementSpec pSpec : this.placementSpecs.values()) {\r\n            LOG.info(\"placementSpec :\" + pSpec + \", container:\" + pSpec.getNumContainers());\r\n            for (int i = 0; i < pSpec.getNumContainers(); i++) {\r\n                SchedulingRequest sr = setupSchedulingRequest(pSpec);\r\n                schedReqs.add(sr);\r\n            }\r\n        }\r\n        amRMClient.addSchedulingRequests(schedReqs);\r\n    }\r\n    numRequestedContainers.set(numTotalContainers);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "startTimelineClient",
  "errType" : [ "UndeclaredThrowableException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void startTimelineClient(final Configuration conf) throws YarnException, IOException, InterruptedException\n{\r\n    try {\r\n        appSubmitterUgi.doAs(new PrivilegedExceptionAction<Void>() {\r\n\r\n            @Override\r\n            public Void run() throws Exception {\r\n                if (YarnConfiguration.timelineServiceEnabled(conf)) {\r\n                    timelineServiceV1Enabled = YarnConfiguration.timelineServiceV1Enabled(conf);\r\n                    timelineServiceV2Enabled = YarnConfiguration.timelineServiceV2Enabled(conf);\r\n                    if (timelineServiceV1Enabled) {\r\n                        timelineClient = TimelineClient.createTimelineClient();\r\n                        timelineClient.init(conf);\r\n                        timelineClient.start();\r\n                        LOG.info(\"Timeline service V1 client is enabled\");\r\n                    }\r\n                    if (timelineServiceV2Enabled) {\r\n                        timelineV2Client = TimelineV2Client.createTimelineClient(appAttemptID.getApplicationId());\r\n                        timelineV2Client.init(conf);\r\n                        timelineV2Client.start();\r\n                        LOG.info(\"Timeline service V2 client is enabled\");\r\n                    }\r\n                } else {\r\n                    timelineClient = null;\r\n                    timelineV2Client = null;\r\n                    LOG.warn(\"Timeline service is not enabled\");\r\n                }\r\n                return null;\r\n            }\r\n        });\r\n    } catch (UndeclaredThrowableException e) {\r\n        throw new YarnException(e.getCause());\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "createNMCallbackHandler",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "NMCallbackHandler createNMCallbackHandler()\n{\r\n    return new NMCallbackHandler(this);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "finish",
  "errType" : [ "InterruptedException", "InterruptedException", "YarnException|IOException" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "boolean finish()\n{\r\n    while (!done && (numCompletedContainers.get() != numTotalContainers)) {\r\n        try {\r\n            Thread.sleep(200);\r\n        } catch (InterruptedException ex) {\r\n        }\r\n    }\r\n    if (timelineServiceV1Enabled) {\r\n        publishApplicationAttemptEvent(timelineClient, appAttemptID.toString(), DSEvent.DS_APP_ATTEMPT_END, domainId, appSubmitterUgi);\r\n    }\r\n    if (timelineServiceV2Enabled) {\r\n        publishApplicationAttemptEventOnTimelineServiceV2(DSEvent.DS_APP_ATTEMPT_END);\r\n    }\r\n    for (Thread launchThread : launchThreads) {\r\n        try {\r\n            launchThread.join(10000);\r\n        } catch (InterruptedException e) {\r\n            LOG.info(\"Exception thrown in thread join: \" + e.getMessage());\r\n            e.printStackTrace();\r\n        }\r\n    }\r\n    LOG.info(\"Application completed. Stopping running containers\");\r\n    nmClientAsync.stop();\r\n    LOG.info(\"Application completed. Signalling finished to RM\");\r\n    FinalApplicationStatus appStatus;\r\n    boolean success = true;\r\n    String message = null;\r\n    if (numCompletedContainers.get() - numFailedContainers.get() >= numTotalContainers) {\r\n        appStatus = FinalApplicationStatus.SUCCEEDED;\r\n    } else {\r\n        appStatus = FinalApplicationStatus.FAILED;\r\n        message = String.format(\"Application Failure: desired = %d, \" + \"completed = %d, allocated = %d, failed = %d, \" + \"diagnostics = %s\", numRequestedContainers.get(), numCompletedContainers.get(), numAllocatedContainers.get(), numFailedContainers.get(), diagnostics);\r\n        success = false;\r\n    }\r\n    try {\r\n        amRMClient.unregisterApplicationMaster(appStatus, message, null);\r\n    } catch (YarnException | IOException ex) {\r\n        LOG.error(\"Failed to unregister application\", ex);\r\n    }\r\n    amRMClient.stop();\r\n    if (timelineServiceV1Enabled) {\r\n        timelineClient.stop();\r\n    }\r\n    if (timelineServiceV2Enabled) {\r\n        timelineV2Client.stop();\r\n    }\r\n    return success;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getRelativePath",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getRelativePath(String appName, String appId, String fileDstPath)\n{\r\n    return appName + \"/\" + appId + \"/\" + fileDstPath;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "renameScriptFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void renameScriptFile(final Path renamedScriptPath) throws IOException, InterruptedException\n{\r\n    appSubmitterUgi.doAs(new PrivilegedExceptionAction<Void>() {\r\n\r\n        @Override\r\n        public Void run() throws IOException {\r\n            FileSystem fs = renamedScriptPath.getFileSystem(conf);\r\n            fs.rename(new Path(scriptPath), renamedScriptPath);\r\n            return null;\r\n        }\r\n    });\r\n    LOG.info(\"User \" + appSubmitterUgi.getUserName() + \" added suffix(.sh/.bat) to script file as \" + renamedScriptPath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "setupContainerAskForRM",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "ContainerRequest setupContainerAskForRM()\n{\r\n    Priority pri = Priority.newInstance(requestPriority);\r\n    ContainerRequest request = new ContainerRequest(getTaskResourceCapability(), null, null, pri, 0, true, null, ExecutionTypeRequest.newInstance(containerType, enforceExecType), containerResourceProfile);\r\n    LOG.info(\"Requested container ask: \" + request.toString());\r\n    return request;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "setupSchedulingRequest",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "SchedulingRequest setupSchedulingRequest(PlacementSpec spec)\n{\r\n    long allocId = allocIdCounter.incrementAndGet();\r\n    SchedulingRequest sReq = SchedulingRequest.newInstance(allocId, Priority.newInstance(requestPriority), ExecutionTypeRequest.newInstance(), Collections.singleton(spec.sourceTag), ResourceSizing.newInstance(getTaskResourceCapability()), null);\r\n    sReq.setPlacementConstraint(spec.constraint);\r\n    LOG.info(\"Scheduling Request made: \" + sReq.toString());\r\n    return sReq;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "fileExist",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean fileExist(String filePath)\n{\r\n    return new File(filePath).exists();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "readContent",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String readContent(String filePath) throws IOException\n{\r\n    try (DataInputStream ds = new DataInputStream(new FileInputStream(filePath))) {\r\n        return ds.readUTF();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishContainerStartEvent",
  "errType" : [ "YarnException|IOException|ClientHandlerException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void publishContainerStartEvent(final TimelineClient timelineClient, final Container container, String domainId, UserGroupInformation ugi)\n{\r\n    final TimelineEntity entity = new TimelineEntity();\r\n    entity.setEntityId(container.getId().toString());\r\n    entity.setEntityType(DSEntity.DS_CONTAINER.toString());\r\n    entity.setDomainId(domainId);\r\n    entity.addPrimaryFilter(USER_TIMELINE_FILTER_NAME, ugi.getShortUserName());\r\n    entity.addPrimaryFilter(APPID_TIMELINE_FILTER_NAME, container.getId().getApplicationAttemptId().getApplicationId().toString());\r\n    TimelineEvent event = new TimelineEvent();\r\n    event.setTimestamp(System.currentTimeMillis());\r\n    event.setEventType(DSEvent.DS_CONTAINER_START.toString());\r\n    event.addEventInfo(\"Node\", container.getNodeId().toString());\r\n    event.addEventInfo(\"Resources\", container.getResource().toString());\r\n    entity.addEvent(event);\r\n    try {\r\n        processTimelineResponseErrors(putContainerEntity(timelineClient, container.getId().getApplicationAttemptId(), entity));\r\n    } catch (YarnException | IOException | ClientHandlerException e) {\r\n        LOG.error(\"Container start event could not be published for \" + container.getId().toString(), e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishContainerEndEvent",
  "errType" : [ "YarnException|IOException|ClientHandlerException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void publishContainerEndEvent(final TimelineClient timelineClient, ContainerStatus container, String domainId, UserGroupInformation ugi)\n{\r\n    final TimelineEntity entity = new TimelineEntity();\r\n    entity.setEntityId(container.getContainerId().toString());\r\n    entity.setEntityType(DSEntity.DS_CONTAINER.toString());\r\n    entity.setDomainId(domainId);\r\n    entity.addPrimaryFilter(USER_TIMELINE_FILTER_NAME, ugi.getShortUserName());\r\n    entity.addPrimaryFilter(APPID_TIMELINE_FILTER_NAME, container.getContainerId().getApplicationAttemptId().getApplicationId().toString());\r\n    TimelineEvent event = new TimelineEvent();\r\n    event.setTimestamp(System.currentTimeMillis());\r\n    event.setEventType(DSEvent.DS_CONTAINER_END.toString());\r\n    event.addEventInfo(\"State\", container.getState().name());\r\n    event.addEventInfo(\"Exit Status\", container.getExitStatus());\r\n    event.addEventInfo(DIAGNOSTICS, container.getDiagnostics());\r\n    entity.addEvent(event);\r\n    try {\r\n        processTimelineResponseErrors(putContainerEntity(timelineClient, container.getContainerId().getApplicationAttemptId(), entity));\r\n    } catch (YarnException | IOException | ClientHandlerException e) {\r\n        LOG.error(\"Container end event could not be published for \" + container.getContainerId().toString(), e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "putContainerEntity",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TimelinePutResponse putContainerEntity(TimelineClient timelineClient, ApplicationAttemptId currAttemptId, TimelineEntity entity) throws YarnException, IOException\n{\r\n    if (TimelineUtils.timelineServiceV1_5Enabled(conf)) {\r\n        TimelineEntityGroupId groupId = TimelineEntityGroupId.newInstance(currAttemptId.getApplicationId(), CONTAINER_ENTITY_GROUP_ID);\r\n        return timelineClient.putEntities(currAttemptId, groupId, entity);\r\n    } else {\r\n        return timelineClient.putEntities(entity);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishApplicationAttemptEvent",
  "errType" : [ "YarnException|IOException|ClientHandlerException" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void publishApplicationAttemptEvent(final TimelineClient timelineClient, String appAttemptId, DSEvent appEvent, String domainId, UserGroupInformation ugi)\n{\r\n    final TimelineEntity entity = new TimelineEntity();\r\n    entity.setEntityId(appAttemptId);\r\n    entity.setEntityType(DSEntity.DS_APP_ATTEMPT.toString());\r\n    entity.setDomainId(domainId);\r\n    entity.addPrimaryFilter(USER_TIMELINE_FILTER_NAME, ugi.getShortUserName());\r\n    TimelineEvent event = new TimelineEvent();\r\n    event.setEventType(appEvent.toString());\r\n    event.setTimestamp(System.currentTimeMillis());\r\n    entity.addEvent(event);\r\n    try {\r\n        TimelinePutResponse response = timelineClient.putEntities(entity);\r\n        processTimelineResponseErrors(response);\r\n    } catch (YarnException | IOException | ClientHandlerException e) {\r\n        LOG.error(\"App Attempt \" + (appEvent.equals(DSEvent.DS_APP_ATTEMPT_START) ? \"start\" : \"end\") + \" event could not be published for \" + appAttemptID, e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "processTimelineResponseErrors",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TimelinePutResponse processTimelineResponseErrors(TimelinePutResponse response)\n{\r\n    List<TimelinePutResponse.TimelinePutError> errors = response.getErrors();\r\n    if (errors.size() == 0) {\r\n        LOG.debug(\"Timeline entities are successfully put\");\r\n    } else {\r\n        for (TimelinePutResponse.TimelinePutError error : errors) {\r\n            LOG.error(\"Error when publishing entity [\" + error.getEntityType() + \",\" + error.getEntityId() + \"], server side error code: \" + error.getErrorCode());\r\n        }\r\n    }\r\n    return response;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getRMCallbackHandler",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "RMCallbackHandler getRMCallbackHandler()\n{\r\n    return new RMCallbackHandler();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "setAmRMClient",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setAmRMClient(AMRMClientAsync client)\n{\r\n    this.amRMClient = client;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getNumCompletedContainers",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getNumCompletedContainers()\n{\r\n    return numCompletedContainers.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getDone",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean getDone()\n{\r\n    return done;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "createLaunchContainerThread",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Thread createLaunchContainerThread(Container allocatedContainer, String shellId)\n{\r\n    LaunchContainerRunnable runnableLaunchContainer = new LaunchContainerRunnable(allocatedContainer, containerListener, shellId);\r\n    return new Thread(runnableLaunchContainer);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishContainerStartEventOnTimelineServiceV2",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void publishContainerStartEventOnTimelineServiceV2(Container container, long startTime)\n{\r\n    final org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity entity = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity();\r\n    entity.setId(container.getId().toString());\r\n    entity.setType(DSEntity.DS_CONTAINER.toString());\r\n    entity.setCreatedTime(startTime);\r\n    entity.addInfo(\"user\", appSubmitterUgi.getShortUserName());\r\n    org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent event = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent();\r\n    event.setTimestamp(startTime);\r\n    event.setId(DSEvent.DS_CONTAINER_START.toString());\r\n    event.addInfo(\"Node\", container.getNodeId().toString());\r\n    event.addInfo(\"Resources\", container.getResource().toString());\r\n    entity.addEvent(event);\r\n    entity.setIdPrefix(TimelineServiceHelper.invertLong(startTime));\r\n    try {\r\n        appSubmitterUgi.doAs(new PrivilegedExceptionAction<Object>() {\r\n\r\n            @Override\r\n            public TimelinePutResponse run() throws Exception {\r\n                timelineV2Client.putEntitiesAsync(entity);\r\n                return null;\r\n            }\r\n        });\r\n    } catch (Exception e) {\r\n        LOG.error(\"Container start event could not be published for \" + container.getId().toString(), e instanceof UndeclaredThrowableException ? e.getCause() : e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishContainerStartFailedEventOnTimelineServiceV2",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void publishContainerStartFailedEventOnTimelineServiceV2(final ContainerId containerId, String diagnostics)\n{\r\n    final org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity entity = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity();\r\n    entity.setId(containerId.toString());\r\n    entity.setType(DSEntity.DS_CONTAINER.toString());\r\n    entity.addInfo(\"user\", appSubmitterUgi.getShortUserName());\r\n    org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent event = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent();\r\n    event.setTimestamp(System.currentTimeMillis());\r\n    event.setId(DSEvent.DS_CONTAINER_END.toString());\r\n    event.addInfo(DIAGNOSTICS, diagnostics);\r\n    entity.addEvent(event);\r\n    try {\r\n        appSubmitterUgi.doAs((PrivilegedExceptionAction<Object>) () -> {\r\n            timelineV2Client.putEntitiesAsync(entity);\r\n            return null;\r\n        });\r\n    } catch (Exception e) {\r\n        LOG.error(\"Container start failed event could not be published for {}\", containerId, e instanceof UndeclaredThrowableException ? e.getCause() : e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishContainerStartFailedEvent",
  "errType" : [ "YarnException|IOException|ClientHandlerException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void publishContainerStartFailedEvent(final ContainerId containerId, String diagnostics)\n{\r\n    final TimelineEntity entityV1 = new TimelineEntity();\r\n    entityV1.setEntityId(containerId.toString());\r\n    entityV1.setEntityType(DSEntity.DS_CONTAINER.toString());\r\n    entityV1.setDomainId(domainId);\r\n    entityV1.addPrimaryFilter(USER_TIMELINE_FILTER_NAME, appSubmitterUgi.getShortUserName());\r\n    entityV1.addPrimaryFilter(APPID_TIMELINE_FILTER_NAME, containerId.getApplicationAttemptId().getApplicationId().toString());\r\n    TimelineEvent eventV1 = new TimelineEvent();\r\n    eventV1.setTimestamp(System.currentTimeMillis());\r\n    eventV1.setEventType(DSEvent.DS_CONTAINER_END.toString());\r\n    eventV1.addEventInfo(DIAGNOSTICS, diagnostics);\r\n    entityV1.addEvent(eventV1);\r\n    try {\r\n        processTimelineResponseErrors(putContainerEntity(timelineClient, containerId.getApplicationAttemptId(), entityV1));\r\n    } catch (YarnException | IOException | ClientHandlerException e) {\r\n        LOG.error(\"Container end event could not be published for {}\", containerId, e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishContainerEndEventOnTimelineServiceV2",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void publishContainerEndEventOnTimelineServiceV2(final ContainerStatus container, long containerStartTime)\n{\r\n    final org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity entity = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity();\r\n    entity.setId(container.getContainerId().toString());\r\n    entity.setType(DSEntity.DS_CONTAINER.toString());\r\n    entity.addInfo(\"user\", appSubmitterUgi.getShortUserName());\r\n    org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent event = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent();\r\n    event.setTimestamp(System.currentTimeMillis());\r\n    event.setId(DSEvent.DS_CONTAINER_END.toString());\r\n    event.addInfo(\"State\", container.getState().name());\r\n    event.addInfo(\"Exit Status\", container.getExitStatus());\r\n    event.addInfo(DIAGNOSTICS, container.getDiagnostics());\r\n    entity.addEvent(event);\r\n    entity.setIdPrefix(TimelineServiceHelper.invertLong(containerStartTime));\r\n    try {\r\n        appSubmitterUgi.doAs(new PrivilegedExceptionAction<Object>() {\r\n\r\n            @Override\r\n            public TimelinePutResponse run() throws Exception {\r\n                timelineV2Client.putEntitiesAsync(entity);\r\n                return null;\r\n            }\r\n        });\r\n    } catch (Exception e) {\r\n        LOG.error(\"Container end event could not be published for \" + container.getContainerId().toString(), e instanceof UndeclaredThrowableException ? e.getCause() : e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "publishApplicationAttemptEventOnTimelineServiceV2",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void publishApplicationAttemptEventOnTimelineServiceV2(DSEvent appEvent)\n{\r\n    final org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity entity = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity();\r\n    entity.setId(appAttemptID.toString());\r\n    entity.setType(DSEntity.DS_APP_ATTEMPT.toString());\r\n    long ts = System.currentTimeMillis();\r\n    if (appEvent == DSEvent.DS_APP_ATTEMPT_START) {\r\n        entity.setCreatedTime(ts);\r\n    }\r\n    entity.addInfo(\"user\", appSubmitterUgi.getShortUserName());\r\n    org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent event = new org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent();\r\n    event.setId(appEvent.toString());\r\n    event.setTimestamp(ts);\r\n    entity.addEvent(event);\r\n    entity.setIdPrefix(TimelineServiceHelper.invertLong(appAttemptID.getAttemptId()));\r\n    try {\r\n        appSubmitterUgi.doAs(new PrivilegedExceptionAction<Object>() {\r\n\r\n            @Override\r\n            public TimelinePutResponse run() throws Exception {\r\n                timelineV2Client.putEntitiesAsync(entity);\r\n                return null;\r\n            }\r\n        });\r\n    } catch (Exception e) {\r\n        LOG.error(\"App Attempt \" + (appEvent.equals(DSEvent.DS_APP_ATTEMPT_START) ? \"start\" : \"end\") + \" event could not be published for \" + appAttemptID, e instanceof UndeclaredThrowableException ? e.getCause() : e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getTaskResourceCapability",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Resource getTaskResourceCapability() throws YarnRuntimeException\n{\r\n    if (containerMemory < -1 || containerMemory == 0) {\r\n        throw new YarnRuntimeException(\"Value of AM memory '\" + containerMemory + \"' has to be greater than 0\");\r\n    }\r\n    if (containerVirtualCores < -1 || containerVirtualCores == 0) {\r\n        throw new YarnRuntimeException(\"Value of AM vcores '\" + containerVirtualCores + \"' has to be greater than 0\");\r\n    }\r\n    Resource resourceCapability = Resource.newInstance(containerMemory, containerVirtualCores);\r\n    containerMemory = containerMemory == -1 ? DEFAULT_CONTAINER_MEMORY : containerMemory;\r\n    containerVirtualCores = containerVirtualCores == -1 ? DEFAULT_CONTAINER_VCORES : containerVirtualCores;\r\n    resourceCapability.setMemorySize(containerMemory);\r\n    resourceCapability.setVirtualCores(containerVirtualCores);\r\n    for (Map.Entry<String, Long> entry : containerResources.entrySet()) {\r\n        resourceCapability.setResourceValue(entry.getKey(), entry.getValue());\r\n    }\r\n    return resourceCapability;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getTimelineEntityGroupId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Set<TimelineEntityGroupId> getTimelineEntityGroupId(String entityType, NameValuePair primaryFilter, Collection<NameValuePair> secondaryFilters)\n{\r\n    if (ApplicationMaster.DSEntity.DS_CONTAINER.toString().equals(entityType)) {\r\n        if (primaryFilter == null) {\r\n            return null;\r\n        }\r\n        return toEntityGroupId(primaryFilter.getValue().toString());\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getTimelineEntityGroupId",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "Set<TimelineEntityGroupId> getTimelineEntityGroupId(String entityId, String entityType)\n{\r\n    if (ApplicationMaster.DSEntity.DS_CONTAINER.toString().equals(entityType)) {\r\n        ContainerId containerId = ContainerId.fromString(entityId);\r\n        ApplicationId appId = containerId.getApplicationAttemptId().getApplicationId();\r\n        return toEntityGroupId(appId.toString());\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getTimelineEntityGroupId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Set<TimelineEntityGroupId> getTimelineEntityGroupId(String entityType, SortedSet<String> entityIds, Set<String> eventTypes)\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "toEntityGroupId",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Set<TimelineEntityGroupId> toEntityGroupId(String strAppId)\n{\r\n    ApplicationId appId = ApplicationId.fromString(strAppId);\r\n    TimelineEntityGroupId groupId = TimelineEntityGroupId.newInstance(appId, ApplicationMaster.CONTAINER_ENTITY_GROUP_ID);\r\n    Set<TimelineEntityGroupId> result = new HashSet<>();\r\n    result.add(groupId);\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "getNumContainers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumContainers()\n{\r\n    return numContainers;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "setNumContainers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setNumContainers(int numContainers)\n{\r\n    this.numContainers = numContainers;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "parse",
  "errType" : [ "PlacementConstraintParseException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "Map<String, PlacementSpec> parse(String specs) throws IllegalArgumentException\n{\r\n    LOG.info(\"Parsing Placement Specs: [{}]\", specs);\r\n    Map<String, PlacementSpec> pSpecs = new HashMap<>();\r\n    Map<SourceTags, PlacementConstraint> parsed;\r\n    try {\r\n        parsed = PlacementConstraintParser.parsePlacementSpec(specs);\r\n        for (Map.Entry<SourceTags, PlacementConstraint> entry : parsed.entrySet()) {\r\n            LOG.info(\"Parsed source tag: {}, number of allocations: {}\", entry.getKey().getTag(), entry.getKey().getNumOfAllocations());\r\n            if (entry.getValue() != null) {\r\n                LOG.info(\"Parsed constraint: {}\", entry.getValue().getConstraintExpr().getClass().getSimpleName());\r\n            } else {\r\n                LOG.info(\"Parsed constraint Empty\");\r\n            }\r\n            pSpecs.put(entry.getKey().getTag(), new PlacementSpec(entry.getKey().getTag(), entry.getKey().getNumOfAllocations(), entry.getValue()));\r\n        }\r\n        return pSpecs;\r\n    } catch (PlacementConstraintParseException e) {\r\n        throw new IllegalArgumentException(\"Invalid placement spec: \" + specs, e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-yarn-project\\hadoop-yarn\\hadoop-yarn-applications\\hadoop-yarn-applications-distributedshell\\src\\main\\java\\org\\apache\\hadoop\\yarn\\applications\\distributedshell",
  "methodName" : "updateLog4jConfiguration",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void updateLog4jConfiguration(Class<?> targetClass, String log4jPath) throws Exception\n{\r\n    Properties customProperties = new Properties();\r\n    try (FileInputStream fs = new FileInputStream(log4jPath);\r\n        InputStream is = targetClass.getResourceAsStream(\"/log4j.properties\")) {\r\n        customProperties.load(fs);\r\n        Properties originalProperties = new Properties();\r\n        originalProperties.load(is);\r\n        for (Entry<Object, Object> entry : customProperties.entrySet()) {\r\n            originalProperties.setProperty(entry.getKey().toString(), entry.getValue().toString());\r\n        }\r\n        LogManager.resetConfiguration();\r\n        PropertyConfigurator.configure(originalProperties);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
} ]