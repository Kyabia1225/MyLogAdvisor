[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setTypedBytesInput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTypedBytesInput(TypedBytesInput in)\n{\r\n    this.in = in;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBytesRecordInput get(TypedBytesInput in)\n{\r\n    TypedBytesRecordInput bin = TB_IN.get();\r\n    bin.setTypedBytesInput(in);\r\n    return bin;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TypedBytesRecordInput get(DataInput in)\n{\r\n    return get(TypedBytesInput.get(in));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBool",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean readBool(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readBool();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBuffer",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Buffer readBuffer(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return new Buffer(in.readBytes());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readByte",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "byte readByte(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readByte();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readDouble",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "double readDouble(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readDouble();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readFloat",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "float readFloat(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readFloat();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readInt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int readInt(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readInt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readLong",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "long readLong(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readLong();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String readString(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return in.readString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "startRecord",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void startRecord(String tag) throws IOException\n{\r\n    in.skipType();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "startVector",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Index startVector(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return new TypedBytesIndex(in.readVectorHeader());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "startMap",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Index startMap(String tag) throws IOException\n{\r\n    in.skipType();\r\n    return new TypedBytesIndex(in.readMapHeader());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "endRecord",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endRecord(String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "endVector",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endVector(String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "endMap",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endMap(String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toXMLString",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "String toXMLString(String s)\n{\r\n    StringBuilder sb = new StringBuilder();\r\n    for (int idx = 0; idx < s.length(); idx++) {\r\n        char ch = s.charAt(idx);\r\n        if (ch == '<') {\r\n            sb.append(\"&lt;\");\r\n        } else if (ch == '&') {\r\n            sb.append(\"&amp;\");\r\n        } else if (ch == '%') {\r\n            sb.append(\"%0025\");\r\n        } else if (ch < 0x20 || (ch > 0xD7FF && ch < 0xE000) || (ch > 0xFFFD)) {\r\n            sb.append(\"%\");\r\n            sb.append(hexchars[(ch & 0xF000) >> 12]);\r\n            sb.append(hexchars[(ch & 0x0F00) >> 8]);\r\n            sb.append(hexchars[(ch & 0x00F0) >> 4]);\r\n            sb.append(hexchars[(ch & 0x000F)]);\r\n        } else {\r\n            sb.append(ch);\r\n        }\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "h2c",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int h2c(char ch)\n{\r\n    if (ch >= '0' && ch <= '9') {\r\n        return ch - '0';\r\n    } else if (ch >= 'A' && ch <= 'F') {\r\n        return ch - 'A' + 10;\r\n    } else if (ch >= 'a' && ch <= 'f') {\r\n        return ch - 'a' + 10;\r\n    }\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "fromXMLString",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "String fromXMLString(String s)\n{\r\n    StringBuilder sb = new StringBuilder();\r\n    for (int idx = 0; idx < s.length(); ) {\r\n        char ch = s.charAt(idx++);\r\n        if (ch == '%') {\r\n            int ch1 = h2c(s.charAt(idx++)) << 12;\r\n            int ch2 = h2c(s.charAt(idx++)) << 8;\r\n            int ch3 = h2c(s.charAt(idx++)) << 4;\r\n            int ch4 = h2c(s.charAt(idx++));\r\n            char res = (char) (ch1 | ch2 | ch3 | ch4);\r\n            sb.append(res);\r\n        } else {\r\n            sb.append(ch);\r\n        }\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toCSVString",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "String toCSVString(String s)\n{\r\n    StringBuilder sb = new StringBuilder(s.length() + 1);\r\n    sb.append('\\'');\r\n    int len = s.length();\r\n    for (int i = 0; i < len; i++) {\r\n        char c = s.charAt(i);\r\n        switch(c) {\r\n            case '\\0':\r\n                sb.append(\"%00\");\r\n                break;\r\n            case '\\n':\r\n                sb.append(\"%0A\");\r\n                break;\r\n            case '\\r':\r\n                sb.append(\"%0D\");\r\n                break;\r\n            case ',':\r\n                sb.append(\"%2C\");\r\n                break;\r\n            case '}':\r\n                sb.append(\"%7D\");\r\n                break;\r\n            case '%':\r\n                sb.append(\"%25\");\r\n                break;\r\n            default:\r\n                sb.append(c);\r\n        }\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "fromCSVString",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "String fromCSVString(String s) throws IOException\n{\r\n    if (s.charAt(0) != '\\'') {\r\n        throw new IOException(\"Error deserializing string.\");\r\n    }\r\n    int len = s.length();\r\n    StringBuilder sb = new StringBuilder(len - 1);\r\n    for (int i = 1; i < len; i++) {\r\n        char c = s.charAt(i);\r\n        if (c == '%') {\r\n            char ch1 = s.charAt(i + 1);\r\n            char ch2 = s.charAt(i + 2);\r\n            i += 2;\r\n            if (ch1 == '0' && ch2 == '0') {\r\n                sb.append('\\0');\r\n            } else if (ch1 == '0' && ch2 == 'A') {\r\n                sb.append('\\n');\r\n            } else if (ch1 == '0' && ch2 == 'D') {\r\n                sb.append('\\r');\r\n            } else if (ch1 == '2' && ch2 == 'C') {\r\n                sb.append(',');\r\n            } else if (ch1 == '7' && ch2 == 'D') {\r\n                sb.append('}');\r\n            } else if (ch1 == '2' && ch2 == '5') {\r\n                sb.append('%');\r\n            } else {\r\n                throw new IOException(\"Error deserializing string.\");\r\n            }\r\n        } else {\r\n            sb.append(c);\r\n        }\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toXMLBuffer",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toXMLBuffer(Buffer s)\n{\r\n    return s.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "fromXMLBuffer",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Buffer fromXMLBuffer(String s) throws IOException\n{\r\n    if (s.length() == 0) {\r\n        return new Buffer();\r\n    }\r\n    int blen = s.length() / 2;\r\n    byte[] barr = new byte[blen];\r\n    for (int idx = 0; idx < blen; idx++) {\r\n        char c1 = s.charAt(2 * idx);\r\n        char c2 = s.charAt(2 * idx + 1);\r\n        barr[idx] = (byte) Integer.parseInt(\"\" + c1 + c2, 16);\r\n    }\r\n    return new Buffer(barr);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toCSVBuffer",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String toCSVBuffer(Buffer buf)\n{\r\n    StringBuilder sb = new StringBuilder(\"#\");\r\n    sb.append(buf.toString());\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "fromCSVBuffer",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "Buffer fromCSVBuffer(String s) throws IOException\n{\r\n    if (s.charAt(0) != '#') {\r\n        throw new IOException(\"Error deserializing buffer.\");\r\n    }\r\n    if (s.length() == 1) {\r\n        return new Buffer();\r\n    }\r\n    int blen = (s.length() - 1) / 2;\r\n    byte[] barr = new byte[blen];\r\n    for (int idx = 0; idx < blen; idx++) {\r\n        char c1 = s.charAt(2 * idx + 1);\r\n        char c2 = s.charAt(2 * idx + 2);\r\n        barr[idx] = (byte) Integer.parseInt(\"\" + c1 + c2, 16);\r\n    }\r\n    return new Buffer(barr);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "utf8LenForCodePoint",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int utf8LenForCodePoint(final int cpt) throws IOException\n{\r\n    if (cpt >= 0 && cpt <= 0x7F) {\r\n        return 1;\r\n    }\r\n    if (cpt >= 0x80 && cpt <= 0x07FF) {\r\n        return 2;\r\n    }\r\n    if ((cpt >= 0x0800 && cpt < 0xD800) || (cpt > 0xDFFF && cpt <= 0xFFFD)) {\r\n        return 3;\r\n    }\r\n    if (cpt >= 0x10000 && cpt <= 0x10FFFF) {\r\n        return 4;\r\n    }\r\n    throw new IOException(\"Illegal Unicode Codepoint \" + Integer.toHexString(cpt) + \" in string.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeUtf8",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int writeUtf8(int cpt, final byte[] bytes, final int offset) throws IOException\n{\r\n    if (cpt >= 0 && cpt <= 0x7F) {\r\n        bytes[offset] = (byte) cpt;\r\n        return 1;\r\n    }\r\n    if (cpt >= 0x80 && cpt <= 0x07FF) {\r\n        bytes[offset + 1] = (byte) (B10 | (cpt & 0x3F));\r\n        cpt = cpt >> 6;\r\n        bytes[offset] = (byte) (B110 | (cpt & 0x1F));\r\n        return 2;\r\n    }\r\n    if ((cpt >= 0x0800 && cpt < 0xD800) || (cpt > 0xDFFF && cpt <= 0xFFFD)) {\r\n        bytes[offset + 2] = (byte) (B10 | (cpt & 0x3F));\r\n        cpt = cpt >> 6;\r\n        bytes[offset + 1] = (byte) (B10 | (cpt & 0x3F));\r\n        cpt = cpt >> 6;\r\n        bytes[offset] = (byte) (B1110 | (cpt & 0x0F));\r\n        return 3;\r\n    }\r\n    if (cpt >= 0x10000 && cpt <= 0x10FFFF) {\r\n        bytes[offset + 3] = (byte) (B10 | (cpt & 0x3F));\r\n        cpt = cpt >> 6;\r\n        bytes[offset + 2] = (byte) (B10 | (cpt & 0x3F));\r\n        cpt = cpt >> 6;\r\n        bytes[offset + 1] = (byte) (B10 | (cpt & 0x3F));\r\n        cpt = cpt >> 6;\r\n        bytes[offset] = (byte) (B11110 | (cpt & 0x07));\r\n        return 4;\r\n    }\r\n    throw new IOException(\"Illegal Unicode Codepoint \" + Integer.toHexString(cpt) + \" in string.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toBinaryString",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void toBinaryString(final DataOutput out, final String str) throws IOException\n{\r\n    final int strlen = str.length();\r\n    byte[] bytes = new byte[strlen * 4];\r\n    int utf8Len = 0;\r\n    int idx = 0;\r\n    while (idx < strlen) {\r\n        final int cpt = str.codePointAt(idx);\r\n        idx += Character.isSupplementaryCodePoint(cpt) ? 2 : 1;\r\n        utf8Len += writeUtf8(cpt, bytes, utf8Len);\r\n    }\r\n    writeVInt(out, utf8Len);\r\n    out.write(bytes, 0, utf8Len);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "isValidCodePoint",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isValidCodePoint(int cpt)\n{\r\n    return !((cpt > 0x10FFFF) || (cpt >= 0xD800 && cpt <= 0xDFFF) || (cpt >= 0xFFFE && cpt <= 0xFFFF));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "utf8ToCodePoint",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int utf8ToCodePoint(int b1, int b2, int b3, int b4)\n{\r\n    int cpt = 0;\r\n    cpt = (((b1 & ~B11111) << 18) | ((b2 & ~B11) << 12) | ((b3 & ~B11) << 6) | (b4 & ~B11));\r\n    return cpt;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "utf8ToCodePoint",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int utf8ToCodePoint(int b1, int b2, int b3)\n{\r\n    int cpt = 0;\r\n    cpt = (((b1 & ~B1111) << 12) | ((b2 & ~B11) << 6) | (b3 & ~B11));\r\n    return cpt;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "utf8ToCodePoint",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int utf8ToCodePoint(int b1, int b2)\n{\r\n    int cpt = 0;\r\n    cpt = (((b1 & ~B111) << 6) | (b2 & ~B11));\r\n    return cpt;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "checkB10",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void checkB10(int b) throws IOException\n{\r\n    if ((b & B11) != B10) {\r\n        throw new IOException(\"Invalid UTF-8 representation.\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "fromBinaryString",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "String fromBinaryString(final DataInput din) throws IOException\n{\r\n    final int utf8Len = readVInt(din);\r\n    final byte[] bytes = new byte[utf8Len];\r\n    din.readFully(bytes);\r\n    int len = 0;\r\n    StringBuilder sb = new StringBuilder(utf8Len);\r\n    while (len < utf8Len) {\r\n        int cpt = 0;\r\n        final int b1 = bytes[len++] & 0xFF;\r\n        if (b1 <= 0x7F) {\r\n            cpt = b1;\r\n        } else if ((b1 & B11111) == B11110) {\r\n            int b2 = bytes[len++] & 0xFF;\r\n            checkB10(b2);\r\n            int b3 = bytes[len++] & 0xFF;\r\n            checkB10(b3);\r\n            int b4 = bytes[len++] & 0xFF;\r\n            checkB10(b4);\r\n            cpt = utf8ToCodePoint(b1, b2, b3, b4);\r\n        } else if ((b1 & B1111) == B1110) {\r\n            int b2 = bytes[len++] & 0xFF;\r\n            checkB10(b2);\r\n            int b3 = bytes[len++] & 0xFF;\r\n            checkB10(b3);\r\n            cpt = utf8ToCodePoint(b1, b2, b3);\r\n        } else if ((b1 & B111) == B110) {\r\n            int b2 = bytes[len++] & 0xFF;\r\n            checkB10(b2);\r\n            cpt = utf8ToCodePoint(b1, b2);\r\n        } else {\r\n            throw new IOException(\"Invalid UTF-8 byte \" + Integer.toHexString(b1) + \" at offset \" + (len - 1) + \" in length of \" + utf8Len);\r\n        }\r\n        if (!isValidCodePoint(cpt)) {\r\n            throw new IOException(\"Illegal Unicode Codepoint \" + Integer.toHexString(cpt) + \" in stream.\");\r\n        }\r\n        sb.appendCodePoint(cpt);\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float readFloat(byte[] bytes, int start)\n{\r\n    return WritableComparator.readFloat(bytes, start);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "double readDouble(byte[] bytes, int start)\n{\r\n    return WritableComparator.readDouble(bytes, start);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readVLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long readVLong(byte[] bytes, int start) throws IOException\n{\r\n    return WritableComparator.readVLong(bytes, start);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readVInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readVInt(byte[] bytes, int start) throws IOException\n{\r\n    return WritableComparator.readVInt(bytes, start);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readVLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long readVLong(DataInput in) throws IOException\n{\r\n    return WritableUtils.readVLong(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readVInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readVInt(DataInput in) throws IOException\n{\r\n    return WritableUtils.readVInt(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "getVIntSize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getVIntSize(long i)\n{\r\n    return WritableUtils.getVIntSize(i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeVLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeVLong(DataOutput stream, long i) throws IOException\n{\r\n    WritableUtils.writeVLong(stream, i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeVInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeVInt(DataOutput stream, int i) throws IOException\n{\r\n    WritableUtils.writeVInt(stream, i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "compareBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int compareBytes(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)\n{\r\n    return WritableComparator.compareBytes(b1, s1, l1, b2, s2, l2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.conf = conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "run",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "int run(String[] args) throws Exception\n{\r\n    if (args.length == 0) {\r\n        System.err.println(\"Too few arguments!\");\r\n        printUsage();\r\n        return 1;\r\n    }\r\n    Path pattern = new Path(args[0]);\r\n    FileSystem fs = pattern.getFileSystem(getConf());\r\n    fs.setVerifyChecksum(true);\r\n    for (Path p : FileUtil.stat2Paths(fs.globStatus(pattern), pattern)) {\r\n        List<FileStatus> inputFiles = new ArrayList<FileStatus>();\r\n        FileStatus status = fs.getFileStatus(p);\r\n        if (status.isDirectory()) {\r\n            FileStatus[] files = fs.listStatus(p);\r\n            Collections.addAll(inputFiles, files);\r\n        } else {\r\n            inputFiles.add(status);\r\n        }\r\n        return dumpTypedBytes(inputFiles);\r\n    }\r\n    return -1;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void printUsage()\n{\r\n    System.out.println(\"Usage: mapred streaming dumptb <glob-pattern>\");\r\n    System.out.println(\"  Dumps all files that match the given pattern to \" + \"standard output as typed bytes.\");\r\n    System.out.println(\"  The files can be text or sequence files\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "dumpTypedBytes",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "int dumpTypedBytes(List<FileStatus> files) throws IOException\n{\r\n    JobConf job = new JobConf(getConf());\r\n    DataOutputStream dout = new DataOutputStream(System.out);\r\n    AutoInputFormat autoInputFormat = new AutoInputFormat();\r\n    for (FileStatus fileStatus : files) {\r\n        FileSplit split = new FileSplit(fileStatus.getPath(), 0, fileStatus.getLen() * fileStatus.getBlockSize(), (String[]) null);\r\n        RecordReader recReader = null;\r\n        try {\r\n            recReader = autoInputFormat.getRecordReader(split, job, Reporter.NULL);\r\n            Object key = recReader.createKey();\r\n            Object value = recReader.createValue();\r\n            while (recReader.next(key, value)) {\r\n                if (key instanceof Writable) {\r\n                    TypedBytesWritableOutput.get(dout).write((Writable) key);\r\n                } else {\r\n                    TypedBytesOutput.get(dout).write(key);\r\n                }\r\n                if (value instanceof Writable) {\r\n                    TypedBytesWritableOutput.get(dout).write((Writable) value);\r\n                } else {\r\n                    TypedBytesOutput.get(dout).write(value);\r\n                }\r\n            }\r\n        } finally {\r\n            if (recReader != null) {\r\n                recReader.close();\r\n            }\r\n        }\r\n    }\r\n    dout.flush();\r\n    return 0;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void main(String[] args) throws Exception\n{\r\n    DumpTypedBytes dumptb = new DumpTypedBytes();\r\n    int res = ToolRunner.run(dumptb, args);\r\n    System.exit(res);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean next(Text key, Text value) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "getPos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getPos() throws IOException\n{\r\n    return in_.getPos();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    in_.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress() throws IOException\n{\r\n    if (end_ == start_) {\r\n        return 1.0f;\r\n    } else {\r\n        return ((float) (in_.getPos() - start_)) / ((float) (end_ - start_));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "createKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text createKey()\n{\r\n    return new Text();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "createValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text createValue()\n{\r\n    return new Text();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "seekNextRecordBoundary",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void seekNextRecordBoundary() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "numRecStats",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void numRecStats(byte[] record, int start, int len) throws IOException\n{\r\n    numRec_++;\r\n    if (numRec_ == nextStatusRec_) {\r\n        String recordStr = new String(record, start, Math.min(len, statusMaxRecordChars_), \"UTF-8\");\r\n        nextStatusRec_ += 100;\r\n        String status = getStatus(recordStr);\r\n        LOG.info(status);\r\n        context_.setStatus(status);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "getStatus",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "String getStatus(CharSequence record)\n{\r\n    long pos = -1;\r\n    try {\r\n        pos = getPos();\r\n    } catch (IOException io) {\r\n    }\r\n    String recStr;\r\n    if (record.length() > statusMaxRecordChars_) {\r\n        recStr = record.subSequence(0, statusMaxRecordChars_) + \"...\";\r\n    } else {\r\n        recStr = record.toString();\r\n    }\r\n    String unqualSplit = split_.getPath().getName() + \":\" + split_.getStart() + \"+\" + split_.getLength();\r\n    String status = \"HSTR \" + StreamUtil.getHost() + \" \" + numRec_ + \". pos=\" + pos + \" \" + unqualSplit + \" Processing record=\" + recStr;\r\n    status += \" \" + splitName_;\r\n    return status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean next(Text key, Text value) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getPos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getPos() throws IOException\n{\r\n    return in_.getPos();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    in_.close();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress() throws IOException\n{\r\n    if (end_ == start_) {\r\n        return 1.0f;\r\n    } else {\r\n        return ((float) (in_.getPos() - start_)) / ((float) (end_ - start_));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text createKey()\n{\r\n    return new Text();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text createValue()\n{\r\n    return new Text();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "seekNextRecordBoundary",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void seekNextRecordBoundary() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "numRecStats",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void numRecStats(byte[] record, int start, int len) throws IOException\n{\r\n    numRec_++;\r\n    if (numRec_ == nextStatusRec_) {\r\n        String recordStr = new String(record, start, Math.min(len, statusMaxRecordChars_), \"UTF-8\");\r\n        nextStatusRec_ += 100;\r\n        String status = getStatus(recordStr);\r\n        LOG.info(status);\r\n        reporter_.setStatus(status);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getStatus",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 8,
  "sourceCodeText" : "String getStatus(CharSequence record)\n{\r\n    long pos = -1;\r\n    try {\r\n        pos = getPos();\r\n    } catch (IOException io) {\r\n    }\r\n    String recStr;\r\n    if (record.length() > statusMaxRecordChars_) {\r\n        recStr = record.subSequence(0, statusMaxRecordChars_) + \"...\";\r\n    } else {\r\n        recStr = record.toString();\r\n    }\r\n    String unqualSplit = split_.getPath().getName() + \":\" + split_.getStart() + \"+\" + split_.getLength();\r\n    String status = \"HSTR \" + StreamUtil.getHost() + \" \" + numRec_ + \". pos=\" + pos + \" \" + unqualSplit + \" Processing record=\" + recStr;\r\n    status += \" \" + splitName_;\r\n    return status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    clientOut = pipeMapRed.getClientOutput();\r\n    inputSeparator = pipeMapRed.getInputSeparator();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeKey",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeKey(Object key) throws IOException\n{\r\n    writeUTF8(key);\r\n    clientOut.write(inputSeparator);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeValue",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeValue(Object value) throws IOException\n{\r\n    writeUTF8(value);\r\n    clientOut.write('\\n');\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeUTF8",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void writeUTF8(Object object) throws IOException\n{\r\n    byte[] bval;\r\n    int valSize;\r\n    if (object instanceof BytesWritable) {\r\n        BytesWritable val = (BytesWritable) object;\r\n        bval = val.getBytes();\r\n        valSize = val.getLength();\r\n    } else if (object instanceof Text) {\r\n        Text val = (Text) object;\r\n        bval = val.getBytes();\r\n        valSize = val.getLength();\r\n    } else {\r\n        String sval = object.toString();\r\n        bval = sval.getBytes(\"UTF-8\");\r\n        valSize = bval.length;\r\n    }\r\n    clientOut.write(bval, 0, valSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void writeKey(K key) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void writeValue(V value) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setTypedBytesOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTypedBytesOutput(TypedBytesOutput out)\n{\r\n    this.out = out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBytesWritableOutput get(TypedBytesOutput out)\n{\r\n    TypedBytesWritableOutput bout = TB_OUT.get();\r\n    bout.setTypedBytesOutput(out);\r\n    return bout;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TypedBytesWritableOutput get(DataOutput out)\n{\r\n    return get(TypedBytesOutput.get(out));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void write(Writable w) throws IOException\n{\r\n    if (w instanceof TypedBytesWritable) {\r\n        writeTypedBytes((TypedBytesWritable) w);\r\n    } else if (w instanceof BytesWritable) {\r\n        writeBytes((BytesWritable) w);\r\n    } else if (w instanceof ByteWritable) {\r\n        writeByte((ByteWritable) w);\r\n    } else if (w instanceof BooleanWritable) {\r\n        writeBoolean((BooleanWritable) w);\r\n    } else if (w instanceof IntWritable) {\r\n        writeInt((IntWritable) w);\r\n    } else if (w instanceof VIntWritable) {\r\n        writeVInt((VIntWritable) w);\r\n    } else if (w instanceof LongWritable) {\r\n        writeLong((LongWritable) w);\r\n    } else if (w instanceof VLongWritable) {\r\n        writeVLong((VLongWritable) w);\r\n    } else if (w instanceof FloatWritable) {\r\n        writeFloat((FloatWritable) w);\r\n    } else if (w instanceof DoubleWritable) {\r\n        writeDouble((DoubleWritable) w);\r\n    } else if (w instanceof Text) {\r\n        writeText((Text) w);\r\n    } else if (w instanceof ArrayWritable) {\r\n        writeArray((ArrayWritable) w);\r\n    } else if (w instanceof MapWritable) {\r\n        writeMap((MapWritable) w);\r\n    } else if (w instanceof SortedMapWritable) {\r\n        writeSortedMap((SortedMapWritable<?>) w);\r\n    } else if (w instanceof Record) {\r\n        writeRecord((Record) w);\r\n    } else {\r\n        writeWritable(w);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeTypedBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeTypedBytes(TypedBytesWritable tbw) throws IOException\n{\r\n    out.writeRaw(tbw.getBytes(), 0, tbw.getLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBytes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeBytes(BytesWritable bw) throws IOException\n{\r\n    byte[] bytes = Arrays.copyOfRange(bw.getBytes(), 0, bw.getLength());\r\n    out.writeBytes(bytes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeByte(ByteWritable bw) throws IOException\n{\r\n    out.writeByte(bw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBoolean",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBoolean(BooleanWritable bw) throws IOException\n{\r\n    out.writeBool(bw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeInt(IntWritable iw) throws IOException\n{\r\n    out.writeInt(iw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeVInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeVInt(VIntWritable viw) throws IOException\n{\r\n    out.writeInt(viw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeLong(LongWritable lw) throws IOException\n{\r\n    out.writeLong(lw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeVLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeVLong(VLongWritable vlw) throws IOException\n{\r\n    out.writeLong(vlw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeFloat(FloatWritable fw) throws IOException\n{\r\n    out.writeFloat(fw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeDouble(DoubleWritable dw) throws IOException\n{\r\n    out.writeDouble(dw.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeText",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeText(Text t) throws IOException\n{\r\n    out.writeString(t.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeArray",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeArray(ArrayWritable aw) throws IOException\n{\r\n    Writable[] writables = aw.get();\r\n    out.writeVectorHeader(writables.length);\r\n    for (Writable writable : writables) {\r\n        write(writable);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeMap",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void writeMap(MapWritable mw) throws IOException\n{\r\n    out.writeMapHeader(mw.size());\r\n    for (Map.Entry<Writable, Writable> entry : mw.entrySet()) {\r\n        write(entry.getKey());\r\n        write(entry.getValue());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeSortedMap",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void writeSortedMap(SortedMapWritable<?> smw) throws IOException\n{\r\n    out.writeMapHeader(smw.size());\r\n    for (Map.Entry<? extends WritableComparable<?>, Writable> entry : smw.entrySet()) {\r\n        write(entry.getKey());\r\n        write(entry.getValue());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeRecord",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeRecord(Record r) throws IOException\n{\r\n    r.serialize(TypedBytesRecordOutput.get(out));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeWritable",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void writeWritable(Writable w) throws IOException\n{\r\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n    DataOutputStream dos = new DataOutputStream(baos);\r\n    WritableUtils.writeString(dos, w.getClass().getName());\r\n    w.write(dos);\r\n    dos.close();\r\n    out.writeBytes(baos.toByteArray(), Type.WRITABLE.code);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setValue",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setValue(Object obj)\n{\r\n    try {\r\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\r\n        TypedBytesOutput tbo = TypedBytesOutput.get(new DataOutputStream(baos));\r\n        tbo.write(obj);\r\n        byte[] bytes = baos.toByteArray();\r\n        set(bytes, 0, bytes.length);\r\n    } catch (IOException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "getValue",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Object getValue()\n{\r\n    try {\r\n        ByteArrayInputStream bais = new ByteArrayInputStream(getBytes());\r\n        TypedBytesInput tbi = TypedBytesInput.get(new DataInputStream(bais));\r\n        Object obj = tbi.read();\r\n        return obj;\r\n    } catch (IOException e) {\r\n        throw new RuntimeException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "getType",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Type getType()\n{\r\n    byte[] bytes = getBytes();\r\n    if (bytes == null || bytes.length == 0) {\r\n        return null;\r\n    }\r\n    for (Type type : Type.values()) {\r\n        if (type.code == (int) bytes[0]) {\r\n            return type;\r\n        }\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toString()\n{\r\n    return getValue().toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "serialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void serialize(RecordOutput rout, String tag) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "deserialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void deserialize(RecordInput rin, String tag) throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int compareTo(final Object peer) throws ClassCastException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "serialize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void serialize(RecordOutput rout) throws IOException\n{\r\n    this.serialize(rout, \"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "deserialize",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void deserialize(RecordInput rin) throws IOException\n{\r\n    this.deserialize(rin, \"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void write(final DataOutput out) throws java.io.IOException\n{\r\n    BinaryRecordOutput bout = BinaryRecordOutput.get(out);\r\n    this.serialize(bout);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void readFields(final DataInput din) throws java.io.IOException\n{\r\n    BinaryRecordInput rin = BinaryRecordInput.get(din);\r\n    this.deserialize(rin);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toString",
  "errType" : [ "Throwable" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String toString()\n{\r\n    try {\r\n        ByteArrayOutputStream s = new ByteArrayOutputStream();\r\n        CsvRecordOutput a = new CsvRecordOutput(s);\r\n        this.serialize(a);\r\n        return new String(s.toByteArray(), \"UTF-8\");\r\n    } catch (Throwable ex) {\r\n        throw new RuntimeException(ex);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return config_;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.config_ = conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "run",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "int run(String[] args) throws Exception\n{\r\n    try {\r\n        this.argv_ = Arrays.copyOf(args, args.length);\r\n        init();\r\n        preProcessArgs();\r\n        parseArgv();\r\n        if (printUsage) {\r\n            printUsage(detailedUsage_);\r\n            return 0;\r\n        }\r\n        postProcessArgs();\r\n        setJobConf();\r\n    } catch (IllegalArgumentException ex) {\r\n        LOG.debug(\"Error in streaming job\", ex);\r\n        return 1;\r\n    }\r\n    return submitAndMonitorJob();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createJob",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "JobConf createJob(String[] argv) throws IOException\n{\r\n    StreamJob job = new StreamJob();\r\n    job.argv_ = argv;\r\n    job.init();\r\n    job.preProcessArgs();\r\n    job.parseArgv();\r\n    job.postProcessArgs();\r\n    job.setJobConf();\r\n    return job.jobConf_;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "go",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int go() throws IOException\n{\r\n    try {\r\n        return run(argv_);\r\n    } catch (Exception ex) {\r\n        throw new IOException(ex.getMessage());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "init",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void init()\n{\r\n    try {\r\n        env_ = new Environment();\r\n    } catch (IOException io) {\r\n        throw new RuntimeException(io);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "preProcessArgs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void preProcessArgs()\n{\r\n    verbose_ = false;\r\n    addTaskEnvironment_ = \"HADOOP_ROOT_LOGGER=\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "postProcessArgs",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void postProcessArgs() throws IOException\n{\r\n    if (inputSpecs_.size() == 0) {\r\n        fail(\"Required argument: -input <name>\");\r\n    }\r\n    if (output_ == null) {\r\n        fail(\"Required argument: -output \");\r\n    }\r\n    msg(\"addTaskEnvironment=\" + addTaskEnvironment_);\r\n    for (final String packageFile : packageFiles_) {\r\n        File f = new File(packageFile);\r\n        if (f.isFile()) {\r\n            shippedCanonFiles_.add(f.getCanonicalPath());\r\n        }\r\n    }\r\n    msg(\"shippedCanonFiles_=\" + shippedCanonFiles_);\r\n    mapCmd_ = unqualifyIfLocalPath(mapCmd_);\r\n    comCmd_ = unqualifyIfLocalPath(comCmd_);\r\n    redCmd_ = unqualifyIfLocalPath(redCmd_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "unqualifyIfLocalPath",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "String unqualifyIfLocalPath(String cmd) throws IOException\n{\r\n    if (cmd == null) {\r\n    } else {\r\n        String prog = cmd;\r\n        String args = \"\";\r\n        int s = cmd.indexOf(\" \");\r\n        if (s != -1) {\r\n            prog = cmd.substring(0, s);\r\n            args = cmd.substring(s + 1);\r\n        }\r\n        String progCanon;\r\n        try {\r\n            progCanon = new File(prog).getCanonicalPath();\r\n        } catch (IOException io) {\r\n            progCanon = prog;\r\n        }\r\n        boolean shipped = shippedCanonFiles_.contains(progCanon);\r\n        msg(\"shipped: \" + shipped + \" \" + progCanon);\r\n        if (shipped) {\r\n            prog = new File(prog).getName();\r\n            if (args.length() > 0) {\r\n                cmd = prog + \" \" + args;\r\n            } else {\r\n                cmd = prog;\r\n            }\r\n        }\r\n    }\r\n    msg(\"cmd=\" + cmd);\r\n    return cmd;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "parseArgv",
  "errType" : [ "Exception", "Exception" ],
  "containingMethodsNum" : 55,
  "sourceCodeText" : "void parseArgv()\n{\r\n    CommandLine cmdLine = null;\r\n    try {\r\n        cmdLine = parser.parse(allOptions, argv_);\r\n    } catch (Exception oe) {\r\n        LOG.error(oe.getMessage());\r\n        exitUsage(argv_.length > 0 && \"-info\".equals(argv_[0]));\r\n    }\r\n    if (cmdLine != null) {\r\n        @SuppressWarnings(\"unchecked\")\r\n        List<String> args = cmdLine.getArgList();\r\n        if (args != null && args.size() > 0) {\r\n            fail(\"Found \" + args.size() + \" unexpected arguments on the \" + \"command line \" + args);\r\n        }\r\n        detailedUsage_ = cmdLine.hasOption(\"info\");\r\n        if (cmdLine.hasOption(\"help\") || detailedUsage_) {\r\n            printUsage = true;\r\n            return;\r\n        }\r\n        verbose_ = cmdLine.hasOption(\"verbose\");\r\n        background_ = cmdLine.hasOption(\"background\");\r\n        debug_ = cmdLine.hasOption(\"debug\") ? debug_ + 1 : debug_;\r\n        String[] values = cmdLine.getOptionValues(\"input\");\r\n        if (values != null && values.length > 0) {\r\n            for (String input : values) {\r\n                inputSpecs_.add(input);\r\n            }\r\n        }\r\n        output_ = cmdLine.getOptionValue(\"output\");\r\n        mapCmd_ = cmdLine.getOptionValue(\"mapper\");\r\n        comCmd_ = cmdLine.getOptionValue(\"combiner\");\r\n        redCmd_ = cmdLine.getOptionValue(\"reducer\");\r\n        lazyOutput_ = cmdLine.hasOption(\"lazyOutput\");\r\n        values = cmdLine.getOptionValues(\"file\");\r\n        if (values != null && values.length > 0) {\r\n            LOG.warn(\"-file option is deprecated, please use generic option\" + \" -files instead.\");\r\n            StringBuffer fileList = new StringBuffer();\r\n            for (String file : values) {\r\n                packageFiles_.add(file);\r\n                try {\r\n                    Path path = new Path(file);\r\n                    FileSystem localFs = FileSystem.getLocal(config_);\r\n                    Path qualifiedPath = path.makeQualified(localFs.getUri(), localFs.getWorkingDirectory());\r\n                    validate(qualifiedPath);\r\n                    String finalPath = qualifiedPath.toString();\r\n                    if (fileList.length() > 0) {\r\n                        fileList.append(',');\r\n                    }\r\n                    fileList.append(finalPath);\r\n                } catch (Exception e) {\r\n                    throw new IllegalArgumentException(e);\r\n                }\r\n            }\r\n            String tmpFiles = config_.get(\"tmpfiles\", \"\");\r\n            if (tmpFiles.isEmpty()) {\r\n                tmpFiles = fileList.toString();\r\n            } else {\r\n                tmpFiles = tmpFiles + \",\" + fileList;\r\n            }\r\n            config_.set(\"tmpfiles\", tmpFiles);\r\n        }\r\n        String fsName = cmdLine.getOptionValue(\"dfs\");\r\n        if (null != fsName) {\r\n            LOG.warn(\"-dfs option is deprecated, please use -fs instead.\");\r\n            config_.set(\"fs.default.name\", fsName);\r\n        }\r\n        additionalConfSpec_ = cmdLine.getOptionValue(\"additionalconfspec\");\r\n        inputFormatSpec_ = cmdLine.getOptionValue(\"inputformat\");\r\n        outputFormatSpec_ = cmdLine.getOptionValue(\"outputformat\");\r\n        numReduceTasksSpec_ = cmdLine.getOptionValue(\"numReduceTasks\");\r\n        partitionerSpec_ = cmdLine.getOptionValue(\"partitioner\");\r\n        inReaderSpec_ = cmdLine.getOptionValue(\"inputreader\");\r\n        mapDebugSpec_ = cmdLine.getOptionValue(\"mapdebug\");\r\n        reduceDebugSpec_ = cmdLine.getOptionValue(\"reducedebug\");\r\n        ioSpec_ = cmdLine.getOptionValue(\"io\");\r\n        String[] car = cmdLine.getOptionValues(\"cacheArchive\");\r\n        if (null != car && car.length > 0) {\r\n            LOG.warn(\"-cacheArchive option is deprecated, please use -archives instead.\");\r\n            for (String s : car) {\r\n                cacheArchives = (cacheArchives == null) ? s : cacheArchives + \",\" + s;\r\n            }\r\n        }\r\n        String[] caf = cmdLine.getOptionValues(\"cacheFile\");\r\n        if (null != caf && caf.length > 0) {\r\n            LOG.warn(\"-cacheFile option is deprecated, please use -files instead.\");\r\n            for (String s : caf) {\r\n                cacheFiles = (cacheFiles == null) ? s : cacheFiles + \",\" + s;\r\n            }\r\n        }\r\n        String[] jobconf = cmdLine.getOptionValues(\"jobconf\");\r\n        if (null != jobconf && jobconf.length > 0) {\r\n            LOG.warn(\"-jobconf option is deprecated, please use -D instead.\");\r\n            for (String s : jobconf) {\r\n                String[] parts = s.split(\"=\", 2);\r\n                config_.set(parts[0], parts[1]);\r\n            }\r\n        }\r\n        String[] cmd = cmdLine.getOptionValues(\"cmdenv\");\r\n        if (null != cmd && cmd.length > 0) {\r\n            for (String s : cmd) {\r\n                if (addTaskEnvironment_.length() > 0) {\r\n                    addTaskEnvironment_ += \" \";\r\n                }\r\n                addTaskEnvironment_ += s;\r\n            }\r\n        }\r\n    } else {\r\n        exitUsage(argv_.length > 0 && \"-info\".equals(argv_[0]));\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "msg",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void msg(String msg)\n{\r\n    if (verbose_) {\r\n        System.out.println(\"STREAM: \" + msg);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createOption",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Option createOption(String name, String desc, String argName, int max, boolean required)\n{\r\n    return OptionBuilder.withArgName(argName).hasArgs(max).withDescription(desc).isRequired(required).create(name);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createBoolOption",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Option createBoolOption(String name, String desc)\n{\r\n    return OptionBuilder.withDescription(desc).create(name);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "validate",
  "errType" : [ "FileNotFoundException", "AccessControlException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void validate(final Path path) throws IOException\n{\r\n    try {\r\n        path.getFileSystem(config_).access(path, FsAction.READ);\r\n    } catch (FileNotFoundException e) {\r\n        fail(\"File: \" + path + \" does not exist.\");\r\n    } catch (AccessControlException e) {\r\n        fail(\"File: \" + path + \" is not readable.\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setupOptions",
  "errType" : null,
  "containingMethodsNum" : 27,
  "sourceCodeText" : "void setupOptions()\n{\r\n    Option input = createOption(\"input\", \"DFS input file(s) for the Map step\", \"path\", Integer.MAX_VALUE, false);\r\n    Option output = createOption(\"output\", \"DFS output directory for the Reduce step\", \"path\", 1, false);\r\n    Option mapper = createOption(\"mapper\", \"The streaming command to run\", \"cmd\", 1, false);\r\n    Option combiner = createOption(\"combiner\", \"The streaming command to run\", \"cmd\", 1, false);\r\n    Option reducer = createOption(\"reducer\", \"The streaming command to run\", \"cmd\", 1, false);\r\n    Option file = createOption(\"file\", \"File to be shipped in the Job jar file\", \"file\", Integer.MAX_VALUE, false);\r\n    Option dfs = createOption(\"dfs\", \"Optional. Override DFS configuration\", \"<h:p>|local\", 1, false);\r\n    Option additionalconfspec = createOption(\"additionalconfspec\", \"Optional.\", \"spec\", 1, false);\r\n    Option inputformat = createOption(\"inputformat\", \"Optional.\", \"spec\", 1, false);\r\n    Option outputformat = createOption(\"outputformat\", \"Optional.\", \"spec\", 1, false);\r\n    Option partitioner = createOption(\"partitioner\", \"Optional.\", \"spec\", 1, false);\r\n    Option numReduceTasks = createOption(\"numReduceTasks\", \"Optional.\", \"spec\", 1, false);\r\n    Option inputreader = createOption(\"inputreader\", \"Optional.\", \"spec\", 1, false);\r\n    Option mapDebug = createOption(\"mapdebug\", \"Optional.\", \"spec\", 1, false);\r\n    Option reduceDebug = createOption(\"reducedebug\", \"Optional\", \"spec\", 1, false);\r\n    Option jobconf = createOption(\"jobconf\", \"(n=v) Optional. Add or override a JobConf property.\", \"spec\", 1, false);\r\n    Option cmdenv = createOption(\"cmdenv\", \"(n=v) Pass env.var to streaming commands.\", \"spec\", 1, false);\r\n    Option cacheFile = createOption(\"cacheFile\", \"File name URI\", \"fileNameURI\", Integer.MAX_VALUE, false);\r\n    Option cacheArchive = createOption(\"cacheArchive\", \"File name URI\", \"fileNameURI\", Integer.MAX_VALUE, false);\r\n    Option io = createOption(\"io\", \"Optional.\", \"spec\", 1, false);\r\n    Option background = createBoolOption(\"background\", \"Submit the job and don't wait till it completes.\");\r\n    Option verbose = createBoolOption(\"verbose\", \"print verbose output\");\r\n    Option info = createBoolOption(\"info\", \"print verbose output\");\r\n    Option help = createBoolOption(\"help\", \"print this help message\");\r\n    Option debug = createBoolOption(\"debug\", \"print debug output\");\r\n    Option lazyOutput = createBoolOption(\"lazyOutput\", \"create outputs lazily\");\r\n    allOptions = new Options().addOption(input).addOption(output).addOption(mapper).addOption(combiner).addOption(reducer).addOption(file).addOption(dfs).addOption(additionalconfspec).addOption(inputformat).addOption(outputformat).addOption(partitioner).addOption(numReduceTasks).addOption(inputreader).addOption(mapDebug).addOption(reduceDebug).addOption(jobconf).addOption(cmdenv).addOption(cacheFile).addOption(cacheArchive).addOption(io).addOption(background).addOption(verbose).addOption(info).addOption(debug).addOption(help).addOption(lazyOutput);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "exitUsage",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void exitUsage(boolean detailed)\n{\r\n    printUsage(detailed);\r\n    fail(\"\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 90,
  "sourceCodeText" : "void printUsage(boolean detailed)\n{\r\n    System.out.println(\"Usage: $HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar\" + \" [options]\");\r\n    System.out.println(\"Options:\");\r\n    System.out.println(\"  -input          <path> DFS input file(s) for the Map\" + \" step.\");\r\n    System.out.println(\"  -output         <path> DFS output directory for the\" + \" Reduce step.\");\r\n    System.out.println(\"  -mapper         <cmd|JavaClassName> Optional. Command\" + \" to be run as mapper.\");\r\n    System.out.println(\"  -combiner       <cmd|JavaClassName> Optional. Command\" + \" to be run as combiner.\");\r\n    System.out.println(\"  -reducer        <cmd|JavaClassName> Optional. Command\" + \" to be run as reducer.\");\r\n    System.out.println(\"  -file           <file> Optional. File/dir to be \" + \"shipped in the Job jar file.\\n\" + \"                  Deprecated. Use generic option \\\"-files\\\" instead.\");\r\n    System.out.println(\"  -inputformat    <TextInputFormat(default)\" + \"|SequenceFileAsTextInputFormat|JavaClassName>\\n\" + \"                  Optional. The input format class.\");\r\n    System.out.println(\"  -outputformat   <TextOutputFormat(default)\" + \"|JavaClassName>\\n\" + \"                  Optional. The output format class.\");\r\n    System.out.println(\"  -partitioner    <JavaClassName>  Optional. The\" + \" partitioner class.\");\r\n    System.out.println(\"  -numReduceTasks <num> Optional. Number of reduce \" + \"tasks.\");\r\n    System.out.println(\"  -inputreader    <spec> Optional. Input recordreader\" + \" spec.\");\r\n    System.out.println(\"  -cmdenv         <n>=<v> Optional. Pass env.var to\" + \" streaming commands.\");\r\n    System.out.println(\"  -mapdebug       <cmd> Optional. \" + \"To run this script when a map task fails.\");\r\n    System.out.println(\"  -reducedebug    <cmd> Optional.\" + \" To run this script when a reduce task fails.\");\r\n    System.out.println(\"  -io             <identifier> Optional. Format to use\" + \" for input to and output\");\r\n    System.out.println(\"                  from mapper/reducer commands\");\r\n    System.out.println(\"  -lazyOutput     Optional. Lazily create Output.\");\r\n    System.out.println(\"  -background     Optional. Submit the job and don't wait till it completes.\");\r\n    System.out.println(\"  -verbose        Optional. Print verbose output.\");\r\n    System.out.println(\"  -info           Optional. Print detailed usage.\");\r\n    System.out.println(\"  -help           Optional. Print help message.\");\r\n    System.out.println();\r\n    GenericOptionsParser.printGenericCommandUsage(System.out);\r\n    if (!detailed) {\r\n        System.out.println();\r\n        System.out.println(\"For more details about these options:\");\r\n        System.out.println(\"Use \" + \"$HADOOP_HOME/bin/hadoop jar hadoop-streaming.jar -info\");\r\n        return;\r\n    }\r\n    System.out.println();\r\n    System.out.println(\"Usage tips:\");\r\n    System.out.println(\"In -input: globbing on <path> is supported and can \" + \"have multiple -input\");\r\n    System.out.println();\r\n    System.out.println(\"Default Map input format: a line is a record in UTF-8 \" + \"the key part ends at first\");\r\n    System.out.println(\"  TAB, the rest of the line is the value\");\r\n    System.out.println();\r\n    System.out.println(\"To pass a Custom input format:\");\r\n    System.out.println(\"  -inputformat package.MyInputFormat\");\r\n    System.out.println();\r\n    System.out.println(\"Similarly, to pass a custom output format:\");\r\n    System.out.println(\"  -outputformat package.MyOutputFormat\");\r\n    System.out.println();\r\n    System.out.println(\"The files with extensions .class and .jar/.zip,\" + \" specified for the -file\");\r\n    System.out.println(\"  argument[s], end up in \\\"classes\\\" and \\\"lib\\\" \" + \"directories respectively inside\");\r\n    System.out.println(\"  the working directory when the mapper and reducer are\" + \" run. All other files\");\r\n    System.out.println(\"  specified for the -file argument[s]\" + \" end up in the working directory when the\");\r\n    System.out.println(\"  mapper and reducer are run. The location of this \" + \"working directory is\");\r\n    System.out.println(\"  unspecified.\");\r\n    System.out.println();\r\n    System.out.println(\"To set the number of reduce tasks (num. of output \" + \"files) as, say 10:\");\r\n    System.out.println(\"  Use -numReduceTasks 10\");\r\n    System.out.println(\"To skip the sort/combine/shuffle/sort/reduce step:\");\r\n    System.out.println(\"  Use -numReduceTasks 0\");\r\n    System.out.println(\"  Map output then becomes a 'side-effect \" + \"output' rather than a reduce input.\");\r\n    System.out.println(\"  This speeds up processing. This also feels \" + \"more like \\\"in-place\\\" processing\");\r\n    System.out.println(\"  because the input filename and the map \" + \"input order are preserved.\");\r\n    System.out.println(\"  This is equivalent to -reducer NONE\");\r\n    System.out.println();\r\n    System.out.println(\"To speed up the last maps:\");\r\n    System.out.println(\"  -D \" + MRJobConfig.MAP_SPECULATIVE + \"=true\");\r\n    System.out.println(\"To speed up the last reduces:\");\r\n    System.out.println(\"  -D \" + MRJobConfig.REDUCE_SPECULATIVE + \"=true\");\r\n    System.out.println(\"To name the job (appears in the JobTracker Web UI):\");\r\n    System.out.println(\"  -D \" + MRJobConfig.JOB_NAME + \"='My Job'\");\r\n    System.out.println(\"To change the local temp directory:\");\r\n    System.out.println(\"  -D dfs.data.dir=/tmp/dfs\");\r\n    System.out.println(\"  -D stream.tmpdir=/tmp/streaming\");\r\n    System.out.println(\"Additional local temp directories with -jt local:\");\r\n    System.out.println(\"  -D \" + MRConfig.LOCAL_DIR + \"=/tmp/local\");\r\n    System.out.println(\"  -D \" + JTConfig.JT_SYSTEM_DIR + \"=/tmp/system\");\r\n    System.out.println(\"  -D \" + MRConfig.TEMP_DIR + \"=/tmp/temp\");\r\n    System.out.println(\"To treat tasks with non-zero exit status as SUCCEDED:\");\r\n    System.out.println(\"  -D stream.non.zero.exit.is.failure=false\");\r\n    System.out.println(\"Use a custom hadoop streaming build along with standard\" + \" hadoop install:\");\r\n    System.out.println(\"  $HADOOP_HOME/bin/hadoop jar \" + \"/path/my-hadoop-streaming.jar [...]\\\\\");\r\n    System.out.println(\"    [...] -D stream.shipped.hadoopstreaming=\" + \"/path/my-hadoop-streaming.jar\");\r\n    System.out.println(\"For more details about jobconf parameters see:\");\r\n    System.out.println(\"  http://wiki.apache.org/hadoop/JobConfFile\");\r\n    System.out.println(\"Truncate the values of the job configuration copied\" + \"to the environment at the given length:\");\r\n    System.out.println(\"   -D stream.jobconf.truncate.limit=-1\");\r\n    System.out.println(\"To set an environment variable in a streaming \" + \"command:\");\r\n    System.out.println(\"   -cmdenv EXAMPLE_DIR=/home/example/dictionaries/\");\r\n    System.out.println();\r\n    System.out.println(\"Shortcut:\");\r\n    System.out.println(\"   setenv HSTREAMING \\\"$HADOOP_HOME/bin/hadoop jar \" + \"hadoop-streaming.jar\\\"\");\r\n    System.out.println();\r\n    System.out.println(\"Example: $HSTREAMING -mapper \" + \"\\\"/usr/local/bin/perl5 filter.pl\\\"\");\r\n    System.out.println(\"           -file /local/filter.pl -input \" + \"\\\"/logs/0604*/*\\\" [...]\");\r\n    System.out.println(\"  Ships a script, invokes the non-shipped perl \" + \"interpreter. Shipped files go to\");\r\n    System.out.println(\"  the working directory so filter.pl is found by perl. \" + \"Input files are all the\");\r\n    System.out.println(\"  daily logs for days in month 2006-04\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "fail",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void fail(String message)\n{\r\n    System.err.println(message);\r\n    System.err.println(\"Try -help for more information\");\r\n    throw new IllegalArgumentException(message);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getHadoopClientHome",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getHadoopClientHome()\n{\r\n    String h = env_.getProperty(\"HADOOP_HOME\");\r\n    if (h == null) {\r\n        h = \"UNDEF\";\r\n    }\r\n    return h;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "isLocalHadoop",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isLocalHadoop()\n{\r\n    return StreamUtil.isLocalJobTracker(jobConf_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getClusterNick",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getClusterNick()\n{\r\n    return \"default\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "packageJobJar",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "String packageJobJar() throws IOException\n{\r\n    ArrayList<String> unjarFiles = new ArrayList<String>();\r\n    String runtimeClasses = config_.get(\"stream.shipped.hadoopstreaming\");\r\n    if (runtimeClasses == null) {\r\n        runtimeClasses = StreamUtil.findInClasspath(StreamJob.class.getName());\r\n    }\r\n    if (runtimeClasses == null) {\r\n        throw new IOException(\"runtime classes not found: \" + getClass().getPackage());\r\n    } else {\r\n        msg(\"Found runtime classes in: \" + runtimeClasses);\r\n    }\r\n    if (isLocalHadoop()) {\r\n    } else {\r\n        if (new File(runtimeClasses).isDirectory()) {\r\n            packageFiles_.add(runtimeClasses);\r\n        } else {\r\n            unjarFiles.add(runtimeClasses);\r\n        }\r\n    }\r\n    if (packageFiles_.size() + unjarFiles.size() == 0) {\r\n        return null;\r\n    }\r\n    String tmp = jobConf_.get(\"stream.tmpdir\");\r\n    File tmpDir = (tmp == null) ? null : new File(tmp);\r\n    File jobJar = File.createTempFile(\"streamjob\", \".jar\", tmpDir);\r\n    System.out.println(\"packageJobJar: \" + packageFiles_ + \" \" + unjarFiles + \" \" + jobJar + \" tmpDir=\" + tmpDir);\r\n    if (debug_ == 0) {\r\n        jobJar.deleteOnExit();\r\n    }\r\n    JarBuilder builder = new JarBuilder();\r\n    if (verbose_) {\r\n        builder.setVerbose(true);\r\n    }\r\n    String jobJarName = jobJar.getAbsolutePath();\r\n    builder.merge(packageFiles_, unjarFiles, jobJarName);\r\n    return jobJarName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getURIs",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void getURIs(String lcacheArchives, String lcacheFiles)\n{\r\n    String[] archives = StringUtils.getStrings(lcacheArchives);\r\n    String[] files = StringUtils.getStrings(lcacheFiles);\r\n    fileURIs = StringUtils.stringToURI(files);\r\n    archiveURIs = StringUtils.stringToURI(archives);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setJobConf",
  "errType" : null,
  "containingMethodsNum" : 90,
  "sourceCodeText" : "void setJobConf() throws IOException\n{\r\n    if (additionalConfSpec_ != null) {\r\n        LOG.warn(\"-additionalconfspec option is deprecated, please use -conf instead.\");\r\n        config_.addResource(new Path(additionalConfSpec_));\r\n    }\r\n    jobConf_ = new JobConf(config_, StreamJob.class);\r\n    for (int i = 0; i < inputSpecs_.size(); i++) {\r\n        FileInputFormat.addInputPaths(jobConf_, (String) inputSpecs_.get(i));\r\n    }\r\n    String defaultPackage = this.getClass().getPackage().getName();\r\n    Class c;\r\n    Class fmt = null;\r\n    if (inReaderSpec_ == null && inputFormatSpec_ == null) {\r\n        fmt = TextInputFormat.class;\r\n    } else if (inputFormatSpec_ != null) {\r\n        if (inputFormatSpec_.equals(TextInputFormat.class.getName()) || inputFormatSpec_.equals(TextInputFormat.class.getCanonicalName()) || inputFormatSpec_.equals(TextInputFormat.class.getSimpleName())) {\r\n            fmt = TextInputFormat.class;\r\n        } else if (inputFormatSpec_.equals(KeyValueTextInputFormat.class.getName()) || inputFormatSpec_.equals(KeyValueTextInputFormat.class.getCanonicalName()) || inputFormatSpec_.equals(KeyValueTextInputFormat.class.getSimpleName())) {\r\n            if (inReaderSpec_ == null) {\r\n                fmt = KeyValueTextInputFormat.class;\r\n            }\r\n        } else if (inputFormatSpec_.equals(SequenceFileInputFormat.class.getName()) || inputFormatSpec_.equals(org.apache.hadoop.mapred.SequenceFileInputFormat.class.getCanonicalName()) || inputFormatSpec_.equals(org.apache.hadoop.mapred.SequenceFileInputFormat.class.getSimpleName())) {\r\n            if (inReaderSpec_ == null) {\r\n                fmt = SequenceFileInputFormat.class;\r\n            }\r\n        } else if (inputFormatSpec_.equals(SequenceFileAsTextInputFormat.class.getName()) || inputFormatSpec_.equals(SequenceFileAsTextInputFormat.class.getCanonicalName()) || inputFormatSpec_.equals(SequenceFileAsTextInputFormat.class.getSimpleName())) {\r\n            fmt = SequenceFileAsTextInputFormat.class;\r\n        } else {\r\n            c = StreamUtil.goodClassOrNull(jobConf_, inputFormatSpec_, defaultPackage);\r\n            if (c != null) {\r\n                fmt = c;\r\n            } else {\r\n                fail(\"-inputformat : class not found : \" + inputFormatSpec_);\r\n            }\r\n        }\r\n    }\r\n    if (fmt == null) {\r\n        fmt = StreamInputFormat.class;\r\n    }\r\n    jobConf_.setInputFormat(fmt);\r\n    if (ioSpec_ != null) {\r\n        jobConf_.set(\"stream.map.input\", ioSpec_);\r\n        jobConf_.set(\"stream.map.output\", ioSpec_);\r\n        jobConf_.set(\"stream.reduce.input\", ioSpec_);\r\n        jobConf_.set(\"stream.reduce.output\", ioSpec_);\r\n    }\r\n    Class<? extends IdentifierResolver> idResolverClass = jobConf_.getClass(\"stream.io.identifier.resolver.class\", IdentifierResolver.class, IdentifierResolver.class);\r\n    IdentifierResolver idResolver = ReflectionUtils.newInstance(idResolverClass, jobConf_);\r\n    idResolver.resolve(jobConf_.get(\"stream.map.input\", IdentifierResolver.TEXT_ID));\r\n    jobConf_.setClass(\"stream.map.input.writer.class\", idResolver.getInputWriterClass(), InputWriter.class);\r\n    idResolver.resolve(jobConf_.get(\"stream.reduce.input\", IdentifierResolver.TEXT_ID));\r\n    jobConf_.setClass(\"stream.reduce.input.writer.class\", idResolver.getInputWriterClass(), InputWriter.class);\r\n    jobConf_.set(\"stream.addenvironment\", addTaskEnvironment_);\r\n    boolean isMapperACommand = false;\r\n    if (mapCmd_ != null) {\r\n        c = StreamUtil.goodClassOrNull(jobConf_, mapCmd_, defaultPackage);\r\n        if (c != null) {\r\n            jobConf_.setMapperClass(c);\r\n        } else {\r\n            isMapperACommand = true;\r\n            jobConf_.setMapperClass(PipeMapper.class);\r\n            jobConf_.setMapRunnerClass(PipeMapRunner.class);\r\n            jobConf_.set(\"stream.map.streamprocessor\", URLEncoder.encode(mapCmd_, \"UTF-8\"));\r\n        }\r\n    }\r\n    if (comCmd_ != null) {\r\n        c = StreamUtil.goodClassOrNull(jobConf_, comCmd_, defaultPackage);\r\n        if (c != null) {\r\n            jobConf_.setCombinerClass(c);\r\n        } else {\r\n            jobConf_.setCombinerClass(PipeCombiner.class);\r\n            jobConf_.set(\"stream.combine.streamprocessor\", URLEncoder.encode(comCmd_, \"UTF-8\"));\r\n        }\r\n    }\r\n    if (numReduceTasksSpec_ != null) {\r\n        int numReduceTasks = Integer.parseInt(numReduceTasksSpec_);\r\n        jobConf_.setNumReduceTasks(numReduceTasks);\r\n    }\r\n    boolean isReducerACommand = false;\r\n    if (redCmd_ != null) {\r\n        if (redCmd_.equals(REDUCE_NONE)) {\r\n            jobConf_.setNumReduceTasks(0);\r\n        }\r\n        if (jobConf_.getNumReduceTasks() != 0) {\r\n            if (redCmd_.compareToIgnoreCase(\"aggregate\") == 0) {\r\n                jobConf_.setReducerClass(ValueAggregatorReducer.class);\r\n                jobConf_.setCombinerClass(ValueAggregatorCombiner.class);\r\n            } else {\r\n                c = StreamUtil.goodClassOrNull(jobConf_, redCmd_, defaultPackage);\r\n                if (c != null) {\r\n                    jobConf_.setReducerClass(c);\r\n                } else {\r\n                    isReducerACommand = true;\r\n                    jobConf_.setReducerClass(PipeReducer.class);\r\n                    jobConf_.set(\"stream.reduce.streamprocessor\", URLEncoder.encode(redCmd_, \"UTF-8\"));\r\n                }\r\n            }\r\n        }\r\n    }\r\n    idResolver.resolve(jobConf_.get(\"stream.map.output\", IdentifierResolver.TEXT_ID));\r\n    jobConf_.setClass(\"stream.map.output.reader.class\", idResolver.getOutputReaderClass(), OutputReader.class);\r\n    if (isMapperACommand || jobConf_.get(\"stream.map.output\") != null) {\r\n        jobConf_.setMapOutputKeyClass(idResolver.getOutputKeyClass());\r\n        jobConf_.setMapOutputValueClass(idResolver.getOutputValueClass());\r\n        if (jobConf_.getNumReduceTasks() == 0) {\r\n            jobConf_.setOutputKeyClass(idResolver.getOutputKeyClass());\r\n            jobConf_.setOutputValueClass(idResolver.getOutputValueClass());\r\n        }\r\n    }\r\n    idResolver.resolve(jobConf_.get(\"stream.reduce.output\", IdentifierResolver.TEXT_ID));\r\n    jobConf_.setClass(\"stream.reduce.output.reader.class\", idResolver.getOutputReaderClass(), OutputReader.class);\r\n    if (isReducerACommand || jobConf_.get(\"stream.reduce.output\") != null) {\r\n        jobConf_.setOutputKeyClass(idResolver.getOutputKeyClass());\r\n        jobConf_.setOutputValueClass(idResolver.getOutputValueClass());\r\n    }\r\n    if (inReaderSpec_ != null) {\r\n        String[] args = inReaderSpec_.split(\",\");\r\n        String readerClass = args[0];\r\n        c = StreamUtil.goodClassOrNull(jobConf_, readerClass, defaultPackage);\r\n        if (c != null) {\r\n            jobConf_.set(\"stream.recordreader.class\", c.getName());\r\n        } else {\r\n            fail(\"-inputreader: class not found: \" + readerClass);\r\n        }\r\n        for (int i = 1; i < args.length; i++) {\r\n            String[] nv = args[i].split(\"=\", 2);\r\n            String k = \"stream.recordreader.\" + nv[0];\r\n            String v = (nv.length > 1) ? nv[1] : \"\";\r\n            jobConf_.set(k, v);\r\n        }\r\n    }\r\n    FileOutputFormat.setOutputPath(jobConf_, new Path(output_));\r\n    fmt = null;\r\n    if (outputFormatSpec_ != null) {\r\n        c = StreamUtil.goodClassOrNull(jobConf_, outputFormatSpec_, defaultPackage);\r\n        if (c != null) {\r\n            fmt = c;\r\n        } else {\r\n            fail(\"-outputformat : class not found : \" + outputFormatSpec_);\r\n        }\r\n    }\r\n    if (fmt == null) {\r\n        fmt = TextOutputFormat.class;\r\n    }\r\n    if (lazyOutput_) {\r\n        LazyOutputFormat.setOutputFormatClass(jobConf_, fmt);\r\n    } else {\r\n        jobConf_.setOutputFormat(fmt);\r\n    }\r\n    if (partitionerSpec_ != null) {\r\n        c = StreamUtil.goodClassOrNull(jobConf_, partitionerSpec_, defaultPackage);\r\n        if (c != null) {\r\n            jobConf_.setPartitionerClass(c);\r\n        } else {\r\n            fail(\"-partitioner : class not found : \" + partitionerSpec_);\r\n        }\r\n    }\r\n    if (mapDebugSpec_ != null) {\r\n        jobConf_.setMapDebugScript(mapDebugSpec_);\r\n    }\r\n    if (reduceDebugSpec_ != null) {\r\n        jobConf_.setReduceDebugScript(reduceDebugSpec_);\r\n    }\r\n    jar_ = packageJobJar();\r\n    if (jar_ != null) {\r\n        jobConf_.setJar(jar_);\r\n    }\r\n    if ((cacheArchives != null) || (cacheFiles != null)) {\r\n        getURIs(cacheArchives, cacheFiles);\r\n        boolean b = DistributedCache.checkURIs(fileURIs, archiveURIs);\r\n        if (!b)\r\n            fail(LINK_URI);\r\n    }\r\n    if (cacheArchives != null) {\r\n        Job.setCacheArchives(archiveURIs, jobConf_);\r\n    }\r\n    if (cacheFiles != null) {\r\n        Job.setCacheFiles(fileURIs, jobConf_);\r\n    }\r\n    if (verbose_) {\r\n        listJobConfProperties();\r\n    }\r\n    msg(\"submitting to jobconf: \" + getJobTrackerHostPort());\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "listJobConfProperties",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void listJobConfProperties()\n{\r\n    msg(\"==== JobConf properties:\");\r\n    TreeMap<String, String> sorted = new TreeMap<String, String>();\r\n    for (final Map.Entry<String, String> en : jobConf_) {\r\n        sorted.put(en.getKey(), en.getValue());\r\n    }\r\n    for (final Map.Entry<String, String> en : sorted.entrySet()) {\r\n        msg(en.getKey() + \"=\" + en.getValue());\r\n    }\r\n    msg(\"====\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getJobTrackerHostPort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJobTrackerHostPort()\n{\r\n    return jobConf_.get(JTConfig.JT_IPC_ADDRESS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "submitAndMonitorJob",
  "errType" : [ "FileNotFoundException", "InvalidJobConfException", "FileAlreadyExistsException", "IOException", "InterruptedException" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "int submitAndMonitorJob() throws IOException\n{\r\n    if (jar_ != null && isLocalHadoop()) {\r\n        File wd = new File(\".\").getAbsoluteFile();\r\n        RunJar.unJar(new File(jar_), wd, MATCH_ANY);\r\n    }\r\n    jc_ = new JobClient(jobConf_);\r\n    running_ = null;\r\n    try {\r\n        running_ = jc_.submitJob(jobConf_);\r\n        jobId_ = running_.getID();\r\n        if (background_) {\r\n            LOG.info(\"Job is running in background.\");\r\n        } else if (!jc_.monitorAndPrintJob(jobConf_, running_)) {\r\n            LOG.error(\"Job not successful!\");\r\n            return 1;\r\n        }\r\n        LOG.info(\"Output directory: \" + output_);\r\n    } catch (FileNotFoundException fe) {\r\n        LOG.error(\"Error launching job , bad input path : \" + fe.getMessage());\r\n        return 2;\r\n    } catch (InvalidJobConfException je) {\r\n        LOG.error(\"Error launching job , Invalid job conf : \" + je.getMessage());\r\n        return 3;\r\n    } catch (FileAlreadyExistsException fae) {\r\n        LOG.error(\"Error launching job , Output path already exists : \" + fae.getMessage());\r\n        return 4;\r\n    } catch (IOException ioe) {\r\n        LOG.error(\"Error Launching job : \" + ioe.getMessage());\r\n        return 5;\r\n    } catch (InterruptedException ie) {\r\n        LOG.error(\"Error monitoring job : \" + ie.getMessage());\r\n        return 6;\r\n    } finally {\r\n        jc_.close();\r\n    }\r\n    return 0;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void main(String[] args) throws Exception\n{\r\n    if (args.length < 1) {\r\n        System.err.println(\"No Arguments Given!\");\r\n        printUsage();\r\n        System.exit(1);\r\n    }\r\n    int returnStatus = 0;\r\n    String cmd = args[0];\r\n    String[] remainingArgs = Arrays.copyOfRange(args, 1, args.length);\r\n    if (cmd.equalsIgnoreCase(\"dumptb\")) {\r\n        DumpTypedBytes dumptb = new DumpTypedBytes();\r\n        returnStatus = ToolRunner.run(dumptb, remainingArgs);\r\n    } else if (cmd.equalsIgnoreCase(\"loadtb\")) {\r\n        LoadTypedBytes loadtb = new LoadTypedBytes();\r\n        returnStatus = ToolRunner.run(loadtb, remainingArgs);\r\n    } else if (cmd.equalsIgnoreCase(\"streamjob\")) {\r\n        StreamJob job = new StreamJob();\r\n        returnStatus = ToolRunner.run(job, remainingArgs);\r\n    } else {\r\n        StreamJob job = new StreamJob();\r\n        returnStatus = ToolRunner.run(job, args);\r\n    }\r\n    if (returnStatus != 0) {\r\n        System.err.println(\"Streaming Command Failed!\");\r\n        System.exit(returnStatus);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void printUsage()\n{\r\n    System.out.println(\"Usage: mapred streaming [options]\");\r\n    System.out.println(\"Options:\");\r\n    System.out.println(\"  dumptb <glob-pattern> Dumps all files that match the\" + \" given pattern to \");\r\n    System.out.println(\"                        standard output as typed \" + \"bytes.\");\r\n    System.out.println(\"  loadtb <path> Reads typed bytes from standard input\" + \" and stores them in\");\r\n    System.out.println(\"                a sequence file in the specified path\");\r\n    System.out.println(\"  [streamjob] <args> Runs streaming job with given\" + \" arguments\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "toArray",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String[] toArray()\n{\r\n    String[] arr = new String[super.size()];\r\n    Enumeration<Object> it = super.keys();\r\n    int i = -1;\r\n    while (it.hasMoreElements()) {\r\n        String key = (String) it.nextElement();\r\n        String val = (String) get(key);\r\n        i++;\r\n        arr[i] = key + \"=\" + val;\r\n    }\r\n    return arr;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "toMap",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Map<String, String> toMap()\n{\r\n    Map<String, String> map = new HashMap<String, String>();\r\n    Enumeration<Object> it = super.keys();\r\n    while (it.hasMoreElements()) {\r\n        String key = (String) it.nextElement();\r\n        String val = (String) get(key);\r\n        map.put(key, val);\r\n    }\r\n    return map;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getHost",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getHost()\n{\r\n    String host = getProperty(\"HOST\");\r\n    if (host == null) {\r\n        try {\r\n            host = InetAddress.getLocalHost().getHostName();\r\n        } catch (IOException io) {\r\n            io.printStackTrace();\r\n        }\r\n    }\r\n    return host;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "resolve",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void resolve(String identifier)\n{\r\n    if (identifier.equalsIgnoreCase(RAW_BYTES_ID)) {\r\n        setInputWriterClass(RawBytesInputWriter.class);\r\n        setOutputReaderClass(RawBytesOutputReader.class);\r\n        setOutputKeyClass(BytesWritable.class);\r\n        setOutputValueClass(BytesWritable.class);\r\n    } else if (identifier.equalsIgnoreCase(TYPED_BYTES_ID)) {\r\n        setInputWriterClass(TypedBytesInputWriter.class);\r\n        setOutputReaderClass(TypedBytesOutputReader.class);\r\n        setOutputKeyClass(TypedBytesWritable.class);\r\n        setOutputValueClass(TypedBytesWritable.class);\r\n    } else if (identifier.equalsIgnoreCase(KEY_ONLY_TEXT_ID)) {\r\n        setInputWriterClass(KeyOnlyTextInputWriter.class);\r\n        setOutputReaderClass(KeyOnlyTextOutputReader.class);\r\n        setOutputKeyClass(Text.class);\r\n        setOutputValueClass(NullWritable.class);\r\n    } else {\r\n        setInputWriterClass(TextInputWriter.class);\r\n        setOutputReaderClass(TextOutputReader.class);\r\n        setOutputKeyClass(Text.class);\r\n        setOutputValueClass(Text.class);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getInputWriterClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Class<? extends InputWriter> getInputWriterClass()\n{\r\n    return inputWriterClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getOutputReaderClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Class<? extends OutputReader> getOutputReaderClass()\n{\r\n    return outputReaderClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getOutputKeyClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Class getOutputKeyClass()\n{\r\n    return outputKeyClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getOutputValueClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Class getOutputValueClass()\n{\r\n    return outputValueClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "setInputWriterClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setInputWriterClass(Class<? extends InputWriter> inputWriterClass)\n{\r\n    this.inputWriterClass = inputWriterClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "setOutputReaderClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setOutputReaderClass(Class<? extends OutputReader> outputReaderClass)\n{\r\n    this.outputReaderClass = outputReaderClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "setOutputKeyClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setOutputKeyClass(Class outputKeyClass)\n{\r\n    this.outputKeyClass = outputKeyClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "setOutputValueClass",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setOutputValueClass(Class outputValueClass)\n{\r\n    this.outputValueClass = outputValueClass;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "init",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void init() throws IOException\n{\r\n    LOG.info(\"StreamBaseRecordReader.init: \" + \" start_=\" + start_ + \" end_=\" + end_ + \" length_=\" + length_ + \" start_ > in_.getPos() =\" + (start_ > in_.getPos()) + \" \" + start_ + \" > \" + in_.getPos());\r\n    if (start_ > in_.getPos()) {\r\n        in_.seek(start_);\r\n    }\r\n    pos_ = start_;\r\n    bin_ = new BufferedInputStream(in_);\r\n    seekNextRecordBoundary();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "boolean next(Text key, Text value) throws IOException\n{\r\n    numNext++;\r\n    if (pos_ >= end_) {\r\n        return false;\r\n    }\r\n    DataOutputBuffer buf = new DataOutputBuffer();\r\n    if (!readUntilMatchBegin()) {\r\n        return false;\r\n    }\r\n    if (pos_ >= end_ || !readUntilMatchEnd(buf)) {\r\n        return false;\r\n    }\r\n    byte[] record = new byte[buf.getLength()];\r\n    System.arraycopy(buf.getData(), 0, record, 0, record.length);\r\n    numRecStats(record, 0, record.length);\r\n    key.set(record);\r\n    value.set(\"\");\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "seekNextRecordBoundary",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void seekNextRecordBoundary() throws IOException\n{\r\n    readUntilMatchBegin();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "readUntilMatchBegin",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean readUntilMatchBegin() throws IOException\n{\r\n    if (slowMatch_) {\r\n        return slowReadUntilMatch(beginPat_, false, null);\r\n    } else {\r\n        return fastReadUntilMatch(beginMark_, false, null);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "readUntilMatchEnd",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean readUntilMatchEnd(DataOutputBuffer buf) throws IOException\n{\r\n    if (slowMatch_) {\r\n        return slowReadUntilMatch(endPat_, true, buf);\r\n    } else {\r\n        return fastReadUntilMatch(endMark_, true, buf);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "slowReadUntilMatch",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "boolean slowReadUntilMatch(Pattern markPattern, boolean includePat, DataOutputBuffer outBufOrNull) throws IOException\n{\r\n    byte[] buf = new byte[Math.max(lookAhead_, maxRecSize_)];\r\n    int read = 0;\r\n    bin_.mark(Math.max(lookAhead_, maxRecSize_) + 2);\r\n    read = bin_.read(buf);\r\n    if (read == -1)\r\n        return false;\r\n    String sbuf = new String(buf, 0, read, \"UTF-8\");\r\n    Matcher match = markPattern.matcher(sbuf);\r\n    firstMatchStart_ = NA;\r\n    firstMatchEnd_ = NA;\r\n    int bufPos = 0;\r\n    int state = synched_ ? CDATA_OUT : CDATA_UNK;\r\n    int s = 0;\r\n    while (match.find(bufPos)) {\r\n        int input;\r\n        if (match.group(1) != null) {\r\n            input = CDATA_BEGIN;\r\n        } else if (match.group(2) != null) {\r\n            input = CDATA_END;\r\n            firstMatchStart_ = NA;\r\n        } else {\r\n            input = RECORD_MAYBE;\r\n        }\r\n        if (input == RECORD_MAYBE) {\r\n            if (firstMatchStart_ == NA) {\r\n                firstMatchStart_ = match.start();\r\n                firstMatchEnd_ = match.end();\r\n            }\r\n        }\r\n        state = nextState(state, input, match.start());\r\n        if (state == RECORD_ACCEPT) {\r\n            break;\r\n        }\r\n        bufPos = match.end();\r\n        s++;\r\n    }\r\n    if (state != CDATA_UNK) {\r\n        synched_ = true;\r\n    }\r\n    boolean matched = (firstMatchStart_ != NA) && (state == RECORD_ACCEPT || state == CDATA_UNK);\r\n    if (matched) {\r\n        int endPos = includePat ? firstMatchEnd_ : firstMatchStart_;\r\n        bin_.reset();\r\n        for (long skiplen = endPos; skiplen > 0; ) {\r\n            skiplen -= bin_.skip(skiplen);\r\n        }\r\n        pos_ += endPos;\r\n        if (outBufOrNull != null) {\r\n            outBufOrNull.writeBytes(sbuf.substring(0, endPos));\r\n        }\r\n    }\r\n    return matched;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "nextState",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int nextState(int state, int input, int bufPos)\n{\r\n    switch(state) {\r\n        case CDATA_UNK:\r\n        case CDATA_OUT:\r\n            switch(input) {\r\n                case CDATA_BEGIN:\r\n                    return CDATA_IN;\r\n                case CDATA_END:\r\n                    if (state == CDATA_OUT) {\r\n                    }\r\n                    return CDATA_OUT;\r\n                case RECORD_MAYBE:\r\n                    return (state == CDATA_UNK) ? CDATA_UNK : RECORD_ACCEPT;\r\n            }\r\n            break;\r\n        case CDATA_IN:\r\n            return (input == CDATA_END) ? CDATA_OUT : CDATA_IN;\r\n    }\r\n    throw new IllegalStateException(state + \" \" + input + \" \" + bufPos + \" \" + splitName_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "makePatternCDataOrMark",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "Pattern makePatternCDataOrMark(String escapedMark)\n{\r\n    StringBuffer pat = new StringBuffer();\r\n    addGroup(pat, StreamUtil.regexpEscape(\"CDATA[\"));\r\n    addGroup(pat, StreamUtil.regexpEscape(\"]]>\"));\r\n    addGroup(pat, escapedMark);\r\n    return Pattern.compile(pat.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "addGroup",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void addGroup(StringBuffer pat, String escapedGroup)\n{\r\n    if (pat.length() > 0) {\r\n        pat.append(\"|\");\r\n    }\r\n    pat.append(\"(\");\r\n    pat.append(escapedGroup);\r\n    pat.append(\")\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "fastReadUntilMatch",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "boolean fastReadUntilMatch(String textPat, boolean includePat, DataOutputBuffer outBufOrNull) throws IOException\n{\r\n    byte[] cpat = textPat.getBytes(\"UTF-8\");\r\n    int m = 0;\r\n    boolean match = false;\r\n    int msup = cpat.length;\r\n    int LL = 120000 * 10;\r\n    bin_.mark(LL);\r\n    while (true) {\r\n        int b = bin_.read();\r\n        if (b == -1)\r\n            break;\r\n        byte c = (byte) b;\r\n        if (c == cpat[m]) {\r\n            m++;\r\n            if (m == msup) {\r\n                match = true;\r\n                break;\r\n            }\r\n        } else {\r\n            bin_.mark(LL);\r\n            if (outBufOrNull != null) {\r\n                outBufOrNull.write(cpat, 0, m);\r\n                outBufOrNull.write(c);\r\n            }\r\n            pos_ += m + 1;\r\n            m = 0;\r\n        }\r\n    }\r\n    if (!includePat && match) {\r\n        bin_.reset();\r\n    } else if (outBufOrNull != null) {\r\n        outBufOrNull.write(cpat);\r\n        pos_ += msup;\r\n    }\r\n    return match;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "checkJobGet",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String checkJobGet(String prop) throws IOException\n{\r\n    String val = conf_.get(prop);\r\n    if (val == null) {\r\n        throw new IOException(\"JobConf: missing required property: \" + prop);\r\n    }\r\n    return val;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getCurrentKey() throws IOException, InterruptedException\n{\r\n    return key;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getCurrentValue() throws IOException, InterruptedException\n{\r\n    return value;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initialize(InputSplit arg0, TaskAttemptContext arg1) throws IOException, InterruptedException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "nextKeyValue",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "boolean nextKeyValue() throws IOException, InterruptedException\n{\r\n    key = createKey();\r\n    value = createValue();\r\n    return next(key, value);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "compare",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "define",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void define(Class c, RecordComparator comparator)\n{\r\n    WritableComparator.define(c, comparator);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "set",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void set(byte[] bytes)\n{\r\n    this.count = (bytes == null) ? 0 : bytes.length;\r\n    this.bytes = bytes;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "copy",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void copy(byte[] bytes, int offset, int length)\n{\r\n    if (this.bytes == null || this.bytes.length < length) {\r\n        this.bytes = new byte[length];\r\n    }\r\n    System.arraycopy(bytes, offset, this.bytes, 0, length);\r\n    this.count = length;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] get()\n{\r\n    if (bytes == null) {\r\n        bytes = new byte[0];\r\n    }\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "getCount",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getCount()\n{\r\n    return count;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "getCapacity",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getCapacity()\n{\r\n    return this.get().length;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "setCapacity",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCapacity(int newCapacity)\n{\r\n    if (newCapacity < 0) {\r\n        throw new IllegalArgumentException(\"Invalid capacity argument \" + newCapacity);\r\n    }\r\n    if (newCapacity == 0) {\r\n        this.bytes = null;\r\n        this.count = 0;\r\n        return;\r\n    }\r\n    if (newCapacity != getCapacity()) {\r\n        byte[] data = new byte[newCapacity];\r\n        if (newCapacity < count) {\r\n            count = newCapacity;\r\n        }\r\n        if (count != 0) {\r\n            System.arraycopy(this.get(), 0, data, 0, count);\r\n        }\r\n        bytes = data;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "reset",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void reset()\n{\r\n    setCapacity(0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "truncate",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void truncate()\n{\r\n    setCapacity(count);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "append",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void append(byte[] bytes, int offset, int length)\n{\r\n    setCapacity(count + length);\r\n    System.arraycopy(bytes, offset, this.get(), count, length);\r\n    count = count + length;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "append",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void append(byte[] bytes)\n{\r\n    append(bytes, 0, bytes.length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    int hash = 1;\r\n    byte[] b = this.get();\r\n    for (int i = 0; i < count; i++) hash = (31 * hash) + b[i];\r\n    return hash;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int compareTo(Object other)\n{\r\n    Buffer right = ((Buffer) other);\r\n    byte[] lb = this.get();\r\n    byte[] rb = right.get();\r\n    for (int i = 0; i < count && i < right.count; i++) {\r\n        int a = (lb[i] & 0xff);\r\n        int b = (rb[i] & 0xff);\r\n        if (a != b) {\r\n            return a - b;\r\n        }\r\n    }\r\n    return count - right.count;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean equals(Object other)\n{\r\n    if (other instanceof Buffer && this != other) {\r\n        return compareTo(other) == 0;\r\n    }\r\n    return (this == other);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder sb = new StringBuilder(2 * count);\r\n    for (int idx = 0; idx < count; idx++) {\r\n        sb.append(Character.forDigit((bytes[idx] & 0xF0) >> 4, 16));\r\n        sb.append(Character.forDigit(bytes[idx] & 0x0F, 16));\r\n    }\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String toString(String charsetName) throws UnsupportedEncodingException\n{\r\n    return new String(this.get(), 0, this.getCount(), charsetName);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "clone",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Object clone() throws CloneNotSupportedException\n{\r\n    Buffer result = (Buffer) super.clone();\r\n    result.copy(this.get(), 0, this.getCount());\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.conf = conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "run",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "int run(String[] args) throws Exception\n{\r\n    if (args.length == 0) {\r\n        System.err.println(\"Too few arguments!\");\r\n        printUsage();\r\n        return 1;\r\n    }\r\n    Path path = new Path(args[0]);\r\n    FileSystem fs = path.getFileSystem(getConf());\r\n    if (fs.exists(path)) {\r\n        System.err.println(\"given path exists already!\");\r\n        return -1;\r\n    }\r\n    TypedBytesInput tbinput = new TypedBytesInput(new DataInputStream(System.in));\r\n    SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, path, TypedBytesWritable.class, TypedBytesWritable.class);\r\n    try {\r\n        TypedBytesWritable key = new TypedBytesWritable();\r\n        TypedBytesWritable value = new TypedBytesWritable();\r\n        byte[] rawKey = tbinput.readRaw();\r\n        while (rawKey != null) {\r\n            byte[] rawValue = tbinput.readRaw();\r\n            key.set(rawKey, 0, rawKey.length);\r\n            value.set(rawValue, 0, rawValue.length);\r\n            writer.append(key, value);\r\n            rawKey = tbinput.readRaw();\r\n        }\r\n    } finally {\r\n        writer.close();\r\n    }\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "printUsage",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void printUsage()\n{\r\n    System.out.println(\"Usage: mapred streaming loadtb <path>\");\r\n    System.out.println(\"  Reads typed bytes from standard input\" + \" and stores them in a sequence file in\");\r\n    System.out.println(\"  the specified path\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void main(String[] args) throws Exception\n{\r\n    LoadTypedBytes loadtb = new LoadTypedBytes();\r\n    int res = ToolRunner.run(loadtb, args);\r\n    System.exit(res);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getPipeCommand",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getPipeCommand(JobConf job)\n{\r\n    String str = job.get(\"stream.combine.streamprocessor\");\r\n    try {\r\n        if (str != null) {\r\n            return URLDecoder.decode(str, \"UTF-8\");\r\n        }\r\n    } catch (UnsupportedEncodingException e) {\r\n        System.err.println(\"stream.combine.streamprocessor\" + \" in jobconf not found\");\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getDoPipe",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean getDoPipe()\n{\r\n    return (getPipeCommand(job_) != null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    clientIn = pipeMapRed.getClientInput();\r\n    conf = pipeMapRed.getConfiguration();\r\n    lineReader = new LineReader((InputStream) clientIn, conf);\r\n    key = new Text();\r\n    line = new Text();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readKeyValue",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean readKeyValue() throws IOException\n{\r\n    if (lineReader.readLine(line) <= 0) {\r\n        return false;\r\n    }\r\n    bytes = line.getBytes();\r\n    key.set(bytes, 0, line.getLength());\r\n    line.clear();\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getCurrentKey() throws IOException\n{\r\n    return key;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "NullWritable getCurrentValue() throws IOException\n{\r\n    return NullWritable.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getLastOutput",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getLastOutput()\n{\r\n    if (bytes != null) {\r\n        try {\r\n            return new String(bytes, \"UTF-8\");\r\n        } catch (UnsupportedEncodingException e) {\r\n            return \"<undecodable>\";\r\n        }\r\n    } else {\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    clientIn = pipeMapRed.getClientInput();\r\n    key = new TypedBytesWritable();\r\n    value = new TypedBytesWritable();\r\n    in = new TypedBytesInput(clientIn);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readKeyValue",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean readKeyValue() throws IOException\n{\r\n    bytes = in.readRaw();\r\n    if (bytes == null) {\r\n        return false;\r\n    }\r\n    key.set(bytes, 0, bytes.length);\r\n    bytes = in.readRaw();\r\n    value.set(bytes, 0, bytes.length);\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TypedBytesWritable getCurrentKey() throws IOException\n{\r\n    return key;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TypedBytesWritable getCurrentValue() throws IOException\n{\r\n    return value;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getLastOutput",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getLastOutput()\n{\r\n    if (bytes != null) {\r\n        return new TypedBytesWritable(bytes).toString();\r\n    } else {\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getPipeCommand",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getPipeCommand(JobConf job)\n{\r\n    String str = job.get(\"stream.reduce.streamprocessor\");\r\n    if (str == null) {\r\n        return str;\r\n    }\r\n    try {\r\n        return URLDecoder.decode(str, \"UTF-8\");\r\n    } catch (UnsupportedEncodingException e) {\r\n        System.err.println(\"stream.reduce.streamprocessor in jobconf not found\");\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getDoPipe",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean getDoPipe()\n{\r\n    String argv = getPipeCommand(job_);\r\n    return (argv != null) && !StreamJob.REDUCE_NONE.equals(argv);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "configure",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    super.configure(job);\r\n    SkipBadRecords.setAutoIncrReducerProcCount(job, false);\r\n    skipping = job.getBoolean(MRJobConfig.SKIP_RECORDS, false);\r\n    try {\r\n        reduceOutFieldSeparator = job_.get(\"stream.reduce.output.field.separator\", \"\\t\").getBytes(\"UTF-8\");\r\n        reduceInputFieldSeparator = job_.get(\"stream.reduce.input.field.separator\", \"\\t\").getBytes(\"UTF-8\");\r\n        this.numOfReduceOutputKeyFields = job_.getInt(\"stream.num.reduce.output.key.fields\", 1);\r\n    } catch (UnsupportedEncodingException e) {\r\n        throw new RuntimeException(\"The current system does not support UTF-8 encoding!\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "reduce",
  "errType" : [ "IOException", "IllegalThreadStateException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void reduce(Object key, Iterator values, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    if (doPipe_ && outThread_ == null) {\r\n        startOutputThreads(output, reporter);\r\n    }\r\n    try {\r\n        while (values.hasNext()) {\r\n            Writable val = (Writable) values.next();\r\n            numRecRead_++;\r\n            maybeLogRecord();\r\n            if (doPipe_) {\r\n                if (outerrThreadsThrowable != null) {\r\n                    mapRedFinished();\r\n                    throw new IOException(\"MROutput/MRErrThread failed:\", outerrThreadsThrowable);\r\n                }\r\n                inWriter_.writeKey(key);\r\n                inWriter_.writeValue(val);\r\n            } else {\r\n                output.collect(key, val);\r\n            }\r\n        }\r\n        if (doPipe_ && skipping) {\r\n            clientOut_.flush();\r\n        }\r\n    } catch (IOException io) {\r\n        String extraInfo = \"\";\r\n        try {\r\n            int exitVal = sim.exitValue();\r\n            if (exitVal == 0) {\r\n                extraInfo = \"subprocess exited successfully\\n\";\r\n            } else {\r\n                extraInfo = \"subprocess exited with error code \" + exitVal + \"\\n\";\r\n            }\r\n            ;\r\n        } catch (IllegalThreadStateException e) {\r\n            extraInfo = \"subprocess still running\\n\";\r\n        }\r\n        ;\r\n        mapRedFinished();\r\n        throw new IOException(extraInfo + getContext() + io.getMessage());\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close()\n{\r\n    mapRedFinished();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getInputSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getInputSeparator()\n{\r\n    return reduceInputFieldSeparator;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getFieldSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getFieldSeparator()\n{\r\n    return reduceOutFieldSeparator;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getNumOfKeyFields",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumOfKeyFields()\n{\r\n    return numOfReduceOutputKeyFields;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createInputWriter",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "InputWriter createInputWriter() throws IOException\n{\r\n    return super.createInputWriter(reduceInputWriterClass_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createOutputReader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "OutputReader createOutputReader() throws IOException\n{\r\n    return super.createOutputReader(reduceOutputReaderClass_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setDataInput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setDataInput(DataInput in)\n{\r\n    this.in = in;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBytesInput get(DataInput in)\n{\r\n    TypedBytesInput bin = TB_IN.get();\r\n    bin.setDataInput(in);\r\n    return bin;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "read",
  "errType" : [ "EOFException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "Object read() throws IOException\n{\r\n    int code = 1;\r\n    try {\r\n        code = in.readUnsignedByte();\r\n    } catch (EOFException eof) {\r\n        return null;\r\n    }\r\n    if (code == Type.BYTES.code) {\r\n        return new Buffer(readBytes());\r\n    } else if (code == Type.BYTE.code) {\r\n        return readByte();\r\n    } else if (code == Type.BOOL.code) {\r\n        return readBool();\r\n    } else if (code == Type.INT.code) {\r\n        return readInt();\r\n    } else if (code == Type.LONG.code) {\r\n        return readLong();\r\n    } else if (code == Type.FLOAT.code) {\r\n        return readFloat();\r\n    } else if (code == Type.DOUBLE.code) {\r\n        return readDouble();\r\n    } else if (code == Type.STRING.code) {\r\n        return readString();\r\n    } else if (code == Type.VECTOR.code) {\r\n        return readVector();\r\n    } else if (code == Type.LIST.code) {\r\n        return readList();\r\n    } else if (code == Type.MAP.code) {\r\n        return readMap();\r\n    } else if (code == Type.MARKER.code) {\r\n        return null;\r\n    } else if (50 <= code && code <= 200) {\r\n        return new Buffer(readBytes());\r\n    } else {\r\n        throw new RuntimeException(\"unknown type\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRaw",
  "errType" : [ "EOFException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "byte[] readRaw() throws IOException\n{\r\n    int code = -1;\r\n    try {\r\n        code = in.readUnsignedByte();\r\n    } catch (EOFException eof) {\r\n        return null;\r\n    }\r\n    if (code == Type.BYTES.code) {\r\n        return readRawBytes();\r\n    } else if (code == Type.BYTE.code) {\r\n        return readRawByte();\r\n    } else if (code == Type.BOOL.code) {\r\n        return readRawBool();\r\n    } else if (code == Type.INT.code) {\r\n        return readRawInt();\r\n    } else if (code == Type.LONG.code) {\r\n        return readRawLong();\r\n    } else if (code == Type.FLOAT.code) {\r\n        return readRawFloat();\r\n    } else if (code == Type.DOUBLE.code) {\r\n        return readRawDouble();\r\n    } else if (code == Type.STRING.code) {\r\n        return readRawString();\r\n    } else if (code == Type.VECTOR.code) {\r\n        return readRawVector();\r\n    } else if (code == Type.LIST.code) {\r\n        return readRawList();\r\n    } else if (code == Type.MAP.code) {\r\n        return readRawMap();\r\n    } else if (code == Type.MARKER.code) {\r\n        return null;\r\n    } else if (50 <= code && code <= 200) {\r\n        return readRawBytes(code);\r\n    } else {\r\n        throw new RuntimeException(\"unknown type\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readType",
  "errType" : [ "EOFException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Type readType() throws IOException\n{\r\n    int code = -1;\r\n    try {\r\n        code = in.readUnsignedByte();\r\n    } catch (EOFException eof) {\r\n        return null;\r\n    }\r\n    for (Type type : Type.values()) {\r\n        if (type.code == code) {\r\n            return type;\r\n        }\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "skipType",
  "errType" : [ "EOFException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean skipType() throws IOException\n{\r\n    try {\r\n        in.readByte();\r\n        return true;\r\n    } catch (EOFException eof) {\r\n        return false;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBytes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "byte[] readBytes() throws IOException\n{\r\n    int length = in.readInt();\r\n    byte[] bytes = new byte[length];\r\n    in.readFully(bytes);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawBytes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "byte[] readRawBytes(int code) throws IOException\n{\r\n    int length = in.readInt();\r\n    byte[] bytes = new byte[5 + length];\r\n    bytes[0] = (byte) code;\r\n    bytes[1] = (byte) (0xff & (length >> 24));\r\n    bytes[2] = (byte) (0xff & (length >> 16));\r\n    bytes[3] = (byte) (0xff & (length >> 8));\r\n    bytes[4] = (byte) (0xff & length);\r\n    in.readFully(bytes, 5, length);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawBytes() throws IOException\n{\r\n    return readRawBytes(Type.BYTES.code);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte readByte() throws IOException\n{\r\n    return in.readByte();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawByte() throws IOException\n{\r\n    byte[] bytes = new byte[2];\r\n    bytes[0] = (byte) Type.BYTE.code;\r\n    in.readFully(bytes, 1, 1);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBool",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean readBool() throws IOException\n{\r\n    return in.readBoolean();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawBool",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawBool() throws IOException\n{\r\n    byte[] bytes = new byte[2];\r\n    bytes[0] = (byte) Type.BOOL.code;\r\n    in.readFully(bytes, 1, 1);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readInt() throws IOException\n{\r\n    return in.readInt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawInt() throws IOException\n{\r\n    byte[] bytes = new byte[5];\r\n    bytes[0] = (byte) Type.INT.code;\r\n    in.readFully(bytes, 1, 4);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long readLong() throws IOException\n{\r\n    return in.readLong();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawLong() throws IOException\n{\r\n    byte[] bytes = new byte[9];\r\n    bytes[0] = (byte) Type.LONG.code;\r\n    in.readFully(bytes, 1, 8);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float readFloat() throws IOException\n{\r\n    return in.readFloat();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawFloat() throws IOException\n{\r\n    byte[] bytes = new byte[5];\r\n    bytes[0] = (byte) Type.FLOAT.code;\r\n    in.readFully(bytes, 1, 4);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "double readDouble() throws IOException\n{\r\n    return in.readDouble();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readRawDouble() throws IOException\n{\r\n    byte[] bytes = new byte[9];\r\n    bytes[0] = (byte) Type.DOUBLE.code;\r\n    in.readFully(bytes, 1, 8);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String readString() throws IOException\n{\r\n    return WritableUtils.readString(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "byte[] readRawString() throws IOException\n{\r\n    int length = in.readInt();\r\n    byte[] bytes = new byte[5 + length];\r\n    bytes[0] = (byte) Type.STRING.code;\r\n    bytes[1] = (byte) (0xff & (length >> 24));\r\n    bytes[2] = (byte) (0xff & (length >> 16));\r\n    bytes[3] = (byte) (0xff & (length >> 8));\r\n    bytes[4] = (byte) (0xff & length);\r\n    in.readFully(bytes, 5, length);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readVector",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ArrayList readVector() throws IOException\n{\r\n    int length = readVectorHeader();\r\n    ArrayList result = new ArrayList(length);\r\n    for (int i = 0; i < length; i++) {\r\n        result.add(read());\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawVector",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "byte[] readRawVector() throws IOException\n{\r\n    Buffer buffer = new Buffer();\r\n    int length = readVectorHeader();\r\n    buffer.append(new byte[] { (byte) Type.VECTOR.code, (byte) (0xff & (length >> 24)), (byte) (0xff & (length >> 16)), (byte) (0xff & (length >> 8)), (byte) (0xff & length) });\r\n    for (int i = 0; i < length; i++) {\r\n        buffer.append(readRaw());\r\n    }\r\n    return buffer.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readVectorHeader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readVectorHeader() throws IOException\n{\r\n    return in.readInt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readList",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "List readList() throws IOException\n{\r\n    List list = new ArrayList();\r\n    Object obj = read();\r\n    while (obj != null) {\r\n        list.add(obj);\r\n        obj = read();\r\n    }\r\n    return list;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawList",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "byte[] readRawList() throws IOException\n{\r\n    Buffer buffer = new Buffer(new byte[] { (byte) Type.LIST.code });\r\n    byte[] bytes = readRaw();\r\n    while (bytes != null) {\r\n        buffer.append(bytes);\r\n        bytes = readRaw();\r\n    }\r\n    buffer.append(new byte[] { (byte) Type.MARKER.code });\r\n    return buffer.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readMap",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TreeMap readMap() throws IOException\n{\r\n    int length = readMapHeader();\r\n    TreeMap result = new TreeMap();\r\n    for (int i = 0; i < length; i++) {\r\n        Object key = read();\r\n        Object value = read();\r\n        result.put(key, value);\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readRawMap",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "byte[] readRawMap() throws IOException\n{\r\n    Buffer buffer = new Buffer();\r\n    int length = readMapHeader();\r\n    buffer.append(new byte[] { (byte) Type.MAP.code, (byte) (0xff & (length >> 24)), (byte) (0xff & (length >> 16)), (byte) (0xff & (length >> 8)), (byte) (0xff & length) });\r\n    for (int i = 0; i < length; i++) {\r\n        buffer.append(readRaw());\r\n        buffer.append(readRaw());\r\n    }\r\n    return buffer.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readMapHeader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readMapHeader() throws IOException\n{\r\n    return in.readInt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "setDataInput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setDataInput(DataInput inp)\n{\r\n    this.in = inp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "BinaryRecordInput get(DataInput inp)\n{\r\n    BinaryRecordInput bin = B_IN.get();\r\n    bin.setDataInput(inp);\r\n    return bin;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte readByte(final String tag) throws IOException\n{\r\n    return in.readByte();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readBool",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean readBool(final String tag) throws IOException\n{\r\n    return in.readBoolean();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readInt(final String tag) throws IOException\n{\r\n    return Utils.readVInt(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long readLong(final String tag) throws IOException\n{\r\n    return Utils.readVLong(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float readFloat(final String tag) throws IOException\n{\r\n    return in.readFloat();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "double readDouble(final String tag) throws IOException\n{\r\n    return in.readDouble();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String readString(final String tag) throws IOException\n{\r\n    return Utils.fromBinaryString(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "readBuffer",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Buffer readBuffer(final String tag) throws IOException\n{\r\n    final int len = Utils.readVInt(in);\r\n    final byte[] barr = new byte[len];\r\n    in.readFully(barr);\r\n    return new Buffer(barr);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startRecord",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void startRecord(final String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endRecord",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endRecord(final String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startVector",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Index startVector(final String tag) throws IOException\n{\r\n    return new BinaryIndex(readInt(tag));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endVector",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endVector(final String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Index startMap(final String tag) throws IOException\n{\r\n    return new BinaryIndex(readInt(tag));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endMap",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endMap(final String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "throwExceptionOnError",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void throwExceptionOnError(String tag) throws IOException\n{\r\n    if (stream.checkError()) {\r\n        throw new IOException(\"Error serializing \" + tag);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "printCommaUnlessFirst",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void printCommaUnlessFirst()\n{\r\n    if (!isFirst) {\r\n        stream.print(\",\");\r\n    }\r\n    isFirst = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeByte(byte b, String tag) throws IOException\n{\r\n    writeLong((long) b, tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeBool",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeBool(boolean b, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    String val = b ? \"T\" : \"F\";\r\n    stream.print(val);\r\n    throwExceptionOnError(tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeInt(int i, String tag) throws IOException\n{\r\n    writeLong((long) i, tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeLong",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeLong(long l, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    stream.print(l);\r\n    throwExceptionOnError(tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeFloat(float f, String tag) throws IOException\n{\r\n    writeDouble((double) f, tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeDouble",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeDouble(double d, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    stream.print(d);\r\n    throwExceptionOnError(tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeString",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeString(String s, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    stream.print(Utils.toCSVString(s));\r\n    throwExceptionOnError(tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeBuffer",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeBuffer(Buffer buf, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    stream.print(Utils.toCSVBuffer(buf));\r\n    throwExceptionOnError(tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startRecord",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void startRecord(Record r, String tag) throws IOException\n{\r\n    if (tag != null && !tag.isEmpty()) {\r\n        printCommaUnlessFirst();\r\n        stream.print(\"s{\");\r\n        isFirst = true;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endRecord",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void endRecord(Record r, String tag) throws IOException\n{\r\n    if (tag == null || tag.isEmpty()) {\r\n        stream.print(\"\\n\");\r\n        isFirst = true;\r\n    } else {\r\n        stream.print(\"}\");\r\n        isFirst = false;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startVector",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void startVector(ArrayList v, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    stream.print(\"v{\");\r\n    isFirst = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endVector",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void endVector(ArrayList v, String tag) throws IOException\n{\r\n    stream.print(\"}\");\r\n    isFirst = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startMap",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void startMap(TreeMap v, String tag) throws IOException\n{\r\n    printCommaUnlessFirst();\r\n    stream.print(\"m{\");\r\n    isFirst = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void endMap(TreeMap v, String tag) throws IOException\n{\r\n    stream.print(\"}\");\r\n    isFirst = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getPipeCommand",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getPipeCommand(JobConf job)\n{\r\n    String str = job.get(\"stream.map.streamprocessor\");\r\n    if (str == null) {\r\n        return str;\r\n    }\r\n    try {\r\n        return URLDecoder.decode(str, \"UTF-8\");\r\n    } catch (UnsupportedEncodingException e) {\r\n        System.err.println(\"stream.map.streamprocessor in jobconf not found\");\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getDoPipe",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean getDoPipe()\n{\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "configure",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    super.configure(job);\r\n    SkipBadRecords.setAutoIncrMapperProcCount(job, false);\r\n    skipping = job.getBoolean(MRJobConfig.SKIP_RECORDS, false);\r\n    if (mapInputWriterClass_.getCanonicalName().equals(TextInputWriter.class.getCanonicalName())) {\r\n        String inputFormatClassName = job.getClass(\"mapred.input.format.class\", TextInputFormat.class).getCanonicalName();\r\n        ignoreKey = job.getBoolean(\"stream.map.input.ignoreKey\", inputFormatClassName.equals(TextInputFormat.class.getCanonicalName()));\r\n    }\r\n    try {\r\n        mapOutputFieldSeparator = job.get(\"stream.map.output.field.separator\", \"\\t\").getBytes(\"UTF-8\");\r\n        mapInputFieldSeparator = job.get(\"stream.map.input.field.separator\", \"\\t\").getBytes(\"UTF-8\");\r\n        numOfMapOutputKeyFields = job.getInt(\"stream.num.map.output.key.fields\", 1);\r\n    } catch (UnsupportedEncodingException e) {\r\n        throw new RuntimeException(\"The current system does not support UTF-8 encoding!\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "map",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void map(Object key, Object value, OutputCollector output, Reporter reporter) throws IOException\n{\r\n    if (outerrThreadsThrowable != null) {\r\n        mapRedFinished();\r\n        throw new IOException(\"MROutput/MRErrThread failed:\", outerrThreadsThrowable);\r\n    }\r\n    try {\r\n        numRecRead_++;\r\n        maybeLogRecord();\r\n        if (numExceptions_ == 0) {\r\n            if (!this.ignoreKey) {\r\n                inWriter_.writeKey(key);\r\n            }\r\n            inWriter_.writeValue(value);\r\n            if (skipping) {\r\n                clientOut_.flush();\r\n            }\r\n        } else {\r\n            numRecSkipped_++;\r\n        }\r\n    } catch (IOException io) {\r\n        numExceptions_++;\r\n        if (numExceptions_ > 1 || numRecWritten_ < minRecWrittenToEnableSkip_) {\r\n            LOG.info(getContext(), io);\r\n            mapRedFinished();\r\n            throw io;\r\n        } else {\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close()\n{\r\n    mapRedFinished();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getInputSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getInputSeparator()\n{\r\n    return mapInputFieldSeparator;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getFieldSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getFieldSeparator()\n{\r\n    return mapOutputFieldSeparator;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getNumOfKeyFields",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumOfKeyFields()\n{\r\n    return numOfMapOutputKeyFields;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createInputWriter",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "InputWriter createInputWriter() throws IOException\n{\r\n    return super.createInputWriter(mapInputWriterClass_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createOutputReader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "OutputReader createOutputReader() throws IOException\n{\r\n    return super.createOutputReader(mapOutputReaderClass_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "setDataOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setDataOutput(DataOutput out)\n{\r\n    this.out = out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "BinaryRecordOutput get(DataOutput out)\n{\r\n    BinaryRecordOutput bout = B_OUT.get();\r\n    bout.setDataOutput(out);\r\n    return bout;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeByte(byte b, String tag) throws IOException\n{\r\n    out.writeByte(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeBool",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBool(boolean b, String tag) throws IOException\n{\r\n    out.writeBoolean(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeInt(int i, String tag) throws IOException\n{\r\n    Utils.writeVInt(out, i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeLong(long l, String tag) throws IOException\n{\r\n    Utils.writeVLong(out, l);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeFloat(float f, String tag) throws IOException\n{\r\n    out.writeFloat(f);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeDouble(double d, String tag) throws IOException\n{\r\n    out.writeDouble(d);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeString(String s, String tag) throws IOException\n{\r\n    Utils.toBinaryString(out, s);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "writeBuffer",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void writeBuffer(Buffer buf, String tag) throws IOException\n{\r\n    byte[] barr = buf.get();\r\n    int len = buf.getCount();\r\n    Utils.writeVInt(out, len);\r\n    out.write(barr, 0, len);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startRecord",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void startRecord(Record r, String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endRecord",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endRecord(Record r, String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startVector",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void startVector(ArrayList v, String tag) throws IOException\n{\r\n    writeInt(v.size(), tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endVector",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endVector(ArrayList v, String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "startMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void startMap(TreeMap v, String tag) throws IOException\n{\r\n    writeInt(v.size(), tag);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\record",
  "methodName" : "endMap",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endMap(TreeMap v, String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    clientIn = pipeMapRed.getClientInput();\r\n    conf = pipeMapRed.getConfiguration();\r\n    numKeyFields = pipeMapRed.getNumOfKeyFields();\r\n    separator = pipeMapRed.getFieldSeparator();\r\n    lineReader = new LineReader((InputStream) clientIn, conf);\r\n    key = new Text();\r\n    value = new Text();\r\n    line = new Text();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readKeyValue",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean readKeyValue() throws IOException\n{\r\n    if (lineReader.readLine(line) <= 0) {\r\n        return false;\r\n    }\r\n    bytes = line.getBytes();\r\n    splitKeyVal(bytes, line.getLength(), key, value);\r\n    line.clear();\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getCurrentKey() throws IOException\n{\r\n    return key;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getCurrentValue() throws IOException\n{\r\n    return value;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getLastOutput",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getLastOutput()\n{\r\n    if (bytes != null) {\r\n        try {\r\n            return new String(bytes, \"UTF-8\");\r\n        } catch (UnsupportedEncodingException e) {\r\n            return \"<undecodable>\";\r\n        }\r\n    } else {\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "splitKeyVal",
  "errType" : [ "CharacterCodingException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void splitKeyVal(byte[] line, int length, Text key, Text val) throws IOException\n{\r\n    int pos = UTF8ByteArrayUtils.findBytes(line, 0, length, separator);\r\n    for (int k = 1; k < numKeyFields && pos != -1; k++) {\r\n        pos = UTF8ByteArrayUtils.findBytes(line, pos + separator.length, length, separator);\r\n    }\r\n    try {\r\n        if (pos == -1) {\r\n            key.set(line, 0, length);\r\n            val.set(\"\");\r\n        } else {\r\n            StreamKeyValUtil.splitKeyVal(line, 0, length, key, val, pos, separator.length);\r\n        }\r\n    } catch (CharacterCodingException e) {\r\n        throw new IOException(StringUtils.stringifyException(e));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeKey",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeKey(Object key) throws IOException\n{\r\n    writeUTF8(key);\r\n    clientOut.write('\\n');\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void writeValue(Object value) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setTypedBytesInput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTypedBytesInput(TypedBytesInput in)\n{\r\n    this.in = in;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBytesWritableInput get(TypedBytesInput in)\n{\r\n    TypedBytesWritableInput bin = TB_IN.get();\r\n    bin.setTypedBytesInput(in);\r\n    return bin;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TypedBytesWritableInput get(DataInput in)\n{\r\n    return get(TypedBytesInput.get(in));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "read",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "Writable read() throws IOException\n{\r\n    Type type = in.readType();\r\n    if (type == null) {\r\n        return null;\r\n    }\r\n    switch(type) {\r\n        case BYTES:\r\n            return readBytes();\r\n        case BYTE:\r\n            return readByte();\r\n        case BOOL:\r\n            return readBoolean();\r\n        case INT:\r\n            return readVInt();\r\n        case LONG:\r\n            return readVLong();\r\n        case FLOAT:\r\n            return readFloat();\r\n        case DOUBLE:\r\n            return readDouble();\r\n        case STRING:\r\n            return readText();\r\n        case VECTOR:\r\n            return readArray();\r\n        case MAP:\r\n            return readMap();\r\n        case WRITABLE:\r\n            return readWritable();\r\n        default:\r\n            throw new RuntimeException(\"unknown type\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readType",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Class<? extends Writable> readType() throws IOException\n{\r\n    Type type = in.readType();\r\n    if (type == null) {\r\n        return null;\r\n    }\r\n    switch(type) {\r\n        case BYTES:\r\n            return BytesWritable.class;\r\n        case BYTE:\r\n            return ByteWritable.class;\r\n        case BOOL:\r\n            return BooleanWritable.class;\r\n        case INT:\r\n            return VIntWritable.class;\r\n        case LONG:\r\n            return VLongWritable.class;\r\n        case FLOAT:\r\n            return FloatWritable.class;\r\n        case DOUBLE:\r\n            return DoubleWritable.class;\r\n        case STRING:\r\n            return Text.class;\r\n        case VECTOR:\r\n            return ArrayWritable.class;\r\n        case MAP:\r\n            return MapWritable.class;\r\n        case WRITABLE:\r\n            return Writable.class;\r\n        default:\r\n            throw new RuntimeException(\"unknown type\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBytes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "BytesWritable readBytes(BytesWritable bw) throws IOException\n{\r\n    byte[] bytes = in.readBytes();\r\n    if (bw == null) {\r\n        bw = new BytesWritable(bytes);\r\n    } else {\r\n        bw.set(bytes, 0, bytes.length);\r\n    }\r\n    return bw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "BytesWritable readBytes() throws IOException\n{\r\n    return readBytes(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ByteWritable readByte(ByteWritable bw) throws IOException\n{\r\n    if (bw == null) {\r\n        bw = new ByteWritable();\r\n    }\r\n    bw.set(in.readByte());\r\n    return bw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ByteWritable readByte() throws IOException\n{\r\n    return readByte(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBoolean",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "BooleanWritable readBoolean(BooleanWritable bw) throws IOException\n{\r\n    if (bw == null) {\r\n        bw = new BooleanWritable();\r\n    }\r\n    bw.set(in.readBool());\r\n    return bw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readBoolean",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "BooleanWritable readBoolean() throws IOException\n{\r\n    return readBoolean(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "IntWritable readInt(IntWritable iw) throws IOException\n{\r\n    if (iw == null) {\r\n        iw = new IntWritable();\r\n    }\r\n    iw.set(in.readInt());\r\n    return iw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "IntWritable readInt() throws IOException\n{\r\n    return readInt(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readVInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "VIntWritable readVInt(VIntWritable iw) throws IOException\n{\r\n    if (iw == null) {\r\n        iw = new VIntWritable();\r\n    }\r\n    iw.set(in.readInt());\r\n    return iw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readVInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "VIntWritable readVInt() throws IOException\n{\r\n    return readVInt(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "LongWritable readLong(LongWritable lw) throws IOException\n{\r\n    if (lw == null) {\r\n        lw = new LongWritable();\r\n    }\r\n    lw.set(in.readLong());\r\n    return lw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "LongWritable readLong() throws IOException\n{\r\n    return readLong(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readVLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "VLongWritable readVLong(VLongWritable lw) throws IOException\n{\r\n    if (lw == null) {\r\n        lw = new VLongWritable();\r\n    }\r\n    lw.set(in.readLong());\r\n    return lw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readVLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "VLongWritable readVLong() throws IOException\n{\r\n    return readVLong(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FloatWritable readFloat(FloatWritable fw) throws IOException\n{\r\n    if (fw == null) {\r\n        fw = new FloatWritable();\r\n    }\r\n    fw.set(in.readFloat());\r\n    return fw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FloatWritable readFloat() throws IOException\n{\r\n    return readFloat(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "DoubleWritable readDouble(DoubleWritable dw) throws IOException\n{\r\n    if (dw == null) {\r\n        dw = new DoubleWritable();\r\n    }\r\n    dw.set(in.readDouble());\r\n    return dw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "DoubleWritable readDouble() throws IOException\n{\r\n    return readDouble(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readText",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Text readText(Text t) throws IOException\n{\r\n    if (t == null) {\r\n        t = new Text();\r\n    }\r\n    t.set(in.readString());\r\n    return t;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readText",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Text readText() throws IOException\n{\r\n    return readText(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readArray",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "ArrayWritable readArray(ArrayWritable aw) throws IOException\n{\r\n    if (aw == null) {\r\n        aw = new ArrayWritable(TypedBytesWritable.class);\r\n    } else if (!aw.getValueClass().equals(TypedBytesWritable.class)) {\r\n        throw new RuntimeException(\"value class has to be TypedBytesWritable\");\r\n    }\r\n    int length = in.readVectorHeader();\r\n    Writable[] writables = new Writable[length];\r\n    for (int i = 0; i < length; i++) {\r\n        writables[i] = new TypedBytesWritable(in.readRaw());\r\n    }\r\n    aw.set(writables);\r\n    return aw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readArray",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ArrayWritable readArray() throws IOException\n{\r\n    return readArray(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readMap",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "MapWritable readMap(MapWritable mw) throws IOException\n{\r\n    if (mw == null) {\r\n        mw = new MapWritable();\r\n    }\r\n    int length = in.readMapHeader();\r\n    for (int i = 0; i < length; i++) {\r\n        Writable key = read();\r\n        Writable value = read();\r\n        mw.put(key, value);\r\n    }\r\n    return mw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "MapWritable readMap() throws IOException\n{\r\n    return readMap(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readSortedMap",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "SortedMapWritable<K> readSortedMap(SortedMapWritable<K> mw) throws IOException\n{\r\n    if (mw == null) {\r\n        mw = new SortedMapWritable<K>();\r\n    }\r\n    int length = in.readMapHeader();\r\n    for (int i = 0; i < length; i++) {\r\n        @SuppressWarnings(\"unchecked\")\r\n        K key = (K) read();\r\n        Writable value = read();\r\n        mw.put(key, value);\r\n    }\r\n    return mw;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readSortedMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "SortedMapWritable<K> readSortedMap() throws IOException\n{\r\n    return readSortedMap((SortedMapWritable<K>) null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readWritable",
  "errType" : [ "ClassNotFoundException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "Writable readWritable(Writable writable) throws IOException\n{\r\n    ByteArrayInputStream bais = new ByteArrayInputStream(in.readBytes());\r\n    DataInputStream dis = new DataInputStream(bais);\r\n    String className = WritableUtils.readString(dis);\r\n    if (writable == null) {\r\n        try {\r\n            Class<? extends Writable> cls = conf.getClassByName(className).asSubclass(Writable.class);\r\n            writable = (Writable) ReflectionUtils.newInstance(cls, conf);\r\n        } catch (ClassNotFoundException e) {\r\n            throw new IOException(e);\r\n        }\r\n    } else if (!writable.getClass().getName().equals(className)) {\r\n        throw new IOException(\"wrong Writable class given\");\r\n    }\r\n    writable.readFields(dis);\r\n    return writable;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "readWritable",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Writable readWritable() throws IOException\n{\r\n    return readWritable(null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "getConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConf()\n{\r\n    return conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setConf(Configuration conf)\n{\r\n    this.conf = conf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getConfiguration",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Configuration getConfiguration()\n{\r\n    return job_;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getClientOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "DataOutput getClientOutput()\n{\r\n    return clientOut_;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getClientInput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "DataInput getClientInput()\n{\r\n    return clientIn_;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getInputSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getInputSeparator()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getFieldSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "byte[] getFieldSeparator()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getNumOfKeyFields",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumOfKeyFields()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getPipeCommand",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getPipeCommand(JobConf job)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getDoPipe",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean getDoPipe()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "splitArgs",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String[] splitArgs(String args)\n{\r\n    ArrayList argList = new ArrayList();\r\n    char[] ch = args.toCharArray();\r\n    int clen = ch.length;\r\n    int state = OUTSIDE;\r\n    int argstart = 0;\r\n    for (int c = 0; c <= clen; c++) {\r\n        boolean last = (c == clen);\r\n        int lastState = state;\r\n        boolean endToken = false;\r\n        if (!last) {\r\n            if (ch[c] == '\\'') {\r\n                if (state == OUTSIDE) {\r\n                    state = SINGLEQ;\r\n                } else if (state == SINGLEQ) {\r\n                    state = OUTSIDE;\r\n                }\r\n                endToken = (state != lastState);\r\n            } else if (ch[c] == '\"') {\r\n                if (state == OUTSIDE) {\r\n                    state = DOUBLEQ;\r\n                } else if (state == DOUBLEQ) {\r\n                    state = OUTSIDE;\r\n                }\r\n                endToken = (state != lastState);\r\n            } else if (ch[c] == ' ') {\r\n                if (state == OUTSIDE) {\r\n                    endToken = true;\r\n                }\r\n            }\r\n        }\r\n        if (last || endToken) {\r\n            if (c == argstart) {\r\n            } else {\r\n                String a;\r\n                a = args.substring(argstart, c);\r\n                argList.add(a);\r\n            }\r\n            argstart = c + 1;\r\n            lastState = state;\r\n        }\r\n    }\r\n    return (String[]) argList.toArray(new String[0]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "configure",
  "errType" : [ "IOException", "InterruptedException" ],
  "containingMethodsNum" : 30,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    try {\r\n        String argv = getPipeCommand(job);\r\n        joinDelay_ = job.getLong(\"stream.joindelay.milli\", 0);\r\n        job_ = job;\r\n        mapInputWriterClass_ = job_.getClass(\"stream.map.input.writer.class\", TextInputWriter.class, InputWriter.class);\r\n        mapOutputReaderClass_ = job_.getClass(\"stream.map.output.reader.class\", TextOutputReader.class, OutputReader.class);\r\n        reduceInputWriterClass_ = job_.getClass(\"stream.reduce.input.writer.class\", TextInputWriter.class, InputWriter.class);\r\n        reduceOutputReaderClass_ = job_.getClass(\"stream.reduce.output.reader.class\", TextOutputReader.class, OutputReader.class);\r\n        nonZeroExitIsFailure_ = job_.getBoolean(\"stream.non.zero.exit.is.failure\", true);\r\n        doPipe_ = getDoPipe();\r\n        if (!doPipe_)\r\n            return;\r\n        setStreamJobDetails(job);\r\n        String[] argvSplit = splitArgs(argv);\r\n        String prog = argvSplit[0];\r\n        File currentDir = new File(\".\").getAbsoluteFile();\r\n        if (new File(prog).isAbsolute()) {\r\n        } else {\r\n            FileUtil.chmod(new File(currentDir, prog).toString(), \"a+x\");\r\n        }\r\n        if (!new File(argvSplit[0]).isAbsolute()) {\r\n            PathFinder finder = new PathFinder(\"PATH\");\r\n            finder.prependPathComponent(currentDir.toString());\r\n            File f = finder.getAbsolutePath(argvSplit[0]);\r\n            if (f != null) {\r\n                argvSplit[0] = f.getAbsolutePath();\r\n            }\r\n            f = null;\r\n        }\r\n        LOG.info(\"PipeMapRed exec \" + Arrays.asList(argvSplit));\r\n        Environment childEnv = (Environment) StreamUtil.env().clone();\r\n        addJobConfToEnvironment(job_, childEnv);\r\n        addEnvironment(childEnv, job_.get(\"stream.addenvironment\"));\r\n        envPut(childEnv, \"TMPDIR\", System.getProperty(\"java.io.tmpdir\"));\r\n        ProcessBuilder builder = new ProcessBuilder(argvSplit);\r\n        builder.environment().putAll(childEnv.toMap());\r\n        sim = builder.start();\r\n        clientOut_ = new DataOutputStream(new BufferedOutputStream(sim.getOutputStream(), BUFFER_SIZE));\r\n        clientIn_ = new DataInputStream(new BufferedInputStream(sim.getInputStream(), BUFFER_SIZE));\r\n        clientErr_ = new DataInputStream(new BufferedInputStream(sim.getErrorStream()));\r\n        startTime_ = System.currentTimeMillis();\r\n    } catch (IOException e) {\r\n        LOG.error(\"configuration exception\", e);\r\n        throw new RuntimeException(\"configuration exception\", e);\r\n    } catch (InterruptedException e) {\r\n        LOG.error(\"configuration exception\", e);\r\n        throw new RuntimeException(\"configuration exception\", e);\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setStreamJobDetails",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setStreamJobDetails(JobConf job)\n{\r\n    String s = job.get(\"stream.minRecWrittenToEnableSkip_\");\r\n    if (s != null) {\r\n        minRecWrittenToEnableSkip_ = Long.parseLong(s);\r\n        LOG.info(\"JobConf set minRecWrittenToEnableSkip_ =\" + minRecWrittenToEnableSkip_);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addJobConfToEnvironment",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void addJobConfToEnvironment(JobConf jobconf, Properties env)\n{\r\n    JobConf conf = new JobConf(jobconf);\r\n    conf.setDeprecatedProperties();\r\n    int lenLimit = conf.getInt(\"stream.jobconf.truncate.limit\", -1);\r\n    for (Entry<String, String> confEntry : conf) {\r\n        String name = confEntry.getKey();\r\n        String value = conf.get(name);\r\n        name = safeEnvVarName(name);\r\n        if (lenLimit > -1 && value.length() > lenLimit) {\r\n            LOG.warn(\"Environment variable \" + name + \" truncated to \" + lenLimit + \" to  fit system limits.\");\r\n            value = value.substring(0, lenLimit);\r\n        }\r\n        envPut(env, name, value);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "safeEnvVarName",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String safeEnvVarName(String var)\n{\r\n    StringBuffer safe = new StringBuffer();\r\n    int len = var.length();\r\n    for (int i = 0; i < len; i++) {\r\n        char c = var.charAt(i);\r\n        char s;\r\n        if ((c >= '0' && c <= '9') || (c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z')) {\r\n            s = c;\r\n        } else {\r\n            s = '_';\r\n        }\r\n        safe.append(s);\r\n    }\r\n    return safe.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addEnvironment",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void addEnvironment(Properties env, String nameVals)\n{\r\n    if (nameVals == null)\r\n        return;\r\n    String[] nv = nameVals.split(\" \");\r\n    for (int i = 0; i < nv.length; i++) {\r\n        String[] pair = nv[i].split(\"=\", 2);\r\n        if (pair.length != 2) {\r\n            LOG.info(\"Skip env entry:\" + nv[i]);\r\n        } else {\r\n            envPut(env, pair[0], pair[1]);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "envPut",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void envPut(Properties env, String name, String value)\n{\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"Add  env entry:\" + name + \"=\" + value);\r\n    }\r\n    env.put(name, value);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "startOutputThreads",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void startOutputThreads(OutputCollector output, Reporter reporter) throws IOException\n{\r\n    inWriter_ = createInputWriter();\r\n    outReader_ = createOutputReader();\r\n    outThread_ = new MROutputThread(outReader_, output, reporter);\r\n    outThread_.start();\r\n    errThread_ = new MRErrorThread();\r\n    errThread_.setReporter(reporter);\r\n    errThread_.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "waitOutputThreads",
  "errType" : [ "InterruptedException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void waitOutputThreads() throws IOException\n{\r\n    try {\r\n        if (outThread_ == null) {\r\n            OutputCollector collector = new OutputCollector() {\r\n\r\n                public void collect(Object key, Object value) throws IOException {\r\n                }\r\n            };\r\n            Reporter reporter = Reporter.NULL;\r\n            startOutputThreads(collector, reporter);\r\n        }\r\n        int exitVal = sim.waitFor();\r\n        if (exitVal != 0) {\r\n            if (nonZeroExitIsFailure_) {\r\n                throw new RuntimeException(\"PipeMapRed.waitOutputThreads(): subprocess failed with code \" + exitVal);\r\n            } else {\r\n                LOG.info(\"PipeMapRed.waitOutputThreads(): subprocess exited with \" + \"code \" + exitVal + \" in \" + PipeMapRed.class.getName());\r\n            }\r\n        }\r\n        if (outThread_ != null) {\r\n            outThread_.join(joinDelay_);\r\n        }\r\n        if (errThread_ != null) {\r\n            errThread_.join(joinDelay_);\r\n        }\r\n        if (outerrThreadsThrowable != null) {\r\n            throw new RuntimeException(outerrThreadsThrowable);\r\n        }\r\n    } catch (InterruptedException e) {\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createInputWriter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "InputWriter createInputWriter() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createInputWriter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "InputWriter createInputWriter(Class<? extends InputWriter> inputWriterClass) throws IOException\n{\r\n    InputWriter inputWriter = ReflectionUtils.newInstance(inputWriterClass, job_);\r\n    inputWriter.initialize(this);\r\n    return inputWriter;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createOutputReader",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "OutputReader createOutputReader() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "createOutputReader",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "OutputReader createOutputReader(Class<? extends OutputReader> outputReaderClass) throws IOException\n{\r\n    OutputReader outputReader = ReflectionUtils.newInstance(outputReaderClass, job_);\r\n    outputReader.initialize(this);\r\n    return outputReader;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "mapRedFinished",
  "errType" : [ "RuntimeException", "IOException", "IOException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void mapRedFinished()\n{\r\n    try {\r\n        if (!doPipe_) {\r\n            LOG.info(\"mapRedFinished\");\r\n            return;\r\n        }\r\n        if (clientOut_ != null) {\r\n            try {\r\n                clientOut_.flush();\r\n                clientOut_.close();\r\n            } catch (IOException io) {\r\n                LOG.warn(\"{}\", io);\r\n            }\r\n        }\r\n        try {\r\n            waitOutputThreads();\r\n        } catch (IOException io) {\r\n            LOG.warn(\"{}\", io);\r\n        }\r\n        if (sim != null)\r\n            sim.destroy();\r\n        LOG.info(\"mapRedFinished\");\r\n    } catch (RuntimeException e) {\r\n        LOG.info(\"PipeMapRed failed!\", e);\r\n        throw e;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "maybeLogRecord",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void maybeLogRecord()\n{\r\n    if (numRecRead_ >= nextRecReadLog_) {\r\n        String info = numRecInfo();\r\n        LOG.info(info);\r\n        if (nextRecReadLog_ < 100000) {\r\n            nextRecReadLog_ *= 10;\r\n        } else {\r\n            nextRecReadLog_ += 100000;\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getContext",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String getContext()\n{\r\n    String s = numRecInfo() + \"\\n\";\r\n    s += \"minRecWrittenToEnableSkip_=\" + minRecWrittenToEnableSkip_ + \" \";\r\n    s += envline(\"HOST\");\r\n    s += envline(\"USER\");\r\n    s += envline(\"HADOOP_USER\");\r\n    if (outThread_ != null) {\r\n        s += \"last tool output: |\" + outReader_.getLastOutput() + \"|\\n\";\r\n    }\r\n    return s;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "envline",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String envline(String var)\n{\r\n    return var + \"=\" + StreamUtil.env().get(var) + \"\\n\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "numRecInfo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String numRecInfo()\n{\r\n    long elapsed = (System.currentTimeMillis() - startTime_) / 1000;\r\n    return \"R/W/S=\" + numRecRead_ + \"/\" + numRecWritten_ + \"/\" + numRecSkipped_ + \" in:\" + safeDiv(numRecRead_, elapsed) + \" [rec/s]\" + \" out:\" + safeDiv(numRecWritten_, elapsed) + \" [rec/s]\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "safeDiv",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String safeDiv(long n, long d)\n{\r\n    return (d == 0) ? \"NA\" : \"\" + n / d + \"=\" + n + \"/\" + d;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "prependPathComponent",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void prependPathComponent(String str)\n{\r\n    pathenv = str + pathSep + pathenv;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getAbsolutePath",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "File getAbsolutePath(String filename)\n{\r\n    if (pathenv == null || pathSep == null || fileSep == null) {\r\n        return null;\r\n    }\r\n    int val = -1;\r\n    String classvalue = pathenv + pathSep;\r\n    while (((val = classvalue.indexOf(pathSep)) >= 0) && classvalue.length() > 0) {\r\n        String entry = classvalue.substring(0, val).trim();\r\n        File f = new File(entry);\r\n        if (f.isDirectory()) {\r\n            f = new File(entry + fileSep + filename);\r\n        }\r\n        if (f.isFile() && FileUtil.canRead(f)) {\r\n            return f;\r\n        }\r\n        classvalue = classvalue.substring(val + 1).trim();\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void main(String[] args) throws IOException\n{\r\n    if (args.length < 1) {\r\n        System.out.println(\"Usage: java PathFinder <filename>\");\r\n        System.exit(1);\r\n    }\r\n    PathFinder finder = new PathFinder(\"PATH\");\r\n    File file = finder.getAbsolutePath(args[0]);\r\n    if (file != null) {\r\n        System.out.println(\"Full path name = \" + file.getCanonicalPath());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "init",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void init() throws IOException\n{\r\n    LOG.info(\"StreamBaseRecordReader.init: \" + \" start_=\" + start_ + \" end_=\" + end_ + \" length_=\" + length_ + \" start_ > in_.getPos() =\" + (start_ > in_.getPos()) + \" \" + start_ + \" > \" + in_.getPos());\r\n    if (start_ > in_.getPos()) {\r\n        in_.seek(start_);\r\n    }\r\n    pos_ = start_;\r\n    bin_ = new BufferedInputStream(in_);\r\n    seekNextRecordBoundary();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "next",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "boolean next(Text key, Text value) throws IOException\n{\r\n    numNext++;\r\n    if (pos_ >= end_) {\r\n        return false;\r\n    }\r\n    DataOutputBuffer buf = new DataOutputBuffer();\r\n    if (!readUntilMatchBegin()) {\r\n        return false;\r\n    }\r\n    if (pos_ >= end_ || !readUntilMatchEnd(buf)) {\r\n        return false;\r\n    }\r\n    byte[] record = new byte[buf.getLength()];\r\n    System.arraycopy(buf.getData(), 0, record, 0, record.length);\r\n    numRecStats(record, 0, record.length);\r\n    key.set(record);\r\n    value.set(\"\");\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "seekNextRecordBoundary",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void seekNextRecordBoundary() throws IOException\n{\r\n    readUntilMatchBegin();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "readUntilMatchBegin",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean readUntilMatchBegin() throws IOException\n{\r\n    if (slowMatch_) {\r\n        return slowReadUntilMatch(beginPat_, false, null);\r\n    } else {\r\n        return fastReadUntilMatch(beginMark_, false, null);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "readUntilMatchEnd",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean readUntilMatchEnd(DataOutputBuffer buf) throws IOException\n{\r\n    if (slowMatch_) {\r\n        return slowReadUntilMatch(endPat_, true, buf);\r\n    } else {\r\n        return fastReadUntilMatch(endMark_, true, buf);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "slowReadUntilMatch",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "boolean slowReadUntilMatch(Pattern markPattern, boolean includePat, DataOutputBuffer outBufOrNull) throws IOException\n{\r\n    byte[] buf = new byte[Math.max(lookAhead_, maxRecSize_)];\r\n    int read = 0;\r\n    bin_.mark(Math.max(lookAhead_, maxRecSize_) + 2);\r\n    read = bin_.read(buf);\r\n    if (read == -1)\r\n        return false;\r\n    String sbuf = new String(buf, 0, read, \"UTF-8\");\r\n    Matcher match = markPattern.matcher(sbuf);\r\n    firstMatchStart_ = NA;\r\n    firstMatchEnd_ = NA;\r\n    int bufPos = 0;\r\n    int state = synched_ ? CDATA_OUT : CDATA_UNK;\r\n    int s = 0;\r\n    while (match.find(bufPos)) {\r\n        int input;\r\n        if (match.group(1) != null) {\r\n            input = CDATA_BEGIN;\r\n        } else if (match.group(2) != null) {\r\n            input = CDATA_END;\r\n            firstMatchStart_ = NA;\r\n        } else {\r\n            input = RECORD_MAYBE;\r\n        }\r\n        if (input == RECORD_MAYBE) {\r\n            if (firstMatchStart_ == NA) {\r\n                firstMatchStart_ = match.start();\r\n                firstMatchEnd_ = match.end();\r\n            }\r\n        }\r\n        state = nextState(state, input, match.start());\r\n        if (state == RECORD_ACCEPT) {\r\n            break;\r\n        }\r\n        bufPos = match.end();\r\n        s++;\r\n    }\r\n    if (state != CDATA_UNK) {\r\n        synched_ = true;\r\n    }\r\n    boolean matched = (firstMatchStart_ != NA) && (state == RECORD_ACCEPT || state == CDATA_UNK);\r\n    if (matched) {\r\n        int endPos = includePat ? firstMatchEnd_ : firstMatchStart_;\r\n        bin_.reset();\r\n        for (long skiplen = endPos; skiplen > 0; ) {\r\n            skiplen -= bin_.skip(skiplen);\r\n        }\r\n        pos_ += endPos;\r\n        if (outBufOrNull != null) {\r\n            outBufOrNull.writeBytes(sbuf.substring(0, endPos));\r\n        }\r\n    }\r\n    return matched;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "nextState",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int nextState(int state, int input, int bufPos)\n{\r\n    switch(state) {\r\n        case CDATA_UNK:\r\n        case CDATA_OUT:\r\n            switch(input) {\r\n                case CDATA_BEGIN:\r\n                    return CDATA_IN;\r\n                case CDATA_END:\r\n                    if (state == CDATA_OUT) {\r\n                    }\r\n                    return CDATA_OUT;\r\n                case RECORD_MAYBE:\r\n                    return (state == CDATA_UNK) ? CDATA_UNK : RECORD_ACCEPT;\r\n            }\r\n            break;\r\n        case CDATA_IN:\r\n            return (input == CDATA_END) ? CDATA_OUT : CDATA_IN;\r\n    }\r\n    throw new IllegalStateException(state + \" \" + input + \" \" + bufPos + \" \" + splitName_);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "makePatternCDataOrMark",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "Pattern makePatternCDataOrMark(String escapedMark)\n{\r\n    StringBuffer pat = new StringBuffer();\r\n    addGroup(pat, StreamUtil.regexpEscape(\"CDATA[\"));\r\n    addGroup(pat, StreamUtil.regexpEscape(\"]]>\"));\r\n    addGroup(pat, escapedMark);\r\n    return Pattern.compile(pat.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addGroup",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void addGroup(StringBuffer pat, String escapedGroup)\n{\r\n    if (pat.length() > 0) {\r\n        pat.append(\"|\");\r\n    }\r\n    pat.append(\"(\");\r\n    pat.append(escapedGroup);\r\n    pat.append(\")\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "fastReadUntilMatch",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "boolean fastReadUntilMatch(String textPat, boolean includePat, DataOutputBuffer outBufOrNull) throws IOException\n{\r\n    byte[] cpat = textPat.getBytes(\"UTF-8\");\r\n    int m = 0;\r\n    boolean match = false;\r\n    int msup = cpat.length;\r\n    int LL = 120000 * 10;\r\n    bin_.mark(LL);\r\n    while (true) {\r\n        int b = bin_.read();\r\n        if (b == -1)\r\n            break;\r\n        byte c = (byte) b;\r\n        if (c == cpat[m]) {\r\n            m++;\r\n            if (m == msup) {\r\n                match = true;\r\n                break;\r\n            }\r\n        } else {\r\n            bin_.mark(LL);\r\n            if (outBufOrNull != null) {\r\n                outBufOrNull.write(cpat, 0, m);\r\n                outBufOrNull.write(c);\r\n            }\r\n            pos_ += m + 1;\r\n            m = 0;\r\n        }\r\n    }\r\n    if (!includePat && match) {\r\n        bin_.reset();\r\n    } else if (outBufOrNull != null) {\r\n        outBufOrNull.write(cpat);\r\n        pos_ += msup;\r\n    }\r\n    return match;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "checkJobGet",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String checkJobGet(String prop) throws IOException\n{\r\n    String val = job_.get(prop);\r\n    if (val == null) {\r\n        throw new IOException(\"JobConf: missing required property: \" + prop);\r\n    }\r\n    return val;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    clientOut = pipeMapRed.getClientOutput();\r\n    bufferOut = new ByteArrayOutputStream();\r\n    bufferDataOut = new DataOutputStream(bufferOut);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeKey",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeKey(Writable key) throws IOException\n{\r\n    writeRawBytes(key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeValue(Writable value) throws IOException\n{\r\n    writeRawBytes(value);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeRawBytes",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void writeRawBytes(Writable writable) throws IOException\n{\r\n    if (writable instanceof BytesWritable) {\r\n        BytesWritable bw = (BytesWritable) writable;\r\n        byte[] bytes = bw.getBytes();\r\n        int length = bw.getLength();\r\n        clientOut.writeInt(length);\r\n        clientOut.write(bytes, 0, length);\r\n    } else {\r\n        bufferOut.reset();\r\n        writable.write(bufferDataOut);\r\n        byte[] bytes = bufferOut.toByteArray();\r\n        clientOut.writeInt(bytes.length);\r\n        clientOut.write(bytes);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "findTab",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int findTab(byte[] utf, int start, int length)\n{\r\n    for (int i = start; i < (start + length); i++) {\r\n        if (utf[i] == (byte) '\\t') {\r\n            return i;\r\n        }\r\n    }\r\n    return -1;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "findTab",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int findTab(byte[] utf)\n{\r\n    return org.apache.hadoop.util.UTF8ByteArrayUtils.findNthByte(utf, 0, utf.length, (byte) '\\t', 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "splitKeyVal",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void splitKeyVal(byte[] utf, int start, int length, Text key, Text val, int splitPos, int separatorLength) throws IOException\n{\r\n    if (splitPos < start || splitPos >= (start + length))\r\n        throw new IllegalArgumentException(\"splitPos must be in the range \" + \"[\" + start + \", \" + (start + length) + \"]: \" + splitPos);\r\n    int keyLen = (splitPos - start);\r\n    int valLen = (start + length) - splitPos - separatorLength;\r\n    key.set(utf, start, keyLen);\r\n    val.set(utf, splitPos + separatorLength, valLen);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "splitKeyVal",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void splitKeyVal(byte[] utf, int start, int length, Text key, Text val, int splitPos) throws IOException\n{\r\n    splitKeyVal(utf, start, length, key, val, splitPos, 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "splitKeyVal",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void splitKeyVal(byte[] utf, Text key, Text val, int splitPos, int separatorLength) throws IOException\n{\r\n    splitKeyVal(utf, 0, utf.length, key, val, splitPos, separatorLength);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "splitKeyVal",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void splitKeyVal(byte[] utf, Text key, Text val, int splitPos) throws IOException\n{\r\n    splitKeyVal(utf, 0, utf.length, key, val, splitPos, 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "readLine",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int readLine(LineReader lineReader, Text out) throws IOException\n{\r\n    out.clear();\r\n    return lineReader.readLine(out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    DataOutput clientOut = pipeMapRed.getClientOutput();\r\n    tbOut = new TypedBytesOutput(clientOut);\r\n    tbwOut = new TypedBytesWritableOutput(clientOut);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeKey",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeKey(Object key) throws IOException\n{\r\n    writeTypedBytes(key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeValue(Object value) throws IOException\n{\r\n    writeTypedBytes(value);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "writeTypedBytes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeTypedBytes(Object value) throws IOException\n{\r\n    if (value instanceof Writable) {\r\n        tbwOut.write((Writable) value);\r\n    } else {\r\n        tbOut.write(value);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "configure",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void configure(JobConf job)\n{\r\n    textInputFormat.configure(job);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getRecordReader",
  "errType" : [ "EOFException" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "RecordReader getRecordReader(InputSplit split, JobConf job, Reporter reporter) throws IOException\n{\r\n    FileSplit fileSplit = (FileSplit) split;\r\n    FileSystem fs = FileSystem.get(fileSplit.getPath().toUri(), job);\r\n    FSDataInputStream is = fs.open(fileSplit.getPath());\r\n    byte[] header = new byte[3];\r\n    RecordReader reader = null;\r\n    try {\r\n        is.readFully(header);\r\n    } catch (EOFException eof) {\r\n        reader = textInputFormat.getRecordReader(split, job, reporter);\r\n    } finally {\r\n        is.close();\r\n    }\r\n    if (header[0] == 'S' && header[1] == 'E' && header[2] == 'Q') {\r\n        reader = seqFileInputFormat.getRecordReader(split, job, reporter);\r\n    } else {\r\n        reader = textInputFormat.getRecordReader(split, job, reporter);\r\n    }\r\n    return reader;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "goodClassOrNull",
  "errType" : [ "ClassNotFoundException", "ClassNotFoundException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Class goodClassOrNull(Configuration conf, String className, String defaultPackage)\n{\r\n    Class clazz = null;\r\n    try {\r\n        clazz = conf.getClassByName(className);\r\n    } catch (ClassNotFoundException cnf) {\r\n    }\r\n    if (clazz == null) {\r\n        if (className.indexOf('.') == -1 && defaultPackage != null) {\r\n            className = defaultPackage + \".\" + className;\r\n            try {\r\n                clazz = conf.getClassByName(className);\r\n            } catch (ClassNotFoundException cnf) {\r\n            }\r\n        }\r\n    }\r\n    return clazz;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "findInClasspath",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String findInClasspath(String className)\n{\r\n    return findInClasspath(className, StreamUtil.class.getClassLoader());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "findInClasspath",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "String findInClasspath(String className, ClassLoader loader)\n{\r\n    String relPath = className;\r\n    relPath = relPath.replace('.', '/');\r\n    relPath += \".class\";\r\n    java.net.URL classUrl = loader.getResource(relPath);\r\n    String codePath;\r\n    if (classUrl != null) {\r\n        boolean inJar = classUrl.getProtocol().equals(\"jar\");\r\n        codePath = classUrl.toString();\r\n        if (codePath.startsWith(\"jar:\")) {\r\n            codePath = codePath.substring(\"jar:\".length());\r\n        }\r\n        if (codePath.startsWith(\"file:\")) {\r\n            codePath = codePath.substring(\"file:\".length());\r\n        }\r\n        if (inJar) {\r\n            int bang = codePath.lastIndexOf('!');\r\n            codePath = codePath.substring(0, bang);\r\n        } else {\r\n            int pos = codePath.lastIndexOf(relPath);\r\n            if (pos == -1) {\r\n                throw new IllegalArgumentException(\"invalid codePath: className=\" + className + \" codePath=\" + codePath);\r\n            }\r\n            codePath = codePath.substring(0, pos);\r\n        }\r\n    } else {\r\n        codePath = null;\r\n    }\r\n    return codePath;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "qualifyHost",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String qualifyHost(String url)\n{\r\n    try {\r\n        return qualifyHost(new URL(url)).toString();\r\n    } catch (IOException io) {\r\n        return url;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "qualifyHost",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "URL qualifyHost(URL url)\n{\r\n    try {\r\n        InetAddress a = InetAddress.getByName(url.getHost());\r\n        String qualHost = a.getCanonicalHostName();\r\n        URL q = new URL(url.getProtocol(), qualHost, url.getPort(), url.getFile());\r\n        return q;\r\n    } catch (IOException io) {\r\n        return url;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "regexpEscape",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String regexpEscape(String plain)\n{\r\n    StringBuffer buf = new StringBuffer();\r\n    char[] ch = plain.toCharArray();\r\n    int csup = ch.length;\r\n    for (int c = 0; c < csup; c++) {\r\n        if (regexpSpecials.indexOf(ch[c]) != -1) {\r\n            buf.append(\"\\\\\");\r\n        }\r\n        buf.append(ch[c]);\r\n    }\r\n    return buf.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "slurp",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String slurp(File f) throws IOException\n{\r\n    int len = (int) f.length();\r\n    byte[] buf = new byte[len];\r\n    FileInputStream in = new FileInputStream(f);\r\n    String contents = null;\r\n    try {\r\n        in.read(buf, 0, len);\r\n        contents = new String(buf, \"UTF-8\");\r\n    } finally {\r\n        in.close();\r\n    }\r\n    return contents;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "slurpHadoop",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String slurpHadoop(Path p, FileSystem fs) throws IOException\n{\r\n    int len = (int) fs.getFileStatus(p).getLen();\r\n    byte[] buf = new byte[len];\r\n    FSDataInputStream in = fs.open(p);\r\n    String contents = null;\r\n    try {\r\n        in.readFully(in.getPos(), buf);\r\n        contents = new String(buf, \"UTF-8\");\r\n    } finally {\r\n        in.close();\r\n    }\r\n    return contents;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getHost",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getHost()\n{\r\n    return host;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "env",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Environment env()\n{\r\n    if (env != null) {\r\n        return env;\r\n    }\r\n    try {\r\n        env = new Environment();\r\n    } catch (IOException io) {\r\n        io.printStackTrace();\r\n    }\r\n    return env;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "isLocalJobTracker",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean isLocalJobTracker(JobConf job)\n{\r\n    String framework = job.get(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\r\n    return framework.equals(MRConfig.LOCAL_FRAMEWORK_NAME);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readKeyValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean readKeyValue() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "K getCurrentKey() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "V getCurrentValue() throws IOException",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getLastOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getLastOutput()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initialize(PipeMapRed pipeMapRed) throws IOException\n{\r\n    super.initialize(pipeMapRed);\r\n    clientIn = pipeMapRed.getClientInput();\r\n    key = new BytesWritable();\r\n    value = new BytesWritable();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readKeyValue",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "boolean readKeyValue() throws IOException\n{\r\n    int length = readLength();\r\n    if (length < 0) {\r\n        return false;\r\n    }\r\n    key.set(readBytes(length), 0, length);\r\n    length = readLength();\r\n    value.set(readBytes(length), 0, length);\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BytesWritable getCurrentKey() throws IOException\n{\r\n    return key;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "BytesWritable getCurrentValue() throws IOException\n{\r\n    return value;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "getLastOutput",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getLastOutput()\n{\r\n    if (bytes != null) {\r\n        return new BytesWritable(bytes).toString();\r\n    } else {\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readLength",
  "errType" : [ "EOFException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int readLength() throws IOException\n{\r\n    try {\r\n        return clientIn.readInt();\r\n    } catch (EOFException eof) {\r\n        return -1;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\io",
  "methodName" : "readBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] readBytes(int length) throws IOException\n{\r\n    bytes = new byte[length];\r\n    clientIn.readFully(bytes);\r\n    return bytes;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "setVerbose",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setVerbose(boolean v)\n{\r\n    this.verbose = v;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "merge",
  "errType" : [ "ZipException" ],
  "containingMethodsNum" : 16,
  "sourceCodeText" : "void merge(List srcNames, List srcUnjar, String dstJar) throws IOException\n{\r\n    String source = null;\r\n    JarOutputStream jarOut = null;\r\n    JarFile jarSource = null;\r\n    jarOut = new JarOutputStream(new FileOutputStream(dstJar));\r\n    boolean throwing = false;\r\n    try {\r\n        if (srcNames != null) {\r\n            Iterator iter = srcNames.iterator();\r\n            while (iter.hasNext()) {\r\n                source = (String) iter.next();\r\n                File fsource = new File(source);\r\n                String base = getBasePathInJarOut(source);\r\n                if (!fsource.exists()) {\r\n                    throwing = true;\r\n                    throw new FileNotFoundException(fsource.getAbsolutePath());\r\n                }\r\n                if (fsource.isDirectory()) {\r\n                    addDirectory(jarOut, base, fsource, 0);\r\n                } else {\r\n                    addFileStream(jarOut, base, fsource);\r\n                }\r\n            }\r\n        }\r\n        if (srcUnjar != null) {\r\n            Iterator iter = srcUnjar.iterator();\r\n            while (iter.hasNext()) {\r\n                source = (String) iter.next();\r\n                jarSource = new JarFile(source);\r\n                addJarEntries(jarOut, jarSource);\r\n                jarSource.close();\r\n            }\r\n        }\r\n    } finally {\r\n        try {\r\n            jarOut.close();\r\n        } catch (ZipException z) {\r\n            if (!throwing) {\r\n                throw new IOException(z.toString());\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "fileExtension",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String fileExtension(String file)\n{\r\n    int leafPos = file.lastIndexOf('/');\r\n    if (leafPos == file.length() - 1)\r\n        return \"\";\r\n    String leafName = file.substring(leafPos + 1);\r\n    int dotPos = leafName.lastIndexOf('.');\r\n    if (dotPos == -1)\r\n        return \"\";\r\n    String ext = leafName.substring(dotPos + 1);\r\n    return ext;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getBasePathInJarOut",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String getBasePathInJarOut(String sourceFile)\n{\r\n    String ext = fileExtension(sourceFile);\r\n    if (ext.equals(\"class\")) {\r\n        return \"classes/\";\r\n    } else if (ext.equals(\"jar\") || ext.equals(\"zip\")) {\r\n        return \"lib/\";\r\n    } else {\r\n        return \"\";\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addJarEntries",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void addJarEntries(JarOutputStream dst, JarFile src) throws IOException\n{\r\n    Enumeration entries = src.entries();\r\n    JarEntry entry = null;\r\n    while (entries.hasMoreElements()) {\r\n        entry = (JarEntry) entries.nextElement();\r\n        InputStream in = src.getInputStream(entry);\r\n        addNamedStream(dst, entry.getName(), in);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addNamedStream",
  "errType" : [ "ZipException" ],
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void addNamedStream(JarOutputStream dst, String name, InputStream in) throws IOException\n{\r\n    if (verbose) {\r\n        System.err.println(\"JarBuilder.addNamedStream \" + name);\r\n    }\r\n    try {\r\n        dst.putNextEntry(new JarEntry(name));\r\n        int bytesRead = 0;\r\n        while ((bytesRead = in.read(buffer, 0, BUFF_SIZE)) != -1) {\r\n            dst.write(buffer, 0, bytesRead);\r\n        }\r\n    } catch (ZipException ze) {\r\n        if (ze.getMessage().indexOf(\"duplicate entry\") >= 0) {\r\n            if (verbose) {\r\n                System.err.println(ze + \" Skip duplicate entry \" + name);\r\n            }\r\n        } else {\r\n            throw ze;\r\n        }\r\n    } finally {\r\n        in.close();\r\n        dst.flush();\r\n        dst.closeEntry();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addFileStream",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addFileStream(JarOutputStream dst, String jarBaseName, File file) throws IOException\n{\r\n    FileInputStream in = new FileInputStream(file);\r\n    try {\r\n        String name = jarBaseName + file.getName();\r\n        addNamedStream(dst, name, in);\r\n    } finally {\r\n        in.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "addDirectory",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void addDirectory(JarOutputStream dst, String jarBaseName, File dir, int depth) throws IOException\n{\r\n    File[] contents = dir.listFiles();\r\n    if (contents != null) {\r\n        for (int i = 0; i < contents.length; i++) {\r\n            File f = contents[i];\r\n            String fBaseName = (depth == 0) ? \"\" : dir.getName();\r\n            if (jarBaseName.length() > 0) {\r\n                fBaseName = jarBaseName + \"/\" + fBaseName;\r\n            }\r\n            if (f.isDirectory()) {\r\n                addDirectory(dst, fBaseName, f, depth + 1);\r\n            } else {\r\n                addFileStream(dst, fBaseName + \"/\", f);\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "main",
  "errType" : [ "Exception" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void main(String[] args)\n{\r\n    if (args.length < 2) {\r\n        System.err.println(\"Usage: JarFiles merged.jar [src.jar | dir | file ]+\");\r\n    } else {\r\n        JarBuilder jarFiles = new JarBuilder();\r\n        List names = new ArrayList();\r\n        List unjar = new ArrayList();\r\n        for (int i = 1; i < args.length; i++) {\r\n            String f = args[i];\r\n            String ext = jarFiles.fileExtension(f);\r\n            boolean expandAsJar = ext.equals(\"jar\") || ext.equals(\"zip\");\r\n            if (expandAsJar) {\r\n                unjar.add(f);\r\n            } else {\r\n                names.add(f);\r\n            }\r\n        }\r\n        try {\r\n            jarFiles.merge(names, unjar, args[0]);\r\n            Date lastMod = new Date(new File(args[0]).lastModified());\r\n            System.out.println(\"Merge done to \" + args[0] + \" \" + lastMod);\r\n        } catch (Exception ge) {\r\n            ge.printStackTrace(System.err);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "getRecordReader",
  "errType" : [ "NoSuchMethodException", "Exception" ],
  "containingMethodsNum" : 10,
  "sourceCodeText" : "RecordReader<Text, Text> getRecordReader(final InputSplit genericSplit, JobConf job, Reporter reporter) throws IOException\n{\r\n    String c = job.get(\"stream.recordreader.class\");\r\n    if (c == null || c.indexOf(\"LineRecordReader\") >= 0) {\r\n        return super.getRecordReader(genericSplit, job, reporter);\r\n    }\r\n    FileSplit split = (FileSplit) genericSplit;\r\n    LOG.info(\"getRecordReader start.....split=\" + split);\r\n    reporter.setStatus(split.toString());\r\n    FileSystem fs = split.getPath().getFileSystem(job);\r\n    FSDataInputStream in = fs.open(split.getPath());\r\n    Class readerClass;\r\n    {\r\n        readerClass = StreamUtil.goodClassOrNull(job, c, null);\r\n        if (readerClass == null) {\r\n            throw new RuntimeException(\"Class not found: \" + c);\r\n        }\r\n    }\r\n    Constructor ctor;\r\n    try {\r\n        ctor = readerClass.getConstructor(new Class[] { FSDataInputStream.class, FileSplit.class, Reporter.class, JobConf.class, FileSystem.class });\r\n    } catch (NoSuchMethodException nsm) {\r\n        throw new RuntimeException(nsm);\r\n    }\r\n    RecordReader<Text, Text> reader;\r\n    try {\r\n        reader = (RecordReader<Text, Text>) ctor.newInstance(new Object[] { in, split, reporter, job, fs });\r\n    } catch (Exception nsm) {\r\n        throw new RuntimeException(nsm);\r\n    }\r\n    return reader;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming",
  "methodName" : "run",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void run(RecordReader<K1, V1> input, OutputCollector<K2, V2> output, Reporter reporter) throws IOException\n{\r\n    PipeMapper pipeMapper = (PipeMapper) getMapper();\r\n    pipeMapper.startOutputThreads(output, reporter);\r\n    super.run(input, output, reporter);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\streaming\\mapreduce",
  "methodName" : "createRecordReader",
  "errType" : [ "NoSuchMethodException", "Exception" ],
  "containingMethodsNum" : 14,
  "sourceCodeText" : "RecordReader<Text, Text> createRecordReader(InputSplit genericSplit, TaskAttemptContext context) throws IOException\n{\r\n    Configuration conf = context.getConfiguration();\r\n    String c = conf.get(\"stream.recordreader.class\");\r\n    if (c == null || c.indexOf(\"LineRecordReader\") >= 0) {\r\n        return super.createRecordReader(genericSplit, context);\r\n    }\r\n    FileSplit split = (FileSplit) genericSplit;\r\n    context.setStatus(split.toString());\r\n    context.progress();\r\n    Path path = split.getPath();\r\n    FileSystem fs = path.getFileSystem(conf);\r\n    final FutureDataInputStreamBuilder builder = fs.openFile(path);\r\n    FutureIOSupport.propagateOptions(builder, conf, MRJobConfig.INPUT_FILE_OPTION_PREFIX, MRJobConfig.INPUT_FILE_MANDATORY_PREFIX);\r\n    FSDataInputStream in = FutureIOSupport.awaitFuture(builder.build());\r\n    Class readerClass;\r\n    {\r\n        readerClass = StreamUtil.goodClassOrNull(conf, c, null);\r\n        if (readerClass == null) {\r\n            throw new RuntimeException(\"Class not found: \" + c);\r\n        }\r\n    }\r\n    Constructor ctor;\r\n    try {\r\n        ctor = readerClass.getConstructor(new Class[] { FSDataInputStream.class, FileSplit.class, TaskAttemptContext.class, Configuration.class, FileSystem.class });\r\n    } catch (NoSuchMethodException nsm) {\r\n        throw new RuntimeException(nsm);\r\n    }\r\n    RecordReader<Text, Text> reader;\r\n    try {\r\n        reader = (RecordReader<Text, Text>) ctor.newInstance(new Object[] { in, split, context, conf, fs });\r\n    } catch (Exception nsm) {\r\n        throw new RuntimeException(nsm);\r\n    }\r\n    return reader;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setDataOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setDataOutput(DataOutput out)\n{\r\n    this.out = out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBytesOutput get(DataOutput out)\n{\r\n    TypedBytesOutput bout = TB_OUT.get();\r\n    bout.setDataOutput(out);\r\n    return bout;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void write(Object obj) throws IOException\n{\r\n    if (obj instanceof Buffer) {\r\n        writeBytes((Buffer) obj);\r\n    } else if (obj instanceof Byte) {\r\n        writeByte((Byte) obj);\r\n    } else if (obj instanceof Boolean) {\r\n        writeBool((Boolean) obj);\r\n    } else if (obj instanceof Integer) {\r\n        writeInt((Integer) obj);\r\n    } else if (obj instanceof Long) {\r\n        writeLong((Long) obj);\r\n    } else if (obj instanceof Float) {\r\n        writeFloat((Float) obj);\r\n    } else if (obj instanceof Double) {\r\n        writeDouble((Double) obj);\r\n    } else if (obj instanceof String) {\r\n        writeString((String) obj);\r\n    } else if (obj instanceof ArrayList) {\r\n        writeVector((ArrayList) obj);\r\n    } else if (obj instanceof List) {\r\n        writeList((List) obj);\r\n    } else if (obj instanceof Map) {\r\n        writeMap((Map) obj);\r\n    } else {\r\n        throw new RuntimeException(\"cannot write objects of this type\");\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeRaw",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeRaw(byte[] bytes) throws IOException\n{\r\n    out.write(bytes);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeRaw",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeRaw(byte[] bytes, int offset, int length) throws IOException\n{\r\n    out.write(bytes, offset, length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBytes",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeBytes(byte[] bytes, int code, int length) throws IOException\n{\r\n    out.write(code);\r\n    out.writeInt(length);\r\n    out.write(bytes, 0, length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBytes(byte[] bytes, int code) throws IOException\n{\r\n    writeBytes(bytes, code, bytes.length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBytes(byte[] bytes) throws IOException\n{\r\n    writeBytes(bytes, Type.BYTES.code);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBytes",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBytes(Buffer buffer) throws IOException\n{\r\n    writeBytes(buffer.get(), Type.BYTES.code, buffer.getCount());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeByte",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeByte(byte b) throws IOException\n{\r\n    out.write(Type.BYTE.code);\r\n    out.write(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBool",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeBool(boolean b) throws IOException\n{\r\n    out.write(Type.BOOL.code);\r\n    out.writeBoolean(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeInt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeInt(int i) throws IOException\n{\r\n    out.write(Type.INT.code);\r\n    out.writeInt(i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeLong",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeLong(long l) throws IOException\n{\r\n    out.write(Type.LONG.code);\r\n    out.writeLong(l);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeFloat",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeFloat(float f) throws IOException\n{\r\n    out.write(Type.FLOAT.code);\r\n    out.writeFloat(f);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeDouble",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeDouble(double d) throws IOException\n{\r\n    out.write(Type.DOUBLE.code);\r\n    out.writeDouble(d);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeString(String s) throws IOException\n{\r\n    out.write(Type.STRING.code);\r\n    WritableUtils.writeString(out, s);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeVector",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeVector(ArrayList vector) throws IOException\n{\r\n    writeVectorHeader(vector.size());\r\n    for (Object obj : vector) {\r\n        write(obj);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeVectorHeader",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeVectorHeader(int length) throws IOException\n{\r\n    out.write(Type.VECTOR.code);\r\n    out.writeInt(length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeList",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void writeList(List list) throws IOException\n{\r\n    writeListHeader();\r\n    for (Object obj : list) {\r\n        write(obj);\r\n    }\r\n    writeListFooter();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeListHeader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeListHeader() throws IOException\n{\r\n    out.write(Type.LIST.code);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeListFooter",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeListFooter() throws IOException\n{\r\n    out.write(Type.MARKER.code);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeMap",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void writeMap(Map map) throws IOException\n{\r\n    writeMapHeader(map.size());\r\n    Set<Entry> entries = map.entrySet();\r\n    for (Entry entry : entries) {\r\n        write(entry.getKey());\r\n        write(entry.getValue());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeMapHeader",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void writeMapHeader(int length) throws IOException\n{\r\n    out.write(Type.MAP.code);\r\n    out.writeInt(length);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "setTypedBytesOutput",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTypedBytesOutput(TypedBytesOutput out)\n{\r\n    this.out = out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TypedBytesRecordOutput get(TypedBytesOutput out)\n{\r\n    TypedBytesRecordOutput bout = TB_OUT.get();\r\n    bout.setTypedBytesOutput(out);\r\n    return bout;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "get",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TypedBytesRecordOutput get(DataOutput out)\n{\r\n    return get(TypedBytesOutput.get(out));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBool",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBool(boolean b, String tag) throws IOException\n{\r\n    out.writeBool(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeBuffer",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeBuffer(Buffer buf, String tag) throws IOException\n{\r\n    out.writeBytes(buf.get());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeByte",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeByte(byte b, String tag) throws IOException\n{\r\n    out.writeByte(b);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeDouble",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeDouble(double d, String tag) throws IOException\n{\r\n    out.writeDouble(d);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeFloat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeFloat(float f, String tag) throws IOException\n{\r\n    out.writeFloat(f);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeInt",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeInt(int i, String tag) throws IOException\n{\r\n    out.writeInt(i);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeLong",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeLong(long l, String tag) throws IOException\n{\r\n    out.writeLong(l);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "writeString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void writeString(String s, String tag) throws IOException\n{\r\n    out.writeString(s);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "startRecord",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void startRecord(Record r, String tag) throws IOException\n{\r\n    out.writeListHeader();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "startVector",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void startVector(ArrayList v, String tag) throws IOException\n{\r\n    out.writeVectorHeader(v.size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "startMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void startMap(TreeMap m, String tag) throws IOException\n{\r\n    out.writeMapHeader(m.size());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "endRecord",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void endRecord(Record r, String tag) throws IOException\n{\r\n    out.writeListFooter();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "endVector",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endVector(ArrayList v, String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-streaming\\src\\main\\java\\org\\apache\\hadoop\\typedbytes",
  "methodName" : "endMap",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void endMap(TreeMap m, String tag) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]