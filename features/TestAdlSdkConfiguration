[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testDefaultTimeout",
  "errType" : [ "URISyntaxException", "URISyntaxException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testDefaultTimeout() throws IOException\n{\r\n    AdlFileSystem fs = null;\r\n    Configuration conf = null;\r\n    int effectiveTimeout;\r\n    conf = AdlStorageConfiguration.getConfiguration();\r\n    conf.setInt(ADL_HTTP_TIMEOUT, -1);\r\n    try {\r\n        fs = (AdlFileSystem) (AdlStorageConfiguration.createStorageConnector(conf));\r\n    } catch (URISyntaxException e) {\r\n        throw new IllegalStateException(\"Can not initialize ADL FileSystem. \" + \"Please check test.fs.adl.name property.\", e);\r\n    }\r\n    Assume.assumeNotNull(fs);\r\n    effectiveTimeout = fs.getAdlClient().getDefaultTimeout();\r\n    Assert.assertFalse(\"A negative timeout is not supposed to take effect\", effectiveTimeout < 0);\r\n    conf = AdlStorageConfiguration.getConfiguration();\r\n    conf.setInt(ADL_HTTP_TIMEOUT, 17);\r\n    try {\r\n        fs = (AdlFileSystem) (AdlStorageConfiguration.createStorageConnector(conf));\r\n    } catch (URISyntaxException e) {\r\n        throw new IllegalStateException(\"Can not initialize ADL FileSystem. \" + \"Please check test.fs.adl.name property.\", e);\r\n    }\r\n    effectiveTimeout = fs.getAdlClient().getDefaultTimeout();\r\n    Assert.assertEquals(\"Timeout is getting set\", effectiveTimeout, 17);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testSSLChannelModeConfig",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testSSLChannelModeConfig() throws IOException, URISyntaxException\n{\r\n    testSSLChannelMode(SSLChannelMode.OpenSSL, \"OpenSSL\");\r\n    testSSLChannelMode(SSLChannelMode.Default_JSE, \"Default_JSE\");\r\n    testSSLChannelMode(SSLChannelMode.Default, \"Default\");\r\n    testSSLChannelMode(SSLChannelMode.Default, \"Invalid\");\r\n    testSSLChannelMode(SSLChannelMode.OpenSSL, \"openssl\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testSSLChannelMode",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testSSLChannelMode(SSLChannelMode expectedMode, String sslChannelModeConfigValue) throws IOException, URISyntaxException\n{\r\n    AdlFileSystem fs = null;\r\n    Configuration conf = null;\r\n    conf = AdlStorageConfiguration.getConfiguration();\r\n    conf.set(ADL_SSL_CHANNEL_MODE, sslChannelModeConfigValue);\r\n    fs = (AdlFileSystem) (AdlStorageConfiguration.createStorageConnector(conf));\r\n    Assume.assumeNotNull(fs);\r\n    SSLChannelMode sslChannelMode = fs.getAdlClient().getSSLChannelMode();\r\n    Assert.assertEquals(\"Unexpected SSL Channel Mode for adl.ssl.channel.mode config value : \" + sslChannelModeConfigValue, expectedMode, sslChannelMode);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n    adlStore = AdlStorageConfiguration.createStorageConnector();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "cleanUp",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void cleanUp() throws Exception\n{\r\n    if (AdlStorageConfiguration.isContractTestEnabled()) {\r\n        adlStore.delete(parent, true);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testContentSummaryOnFile",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testContentSummaryOnFile() throws IOException\n{\r\n    Path child = new Path(UUID.randomUUID().toString());\r\n    Path testFile = new Path(parent, child);\r\n    OutputStream out = adlStore.create(testFile);\r\n    for (int i = 0; i < 1024; ++i) {\r\n        out.write(97);\r\n    }\r\n    out.close();\r\n    Assert.assertTrue(adlStore.isFile(testFile));\r\n    ContentSummary summary = adlStore.getContentSummary(testFile);\r\n    Assert.assertEquals(1024, summary.getSpaceConsumed());\r\n    Assert.assertEquals(1, summary.getFileCount());\r\n    Assert.assertEquals(0, summary.getDirectoryCount());\r\n    Assert.assertEquals(1024, summary.getLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testContentSummaryOnFolder",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testContentSummaryOnFolder() throws IOException\n{\r\n    Path child = new Path(UUID.randomUUID().toString());\r\n    Path testFile = new Path(parent, child);\r\n    OutputStream out = adlStore.create(testFile);\r\n    for (int i = 0; i < 1024; ++i) {\r\n        out.write(97);\r\n    }\r\n    out.close();\r\n    Assert.assertTrue(adlStore.isFile(testFile));\r\n    ContentSummary summary = adlStore.getContentSummary(parent);\r\n    Assert.assertEquals(1024, summary.getSpaceConsumed());\r\n    Assert.assertEquals(1, summary.getFileCount());\r\n    Assert.assertEquals(1, summary.getDirectoryCount());\r\n    Assert.assertEquals(1024, summary.getLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "listStatusOnFile",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void listStatusOnFile() throws IOException\n{\r\n    Path path = new Path(parent, \"a.txt\");\r\n    FileSystem fs = adlStore;\r\n    fs.createNewFile(path);\r\n    Assert.assertTrue(fs.isFile(path));\r\n    FileStatus[] statuses = fs.listStatus(path);\r\n    Assert.assertEquals(path.makeQualified(fs.getUri(), fs.getWorkingDirectory()), statuses[0].getPath());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testUserRepresentationConfiguration",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testUserRepresentationConfiguration() throws IOException\n{\r\n    Path path = new Path(parent, \"a.txt\");\r\n    AdlFileSystem fs = (AdlFileSystem) adlStore;\r\n    fs.setUserGroupRepresentationAsUPN(false);\r\n    fs.createNewFile(path);\r\n    Assert.assertTrue(fs.isFile(path));\r\n    FileStatus fileStatus = fs.getFileStatus(path);\r\n    UUID.fromString(fileStatus.getGroup());\r\n    UUID.fromString(fileStatus.getOwner());\r\n    fs.setUserGroupRepresentationAsUPN(true);\r\n    fileStatus = fs.getFileStatus(path);\r\n    try {\r\n        UUID.fromString(fileStatus.getGroup());\r\n        UUID.fromString(fileStatus.getOwner());\r\n        fail(\"Expected user friendly name to be non guid value.\");\r\n    } catch (IllegalArgumentException e) {\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testRenameFileBeingAppended",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRenameFileBeingAppended() throws Throwable\n{\r\n    ContractTestUtils.unsupported(\"Skipping since renaming file in append \" + \"mode not supported in Adl\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "adlCharTestData",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "Collection<Object[]> adlCharTestData() throws UnsupportedEncodingException\n{\r\n    ArrayList<String> filePathList = new ArrayList<>();\r\n    for (int i = 32; i < 127; ++i) {\r\n        String specialChar = (char) i + \"\";\r\n        if (i >= 48 && i <= 57) {\r\n            continue;\r\n        }\r\n        if (i >= 65 && i <= 90) {\r\n            continue;\r\n        }\r\n        if (i >= 97 && i <= 122) {\r\n            continue;\r\n        }\r\n        if (i != 92 && i != 58 && i != 46 && i != 47) {\r\n            filePathList.add(specialChar + \"\");\r\n        }\r\n        if (i != 92 && i != 47 && i != 58) {\r\n            filePathList.add(\"file \" + i + \" \" + specialChar);\r\n        }\r\n        if (i != 47 && i != 58 && i != 92) {\r\n            filePathList.add(\"file \" + i + \" \" + specialChar + \"_name\");\r\n        }\r\n    }\r\n    filePathList.add(\"a  \");\r\n    filePathList.add(\"a..b\");\r\n    fillUnicodes(filePathList);\r\n    Collection<Object[]> result = new ArrayList<>();\r\n    for (String item : filePathList) {\r\n        result.add(new Object[] { item });\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "fillUnicodes",
  "errType" : null,
  "containingMethodsNum" : 144,
  "sourceCodeText" : "void fillUnicodes(ArrayList<String> filePathList)\n{\r\n    filePathList.add(\"البيانات الكبيرة\");\r\n    filePathList.add(\"Të dhënat i madh\");\r\n    filePathList.add(\"մեծ տվյալները\");\r\n    filePathList.add(\"böyük data\");\r\n    filePathList.add(\"вялікія дадзеныя\");\r\n    filePathList.add(\"বিগ ডেটা\");\r\n    filePathList.add(\"veliki podataka\");\r\n    filePathList.add(\"голяма данни\");\r\n    filePathList.add(\"大数据\");\r\n    filePathList.add(\"大數據\");\r\n    filePathList.add(\"დიდი მონაცემთა\");\r\n    filePathList.add(\"große Daten\");\r\n    filePathList.add(\"μεγάλο δεδομένα\");\r\n    filePathList.add(\"મોટા માહિતી\");\r\n    filePathList.add(\"נתונים גדולים\");\r\n    filePathList.add(\"बड़ा डेटा\");\r\n    filePathList.add(\"stór gögn\");\r\n    filePathList.add(\"sonraí mór\");\r\n    filePathList.add(\"ビッグデータ\");\r\n    filePathList.add(\"үлкен деректер\");\r\n    filePathList.add(\"ទិន្នន័យធំ\");\r\n    filePathList.add(\"빅 데이터\");\r\n    filePathList.add(\"ຂໍ້ມູນ ຂະຫນາດໃຫຍ່\");\r\n    filePathList.add(\"големи податоци\");\r\n    filePathList.add(\"ठूलो डाटा\");\r\n    filePathList.add(\"വലിയ ഡാറ്റ\");\r\n    filePathList.add(\"मोठे डेटा\");\r\n    filePathList.add(\"том мэдээлэл\");\r\n    filePathList.add(\"اطلاعات بزرگ\");\r\n    filePathList.add(\"ਵੱਡੇ ਡਾਟੇ ਨੂੰ\");\r\n    filePathList.add(\"большие данные\");\r\n    filePathList.add(\"Велики података\");\r\n    filePathList.add(\"විශාල දත්ත\");\r\n    filePathList.add(\"big dát\");\r\n    filePathList.add(\"маълумоти калон\");\r\n    filePathList.add(\"பெரிய தரவு\");\r\n    filePathList.add(\"పెద్ద డేటా\");\r\n    filePathList.add(\"ข้อมูลใหญ่\");\r\n    filePathList.add(\"büyük veri\");\r\n    filePathList.add(\"великі дані\");\r\n    filePathList.add(\"بڑے اعداد و شمار\");\r\n    filePathList.add(\"katta ma'lumotlar\");\r\n    filePathList.add(\"dữ liệu lớn\");\r\n    filePathList.add(\"גרויס דאַטן\");\r\n    filePathList.add(\"big idatha\");\r\n    filePathList.add(\"rachelχ\");\r\n    filePathList.add(\"jessicaο\");\r\n    filePathList.add(\"sarahδ\");\r\n    filePathList.add(\"katieν\");\r\n    filePathList.add(\"wendyξ\");\r\n    filePathList.add(\"davidμ\");\r\n    filePathList.add(\"priscillaυ\");\r\n    filePathList.add(\"oscarθ\");\r\n    filePathList.add(\"xavierχ\");\r\n    filePathList.add(\"gabriellaθ\");\r\n    filePathList.add(\"davidυ\");\r\n    filePathList.add(\"ireneμ\");\r\n    filePathList.add(\"fredρ\");\r\n    filePathList.add(\"davidτ\");\r\n    filePathList.add(\"ulyssesν\");\r\n    filePathList.add(\"gabriellaμ\");\r\n    filePathList.add(\"zachζ\");\r\n    filePathList.add(\"gabriellaλ\");\r\n    filePathList.add(\"ulyssesφ\");\r\n    filePathList.add(\"davidχ\");\r\n    filePathList.add(\"sarahσ\");\r\n    filePathList.add(\"hollyψ\");\r\n    filePathList.add(\"nickα\");\r\n    filePathList.add(\"ulyssesι\");\r\n    filePathList.add(\"mikeβ\");\r\n    filePathList.add(\"priscillaκ\");\r\n    filePathList.add(\"wendyθ\");\r\n    filePathList.add(\"jessicaς\");\r\n    filePathList.add(\"fredχ\");\r\n    filePathList.add(\"fredζ\");\r\n    filePathList.add(\"sarahκ\");\r\n    filePathList.add(\"calvinη\");\r\n    filePathList.add(\"xavierχ\");\r\n    filePathList.add(\"yuriχ\");\r\n    filePathList.add(\"ethanλ\");\r\n    filePathList.add(\"hollyε\");\r\n    filePathList.add(\"xavierσ\");\r\n    filePathList.add(\"victorτ\");\r\n    filePathList.add(\"wendyβ\");\r\n    filePathList.add(\"jessicaς\");\r\n    filePathList.add(\"quinnφ\");\r\n    filePathList.add(\"xavierυ\");\r\n    filePathList.add(\"nickι\");\r\n    filePathList.add(\"rachelφ\");\r\n    filePathList.add(\"oscarξ\");\r\n    filePathList.add(\"zachδ\");\r\n    filePathList.add(\"zachλ\");\r\n    filePathList.add(\"rachelα\");\r\n    filePathList.add(\"jessicaφ\");\r\n    filePathList.add(\"lukeφ\");\r\n    filePathList.add(\"tomζ\");\r\n    filePathList.add(\"nickξ\");\r\n    filePathList.add(\"nickκ\");\r\n    filePathList.add(\"ethanδ\");\r\n    filePathList.add(\"fredχ\");\r\n    filePathList.add(\"priscillaθ\");\r\n    filePathList.add(\"zachξ\");\r\n    filePathList.add(\"xavierξ\");\r\n    filePathList.add(\"zachψ\");\r\n    filePathList.add(\"ethanα\");\r\n    filePathList.add(\"oscarι\");\r\n    filePathList.add(\"ireneδ\");\r\n    filePathList.add(\"ireneζ\");\r\n    filePathList.add(\"victorο\");\r\n    filePathList.add(\"wendyβ\");\r\n    filePathList.add(\"mikeσ\");\r\n    filePathList.add(\"fredο\");\r\n    filePathList.add(\"mikeη\");\r\n    filePathList.add(\"sarahρ\");\r\n    filePathList.add(\"quinnβ\");\r\n    filePathList.add(\"mikeυ\");\r\n    filePathList.add(\"nickζ\");\r\n    filePathList.add(\"nickο\");\r\n    filePathList.add(\"tomκ\");\r\n    filePathList.add(\"bobλ\");\r\n    filePathList.add(\"yuriπ\");\r\n    filePathList.add(\"davidτ\");\r\n    filePathList.add(\"quinnπ\");\r\n    filePathList.add(\"mikeλ\");\r\n    filePathList.add(\"davidη\");\r\n    filePathList.add(\"ethanτ\");\r\n    filePathList.add(\"nickφ\");\r\n    filePathList.add(\"yuriο\");\r\n    filePathList.add(\"ethanυ\");\r\n    filePathList.add(\"bobθ\");\r\n    filePathList.add(\"davidλ\");\r\n    filePathList.add(\"priscillaξ\");\r\n    filePathList.add(\"nickγ\");\r\n    filePathList.add(\"lukeυ\");\r\n    filePathList.add(\"ireneλ\");\r\n    filePathList.add(\"xavierο\");\r\n    filePathList.add(\"fredυ\");\r\n    filePathList.add(\"ulyssesμ\");\r\n    filePathList.add(\"wendyγ\");\r\n    filePathList.add(\"zachλ\");\r\n    filePathList.add(\"rachelς\");\r\n    filePathList.add(\"sarahπ\");\r\n    filePathList.add(\"aliceψ\");\r\n    filePathList.add(\"bobτ\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testReport",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testReport() throws IOException, URISyntaxException\n{\r\n    if (!AdlStorageConfiguration.isContractTestEnabled()) {\r\n        return;\r\n    }\r\n    FileSystem fs = AdlStorageConfiguration.createStorageConnector();\r\n    fs.delete(new Path(TEST_ROOT), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testAllowedSpecialCharactersMkdir",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testAllowedSpecialCharactersMkdir() throws IOException, URISyntaxException\n{\r\n    Path parentPath = new Path(TEST_ROOT, UUID.randomUUID().toString() + \"/\");\r\n    Path specialFile = new Path(parentPath, path);\r\n    FileSystem fs = AdlStorageConfiguration.createStorageConnector();\r\n    Assert.assertTrue(\"Mkdir failed : \" + specialFile, fs.mkdirs(specialFile));\r\n    Assert.assertTrue(\"File not Found after Mkdir success\" + specialFile, fs.exists(specialFile));\r\n    Assert.assertTrue(\"Not listed under parent \" + parentPath, contains(fs.listStatus(parentPath), fs.makeQualified(specialFile).toString()));\r\n    Assert.assertTrue(\"Delete failed : \" + specialFile, fs.delete(specialFile, true));\r\n    Assert.assertFalse(\"File still exist after delete \" + specialFile, fs.exists(specialFile));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "contains",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean contains(FileStatus[] statuses, String remotePath)\n{\r\n    for (FileStatus status : statuses) {\r\n        if (status.getPath().toString().equals(remotePath)) {\r\n            return true;\r\n        }\r\n    }\r\n    Arrays.stream(statuses).forEach(s -> LOG.info(s.getPath().toString()));\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    org.junit.Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testAllowedSpecialCharactersRename",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testAllowedSpecialCharactersRename() throws IOException, URISyntaxException\n{\r\n    String parentPath = TEST_ROOT + UUID.randomUUID().toString() + \"/\";\r\n    Path specialFile = new Path(parentPath + path);\r\n    Path anotherLocation = new Path(parentPath + UUID.randomUUID().toString());\r\n    FileSystem fs = AdlStorageConfiguration.createStorageConnector();\r\n    Assert.assertTrue(\"Could not create \" + specialFile.toString(), fs.createNewFile(specialFile));\r\n    Assert.assertTrue(\"Failed to rename \" + specialFile.toString() + \" --> \" + anotherLocation.toString(), fs.rename(specialFile, anotherLocation));\r\n    Assert.assertFalse(\"File should not be present after successful rename : \" + specialFile.toString(), fs.exists(specialFile));\r\n    Assert.assertTrue(\"File should be present after successful rename : \" + anotherLocation.toString(), fs.exists(anotherLocation));\r\n    Assert.assertFalse(\"Listed under parent whereas expected not listed : \" + parentPath, contains(fs.listStatus(new Path(parentPath)), fs.makeQualified(specialFile).toString()));\r\n    Assert.assertTrue(\"Failed to rename \" + anotherLocation.toString() + \" --> \" + specialFile.toString(), fs.rename(anotherLocation, specialFile));\r\n    Assert.assertTrue(\"File should be present after successful rename : \" + \"\" + specialFile.toString(), fs.exists(specialFile));\r\n    Assert.assertFalse(\"File should not be present after successful rename : \" + anotherLocation.toString(), fs.exists(anotherLocation));\r\n    Assert.assertTrue(\"Not listed under parent \" + parentPath, contains(fs.listStatus(new Path(parentPath)), fs.makeQualified(specialFile).toString()));\r\n    Assert.assertTrue(\"Failed to delete \" + parentPath, fs.delete(new Path(parentPath), true));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "getRandomByteArrayData",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] getRandomByteArrayData(int size)\n{\r\n    byte[] b = new byte[size];\r\n    rand.nextBytes(b);\r\n    return b;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testDataForIntegrityTest",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Collection testDataForIntegrityTest()\n{\r\n    return Arrays.asList(new Object[][] { { 4 * 1024, 1 * 1024 }, { 4 * 1024, 7 * 1024 }, { 4 * 1024, 10 }, { 2 * 1024, 10 }, { 1 * 1024, 10 }, { 100, 1 }, { 4 * 1024, 1 * 1024 }, { 7 * 1024, 2 * 1024 }, { 9 * 1024, 2 * 1024 }, { 10 * 1024, 3 * 1024 }, { 10 * 1024, 1 * 1024 }, { 10 * 1024, 8 * 1024 } });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "cleanUpParent",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void cleanUpParent() throws IOException, URISyntaxException\n{\r\n    if (AdlStorageConfiguration.isContractTestEnabled()) {\r\n        Path path = new Path(\"/test/dataIntegrityCheck/\");\r\n        FileSystem fs = AdlStorageConfiguration.createStorageConnector();\r\n        fs.delete(path, true);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setup() throws Exception\n{\r\n    org.junit.Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testDataIntegrity",
  "errType" : [ "URISyntaxException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testDataIntegrity() throws IOException\n{\r\n    Path path = new Path(\"/test/dataIntegrityCheck/\" + UUID.randomUUID().toString());\r\n    FileSystem fs = null;\r\n    AdlStorageConfiguration.getConfiguration().setInt(WRITE_BUFFER_SIZE_KEY, 4 * 1024);\r\n    try {\r\n        fs = AdlStorageConfiguration.createStorageConnector();\r\n    } catch (URISyntaxException e) {\r\n        throw new IllegalStateException(\"Can not initialize ADL FileSystem. \" + \"Please check test.fs.adl.name property.\", e);\r\n    }\r\n    byte[] expectedData = getRandomByteArrayData(totalSize);\r\n    FSDataOutputStream out = fs.create(path, true);\r\n    int iteration = totalSize / chunkSize;\r\n    int reminderIteration = totalSize % chunkSize;\r\n    int offset = 0;\r\n    for (int i = 0; i < iteration; ++i) {\r\n        out.write(expectedData, offset, chunkSize);\r\n        offset += chunkSize;\r\n    }\r\n    out.write(expectedData, offset, reminderIteration);\r\n    out.close();\r\n    byte[] actualData = new byte[totalSize];\r\n    FSDataInputStream in = fs.open(path);\r\n    in.readFully(0, actualData);\r\n    in.close();\r\n    Assert.assertArrayEquals(expectedData, actualData);\r\n    Assert.assertTrue(fs.delete(path, true));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "skipTestCheck",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void skipTestCheck()\n{\r\n    Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    Configuration conf = AdlStorageConfiguration.getConfiguration();\r\n    String fileSystem = conf.get(KEY_FILE_SYSTEM);\r\n    if (fileSystem == null || fileSystem.trim().length() == 0) {\r\n        throw new Exception(\"Default file system not configured.\");\r\n    }\r\n    URI uri = new URI(fileSystem);\r\n    FileSystem fs = AdlStorageConfiguration.createStorageConnector();\r\n    fc = FileContext.getFileContext(new DelegateToFileSystem(uri, fs, conf, fs.getScheme(), false) {\r\n    }, conf);\r\n    super.setUp();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createFileContextHelper",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FileContextTestHelper createFileContextHelper()\n{\r\n    return new FileContextTestHelper(UUID.randomUUID().toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "listCorruptedBlocksSupported",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean listCorruptedBlocksSupported()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testWorkingDirectory",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testWorkingDirectory() throws Exception\n{\r\n    if (WINDOWS) {\r\n        Assume.assumeTrue(false);\r\n    } else {\r\n        super.testWorkingDirectory();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testUnsupportedSymlink",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testUnsupportedSymlink() throws IOException\n{\r\n    Assume.assumeTrue(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testSetVerifyChecksum",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testSetVerifyChecksum() throws IOException\n{\r\n    Assume.assumeTrue(false);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testConcatMissingTarget",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testConcatMissingTarget() throws Throwable\n{\r\n    Path testPath = path(\"test\");\r\n    Path zeroByteFile = new Path(testPath, \"zero.txt\");\r\n    Path target = new Path(testPath, \"target\");\r\n    touch(getFileSystem(), zeroByteFile);\r\n    getFileSystem().concat(target, new Path[] { zeroByteFile });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration conf)\n{\r\n    return new AdlStorageContract(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "adlCreateNonRecursiveTestData",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Collection adlCreateNonRecursiveTestData() throws UnsupportedEncodingException\n{\r\n    return Arrays.asList(new Object[][] { { \"CNR - When file do not exist.\", UUID.randomUUID().toString(), FsPermission.getFileDefault(), false, false, true, null }, { \"CNR - When file exist. Override false\", UUID.randomUUID().toString(), FsPermission.getFileDefault(), false, true, true, FileAlreadyExistsException.class }, { \"CNR - When file exist. Override true\", UUID.randomUUID().toString(), FsPermission.getFileDefault(), true, true, true, null } });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n    adlStore = AdlStorageConfiguration.createStorageConnector();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testCreateNonRecursiveFunctionality",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testCreateNonRecursiveFunctionality() throws IOException\n{\r\n    if (inputFileAlreadyExist) {\r\n        FileSystem.create(adlStore, inputFileName, inputPermission);\r\n    }\r\n    if (inputParentAlreadyExist) {\r\n        adlStore.mkdirs(inputFileName.getParent());\r\n    } else {\r\n        adlStore.delete(inputFileName.getParent(), true);\r\n    }\r\n    try {\r\n        adlStore.createNonRecursive(inputFileName, inputPermission, inputOverride, CommonConfigurationKeysPublic.IO_FILE_BUFFER_SIZE_DEFAULT, adlStore.getDefaultReplication(inputFileName), adlStore.getDefaultBlockSize(inputFileName), null);\r\n    } catch (IOException e) {\r\n        if (expectedExceptionType == null) {\r\n            throw e;\r\n        }\r\n        Assert.assertEquals(expectedExceptionType, e.getClass());\r\n        return;\r\n    }\r\n    if (expectedExceptionType != null) {\r\n        Assert.fail(\"CreateNonRecursive should have failed with exception \" + expectedExceptionType.getName());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "adlCreateNonRecursiveTestData",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Collection adlCreateNonRecursiveTestData() throws UnsupportedEncodingException\n{\r\n    final Collection<Object[]> datas = new ArrayList<>();\r\n    for (FsAction g : FsAction.values()) {\r\n        for (FsAction o : FsAction.values()) {\r\n            datas.add(new Object[] { new FsPermission(FsAction.ALL, g, o) });\r\n        }\r\n    }\r\n    return datas;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "cleanUp",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void cleanUp() throws IOException, URISyntaxException\n{\r\n    if (AdlStorageConfiguration.isContractTestEnabled()) {\r\n        Assert.assertTrue(AdlStorageConfiguration.createStorageConnector().delete(testRoot, true));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n    adlStore = AdlStorageConfiguration.createStorageConnector();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testFilePermission",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testFilePermission() throws IOException\n{\r\n    path = new Path(testRoot, UUID.randomUUID().toString());\r\n    adlStore.getConf().set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, \"000\");\r\n    adlStore.mkdirs(path.getParent(), new FsPermission(FsAction.ALL, FsAction.WRITE, FsAction.NONE));\r\n    adlStore.removeDefaultAcl(path.getParent());\r\n    adlStore.create(path, permission, true, 1024, (short) 1, 1023, null);\r\n    FileStatus status = adlStore.getFileStatus(path);\r\n    Assert.assertEquals(permission, status.getPermission());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "testFolderPermission",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testFolderPermission() throws IOException\n{\r\n    path = new Path(testRoot, UUID.randomUUID().toString());\r\n    adlStore.getConf().set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, \"000\");\r\n    adlStore.mkdirs(path.getParent(), new FsPermission(FsAction.ALL, FsAction.WRITE, FsAction.NONE));\r\n    adlStore.removeDefaultAcl(path.getParent());\r\n    adlStore.mkdirs(path, permission);\r\n    FileStatus status = adlStore.getFileStatus(path);\r\n    Assert.assertEquals(permission, status.getPermission());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "skipTestCheck",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void skipTestCheck()\n{\r\n    Assume.assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    Configuration conf = AdlStorageConfiguration.getConfiguration();\r\n    String fileSystem = conf.get(KEY_FILE_SYSTEM);\r\n    if (fileSystem == null || fileSystem.trim().length() == 0) {\r\n        throw new Exception(\"Default file system not configured.\");\r\n    }\r\n    URI uri = new URI(fileSystem);\r\n    FileSystem fs = AdlStorageConfiguration.createStorageConnector();\r\n    fc = FileContext.getFileContext(new DelegateToFileSystem(uri, fs, conf, fs.getScheme(), false) {\r\n    }, conf);\r\n    super.setUp();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createFileContextHelper",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FileContextTestHelper createFileContextHelper()\n{\r\n    return new FileContextTestHelper(UUID.randomUUID().toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testToRelativePath",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testToRelativePath() throws URISyntaxException, IOException\n{\r\n    AdlFileSystem fs = new AdlFileSystem();\r\n    Configuration configuration = new Configuration();\r\n    configuration.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, TokenProviderType.Custom);\r\n    configuration.set(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY, \"org.apache.hadoop.fs.adl.common.CustomMockTokenProvider\");\r\n    fs.initialize(new URI(\"adl://temp.account.net\"), configuration);\r\n    Assert.assertEquals(\"/usr\", fs.toRelativeFilePath(new Path(\"/usr\")));\r\n    Assert.assertEquals(\"/usr\", fs.toRelativeFilePath(new Path(\"adl://temp.account.net/usr\")));\r\n    fs.setWorkingDirectory(new Path(\"/a/b/\"));\r\n    Assert.assertEquals(\"/usr\", fs.toRelativeFilePath(new Path(\"/usr\")));\r\n    Assert.assertEquals(\"/a/b/usr\", fs.toRelativeFilePath(new Path(\"usr\")));\r\n    Assert.assertEquals(\"/usr\", fs.toRelativeFilePath(new Path(\"adl://temp.account.net/usr\")));\r\n    Assert.assertEquals(\"/usr\", fs.toRelativeFilePath(new Path(\"wasb://temp.account.net/usr\")));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "getConfiguration",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Configuration getConfiguration()\n{\r\n    Configuration newConf = new Configuration();\r\n    newConf.addResource(CONTRACT_XML);\r\n    return newConf;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "isContractTestEnabled",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean isContractTestEnabled()\n{\r\n    if (conf == null) {\r\n        conf = getConfiguration();\r\n    }\r\n    isContractTestEnabled = conf.getBoolean(CONTRACT_ENABLE_KEY, CONTRACT_ENABLE_DEFAULT);\r\n    return isContractTestEnabled;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createStorageConnector",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "FileSystem createStorageConnector() throws URISyntaxException, IOException\n{\r\n    if (conf == null) {\r\n        conf = getConfiguration();\r\n    }\r\n    return createStorageConnector(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createStorageConnector",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "FileSystem createStorageConnector(Configuration fsConfig) throws URISyntaxException, IOException\n{\r\n    if (!isContractTestEnabled()) {\r\n        return null;\r\n    }\r\n    String fileSystem = fsConfig.get(FILE_SYSTEM_KEY);\r\n    if (fileSystem == null || fileSystem.trim().length() == 0) {\r\n        throw new IOException(\"Default file system not configured.\");\r\n    }\r\n    Class<?> clazz = fsConfig.getClass(FILE_SYSTEM_IMPL_KEY, FILE_SYSTEM_IMPL_DEFAULT);\r\n    FileSystem fs = (FileSystem) ReflectionUtils.newInstance(clazz, fsConfig);\r\n    fs.initialize(new URI(fileSystem), fsConfig);\r\n    return fs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getGetFileStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "String getGetFileStatusJSONResponse(FileStatus status)\n{\r\n    return \"{\\\"FileStatus\\\":{\\\"length\\\":\" + status.getLen() + \",\" + \"\\\"pathSuffix\\\":\\\"\\\",\\\"type\\\":\\\"\" + (status.isDirectory() ? \"DIRECTORY\" : \"FILE\") + \"\\\"\" + \",\\\"blockSize\\\":\" + status.getBlockSize() + \",\\\"accessTime\\\":\" + status.getAccessTime() + \",\\\"modificationTime\\\":\" + status.getModificationTime() + \"\" + \",\\\"replication\\\":\" + status.getReplication() + \",\\\"permission\\\":\\\"\" + status.getPermission() + \"\\\",\\\"owner\\\":\\\"\" + status.getOwner() + \"\\\",\\\"group\\\":\\\"\" + status.getGroup() + \"\\\"}}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getGetFileStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getGetFileStatusJSONResponse()\n{\r\n    return getGetFileStatusJSONResponse(4194304);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getGetAclStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getGetAclStatusJSONResponse()\n{\r\n    return \"{\\n\" + \"    \\\"AclStatus\\\": {\\n\" + \"        \\\"entries\\\": [\\n\" + \"            \\\"user:carla:rw-\\\", \\n\" + \"            \\\"group::r-x\\\"\\n\" + \"        ], \\n\" + \"        \\\"group\\\": \\\"supergroup\\\", \\n\" + \"        \\\"owner\\\": \\\"hadoop\\\", \\n\" + \"        \\\"permission\\\":\\\"775\\\",\\n\" + \"        \\\"stickyBit\\\": false\\n\" + \"    }\\n\" + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getGetFileStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getGetFileStatusJSONResponse(long length)\n{\r\n    return \"{\\\"FileStatus\\\":{\\\"length\\\":\" + length + \",\" + \"\\\"pathSuffix\\\":\\\"\\\",\\\"type\\\":\\\"FILE\\\",\\\"blockSize\\\":268435456,\" + \"\\\"accessTime\\\":1452103827023,\\\"modificationTime\\\":1452103827023,\" + \"\\\"replication\\\":0,\\\"permission\\\":\\\"777\\\",\" + \"\\\"owner\\\":\\\"NotSupportYet\\\",\\\"group\\\":\\\"NotSupportYet\\\"}}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getGetFileStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getGetFileStatusJSONResponse(boolean aclBit)\n{\r\n    return \"{\\\"FileStatus\\\":{\\\"length\\\":1024,\" + \"\\\"pathSuffix\\\":\\\"\\\",\\\"type\\\":\\\"FILE\\\",\\\"blockSize\\\":268435456,\" + \"\\\"accessTime\\\":1452103827023,\\\"modificationTime\\\":1452103827023,\" + \"\\\"replication\\\":0,\\\"permission\\\":\\\"777\\\",\" + \"\\\"owner\\\":\\\"NotSupportYet\\\",\\\"group\\\":\\\"NotSupportYet\\\",\\\"aclBit\\\":\\\"\" + aclBit + \"\\\"}}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getListFileStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getListFileStatusJSONResponse(int dirSize)\n{\r\n    String list = \"\";\r\n    for (int i = 0; i < dirSize; ++i) {\r\n        list += \"{\\\"length\\\":1024,\\\"pathSuffix\\\":\\\"\" + java.util.UUID.randomUUID() + \"\\\",\\\"type\\\":\\\"FILE\\\",\\\"blockSize\\\":268435456,\" + \"\\\"accessTime\\\":1452103878833,\" + \"\\\"modificationTime\\\":1452103879190,\\\"replication\\\":0,\" + \"\\\"permission\\\":\\\"777\\\",\\\"owner\\\":\\\"NotSupportYet\\\",\" + \"\\\"group\\\":\\\"NotSupportYet\\\"},\";\r\n    }\r\n    list = list.substring(0, list.length() - 1);\r\n    return \"{\\\"FileStatuses\\\":{\\\"FileStatus\\\":[\" + list + \"]}}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getListFileStatusJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getListFileStatusJSONResponse(boolean aclBit)\n{\r\n    return \"{\\\"FileStatuses\\\":{\\\"FileStatus\\\":[{\\\"length\\\":0,\\\"pathSuffix\\\":\\\"\" + java.util.UUID.randomUUID() + \"\\\",\\\"type\\\":\\\"DIRECTORY\\\",\\\"blockSize\\\":0,\" + \"\\\"accessTime\\\":1481184513488,\" + \"\\\"modificationTime\\\":1481184513488,\\\"replication\\\":0,\" + \"\\\"permission\\\":\\\"770\\\",\" + \"\\\"owner\\\":\\\"4b27fe1a-d9ab-4a04-ad7a-4bba72cd9e6c\\\",\" + \"\\\"group\\\":\\\"4b27fe1a-d9ab-4a04-ad7a-4bba72cd9e6c\\\",\\\"aclBit\\\":\\\"\" + aclBit + \"\\\"}]}}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getJSONResponse(boolean status)\n{\r\n    return \"{\\\"boolean\\\":\" + status + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getErrorIllegalArgumentExceptionJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getErrorIllegalArgumentExceptionJSONResponse()\n{\r\n    return \"{\\n\" + \"  \\\"RemoteException\\\":\\n\" + \"  {\\n\" + \"    \\\"exception\\\"    : \\\"IllegalArgumentException\\\",\\n\" + \"    \\\"javaClassName\\\": \\\"java.lang.IllegalArgumentException\\\",\\n\" + \"    \\\"message\\\"      : \\\"Invalid\\\"\" + \"  }\\n\" + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getErrorBadOffsetExceptionJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getErrorBadOffsetExceptionJSONResponse()\n{\r\n    return \"{\\n\" + \"  \\\"RemoteException\\\":\\n\" + \"  {\\n\" + \"    \\\"exception\\\"    : \\\"BadOffsetException\\\",\\n\" + \"    \\\"javaClassName\\\": \\\"org.apache.hadoop.fs.adl\" + \".BadOffsetException\\\",\\n\" + \"    \\\"message\\\"      : \\\"Invalid\\\"\" + \"  }\\n\" + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getErrorInternalServerExceptionJSONResponse",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getErrorInternalServerExceptionJSONResponse()\n{\r\n    return \"{\\n\" + \"  \\\"RemoteException\\\":\\n\" + \"  {\\n\" + \"    \\\"exception\\\"    : \\\"RuntimeException\\\",\\n\" + \"    \\\"javaClassName\\\": \\\"java.lang.RuntimeException\\\",\\n\" + \"    \\\"message\\\"      : \\\"Internal Server Error\\\"\" + \"  }\\n\" + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getAccessControlException",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getAccessControlException()\n{\r\n    return \"{\\n\" + \"  \\\"RemoteException\\\":\\n\" + \"  {\\n\" + \"    \\\"exception\\\"    : \\\"AccessControlException\\\",\\n\" + \"    \\\"javaClassName\\\": \\\"org.apache.hadoop.security\" + \".AccessControlException\\\",\\n\" + \"    \\\"message\\\"      : \\\"Permission denied: ...\\\"\\n\" + \"  }\\n\" + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getFileNotFoundException",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getFileNotFoundException()\n{\r\n    return \"{\\n\" + \"  \\\"RemoteException\\\":\\n\" + \"  {\\n\" + \"    \\\"exception\\\"    : \\\"FileNotFoundException\\\",\\n\" + \"    \\\"javaClassName\\\": \\\"java.io.FileNotFoundException\\\",\\n\" + \"    \\\"message\\\"      : \\\"File does not exist\\\"\\n\" + \"  }\\n\" + \"}\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getRandomByteArrayData",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] getRandomByteArrayData()\n{\r\n    return getRandomByteArrayData(4 * 1024 * 1024);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "getRandomByteArrayData",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "byte[] getRandomByteArrayData(int size)\n{\r\n    byte[] b = new byte[size];\r\n    Random rand = new Random();\r\n    rand.nextBytes(b);\r\n    return b;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\common",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initialize(Configuration configuration) throws IOException\n{\r\n    random = new Random();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\common",
  "methodName" : "getAccessToken",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getAccessToken() throws IOException\n{\r\n    accessTokenRequestCount++;\r\n    return String.valueOf(random.nextInt());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\common",
  "methodName" : "getExpiryTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Date getExpiryTime()\n{\r\n    Date before10Min = new Date();\r\n    before10Min.setTime(expiryTime);\r\n    return before10Min;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\common",
  "methodName" : "setExpiryTimeInMillisAfter",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setExpiryTimeInMillisAfter(long timeInMillis)\n{\r\n    expiryTime = System.currentTimeMillis() + timeInMillis;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\common",
  "methodName" : "getAccessTokenRequestCount",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getAccessTokenRequestCount()\n{\r\n    return accessTokenRequestCount;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "validateConfigurationKeys",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void validateConfigurationKeys()\n{\r\n    assertEquals(\"fs.adl.oauth2.refresh.url\", AZURE_AD_REFRESH_URL_KEY);\r\n    assertEquals(\"fs.adl.oauth2.access.token.provider\", AZURE_AD_TOKEN_PROVIDER_CLASS_KEY);\r\n    assertEquals(\"fs.adl.oauth2.client.id\", AZURE_AD_CLIENT_ID_KEY);\r\n    assertEquals(\"fs.adl.oauth2.refresh.token\", AZURE_AD_REFRESH_TOKEN_KEY);\r\n    assertEquals(\"fs.adl.oauth2.credential\", AZURE_AD_CLIENT_SECRET_KEY);\r\n    assertEquals(\"adl.debug.override.localuserasfileowner\", ADL_DEBUG_OVERRIDE_LOCAL_USER_AS_OWNER);\r\n    assertEquals(\"fs.adl.oauth2.access.token.provider.type\", AZURE_AD_TOKEN_PROVIDER_TYPE_KEY);\r\n    assertEquals(\"adl.feature.client.cache.readahead\", READ_AHEAD_BUFFER_SIZE_KEY);\r\n    assertEquals(\"adl.feature.client.cache.drop.behind.writes\", WRITE_BUFFER_SIZE_KEY);\r\n    assertEquals(\"RefreshToken\", TOKEN_PROVIDER_TYPE_REFRESH_TOKEN);\r\n    assertEquals(\"ClientCredential\", TOKEN_PROVIDER_TYPE_CLIENT_CRED);\r\n    assertEquals(\"adl.enable.client.latency.tracker\", LATENCY_TRACKER_KEY);\r\n    assertEquals(true, LATENCY_TRACKER_DEFAULT);\r\n    assertEquals(true, ADL_EXPERIMENT_POSITIONAL_READ_DEFAULT);\r\n    assertEquals(\"adl.feature.experiment.positional.read.enable\", ADL_EXPERIMENT_POSITIONAL_READ_KEY);\r\n    assertEquals(1, ADL_REPLICATION_FACTOR);\r\n    assertEquals(256 * 1024 * 1024, ADL_BLOCK_SIZE);\r\n    assertEquals(false, ADL_DEBUG_SET_LOCAL_USER_AS_OWNER_DEFAULT);\r\n    assertEquals(4 * 1024 * 1024, DEFAULT_READ_AHEAD_BUFFER_SIZE);\r\n    assertEquals(4 * 1024 * 1024, DEFAULT_WRITE_AHEAD_BUFFER_SIZE);\r\n    assertEquals(\"adl.feature.ownerandgroup.enableupn\", ADL_ENABLEUPN_FOR_OWNERGROUP_KEY);\r\n    assertEquals(false, ADL_ENABLEUPN_FOR_OWNERGROUP_DEFAULT);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testSetDeprecatedKeys",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testSetDeprecatedKeys() throws ClassNotFoundException\n{\r\n    Configuration conf = new Configuration(true);\r\n    setDeprecatedKeys(conf);\r\n    Class.forName(AdlFileSystem.class.getName());\r\n    assertDeprecatedKeys(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testLoadDeprecatedKeys",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testLoadDeprecatedKeys() throws IOException, ClassNotFoundException\n{\r\n    Configuration saveConf = new Configuration(false);\r\n    setDeprecatedKeys(saveConf);\r\n    final File testRootDir = GenericTestUtils.getTestDir();\r\n    File confXml = new File(testRootDir, \"testLoadDeprecatedKeys.xml\");\r\n    OutputStream out = new FileOutputStream(confXml);\r\n    saveConf.writeXml(out);\r\n    out.close();\r\n    Configuration conf = new Configuration(true);\r\n    conf.addResource(confXml.toURI().toURL());\r\n    conf.get(\"dummy.key\");\r\n    Class.forName(AdlFileSystem.class.getName());\r\n    assertDeprecatedKeys(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testGetAccountNameFromFQDN",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testGetAccountNameFromFQDN()\n{\r\n    assertEquals(\"dummy\", AdlFileSystem.getAccountNameFromFQDN(\"dummy.azuredatalakestore.net\"));\r\n    assertEquals(\"localhost\", AdlFileSystem.getAccountNameFromFQDN(\"localhost\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testPropagateAccountOptionsDefault",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testPropagateAccountOptionsDefault()\n{\r\n    Configuration conf = new Configuration(false);\r\n    conf.set(\"fs.adl.oauth2.client.id\", \"defaultClientId\");\r\n    conf.set(\"fs.adl.oauth2.credential\", \"defaultCredential\");\r\n    conf.set(\"some.other.config\", \"someValue\");\r\n    Configuration propagatedConf = AdlFileSystem.propagateAccountOptions(conf, \"dummy\");\r\n    assertEquals(\"defaultClientId\", propagatedConf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(\"defaultCredential\", propagatedConf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"someValue\", propagatedConf.get(\"some.other.config\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testPropagateAccountOptionsSpecified",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testPropagateAccountOptionsSpecified()\n{\r\n    Configuration conf = new Configuration(false);\r\n    conf.set(\"fs.adl.account.dummy.oauth2.client.id\", \"dummyClientId\");\r\n    conf.set(\"fs.adl.account.dummy.oauth2.credential\", \"dummyCredential\");\r\n    conf.set(\"some.other.config\", \"someValue\");\r\n    Configuration propagatedConf = AdlFileSystem.propagateAccountOptions(conf, \"dummy\");\r\n    assertEquals(\"dummyClientId\", propagatedConf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(\"dummyCredential\", propagatedConf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"someValue\", propagatedConf.get(\"some.other.config\"));\r\n    propagatedConf = AdlFileSystem.propagateAccountOptions(conf, \"anotherDummy\");\r\n    assertEquals(null, propagatedConf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(null, propagatedConf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"someValue\", propagatedConf.get(\"some.other.config\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testPropagateAccountOptionsAll",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void testPropagateAccountOptionsAll()\n{\r\n    Configuration conf = new Configuration(false);\r\n    conf.set(\"fs.adl.oauth2.client.id\", \"defaultClientId\");\r\n    conf.set(\"fs.adl.oauth2.credential\", \"defaultCredential\");\r\n    conf.set(\"some.other.config\", \"someValue\");\r\n    conf.set(\"fs.adl.account.dummy1.oauth2.client.id\", \"dummyClientId1\");\r\n    conf.set(\"fs.adl.account.dummy1.oauth2.credential\", \"dummyCredential1\");\r\n    conf.set(\"fs.adl.account.dummy2.oauth2.client.id\", \"dummyClientId2\");\r\n    conf.set(\"fs.adl.account.dummy2.oauth2.credential\", \"dummyCredential2\");\r\n    Configuration propagatedConf = AdlFileSystem.propagateAccountOptions(conf, \"dummy1\");\r\n    assertEquals(\"dummyClientId1\", propagatedConf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(\"dummyCredential1\", propagatedConf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"someValue\", propagatedConf.get(\"some.other.config\"));\r\n    propagatedConf = AdlFileSystem.propagateAccountOptions(conf, \"dummy2\");\r\n    assertEquals(\"dummyClientId2\", propagatedConf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(\"dummyCredential2\", propagatedConf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"someValue\", propagatedConf.get(\"some.other.config\"));\r\n    propagatedConf = AdlFileSystem.propagateAccountOptions(conf, \"anotherDummy\");\r\n    assertEquals(\"defaultClientId\", propagatedConf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(\"defaultCredential\", propagatedConf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"someValue\", propagatedConf.get(\"some.other.config\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "setDeprecatedKeys",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void setDeprecatedKeys(Configuration conf)\n{\r\n    conf.set(\"dfs.adls.oauth2.access.token.provider.type\", \"dummyType\");\r\n    conf.set(\"dfs.adls.oauth2.client.id\", \"dummyClientId\");\r\n    conf.set(\"dfs.adls.oauth2.refresh.token\", \"dummyRefreshToken\");\r\n    conf.set(\"dfs.adls.oauth2.refresh.url\", \"dummyRefreshUrl\");\r\n    conf.set(\"dfs.adls.oauth2.credential\", \"dummyCredential\");\r\n    conf.set(\"dfs.adls.oauth2.access.token.provider\", \"dummyClass\");\r\n    conf.set(\"adl.dfs.enable.client.latency.tracker\", \"dummyTracker\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "assertDeprecatedKeys",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void assertDeprecatedKeys(Configuration conf)\n{\r\n    assertEquals(\"dummyType\", conf.get(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY));\r\n    assertEquals(\"dummyClientId\", conf.get(AZURE_AD_CLIENT_ID_KEY));\r\n    assertEquals(\"dummyRefreshToken\", conf.get(AZURE_AD_REFRESH_TOKEN_KEY));\r\n    assertEquals(\"dummyRefreshUrl\", conf.get(AZURE_AD_REFRESH_URL_KEY));\r\n    assertEquals(\"dummyCredential\", conf.get(AZURE_AD_CLIENT_SECRET_KEY));\r\n    assertEquals(\"dummyClass\", conf.get(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY));\r\n    assertEquals(\"dummyTracker\", conf.get(LATENCY_TRACKER_KEY));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "setUp",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void setUp() throws Exception\n{\r\n    skipTestCheck();\r\n    adlStore = AdlStorageConfiguration.createStorageConnector();\r\n    if (AdlStorageConfiguration.isContractTestEnabled()) {\r\n        fs = adlStore;\r\n    }\r\n    assumeNotNull(fs);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void tearDown() throws Exception\n{\r\n    if (AdlStorageConfiguration.isContractTestEnabled()) {\r\n        cleanup();\r\n    }\r\n    super.tearDown();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "cleanup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void cleanup() throws IOException\n{\r\n    adlStore.delete(new Path(\"/test\"), true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "skipTestCheck",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void skipTestCheck()\n{\r\n    assumeTrue(AdlStorageConfiguration.isContractTestEnabled());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "createContract",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AbstractFSContract createContract(Configuration configuration)\n{\r\n    return new AdlStorageContract(configuration);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testRefreshTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testRefreshTokenProvider() throws URISyntaxException, IOException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(AZURE_AD_CLIENT_ID_KEY, \"MY_CLIENTID\");\r\n    conf.set(AZURE_AD_REFRESH_TOKEN_KEY, \"XYZ\");\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, RefreshToken);\r\n    conf.set(AZURE_AD_REFRESH_URL_KEY, \"http://localhost:8080/refresh\");\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    AccessTokenProvider tokenProvider = fileSystem.getTokenProvider();\r\n    Assert.assertTrue(tokenProvider instanceof RefreshTokenBasedTokenProvider);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testClientCredTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testClientCredTokenProvider() throws IOException, URISyntaxException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(AZURE_AD_CLIENT_ID_KEY, \"MY_CLIENTID\");\r\n    conf.set(AZURE_AD_CLIENT_SECRET_KEY, \"XYZ\");\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, ClientCredential);\r\n    conf.set(AZURE_AD_REFRESH_URL_KEY, \"http://localhost:8080/refresh\");\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    AccessTokenProvider tokenProvider = fileSystem.getTokenProvider();\r\n    Assert.assertTrue(tokenProvider instanceof ClientCredsTokenProvider);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testMSITokenProvider",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testMSITokenProvider() throws IOException, URISyntaxException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, MSI);\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    AccessTokenProvider tokenProvider = fileSystem.getTokenProvider();\r\n    Assert.assertTrue(tokenProvider instanceof MsiTokenProvider);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testDeviceCodeTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testDeviceCodeTokenProvider() throws IOException, URISyntaxException\n{\r\n    boolean runTest = false;\r\n    if (runTest) {\r\n        Configuration conf = new Configuration();\r\n        conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, DeviceCode);\r\n        conf.set(DEVICE_CODE_CLIENT_APP_ID, \"CLIENT_APP_ID_GUID\");\r\n        URI uri = new URI(\"adl://localhost:8080\");\r\n        AdlFileSystem fileSystem = new AdlFileSystem();\r\n        fileSystem.initialize(uri, conf);\r\n        AccessTokenProvider tokenProvider = fileSystem.getTokenProvider();\r\n        Assert.assertTrue(tokenProvider instanceof DeviceCodeTokenProvider);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testCustomCredTokenProvider",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testCustomCredTokenProvider() throws URISyntaxException, IOException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, TokenProviderType.Custom);\r\n    conf.setClass(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY, CustomMockTokenProvider.class, AzureADTokenProvider.class);\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    AccessTokenProvider tokenProvider = fileSystem.getTokenProvider();\r\n    Assert.assertTrue(tokenProvider instanceof SdkTokenProviderAdapter);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testInvalidProviderConfigurationForType",
  "errType" : [ "IllegalArgumentException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testInvalidProviderConfigurationForType() throws URISyntaxException, IOException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, TokenProviderType.Custom);\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    try {\r\n        fileSystem.initialize(uri, conf);\r\n        Assert.fail(\"Initialization should have failed due no token provider \" + \"configuration\");\r\n    } catch (IllegalArgumentException e) {\r\n        GenericTestUtils.assertExceptionContains(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY, e);\r\n    }\r\n    conf.setClass(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY, CustomMockTokenProvider.class, AzureADTokenProvider.class);\r\n    fileSystem.initialize(uri, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testInvalidProviderConfigurationForClassPath",
  "errType" : [ "RuntimeException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testInvalidProviderConfigurationForClassPath() throws URISyntaxException, IOException\n{\r\n    Configuration conf = new Configuration();\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, TokenProviderType.Custom);\r\n    conf.set(AZURE_AD_TOKEN_PROVIDER_CLASS_KEY, \"wrong.classpath.CustomMockTokenProvider\");\r\n    try {\r\n        fileSystem.initialize(uri, conf);\r\n        Assert.fail(\"Initialization should have failed due invalid provider \" + \"configuration\");\r\n    } catch (RuntimeException e) {\r\n        Assert.assertTrue(e.getMessage().contains(\"wrong.classpath.CustomMockTokenProvider\"));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "createTempCredProvider",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "CredentialProvider createTempCredProvider(Configuration conf) throws URISyntaxException, IOException\n{\r\n    final File file = tempDir.newFile(\"test.jks\");\r\n    final URI jks = ProviderUtils.nestURIForLocalJavaKeyStoreProvider(file.toURI());\r\n    conf.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, jks.toString());\r\n    return CredentialProviderFactory.getProviders(conf).get(0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testRefreshTokenWithCredentialProvider",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testRefreshTokenWithCredentialProvider() throws IOException, URISyntaxException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(AZURE_AD_CLIENT_ID_KEY, \"DUMMY\");\r\n    conf.set(AZURE_AD_REFRESH_TOKEN_KEY, \"DUMMY\");\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, RefreshToken);\r\n    CredentialProvider provider = createTempCredProvider(conf);\r\n    provider.createCredentialEntry(AZURE_AD_CLIENT_ID_KEY, CLIENT_ID.toCharArray());\r\n    provider.createCredentialEntry(AZURE_AD_REFRESH_TOKEN_KEY, REFRESH_TOKEN.toCharArray());\r\n    provider.flush();\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    RefreshTokenBasedTokenProvider expected = new RefreshTokenBasedTokenProvider(CLIENT_ID, REFRESH_TOKEN);\r\n    Assert.assertTrue(EqualsBuilder.reflectionEquals(expected, fileSystem.getTokenProvider()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testRefreshTokenWithCredentialProviderFallback",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testRefreshTokenWithCredentialProviderFallback() throws IOException, URISyntaxException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(AZURE_AD_CLIENT_ID_KEY, CLIENT_ID);\r\n    conf.set(AZURE_AD_REFRESH_TOKEN_KEY, REFRESH_TOKEN);\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, RefreshToken);\r\n    createTempCredProvider(conf);\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    RefreshTokenBasedTokenProvider expected = new RefreshTokenBasedTokenProvider(CLIENT_ID, REFRESH_TOKEN);\r\n    Assert.assertTrue(EqualsBuilder.reflectionEquals(expected, fileSystem.getTokenProvider()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testClientCredWithCredentialProvider",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testClientCredWithCredentialProvider() throws IOException, URISyntaxException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(AZURE_AD_CLIENT_ID_KEY, \"DUMMY\");\r\n    conf.set(AZURE_AD_CLIENT_SECRET_KEY, \"DUMMY\");\r\n    conf.set(AZURE_AD_REFRESH_URL_KEY, \"DUMMY\");\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, ClientCredential);\r\n    CredentialProvider provider = createTempCredProvider(conf);\r\n    provider.createCredentialEntry(AZURE_AD_CLIENT_ID_KEY, CLIENT_ID.toCharArray());\r\n    provider.createCredentialEntry(AZURE_AD_CLIENT_SECRET_KEY, CLIENT_SECRET.toCharArray());\r\n    provider.createCredentialEntry(AZURE_AD_REFRESH_URL_KEY, REFRESH_URL.toCharArray());\r\n    provider.flush();\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    ClientCredsTokenProvider expected = new ClientCredsTokenProvider(REFRESH_URL, CLIENT_ID, CLIENT_SECRET);\r\n    Assert.assertTrue(EqualsBuilder.reflectionEquals(expected, fileSystem.getTokenProvider()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testClientCredWithCredentialProviderFallback",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testClientCredWithCredentialProviderFallback() throws IOException, URISyntaxException\n{\r\n    Configuration conf = new Configuration();\r\n    conf.set(AZURE_AD_CLIENT_ID_KEY, CLIENT_ID);\r\n    conf.set(AZURE_AD_CLIENT_SECRET_KEY, CLIENT_SECRET);\r\n    conf.set(AZURE_AD_REFRESH_URL_KEY, REFRESH_URL);\r\n    conf.setEnum(AZURE_AD_TOKEN_PROVIDER_TYPE_KEY, ClientCredential);\r\n    createTempCredProvider(conf);\r\n    URI uri = new URI(\"adl://localhost:8080\");\r\n    AdlFileSystem fileSystem = new AdlFileSystem();\r\n    fileSystem.initialize(uri, conf);\r\n    ClientCredsTokenProvider expected = new ClientCredsTokenProvider(REFRESH_URL, CLIENT_ID, CLIENT_SECRET);\r\n    Assert.assertTrue(EqualsBuilder.reflectionEquals(expected, fileSystem.getTokenProvider()));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testCredentialProviderPathExclusions",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testCredentialProviderPathExclusions() throws Exception\n{\r\n    String providerPath = \"user:///,jceks://adl/user/hrt_qa/sqoopdbpasswd.jceks,\" + \"jceks://hdfs@nn1.example.com/my/path/test.jceks\";\r\n    Configuration config = new Configuration();\r\n    config.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, providerPath);\r\n    String newPath = \"user:///,jceks://hdfs@nn1.example.com/my/path/test.jceks\";\r\n    excludeAndTestExpectations(config, newPath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "testExcludeAllProviderTypesFromConfig",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testExcludeAllProviderTypesFromConfig() throws Exception\n{\r\n    String providerPath = \"jceks://adl/tmp/test.jceks,\" + \"jceks://adl@/my/path/test.jceks\";\r\n    Configuration config = new Configuration();\r\n    config.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, providerPath);\r\n    String newPath = null;\r\n    excludeAndTestExpectations(config, newPath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl",
  "methodName" : "excludeAndTestExpectations",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void excludeAndTestExpectations(Configuration config, String newPath) throws Exception\n{\r\n    Configuration conf = ProviderUtils.excludeIncompatibleCredentialProviders(config, AdlFileSystem.class);\r\n    String effectivePath = conf.get(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, null);\r\n    assertEquals(newPath, effectivePath);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "getScheme",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getScheme()\n{\r\n    return \"adl\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "getTestFileSystem",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "FileSystem getTestFileSystem() throws IOException\n{\r\n    return this.fs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "getTestPath",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getTestPath()\n{\r\n    return new Path(\"/test\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-azure-datalake\\src\\test\\java\\org\\apache\\hadoop\\fs\\adl\\live",
  "methodName" : "isEnabled",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isEnabled()\n{\r\n    return AdlStorageConfiguration.isContractTestEnabled();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]