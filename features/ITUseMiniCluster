[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "clusterUp",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void clusterUp() throws IOException\n{\r\n    final Configuration conf = new HdfsConfiguration();\r\n    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();\r\n    cluster.waitActive();\r\n    conf.set(\"yarn.scheduler.capacity.root.queues\", \"default\");\r\n    conf.setInt(\"yarn.scheduler.capacity.root.default.capacity\", 100);\r\n    yarnCluster = new MiniYARNCluster(getClass().getName(), 1, 1, 1, 1);\r\n    yarnCluster.init(conf);\r\n    yarnCluster.start();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "clusterDown",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clusterDown()\n{\r\n    if (cluster != null) {\r\n        cluster.close();\r\n    }\r\n    IOUtils.cleanupWithLogger(LOG, yarnCluster);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "useHdfsFileSystem",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void useHdfsFileSystem() throws IOException\n{\r\n    try (FileSystem fs = cluster.getFileSystem()) {\r\n        simpleReadAfterWrite(fs);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "simpleReadAfterWrite",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void simpleReadAfterWrite(final FileSystem fs) throws IOException\n{\r\n    LOG.info(\"Testing read-after-write with FS implementation: {}\", fs);\r\n    final Path path = new Path(TEST_PATH, FILENAME);\r\n    if (!fs.mkdirs(path.getParent())) {\r\n        throw new IOException(\"Mkdirs failed to create \" + TEST_PATH);\r\n    }\r\n    try (FSDataOutputStream out = fs.create(path)) {\r\n        out.writeUTF(TEXT);\r\n    }\r\n    try (FSDataInputStream in = fs.open(path)) {\r\n        final String result = in.readUTF();\r\n        Assert.assertEquals(\"Didn't read back text we wrote.\", TEXT, result);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "useWebHDFS",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void useWebHDFS() throws IOException, URISyntaxException\n{\r\n    try (FileSystem fs = WebHdfsTestUtil.getWebHdfsFileSystem(cluster.getConfiguration(0), WebHdfsConstants.WEBHDFS_SCHEME)) {\r\n        simpleReadAfterWrite(fs);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "testGzipCodec",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testGzipCodec() throws IOException\n{\r\n    ZlibFactory.setNativeZlibLoaded(false);\r\n    assertFalse(ZlibFactory.isNativeZlibLoaded(haddopConf));\r\n    codecTest(haddopConf, dataSeed, 0, \"org.apache.hadoop.io.compress.GzipCodec\");\r\n    codecTest(haddopConf, dataSeed, dataCount, \"org.apache.hadoop.io.compress.GzipCodec\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "testSnappyCodec",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testSnappyCodec() throws IOException\n{\r\n    codecTest(haddopConf, dataSeed, 0, \"org.apache.hadoop.io.compress.SnappyCodec\");\r\n    codecTest(haddopConf, dataSeed, dataCount, \"org.apache.hadoop.io.compress.SnappyCodec\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "testLz4Codec",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testLz4Codec()\n{\r\n    Arrays.asList(false, true).forEach(config -> {\r\n        haddopConf.setBoolean(CommonConfigurationKeys.IO_COMPRESSION_CODEC_LZ4_USELZ4HC_KEY, config);\r\n        try {\r\n            codecTest(haddopConf, dataSeed, 0, \"org.apache.hadoop.io.compress.Lz4Codec\");\r\n            codecTest(haddopConf, dataSeed, dataCount, \"org.apache.hadoop.io.compress.Lz4Codec\");\r\n        } catch (IOException e) {\r\n            throw new RuntimeException(\"failed when running codecTest\", e);\r\n        }\r\n    });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-client-modules\\hadoop-client-integration-tests\\src\\test\\java\\org\\apache\\hadoop\\example",
  "methodName" : "codecTest",
  "errType" : [ "ClassNotFoundException" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "void codecTest(Configuration conf, int seed, int count, String codecClass) throws IOException\n{\r\n    CompressionCodec codec = null;\r\n    try {\r\n        codec = (CompressionCodec) ReflectionUtils.newInstance(conf.getClassByName(codecClass), conf);\r\n    } catch (ClassNotFoundException cnfe) {\r\n        throw new IOException(\"Illegal codec!\");\r\n    }\r\n    LOG.info(\"Created a Codec object of type: \" + codecClass);\r\n    DataOutputBuffer data = new DataOutputBuffer();\r\n    RandomDatum.Generator generator = new RandomDatum.Generator(seed);\r\n    for (int i = 0; i < count; ++i) {\r\n        generator.next();\r\n        RandomDatum key = generator.getKey();\r\n        RandomDatum value = generator.getValue();\r\n        key.write(data);\r\n        value.write(data);\r\n    }\r\n    LOG.info(\"Generated \" + count + \" records\");\r\n    DataOutputBuffer compressedDataBuffer = new DataOutputBuffer();\r\n    try (CompressionOutputStream deflateFilter = codec.createOutputStream(compressedDataBuffer);\r\n        DataOutputStream deflateOut = new DataOutputStream(new BufferedOutputStream(deflateFilter))) {\r\n        deflateOut.write(data.getData(), 0, data.getLength());\r\n        deflateOut.flush();\r\n        deflateFilter.finish();\r\n    }\r\n    DataInputBuffer deCompressedDataBuffer = new DataInputBuffer();\r\n    deCompressedDataBuffer.reset(compressedDataBuffer.getData(), 0, compressedDataBuffer.getLength());\r\n    DataInputBuffer originalData = new DataInputBuffer();\r\n    originalData.reset(data.getData(), 0, data.getLength());\r\n    try (CompressionInputStream inflateFilter = codec.createInputStream(deCompressedDataBuffer);\r\n        DataInputStream originalIn = new DataInputStream(new BufferedInputStream(originalData))) {\r\n        int expected;\r\n        do {\r\n            expected = originalIn.read();\r\n            assertEquals(\"Inflated stream read by byte does not match\", expected, inflateFilter.read());\r\n        } while (expected != -1);\r\n    }\r\n    LOG.info(\"SUCCESS! Completed checking \" + count + \" records\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : true
} ]