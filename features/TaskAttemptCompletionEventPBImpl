[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptCompletionEventProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptId != null) {\r\n        builder.setAttemptId(convertToProtoFormat(this.taskAttemptId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = TaskAttemptCompletionEventProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getAttemptId()\n{\r\n    TaskAttemptCompletionEventProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptId != null) {\r\n        return this.taskAttemptId;\r\n    }\r\n    if (!p.hasAttemptId()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptId = convertFromProtoFormat(p.getAttemptId());\r\n    return this.taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setAttemptId(TaskAttemptId attemptId)\n{\r\n    maybeInitBuilder();\r\n    if (attemptId == null)\r\n        builder.clearAttemptId();\r\n    this.taskAttemptId = attemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStatus",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptCompletionEventStatus getStatus()\n{\r\n    TaskAttemptCompletionEventProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasStatus()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getStatus());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStatus",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setStatus(TaskAttemptCompletionEventStatus status)\n{\r\n    maybeInitBuilder();\r\n    if (status == null) {\r\n        builder.clearStatus();\r\n        return;\r\n    }\r\n    builder.setStatus(convertToProtoFormat(status));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getMapOutputServerAddress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getMapOutputServerAddress()\n{\r\n    TaskAttemptCompletionEventProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasMapOutputServerAddress()) {\r\n        return null;\r\n    }\r\n    return (p.getMapOutputServerAddress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setMapOutputServerAddress",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setMapOutputServerAddress(String mapOutputServerAddress)\n{\r\n    maybeInitBuilder();\r\n    if (mapOutputServerAddress == null) {\r\n        builder.clearMapOutputServerAddress();\r\n        return;\r\n    }\r\n    builder.setMapOutputServerAddress((mapOutputServerAddress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAttemptRunTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getAttemptRunTime()\n{\r\n    TaskAttemptCompletionEventProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getAttemptRunTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setAttemptRunTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setAttemptRunTime(int attemptRunTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setAttemptRunTime((attemptRunTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getEventId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getEventId()\n{\r\n    TaskAttemptCompletionEventProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getEventId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setEventId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setEventId(int eventId)\n{\r\n    maybeInitBuilder();\r\n    builder.setEventId((eventId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptCompletionEventStatusProto convertToProtoFormat(TaskAttemptCompletionEventStatus e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptCompletionEventStatus convertFromProtoFormat(TaskAttemptCompletionEventStatusProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setup",
  "errType" : [ "InterruptedException", "ExecutionException", "URISyntaxException" ],
  "containingMethodsNum" : 40,
  "sourceCodeText" : "void setup(JobConf conf, JobID jobId) throws IOException\n{\r\n    File workDir = new File(System.getProperty(\"user.dir\"));\r\n    Map<String, LocalResource> localResources = new LinkedHashMap<String, LocalResource>();\r\n    MRApps.setupDistributedCache(conf, localResources);\r\n    Map<String, Path> classpaths = new HashMap<String, Path>();\r\n    Path[] archiveClassPaths = JobContextImpl.getArchiveClassPaths(conf);\r\n    if (archiveClassPaths != null) {\r\n        for (Path p : archiveClassPaths) {\r\n            classpaths.put(p.toUri().getPath().toString(), p);\r\n        }\r\n    }\r\n    Path[] fileClassPaths = JobContextImpl.getFileClassPaths(conf);\r\n    if (fileClassPaths != null) {\r\n        for (Path p : fileClassPaths) {\r\n            classpaths.put(p.toUri().getPath().toString(), p);\r\n        }\r\n    }\r\n    LocalDirAllocator localDirAllocator = new LocalDirAllocator(MRConfig.LOCAL_DIR);\r\n    FileContext localFSFileContext = FileContext.getLocalFSFileContext();\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    ExecutorService exec = null;\r\n    try {\r\n        ThreadFactory tf = new ThreadFactoryBuilder().setNameFormat(\"LocalDistributedCacheManager Downloader #%d\").build();\r\n        exec = HadoopExecutors.newCachedThreadPool(tf);\r\n        Path destPath = localDirAllocator.getLocalPathForWrite(\".\", conf);\r\n        Map<LocalResource, Future<Path>> resourcesToPaths = Maps.newHashMap();\r\n        for (LocalResource resource : localResources.values()) {\r\n            Path destPathForDownload = new Path(destPath, jobId.toString() + \"_\" + UUID.randomUUID().toString());\r\n            Callable<Path> download = new FSDownload(localFSFileContext, ugi, conf, destPathForDownload, resource);\r\n            Future<Path> future = exec.submit(download);\r\n            resourcesToPaths.put(resource, future);\r\n        }\r\n        for (Entry<String, LocalResource> entry : localResources.entrySet()) {\r\n            LocalResource resource = entry.getValue();\r\n            Path path;\r\n            try {\r\n                path = resourcesToPaths.get(resource).get();\r\n            } catch (InterruptedException e) {\r\n                throw new IOException(e);\r\n            } catch (ExecutionException e) {\r\n                throw new IOException(e);\r\n            }\r\n            String pathString = path.toUri().toString();\r\n            String link = entry.getKey();\r\n            String target = new File(path.toUri()).getPath();\r\n            symlink(workDir, target, link);\r\n            if (resource.getType() == LocalResourceType.ARCHIVE) {\r\n                localArchives.add(pathString);\r\n            } else if (resource.getType() == LocalResourceType.FILE) {\r\n                localFiles.add(pathString);\r\n            } else if (resource.getType() == LocalResourceType.PATTERN) {\r\n                throw new IllegalArgumentException(\"Resource type PATTERN is not \" + \"implemented yet. \" + resource.getResource());\r\n            }\r\n            Path resourcePath;\r\n            try {\r\n                resourcePath = resource.getResource().toPath();\r\n            } catch (URISyntaxException e) {\r\n                throw new IOException(e);\r\n            }\r\n            LOG.info(String.format(\"Localized %s as %s\", resourcePath, path));\r\n            String cp = resourcePath.toUri().getPath();\r\n            if (classpaths.keySet().contains(cp)) {\r\n                localClasspaths.add(path.toUri().getPath().toString());\r\n            }\r\n        }\r\n    } finally {\r\n        if (exec != null) {\r\n            exec.shutdown();\r\n        }\r\n    }\r\n    if (!localArchives.isEmpty()) {\r\n        conf.set(MRJobConfig.CACHE_LOCALARCHIVES, StringUtils.arrayToString(localArchives.toArray(new String[localArchives.size()])));\r\n    }\r\n    if (!localFiles.isEmpty()) {\r\n        conf.set(MRJobConfig.CACHE_LOCALFILES, StringUtils.arrayToString(localFiles.toArray(new String[localArchives.size()])));\r\n    }\r\n    setupCalled = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "symlink",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void symlink(File workDir, String target, String link) throws IOException\n{\r\n    if (link != null) {\r\n        link = workDir.toString() + Path.SEPARATOR + link;\r\n        File flink = new File(link);\r\n        if (!flink.exists()) {\r\n            LOG.info(String.format(\"Creating symlink: %s <- %s\", target, link));\r\n            if (0 != FileUtil.symLink(target, link)) {\r\n                LOG.warn(String.format(\"Failed to create symlink: %s <- %s\", target, link));\r\n            } else {\r\n                symlinksCreated.add(new File(link));\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "hasLocalClasspaths",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean hasLocalClasspaths()\n{\r\n    if (!setupCalled) {\r\n        throw new IllegalStateException(\"hasLocalClasspaths() should be called after setup()\");\r\n    }\r\n    return !localClasspaths.isEmpty();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "makeClassLoader",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "ClassLoader makeClassLoader(final ClassLoader parent) throws MalformedURLException\n{\r\n    if (classLoaderCreated != null) {\r\n        throw new IllegalStateException(\"A classloader was already created\");\r\n    }\r\n    final URL[] urls = new URL[localClasspaths.size()];\r\n    for (int i = 0; i < localClasspaths.size(); ++i) {\r\n        urls[i] = new File(localClasspaths.get(i)).toURI().toURL();\r\n        LOG.info(urls[i].toString());\r\n    }\r\n    return AccessController.doPrivileged(new PrivilegedAction<ClassLoader>() {\r\n\r\n        @Override\r\n        public ClassLoader run() {\r\n            classLoaderCreated = new URLClassLoader(urls, parent);\r\n            return classLoaderCreated;\r\n        }\r\n    });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void close() throws IOException\n{\r\n    if (classLoaderCreated != null) {\r\n        AccessController.doPrivileged(new PrivilegedAction<Void>() {\r\n\r\n            @Override\r\n            public Void run() {\r\n                try {\r\n                    classLoaderCreated.close();\r\n                    classLoaderCreated = null;\r\n                } catch (IOException e) {\r\n                    LOG.warn(\"Failed to close classloader created \" + \"by LocalDistributedCacheManager\");\r\n                }\r\n                return null;\r\n            }\r\n        });\r\n    }\r\n    for (File symlink : symlinksCreated) {\r\n        if (!symlink.delete()) {\r\n            LOG.warn(\"Failed to delete symlink created by the local job runner: \" + symlink);\r\n        }\r\n    }\r\n    FileContext localFSFileContext = FileContext.getLocalFSFileContext();\r\n    for (String archive : localArchives) {\r\n        localFSFileContext.delete(new Path(archive), true);\r\n    }\r\n    for (String file : localFiles) {\r\n        localFSFileContext.delete(new Path(file), true);\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptIdProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskId != null && !((TaskIdPBImpl) this.taskId).getProto().equals(builder.getTaskId())) {\r\n        builder.setTaskId(convertToProtoFormat(this.taskId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = TaskAttemptIdProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getId()\n{\r\n    TaskAttemptIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setId(int id)\n{\r\n    maybeInitBuilder();\r\n    builder.setId((id));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskId getTaskId()\n{\r\n    TaskAttemptIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskId != null) {\r\n        return this.taskId;\r\n    }\r\n    if (!p.hasTaskId()) {\r\n        return null;\r\n    }\r\n    taskId = convertFromProtoFormat(p.getTaskId());\r\n    return taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskId(TaskId taskId)\n{\r\n    maybeInitBuilder();\r\n    if (taskId == null)\r\n        builder.clearTaskId();\r\n    this.taskId = taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskIdPBImpl convertFromProtoFormat(TaskIdProto p)\n{\r\n    return new TaskIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskIdProto convertToProtoFormat(TaskId t)\n{\r\n    return ((TaskIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newJobId",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "JobId newJobId(ApplicationId appId, int id)\n{\r\n    JobId jobId = Records.newRecord(JobId.class);\r\n    jobId.setAppId(appId);\r\n    jobId.setId(id);\r\n    return jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId newJobId(long clusterTs, int appIdInt, int id)\n{\r\n    ApplicationId appId = ApplicationId.newInstance(clusterTs, appIdInt);\r\n    return MRBuilderUtils.newJobId(appId, id);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newTaskId",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TaskId newTaskId(JobId jobId, int id, TaskType taskType)\n{\r\n    TaskId taskId = Records.newRecord(TaskId.class);\r\n    taskId.setJobId(jobId);\r\n    taskId.setId(id);\r\n    taskId.setTaskType(taskType);\r\n    return taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TaskAttemptId newTaskAttemptId(TaskId taskId, int attemptId)\n{\r\n    TaskAttemptId taskAttemptId = Records.newRecord(TaskAttemptId.class);\r\n    taskAttemptId.setTaskId(taskId);\r\n    taskAttemptId.setId(attemptId);\r\n    return taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newJobReport",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobReport newJobReport(JobId jobId, String jobName, String userName, JobState state, long submitTime, long startTime, long finishTime, float setupProgress, float mapProgress, float reduceProgress, float cleanupProgress, String jobFile, List<AMInfo> amInfos, boolean isUber, String diagnostics)\n{\r\n    return newJobReport(jobId, jobName, userName, state, submitTime, startTime, finishTime, setupProgress, mapProgress, reduceProgress, cleanupProgress, jobFile, amInfos, isUber, diagnostics, Priority.newInstance(0));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newJobReport",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "JobReport newJobReport(JobId jobId, String jobName, String userName, JobState state, long submitTime, long startTime, long finishTime, float setupProgress, float mapProgress, float reduceProgress, float cleanupProgress, String jobFile, List<AMInfo> amInfos, boolean isUber, String diagnostics, Priority priority)\n{\r\n    JobReport report = Records.newRecord(JobReport.class);\r\n    report.setJobId(jobId);\r\n    report.setJobName(jobName);\r\n    report.setUser(userName);\r\n    report.setJobState(state);\r\n    report.setSubmitTime(submitTime);\r\n    report.setStartTime(startTime);\r\n    report.setFinishTime(finishTime);\r\n    report.setSetupProgress(setupProgress);\r\n    report.setCleanupProgress(cleanupProgress);\r\n    report.setMapProgress(mapProgress);\r\n    report.setReduceProgress(reduceProgress);\r\n    report.setJobFile(jobFile);\r\n    report.setAMInfos(amInfos);\r\n    report.setIsUber(isUber);\r\n    report.setDiagnostics(diagnostics);\r\n    report.setJobPriority(priority);\r\n    return report;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "newAMInfo",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "AMInfo newAMInfo(ApplicationAttemptId appAttemptId, long startTime, ContainerId containerId, String nmHost, int nmPort, int nmHttpPort)\n{\r\n    AMInfo amInfo = Records.newRecord(AMInfo.class);\r\n    amInfo.setAppAttemptId(appAttemptId);\r\n    amInfo.setStartTime(startTime);\r\n    amInfo.setContainerId(containerId);\r\n    amInfo.setNodeManagerHost(nmHost);\r\n    amInfo.setNodeManagerPort(nmPort);\r\n    amInfo.setNodeManagerHttpPort(nmHttpPort);\r\n    return amInfo;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Token getDelegationToken()\n{\r\n    GetDelegationTokenResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.mrToken != null) {\r\n        return this.mrToken;\r\n    }\r\n    if (!p.hasToken()) {\r\n        return null;\r\n    }\r\n    this.mrToken = convertFromProtoFormat(p.getToken());\r\n    return this.mrToken;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setDelegationToken(Token mrToken)\n{\r\n    maybeInitBuilder();\r\n    if (mrToken == null)\r\n        builder.getToken();\r\n    this.mrToken = mrToken;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDelegationTokenResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (mrToken != null) {\r\n        builder.setToken(convertToProtoFormat(this.mrToken));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetDelegationTokenResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TokenPBImpl convertFromProtoFormat(TokenProto p)\n{\r\n    return new TokenPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TokenProto convertToProtoFormat(Token t)\n{\r\n    return ((TokenPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "KillTaskRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskId != null) {\r\n        builder.setTaskId(convertToProtoFormat(this.taskId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = KillTaskRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskId getTaskId()\n{\r\n    KillTaskRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskId != null) {\r\n        return this.taskId;\r\n    }\r\n    if (!p.hasTaskId()) {\r\n        return null;\r\n    }\r\n    this.taskId = convertFromProtoFormat(p.getTaskId());\r\n    return this.taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskId(TaskId taskId)\n{\r\n    maybeInitBuilder();\r\n    if (taskId == null)\r\n        builder.clearTaskId();\r\n    this.taskId = taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskIdPBImpl convertFromProtoFormat(TaskIdProto p)\n{\r\n    return new TaskIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskIdProto convertToProtoFormat(TaskId t)\n{\r\n    return ((TaskIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetCountersResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.counters != null) {\r\n        builder.setCounters(convertToProtoFormat(this.counters));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetCountersResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Counters getCounters()\n{\r\n    GetCountersResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.counters != null) {\r\n        return this.counters;\r\n    }\r\n    if (!p.hasCounters()) {\r\n        return null;\r\n    }\r\n    this.counters = convertFromProtoFormat(p.getCounters());\r\n    return this.counters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCounters(Counters counters)\n{\r\n    maybeInitBuilder();\r\n    if (counters == null)\r\n        builder.clearCounters();\r\n    this.counters = counters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CountersPBImpl convertFromProtoFormat(CountersProto p)\n{\r\n    return new CountersPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "CountersProto convertToProtoFormat(Counters t)\n{\r\n    return ((CountersPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getAppId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ApplicationId getAppId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setAppId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setAppId(ApplicationId appId)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setId(int id)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder builder = new StringBuilder(JOB);\r\n    builder.append(SEPARATOR);\r\n    builder.append(getAppId().getClusterTimestamp());\r\n    builder.append(SEPARATOR);\r\n    builder.append(jobIdFormat.get().format(getId()));\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int hashCode()\n{\r\n    final int prime = 31;\r\n    int result = 1;\r\n    result = prime * result + getAppId().hashCode();\r\n    result = prime * result + getId();\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean equals(Object obj)\n{\r\n    if (this == obj)\r\n        return true;\r\n    if (obj == null)\r\n        return false;\r\n    if (getClass() != obj.getClass())\r\n        return false;\r\n    JobId other = (JobId) obj;\r\n    if (!this.getAppId().equals(other.getAppId()))\r\n        return false;\r\n    if (this.getId() != other.getId())\r\n        return false;\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int compareTo(JobId other)\n{\r\n    int appIdComp = this.getAppId().compareTo(other.getAppId());\r\n    if (appIdComp == 0) {\r\n        return this.getId() - other.getId();\r\n    } else {\r\n        return appIdComp;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getDoneFileName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getDoneFileName(JobIndexInfo indexInfo) throws IOException\n{\r\n    return getDoneFileName(indexInfo, JHAdminConfig.DEFAULT_MR_HS_JOBNAME_LIMIT);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getDoneFileName",
  "errType" : null,
  "containingMethodsNum" : 21,
  "sourceCodeText" : "String getDoneFileName(JobIndexInfo indexInfo, int jobNameLimit) throws IOException\n{\r\n    StringBuilder sb = new StringBuilder();\r\n    sb.append(encodeJobHistoryFileName(escapeDelimiters(TypeConverter.fromYarn(indexInfo.getJobId()).toString())));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(String.valueOf(indexInfo.getSubmitTime())));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(escapeDelimiters(getUserName(indexInfo))));\r\n    sb.append(DELIMITER);\r\n    sb.append(trimURLEncodedString(encodeJobHistoryFileName(escapeDelimiters(getJobName(indexInfo))), jobNameLimit));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(String.valueOf(indexInfo.getFinishTime())));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(String.valueOf(indexInfo.getNumMaps())));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(String.valueOf(indexInfo.getNumReduces())));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(indexInfo.getJobStatus()));\r\n    sb.append(DELIMITER);\r\n    sb.append(escapeDelimiters(encodeJobHistoryFileName(getQueueName(indexInfo))));\r\n    sb.append(DELIMITER);\r\n    sb.append(encodeJobHistoryFileName(String.valueOf(indexInfo.getJobStartTime())));\r\n    sb.append(encodeJobHistoryFileName(JobHistoryUtils.JOB_HISTORY_FILE_EXTENSION));\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getIndexInfo",
  "errType" : [ "IndexOutOfBoundsException", "NumberFormatException", "NumberFormatException", "NumberFormatException", "NumberFormatException", "NumberFormatException" ],
  "containingMethodsNum" : 21,
  "sourceCodeText" : "JobIndexInfo getIndexInfo(String jhFileName) throws IOException\n{\r\n    String fileName = jhFileName.substring(0, jhFileName.indexOf(JobHistoryUtils.JOB_HISTORY_FILE_EXTENSION));\r\n    JobIndexInfo indexInfo = new JobIndexInfo();\r\n    String[] jobDetails = fileName.split(DELIMITER);\r\n    JobID oldJobId = JobID.forName(decodeJobHistoryFileName(jobDetails[JOB_ID_INDEX]));\r\n    JobId jobId = TypeConverter.toYarn(oldJobId);\r\n    indexInfo.setJobId(jobId);\r\n    try {\r\n        try {\r\n            indexInfo.setSubmitTime(Long.parseLong(decodeJobHistoryFileName(jobDetails[SUBMIT_TIME_INDEX])));\r\n        } catch (NumberFormatException e) {\r\n            LOG.warn(\"Unable to parse submit time from job history file \" + jhFileName + \" : \" + e);\r\n        }\r\n        indexInfo.setUser(decodeJobHistoryFileName(jobDetails[USER_INDEX]));\r\n        indexInfo.setJobName(decodeJobHistoryFileName(jobDetails[JOB_NAME_INDEX]));\r\n        try {\r\n            indexInfo.setFinishTime(Long.parseLong(decodeJobHistoryFileName(jobDetails[FINISH_TIME_INDEX])));\r\n        } catch (NumberFormatException e) {\r\n            LOG.warn(\"Unable to parse finish time from job history file \" + jhFileName + \" : \" + e);\r\n        }\r\n        try {\r\n            indexInfo.setNumMaps(Integer.parseInt(decodeJobHistoryFileName(jobDetails[NUM_MAPS_INDEX])));\r\n        } catch (NumberFormatException e) {\r\n            LOG.warn(\"Unable to parse num maps from job history file \" + jhFileName + \" : \" + e);\r\n        }\r\n        try {\r\n            indexInfo.setNumReduces(Integer.parseInt(decodeJobHistoryFileName(jobDetails[NUM_REDUCES_INDEX])));\r\n        } catch (NumberFormatException e) {\r\n            LOG.warn(\"Unable to parse num reduces from job history file \" + jhFileName + \" : \" + e);\r\n        }\r\n        indexInfo.setJobStatus(decodeJobHistoryFileName(jobDetails[JOB_STATUS_INDEX]));\r\n        indexInfo.setQueueName(decodeJobHistoryFileName(jobDetails[QUEUE_NAME_INDEX]));\r\n        try {\r\n            if (jobDetails.length <= JOB_START_TIME_INDEX) {\r\n                indexInfo.setJobStartTime(indexInfo.getSubmitTime());\r\n            } else {\r\n                indexInfo.setJobStartTime(Long.parseLong(decodeJobHistoryFileName(jobDetails[JOB_START_TIME_INDEX])));\r\n            }\r\n        } catch (NumberFormatException e) {\r\n            LOG.warn(\"Unable to parse start time from job history file \" + jhFileName + \" : \" + e);\r\n        }\r\n    } catch (IndexOutOfBoundsException e) {\r\n        LOG.warn(\"Parsing job history file with partial data encoded into name: \" + jhFileName);\r\n    }\r\n    return indexInfo;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 6,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "encodeJobHistoryFileName",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 7,
  "sourceCodeText" : "String encodeJobHistoryFileName(String logFileName) throws IOException\n{\r\n    String replacementDelimiterEscape = null;\r\n    if (logFileName.contains(DELIMITER_ESCAPE)) {\r\n        replacementDelimiterEscape = nonOccursString(logFileName);\r\n        logFileName = logFileName.replaceAll(DELIMITER_ESCAPE, replacementDelimiterEscape);\r\n    }\r\n    String encodedFileName = null;\r\n    try {\r\n        encodedFileName = URLEncoder.encode(logFileName, \"UTF-8\");\r\n    } catch (UnsupportedEncodingException uee) {\r\n        IOException ioe = new IOException();\r\n        ioe.initCause(uee);\r\n        ioe.setStackTrace(uee.getStackTrace());\r\n        throw ioe;\r\n    }\r\n    if (replacementDelimiterEscape != null) {\r\n        encodedFileName = encodedFileName.replaceAll(replacementDelimiterEscape, DELIMITER_ESCAPE);\r\n    }\r\n    return encodedFileName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "decodeJobHistoryFileName",
  "errType" : [ "UnsupportedEncodingException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String decodeJobHistoryFileName(String logFileName) throws IOException\n{\r\n    String decodedFileName = null;\r\n    try {\r\n        decodedFileName = URLDecoder.decode(logFileName, \"UTF-8\");\r\n    } catch (UnsupportedEncodingException uee) {\r\n        IOException ioe = new IOException();\r\n        ioe.initCause(uee);\r\n        ioe.setStackTrace(uee.getStackTrace());\r\n        throw ioe;\r\n    }\r\n    return decodedFileName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "nonOccursString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String nonOccursString(String logFileName)\n{\r\n    int adHocIndex = 0;\r\n    String unfoundString = \"q\" + adHocIndex;\r\n    while (logFileName.contains(unfoundString)) {\r\n        unfoundString = \"q\" + ++adHocIndex;\r\n    }\r\n    return unfoundString + \"q\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getUserName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getUserName(JobIndexInfo indexInfo)\n{\r\n    return getNonEmptyString(indexInfo.getUser());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getJobName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJobName(JobIndexInfo indexInfo)\n{\r\n    return getNonEmptyString(indexInfo.getJobName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getQueueName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getQueueName(JobIndexInfo indexInfo)\n{\r\n    return getNonEmptyString(indexInfo.getQueueName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getNonEmptyString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getNonEmptyString(String in)\n{\r\n    if (in == null || in.length() == 0) {\r\n        in = \"NA\";\r\n    }\r\n    return in;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "escapeDelimiters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String escapeDelimiters(String escapee)\n{\r\n    return escapee.replaceAll(DELIMITER, DELIMITER_ESCAPE);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "trimURLEncodedString",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "String trimURLEncodedString(String encodedString, int limitLength)\n{\r\n    assert (limitLength >= 0) : \"limitLength should be positive integer\";\r\n    if (encodedString.length() <= limitLength) {\r\n        return encodedString;\r\n    }\r\n    int index = 0;\r\n    int increase = 0;\r\n    byte[] strBytes = encodedString.getBytes(UTF_8);\r\n    while (true) {\r\n        byte b = strBytes[index];\r\n        if (b == '%') {\r\n            byte minuend1 = strBytes[index + 1];\r\n            byte subtrahend1 = (byte) (Character.isDigit(minuend1) ? '0' : 'A' - 10);\r\n            byte minuend2 = strBytes[index + 2];\r\n            byte subtrahend2 = (byte) (Character.isDigit(minuend2) ? '0' : 'A' - 10);\r\n            int initialHex = ((Character.toUpperCase(minuend1) - subtrahend1) << 4) + (Character.toUpperCase(minuend2) - subtrahend2);\r\n            if (0x00 <= initialHex && initialHex <= 0x7F) {\r\n                increase = 3;\r\n            } else if (0xC2 <= initialHex && initialHex <= 0xDF) {\r\n                increase = 6;\r\n            } else if (0xE0 <= initialHex && initialHex <= 0xEF) {\r\n                increase = 9;\r\n            } else {\r\n                increase = 12;\r\n            }\r\n        } else {\r\n            increase = 1;\r\n        }\r\n        if (index + increase > limitLength) {\r\n            break;\r\n        } else {\r\n            index += increase;\r\n        }\r\n    }\r\n    return encodedString.substring(0, index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobIdProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.applicationId != null && !((ApplicationIdPBImpl) this.applicationId).getProto().equals(builder.getAppId())) {\r\n        builder.setAppId(convertToProtoFormat(this.applicationId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = JobIdProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAppId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ApplicationId getAppId()\n{\r\n    JobIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (applicationId != null) {\r\n        return applicationId;\r\n    }\r\n    if (!p.hasAppId()) {\r\n        return null;\r\n    }\r\n    applicationId = convertFromProtoFormat(p.getAppId());\r\n    return applicationId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setAppId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setAppId(ApplicationId appId)\n{\r\n    maybeInitBuilder();\r\n    if (appId == null) {\r\n        builder.clearAppId();\r\n    }\r\n    this.applicationId = appId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getId()\n{\r\n    JobIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setId(int id)\n{\r\n    maybeInitBuilder();\r\n    builder.setId((id));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ApplicationIdPBImpl convertFromProtoFormat(ApplicationIdProto p)\n{\r\n    return new ApplicationIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ApplicationIdProto convertToProtoFormat(ApplicationId t)\n{\r\n    return ((ApplicationIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KillTaskResponseProto getProto()\n{\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = KillTaskResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptReportRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptId != null) {\r\n        builder.setTaskAttemptId(convertToProtoFormat(this.taskAttemptId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskAttemptReportRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getTaskAttemptId()\n{\r\n    GetTaskAttemptReportRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptId != null) {\r\n        return this.taskAttemptId;\r\n    }\r\n    if (!p.hasTaskAttemptId()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptId = convertFromProtoFormat(p.getTaskAttemptId());\r\n    return this.taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskAttemptId(TaskAttemptId taskAttemptId)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptId == null)\r\n        builder.clearTaskAttemptId();\r\n    this.taskAttemptId = taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "KillJobRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = KillJobRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    KillJobRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    this.jobId = convertFromProtoFormat(p.getJobId());\r\n    return this.jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportsRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskReportsRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    GetTaskReportsRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    this.jobId = convertFromProtoFormat(p.getJobId());\r\n    return this.jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskType",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskType getTaskType()\n{\r\n    GetTaskReportsRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasTaskType()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getTaskType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskType",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setTaskType(TaskType taskType)\n{\r\n    maybeInitBuilder();\r\n    if (taskType == null) {\r\n        builder.clearTaskType();\r\n        return;\r\n    }\r\n    builder.setTaskType(convertToProtoFormat(taskType));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTypeProto convertToProtoFormat(TaskType e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskType convertFromProtoFormat(TaskTypeProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KillTaskAttemptResponseProto getProto()\n{\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = KillTaskAttemptResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskReport != null) {\r\n        builder.setTaskReport(convertToProtoFormat(this.taskReport));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskReportResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskReport getTaskReport()\n{\r\n    GetTaskReportResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskReport != null) {\r\n        return this.taskReport;\r\n    }\r\n    if (!p.hasTaskReport()) {\r\n        return null;\r\n    }\r\n    this.taskReport = convertFromProtoFormat(p.getTaskReport());\r\n    return this.taskReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskReport(TaskReport taskReport)\n{\r\n    maybeInitBuilder();\r\n    if (taskReport == null)\r\n        builder.clearTaskReport();\r\n    this.taskReport = taskReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskReportPBImpl convertFromProtoFormat(TaskReportProto p)\n{\r\n    return new TaskReportPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskReportProto convertToProtoFormat(TaskReport t)\n{\r\n    return ((TaskReportPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Token getDelegationToken()\n{\r\n    CancelDelegationTokenRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.token != null) {\r\n        return this.token;\r\n    }\r\n    this.token = convertFromProtoFormat(p.getToken());\r\n    return this.token;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setDelegationToken(Token token)\n{\r\n    maybeInitBuilder();\r\n    if (token == null)\r\n        builder.clearToken();\r\n    this.token = token;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "CancelDelegationTokenRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (token != null) {\r\n        builder.setToken(convertToProtoFormat(this.token));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = CancelDelegationTokenRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TokenPBImpl convertFromProtoFormat(TokenProto p)\n{\r\n    return new TokenPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TokenProto convertToProtoFormat(Token t)\n{\r\n    return ((TokenPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportsResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskReports != null) {\r\n        addTaskReportsToProto();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskReportsResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskReportList",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<TaskReport> getTaskReportList()\n{\r\n    initTaskReports();\r\n    return this.taskReports;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskReport getTaskReport(int index)\n{\r\n    initTaskReports();\r\n    return this.taskReports.get(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskReportCount",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getTaskReportCount()\n{\r\n    initTaskReports();\r\n    return this.taskReports.size();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "initTaskReports",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initTaskReports()\n{\r\n    if (this.taskReports != null) {\r\n        return;\r\n    }\r\n    GetTaskReportsResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<TaskReportProto> list = p.getTaskReportsList();\r\n    this.taskReports = new ArrayList<TaskReport>();\r\n    for (TaskReportProto c : list) {\r\n        this.taskReports.add(convertFromProtoFormat(c));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addAllTaskReports",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllTaskReports(final List<TaskReport> taskReports)\n{\r\n    if (taskReports == null)\r\n        return;\r\n    initTaskReports();\r\n    this.taskReports.addAll(taskReports);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addTaskReportsToProto",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void addTaskReportsToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearTaskReports();\r\n    if (taskReports == null)\r\n        return;\r\n    Iterable<TaskReportProto> iterable = new Iterable<TaskReportProto>() {\r\n\r\n        @Override\r\n        public Iterator<TaskReportProto> iterator() {\r\n            return new Iterator<TaskReportProto>() {\r\n\r\n                Iterator<TaskReport> iter = taskReports.iterator();\r\n\r\n                @Override\r\n                public boolean hasNext() {\r\n                    return iter.hasNext();\r\n                }\r\n\r\n                @Override\r\n                public TaskReportProto next() {\r\n                    return convertToProtoFormat(iter.next());\r\n                }\r\n\r\n                @Override\r\n                public void remove() {\r\n                    throw new UnsupportedOperationException();\r\n                }\r\n            };\r\n        }\r\n    };\r\n    builder.addAllTaskReports(iterable);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addTaskReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addTaskReport(TaskReport taskReports)\n{\r\n    initTaskReports();\r\n    this.taskReports.add(taskReports);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "removeTaskReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeTaskReport(int index)\n{\r\n    initTaskReports();\r\n    this.taskReports.remove(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "clearTaskReports",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearTaskReports()\n{\r\n    initTaskReports();\r\n    this.taskReports.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskReportPBImpl convertFromProtoFormat(TaskReportProto p)\n{\r\n    return new TaskReportPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskReportProto convertToProtoFormat(TaskReport t)\n{\r\n    return ((TaskReportPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "RenewDelegationTokenResponseProto getProto()\n{\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = RenewDelegationTokenResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getNextExpirationTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getNextExpirationTime()\n{\r\n    RenewDelegationTokenResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    return p.getNewExpiryTime();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setNextExpirationTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setNextExpirationTime(long expTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setNewExpiryTime(expTime);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDiagnosticsResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.diagnostics != null) {\r\n        addDiagnosticsToProto();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetDiagnosticsResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getDiagnosticsList",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> getDiagnosticsList()\n{\r\n    initDiagnostics();\r\n    return this.diagnostics;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getDiagnostics(int index)\n{\r\n    initDiagnostics();\r\n    return this.diagnostics.get(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getDiagnosticsCount",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getDiagnosticsCount()\n{\r\n    initDiagnostics();\r\n    return this.diagnostics.size();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "initDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initDiagnostics()\n{\r\n    if (this.diagnostics != null) {\r\n        return;\r\n    }\r\n    GetDiagnosticsResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<String> list = p.getDiagnosticsList();\r\n    this.diagnostics = new ArrayList<String>();\r\n    for (String c : list) {\r\n        this.diagnostics.add(c);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addAllDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllDiagnostics(final List<String> diagnostics)\n{\r\n    if (diagnostics == null)\r\n        return;\r\n    initDiagnostics();\r\n    this.diagnostics.addAll(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addDiagnosticsToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addDiagnosticsToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearDiagnostics();\r\n    if (diagnostics == null)\r\n        return;\r\n    builder.addAllDiagnostics(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addDiagnostics(String diagnostics)\n{\r\n    initDiagnostics();\r\n    this.diagnostics.add(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "removeDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeDiagnostics(int index)\n{\r\n    initDiagnostics();\r\n    this.diagnostics.remove(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "clearDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearDiagnostics()\n{\r\n    initDiagnostics();\r\n    this.diagnostics.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api",
  "methodName" : "getKind",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Text getKind()\n{\r\n    return KIND_NAME;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetCountersRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetCountersRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    GetCountersRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    this.jobId = convertFromProtoFormat(p.getJobId());\r\n    return this.jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskIdProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null && !((JobIdPBImpl) this.jobId).getProto().equals(builder.getJobId())) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = TaskIdProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getId()\n{\r\n    TaskIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setId(int id)\n{\r\n    maybeInitBuilder();\r\n    builder.setId((id));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    TaskIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    jobId = convertFromProtoFormat(p.getJobId());\r\n    return jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTaskType",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskType getTaskType()\n{\r\n    TaskIdProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasTaskType()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getTaskType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTaskType",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setTaskType(TaskType taskType)\n{\r\n    maybeInitBuilder();\r\n    if (taskType == null) {\r\n        builder.clearTaskType();\r\n        return;\r\n    }\r\n    builder.setTaskType(convertToProtoFormat(taskType));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTypeProto convertToProtoFormat(TaskType e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskType convertFromProtoFormat(TaskTypeProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getSubmitTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getSubmitTime()\n{\r\n    return submitTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setSubmitTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setSubmitTime(long submitTime)\n{\r\n    this.submitTime = submitTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getFinishTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getFinishTime()\n{\r\n    return finishTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setFinishTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setFinishTime(long finishTime)\n{\r\n    this.finishTime = finishTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getUser",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getUser()\n{\r\n    return user;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setUser",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setUser(String user)\n{\r\n    this.user = user;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getQueueName",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getQueueName()\n{\r\n    return queueName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setQueueName",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setQueueName(String queueName)\n{\r\n    this.queueName = queueName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getJobName",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getJobName()\n{\r\n    return jobName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setJobName",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobName(String jobName)\n{\r\n    this.jobName = jobName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    return jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getNumMaps",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumMaps()\n{\r\n    return numMaps;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setNumMaps",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setNumMaps(int numMaps)\n{\r\n    this.numMaps = numMaps;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getNumReduces",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getNumReduces()\n{\r\n    return numReduces;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setNumReduces",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setNumReduces(int numReduces)\n{\r\n    this.numReduces = numReduces;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getJobStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getJobStatus()\n{\r\n    return jobStatus;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setJobStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobStatus(String jobStatus)\n{\r\n    this.jobStatus = jobStatus;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getJobStartTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getJobStartTime()\n{\r\n    return jobStartTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "setJobStartTime",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobStartTime(long lTime)\n{\r\n    this.jobStartTime = lTime;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String toString()\n{\r\n    return \"JobIndexInfo [submitTime=\" + submitTime + \", finishTime=\" + finishTime + \", user=\" + user + \", jobName=\" + jobName + \", jobId=\" + jobId + \", numMaps=\" + numMaps + \", numReduces=\" + numReduces + \", jobStatus=\" + jobStatus + \"]\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setConf",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setConf(Configuration c)\n{\r\n    this.conf = c;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setType",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setType(LocalResourceType t)\n{\r\n    this.type = t;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setUris",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setUris(URI[] u)\n{\r\n    this.uris = u;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setTimestamps",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTimestamps(long[] t)\n{\r\n    this.timestamps = t;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setSizes",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setSizes(long[] s)\n{\r\n    this.sizes = s;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setVisibilities",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setVisibilities(boolean[] v)\n{\r\n    this.visibilities = v;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setSharedCacheUploadPolicies",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setSharedCacheUploadPolicies(Map<String, Boolean> policies)\n{\r\n    this.sharedCacheUploadPolicies = policies;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "createLocalResources",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void createLocalResources(Map<String, LocalResource> localResources) throws IOException\n{\r\n    if (uris != null) {\r\n        if ((uris.length != timestamps.length) || (uris.length != sizes.length) || (uris.length != visibilities.length)) {\r\n            throw new IllegalArgumentException(\"Invalid specification for \" + \"distributed-cache artifacts of type \" + type + \" :\" + \" #uris=\" + uris.length + \" #timestamps=\" + timestamps.length + \" #visibilities=\" + visibilities.length);\r\n        }\r\n        for (int i = 0; i < uris.length; ++i) {\r\n            URI u = uris[i];\r\n            Path p = new Path(u);\r\n            FileSystem remoteFS = p.getFileSystem(conf);\r\n            String linkName = null;\r\n            if (p.getName().equals(DistributedCache.WILDCARD)) {\r\n                p = p.getParent();\r\n                linkName = p.getName() + Path.SEPARATOR + DistributedCache.WILDCARD;\r\n            }\r\n            p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory()));\r\n            if (linkName == null) {\r\n                linkName = u.getFragment();\r\n                if (linkName != null) {\r\n                    Path linkPath = new Path(linkName);\r\n                    if (linkPath.isAbsolute()) {\r\n                        throw new IllegalArgumentException(\"Resource name must be \" + \"relative\");\r\n                    }\r\n                    linkName = linkPath.toUri().getPath();\r\n                }\r\n            } else if (u.getFragment() != null) {\r\n                throw new IllegalArgumentException(\"Invalid path URI: \" + p + \" - cannot contain both a URI fragment and a wildcard\");\r\n            }\r\n            if (linkName == null) {\r\n                linkName = p.getName();\r\n            }\r\n            LocalResource orig = localResources.get(linkName);\r\n            if (orig != null && !orig.getResource().equals(URL.fromURI(p.toUri()))) {\r\n                LOG.warn(getResourceDescription(orig.getType()) + orig.getResource() + \" conflicts with \" + getResourceDescription(type) + u);\r\n                continue;\r\n            }\r\n            Boolean sharedCachePolicy = sharedCacheUploadPolicies.get(u.toString());\r\n            sharedCachePolicy = sharedCachePolicy == null ? Boolean.FALSE : sharedCachePolicy;\r\n            localResources.put(linkName, LocalResource.newInstance(URL.fromURI(p.toUri()), type, visibilities[i] ? LocalResourceVisibility.PUBLIC : LocalResourceVisibility.PRIVATE, sizes[i], timestamps[i], sharedCachePolicy));\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getResourceDescription",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getResourceDescription(LocalResourceType type)\n{\r\n    if (type == LocalResourceType.ARCHIVE || type == LocalResourceType.PATTERN) {\r\n        return \"cache archive (\" + MRJobConfig.CACHE_ARCHIVES + \") \";\r\n    }\r\n    return \"cache file (\" + MRJobConfig.CACHE_FILES + \") \";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "CounterProto getProto()\n{\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = CounterProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getName()\n{\r\n    CounterProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasName()) {\r\n        return null;\r\n    }\r\n    return (p.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setName",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setName(String name)\n{\r\n    maybeInitBuilder();\r\n    if (name == null) {\r\n        builder.clearName();\r\n        return;\r\n    }\r\n    builder.setName((name));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getValue()\n{\r\n    CounterProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getValue());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setValue",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setValue(long value)\n{\r\n    maybeInitBuilder();\r\n    builder.setValue((value));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDisplayName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getDisplayName()\n{\r\n    CounterProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasDisplayName()) {\r\n        return null;\r\n    }\r\n    return (p.getDisplayName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setDisplayName",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setDisplayName(String displayName)\n{\r\n    maybeInitBuilder();\r\n    if (displayName == null) {\r\n        builder.clearDisplayName();\r\n        return;\r\n    }\r\n    builder.setDisplayName((displayName));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetJobReportResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobReport != null) {\r\n        builder.setJobReport(convertToProtoFormat(this.jobReport));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetJobReportResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getJobReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobReport getJobReport()\n{\r\n    GetJobReportResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobReport != null) {\r\n        return this.jobReport;\r\n    }\r\n    if (!p.hasJobReport()) {\r\n        return null;\r\n    }\r\n    this.jobReport = convertFromProtoFormat(p.getJobReport());\r\n    return this.jobReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setJobReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobReport(JobReport jobReport)\n{\r\n    maybeInitBuilder();\r\n    if (jobReport == null)\r\n        builder.clearJobReport();\r\n    this.jobReport = jobReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobReportPBImpl convertFromProtoFormat(JobReportProto p)\n{\r\n    return new JobReportPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobReportProto convertToProtoFormat(JobReport t)\n{\r\n    return ((JobReportPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "FailTaskAttemptRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptId != null) {\r\n        builder.setTaskAttemptId(convertToProtoFormat(this.taskAttemptId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = FailTaskAttemptRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getTaskAttemptId()\n{\r\n    FailTaskAttemptRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptId != null) {\r\n        return this.taskAttemptId;\r\n    }\r\n    if (!p.hasTaskAttemptId()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptId = convertFromProtoFormat(p.getTaskAttemptId());\r\n    return this.taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskAttemptId(TaskAttemptId taskAttemptId)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptId == null)\r\n        builder.clearTaskAttemptId();\r\n    this.taskAttemptId = taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptReportResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptReport != null) {\r\n        builder.setTaskAttemptReport(convertToProtoFormat(this.taskAttemptReport));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskAttemptReportResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskAttemptReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptReport getTaskAttemptReport()\n{\r\n    GetTaskAttemptReportResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptReport != null) {\r\n        return this.taskAttemptReport;\r\n    }\r\n    if (!p.hasTaskAttemptReport()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptReport = convertFromProtoFormat(p.getTaskAttemptReport());\r\n    return this.taskAttemptReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskAttemptReport",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskAttemptReport(TaskAttemptReport taskAttemptReport)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptReport == null)\r\n        builder.clearTaskAttemptReport();\r\n    this.taskAttemptReport = taskAttemptReport;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptReportPBImpl convertFromProtoFormat(TaskAttemptReportProto p)\n{\r\n    return new TaskAttemptReportPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptReportProto convertToProtoFormat(TaskAttemptReport t)\n{\r\n    return ((TaskAttemptReportPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security\\client",
  "methodName" : "getKerberosInfo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KerberosInfo getKerberosInfo(Class<?> protocol, Configuration conf)\n{\r\n    if (!protocol.equals(HSClientProtocolPB.class)) {\r\n        return null;\r\n    }\r\n    return new KerberosInfo() {\r\n\r\n        @Override\r\n        public Class<? extends Annotation> annotationType() {\r\n            return null;\r\n        }\r\n\r\n        @Override\r\n        public String serverPrincipal() {\r\n            return JHAdminConfig.MR_HISTORY_PRINCIPAL;\r\n        }\r\n\r\n        @Override\r\n        public String clientPrincipal() {\r\n            return null;\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security\\client",
  "methodName" : "getTokenInfo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TokenInfo getTokenInfo(Class<?> protocol, Configuration conf)\n{\r\n    if (!protocol.equals(HSClientProtocolPB.class)) {\r\n        return null;\r\n    }\r\n    return new TokenInfo() {\r\n\r\n        @Override\r\n        public Class<? extends Annotation> annotationType() {\r\n            return null;\r\n        }\r\n\r\n        @Override\r\n        public Class<? extends TokenSelector<? extends TokenIdentifier>> value() {\r\n            return ClientHSTokenSelector.class;\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptReportProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptId != null) {\r\n        builder.setTaskAttemptId(convertToProtoFormat(this.taskAttemptId));\r\n    }\r\n    convertRawCountersToCounters();\r\n    if (this.counters != null) {\r\n        builder.setCounters(convertToProtoFormat(this.counters));\r\n    }\r\n    if (this.containerId != null) {\r\n        builder.setContainerId(convertToProtoFormat(this.containerId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = TaskAttemptReportProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getCounters",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Counters getCounters()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    convertRawCountersToCounters();\r\n    if (this.counters != null) {\r\n        return this.counters;\r\n    }\r\n    if (!p.hasCounters()) {\r\n        return null;\r\n    }\r\n    this.counters = convertFromProtoFormat(p.getCounters());\r\n    return this.counters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCounters(Counters counters)\n{\r\n    maybeInitBuilder();\r\n    if (counters == null) {\r\n        builder.clearCounters();\r\n    }\r\n    this.counters = counters;\r\n    this.rawCounters = null;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getRawCounters",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.Counters getRawCounters()\n{\r\n    return this.rawCounters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setRawCounters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setRawCounters(org.apache.hadoop.mapreduce.Counters rCounters)\n{\r\n    setCounters(null);\r\n    this.rawCounters = rCounters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertRawCountersToCounters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void convertRawCountersToCounters()\n{\r\n    if (this.counters == null && this.rawCounters != null) {\r\n        this.counters = TypeConverter.toYarn(rawCounters);\r\n        this.rawCounters = null;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStartTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getStartTime()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getStartTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStartTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setStartTime(long startTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setStartTime((startTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getFinishTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getFinishTime()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getFinishTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setFinishTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setFinishTime(long finishTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setFinishTime((finishTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getShuffleFinishTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getShuffleFinishTime()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getShuffleFinishTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setShuffleFinishTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setShuffleFinishTime(long time)\n{\r\n    maybeInitBuilder();\r\n    builder.setShuffleFinishTime(time);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getSortFinishTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getSortFinishTime()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getSortFinishTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setSortFinishTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setSortFinishTime(long time)\n{\r\n    maybeInitBuilder();\r\n    builder.setSortFinishTime(time);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getTaskAttemptId()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptId != null) {\r\n        return this.taskAttemptId;\r\n    }\r\n    if (!p.hasTaskAttemptId()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptId = convertFromProtoFormat(p.getTaskAttemptId());\r\n    return this.taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskAttemptId(TaskAttemptId taskAttemptId)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptId == null)\r\n        builder.clearTaskAttemptId();\r\n    this.taskAttemptId = taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTaskAttemptState",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptState getTaskAttemptState()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasTaskAttemptState()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getTaskAttemptState());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTaskAttemptState",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setTaskAttemptState(TaskAttemptState taskAttemptState)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptState == null) {\r\n        builder.clearTaskAttemptState();\r\n        return;\r\n    }\r\n    builder.setTaskAttemptState(convertToProtoFormat(taskAttemptState));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getProgress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setProgress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setProgress(float progress)\n{\r\n    maybeInitBuilder();\r\n    builder.setProgress((progress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDiagnosticInfo",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getDiagnosticInfo()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasDiagnosticInfo()) {\r\n        return null;\r\n    }\r\n    return (p.getDiagnosticInfo());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setDiagnosticInfo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setDiagnosticInfo(String diagnosticInfo)\n{\r\n    maybeInitBuilder();\r\n    if (diagnosticInfo == null) {\r\n        builder.clearDiagnosticInfo();\r\n        return;\r\n    }\r\n    builder.setDiagnosticInfo((diagnosticInfo));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStateString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getStateString()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasStateString()) {\r\n        return null;\r\n    }\r\n    return (p.getStateString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStateString",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setStateString(String stateString)\n{\r\n    maybeInitBuilder();\r\n    if (stateString == null) {\r\n        builder.clearStateString();\r\n        return;\r\n    }\r\n    builder.setStateString((stateString));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getPhase",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Phase getPhase()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasPhase()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getPhase());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setPhase",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setPhase(Phase phase)\n{\r\n    maybeInitBuilder();\r\n    if (phase == null) {\r\n        builder.clearPhase();\r\n        return;\r\n    }\r\n    builder.setPhase(convertToProtoFormat(phase));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getNodeManagerHost",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getNodeManagerHost()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasNodeManagerHost()) {\r\n        return null;\r\n    }\r\n    return p.getNodeManagerHost();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setNodeManagerHost",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setNodeManagerHost(String nmHost)\n{\r\n    maybeInitBuilder();\r\n    if (nmHost == null) {\r\n        builder.clearNodeManagerHost();\r\n        return;\r\n    }\r\n    builder.setNodeManagerHost(nmHost);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getNodeManagerPort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getNodeManagerPort()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getNodeManagerPort());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setNodeManagerPort",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setNodeManagerPort(int nmPort)\n{\r\n    maybeInitBuilder();\r\n    builder.setNodeManagerPort(nmPort);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getNodeManagerHttpPort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getNodeManagerHttpPort()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getNodeManagerHttpPort());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setNodeManagerHttpPort",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setNodeManagerHttpPort(int nmHttpPort)\n{\r\n    maybeInitBuilder();\r\n    builder.setNodeManagerHttpPort(nmHttpPort);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getContainerId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ContainerId getContainerId()\n{\r\n    TaskAttemptReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (containerId != null) {\r\n        return containerId;\r\n    }\r\n    if (!p.hasContainerId()) {\r\n        return null;\r\n    }\r\n    containerId = convertFromProtoFormat(p.getContainerId());\r\n    return containerId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setContainerId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setContainerId(ContainerId containerId)\n{\r\n    maybeInitBuilder();\r\n    if (containerId == null) {\r\n        builder.clearContainerId();\r\n    }\r\n    this.containerId = containerId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ContainerIdProto convertToProtoFormat(ContainerId t)\n{\r\n    return ((ContainerIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ContainerIdPBImpl convertFromProtoFormat(ContainerIdProto p)\n{\r\n    return new ContainerIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CountersPBImpl convertFromProtoFormat(CountersProto p)\n{\r\n    return new CountersPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "CountersProto convertToProtoFormat(Counters t)\n{\r\n    return ((CountersPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptStateProto convertToProtoFormat(TaskAttemptState e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptState convertFromProtoFormat(TaskAttemptStateProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "PhaseProto convertToProtoFormat(Phase e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Phase convertFromProtoFormat(PhaseProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobStateProto convertToProtoFormat(JobState e)\n{\r\n    return JobStateProto.valueOf(JOB_STATE_PREFIX + e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobState convertFromProtoFormat(JobStateProto e)\n{\r\n    return JobState.valueOf(e.name().replace(JOB_STATE_PREFIX, \"\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "PhaseProto convertToProtoFormat(Phase e)\n{\r\n    return PhaseProto.valueOf(PHASE_PREFIX + e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Phase convertFromProtoFormat(PhaseProto e)\n{\r\n    return Phase.valueOf(e.name().replace(PHASE_PREFIX, \"\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptCompletionEventStatusProto convertToProtoFormat(TaskAttemptCompletionEventStatus e)\n{\r\n    return TaskAttemptCompletionEventStatusProto.valueOf(TACE_PREFIX + e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptCompletionEventStatus convertFromProtoFormat(TaskAttemptCompletionEventStatusProto e)\n{\r\n    return TaskAttemptCompletionEventStatus.valueOf(e.name().replace(TACE_PREFIX, \"\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptStateProto convertToProtoFormat(TaskAttemptState e)\n{\r\n    return TaskAttemptStateProto.valueOf(TASK_ATTEMPT_STATE_PREFIX + e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptState convertFromProtoFormat(TaskAttemptStateProto e)\n{\r\n    return TaskAttemptState.valueOf(e.name().replace(TASK_ATTEMPT_STATE_PREFIX, \"\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskStateProto convertToProtoFormat(TaskState e)\n{\r\n    return TaskStateProto.valueOf(TASK_STATE_PREFIX + e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskState convertFromProtoFormat(TaskStateProto e)\n{\r\n    return TaskState.valueOf(e.name().replace(TASK_STATE_PREFIX, \"\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTypeProto convertToProtoFormat(TaskType e)\n{\r\n    return TaskTypeProto.valueOf(e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskType convertFromProtoFormat(TaskTypeProto e)\n{\r\n    return TaskType.valueOf(e.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getRenewer",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getRenewer()\n{\r\n    GetDelegationTokenRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.renewer != null) {\r\n        return this.renewer;\r\n    }\r\n    this.renewer = p.getRenewer();\r\n    return this.renewer;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setRenewer",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setRenewer(String renewer)\n{\r\n    maybeInitBuilder();\r\n    if (renewer == null)\r\n        builder.clearRenewer();\r\n    this.renewer = renewer;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDelegationTokenRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (renewer != null) {\r\n        builder.setRenewer(this.renewer);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetDelegationTokenRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetJobReportRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetJobReportRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    GetJobReportRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    this.jobId = convertFromProtoFormat(p.getJobId());\r\n    return this.jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "ClientProtocol create(Configuration conf) throws IOException\n{\r\n    String framework = conf.get(MRConfig.FRAMEWORK_NAME, MRConfig.LOCAL_FRAMEWORK_NAME);\r\n    if (!MRConfig.LOCAL_FRAMEWORK_NAME.equals(framework)) {\r\n        return null;\r\n    }\r\n    conf.setInt(JobContext.NUM_MAPS, 1);\r\n    return new LocalJobRunner(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ClientProtocol create(InetSocketAddress addr, Configuration conf)\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void close(ClientProtocol clientProtocol)\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptCompletionEventsRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskAttemptCompletionEventsRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    GetTaskAttemptCompletionEventsRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    this.jobId = convertFromProtoFormat(p.getJobId());\r\n    return this.jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getFromEventId",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getFromEventId()\n{\r\n    GetTaskAttemptCompletionEventsRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getFromEventId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setFromEventId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setFromEventId(int fromEventId)\n{\r\n    maybeInitBuilder();\r\n    builder.setFromEventId((fromEventId));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getMaxEvents",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getMaxEvents()\n{\r\n    GetTaskAttemptCompletionEventsRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getMaxEvents());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setMaxEvents",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setMaxEvents(int maxEvents)\n{\r\n    maybeInitBuilder();\r\n    builder.setMaxEvents((maxEvents));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDiagnosticsRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptId != null) {\r\n        builder.setTaskAttemptId(convertToProtoFormat(this.taskAttemptId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetDiagnosticsRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getTaskAttemptId()\n{\r\n    GetDiagnosticsRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptId != null) {\r\n        return this.taskAttemptId;\r\n    }\r\n    if (!p.hasTaskAttemptId()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptId = convertFromProtoFormat(p.getTaskAttemptId());\r\n    return this.taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskAttemptId(TaskAttemptId taskAttemptId)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptId == null)\r\n        builder.clearTaskAttemptId();\r\n    this.taskAttemptId = taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "KillJobResponseProto getProto()\n{\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = KillJobResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getJobReport",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetJobReportResponseProto getJobReport(RpcController controller, GetJobReportRequestProto proto) throws ServiceException\n{\r\n    GetJobReportRequestPBImpl request = new GetJobReportRequestPBImpl(proto);\r\n    try {\r\n        GetJobReportResponse response = real.getJobReport(request);\r\n        return ((GetJobReportResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getTaskReport",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportResponseProto getTaskReport(RpcController controller, GetTaskReportRequestProto proto) throws ServiceException\n{\r\n    GetTaskReportRequest request = new GetTaskReportRequestPBImpl(proto);\r\n    try {\r\n        GetTaskReportResponse response = real.getTaskReport(request);\r\n        return ((GetTaskReportResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getTaskAttemptReport",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptReportResponseProto getTaskAttemptReport(RpcController controller, GetTaskAttemptReportRequestProto proto) throws ServiceException\n{\r\n    GetTaskAttemptReportRequest request = new GetTaskAttemptReportRequestPBImpl(proto);\r\n    try {\r\n        GetTaskAttemptReportResponse response = real.getTaskAttemptReport(request);\r\n        return ((GetTaskAttemptReportResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getCounters",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetCountersResponseProto getCounters(RpcController controller, GetCountersRequestProto proto) throws ServiceException\n{\r\n    GetCountersRequest request = new GetCountersRequestPBImpl(proto);\r\n    try {\r\n        GetCountersResponse response = real.getCounters(request);\r\n        return ((GetCountersResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getTaskAttemptCompletionEvents",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptCompletionEventsResponseProto getTaskAttemptCompletionEvents(RpcController controller, GetTaskAttemptCompletionEventsRequestProto proto) throws ServiceException\n{\r\n    GetTaskAttemptCompletionEventsRequest request = new GetTaskAttemptCompletionEventsRequestPBImpl(proto);\r\n    try {\r\n        GetTaskAttemptCompletionEventsResponse response = real.getTaskAttemptCompletionEvents(request);\r\n        return ((GetTaskAttemptCompletionEventsResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getTaskReports",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportsResponseProto getTaskReports(RpcController controller, GetTaskReportsRequestProto proto) throws ServiceException\n{\r\n    GetTaskReportsRequest request = new GetTaskReportsRequestPBImpl(proto);\r\n    try {\r\n        GetTaskReportsResponse response = real.getTaskReports(request);\r\n        return ((GetTaskReportsResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getDiagnostics",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDiagnosticsResponseProto getDiagnostics(RpcController controller, GetDiagnosticsRequestProto proto) throws ServiceException\n{\r\n    GetDiagnosticsRequest request = new GetDiagnosticsRequestPBImpl(proto);\r\n    try {\r\n        GetDiagnosticsResponse response = real.getDiagnostics(request);\r\n        return ((GetDiagnosticsResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "getDelegationToken",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetDelegationTokenResponseProto getDelegationToken(RpcController controller, GetDelegationTokenRequestProto proto) throws ServiceException\n{\r\n    GetDelegationTokenRequest request = new GetDelegationTokenRequestPBImpl(proto);\r\n    try {\r\n        GetDelegationTokenResponse response = real.getDelegationToken(request);\r\n        return ((GetDelegationTokenResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "killJob",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "KillJobResponseProto killJob(RpcController controller, KillJobRequestProto proto) throws ServiceException\n{\r\n    KillJobRequest request = new KillJobRequestPBImpl(proto);\r\n    try {\r\n        KillJobResponse response = real.killJob(request);\r\n        return ((KillJobResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "killTask",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "KillTaskResponseProto killTask(RpcController controller, KillTaskRequestProto proto) throws ServiceException\n{\r\n    KillTaskRequest request = new KillTaskRequestPBImpl(proto);\r\n    try {\r\n        KillTaskResponse response = real.killTask(request);\r\n        return ((KillTaskResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "killTaskAttempt",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "KillTaskAttemptResponseProto killTaskAttempt(RpcController controller, KillTaskAttemptRequestProto proto) throws ServiceException\n{\r\n    KillTaskAttemptRequest request = new KillTaskAttemptRequestPBImpl(proto);\r\n    try {\r\n        KillTaskAttemptResponse response = real.killTaskAttempt(request);\r\n        return ((KillTaskAttemptResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "failTaskAttempt",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "FailTaskAttemptResponseProto failTaskAttempt(RpcController controller, FailTaskAttemptRequestProto proto) throws ServiceException\n{\r\n    FailTaskAttemptRequest request = new FailTaskAttemptRequestPBImpl(proto);\r\n    try {\r\n        FailTaskAttemptResponse response = real.failTaskAttempt(request);\r\n        return ((FailTaskAttemptResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "renewDelegationToken",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "RenewDelegationTokenResponseProto renewDelegationToken(RpcController controller, RenewDelegationTokenRequestProto proto) throws ServiceException\n{\r\n    RenewDelegationTokenRequestPBImpl request = new RenewDelegationTokenRequestPBImpl(proto);\r\n    try {\r\n        RenewDelegationTokenResponse response = real.renewDelegationToken(request);\r\n        return ((RenewDelegationTokenResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\service",
  "methodName" : "cancelDelegationToken",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "CancelDelegationTokenResponseProto cancelDelegationToken(RpcController controller, CancelDelegationTokenRequestProto proto) throws ServiceException\n{\r\n    CancelDelegationTokenRequestPBImpl request = new CancelDelegationTokenRequestPBImpl(proto);\r\n    try {\r\n        CancelDelegationTokenResponse response = real.cancelDelegationToken(request);\r\n        return ((CancelDelegationTokenResponsePBImpl) response).getProto();\r\n    } catch (IOException e) {\r\n        throw new ServiceException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobId getJobId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getTaskType",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskType getTaskType()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobId(JobId jobId)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setTaskType",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTaskType(TaskType taskType)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setId(int id)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int hashCode()\n{\r\n    final int prime = 31;\r\n    int result = 1;\r\n    result = prime * result + getId();\r\n    result = prime * result + getJobId().hashCode();\r\n    result = prime * result + getTaskType().hashCode();\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "boolean equals(Object obj)\n{\r\n    if (this == obj)\r\n        return true;\r\n    if (obj == null)\r\n        return false;\r\n    if (getClass() != obj.getClass())\r\n        return false;\r\n    TaskId other = (TaskId) obj;\r\n    if (getId() != other.getId())\r\n        return false;\r\n    if (!getJobId().equals(other.getJobId()))\r\n        return false;\r\n    if (getTaskType() != other.getTaskType())\r\n        return false;\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder builder = new StringBuilder(TASK);\r\n    JobId jobId = getJobId();\r\n    builder.append(\"_\").append(jobId.getAppId().getClusterTimestamp());\r\n    builder.append(\"_\").append(JobId.jobIdFormat.get().format(jobId.getAppId().getId()));\r\n    builder.append(\"_\");\r\n    builder.append(getTaskType() == TaskType.MAP ? \"m\" : \"r\").append(\"_\");\r\n    builder.append(taskIdFormat.get().format(getId()));\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "int compareTo(TaskId other)\n{\r\n    int jobIdComp = this.getJobId().compareTo(other.getJobId());\r\n    if (jobIdComp == 0) {\r\n        if (this.getTaskType() == other.getTaskType()) {\r\n            return this.getId() - other.getId();\r\n        } else {\r\n            return this.getTaskType().compareTo(other.getTaskType());\r\n        }\r\n    } else {\r\n        return jobIdComp;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "CountersProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.counterGroups != null) {\r\n        addCounterGroupsToProto();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = CountersProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAllCounterGroups",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, CounterGroup> getAllCounterGroups()\n{\r\n    initCounterGroups();\r\n    return this.counterGroups;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getCounterGroup",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "CounterGroup getCounterGroup(String key)\n{\r\n    initCounterGroups();\r\n    return this.counterGroups.get(key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getCounter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Counter getCounter(Enum<?> key)\n{\r\n    CounterGroup group = getCounterGroup(key.getDeclaringClass().getName());\r\n    return group == null ? null : group.getCounter(key.name());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "incrCounter",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void incrCounter(Enum<?> key, long amount)\n{\r\n    String groupName = key.getDeclaringClass().getName();\r\n    if (getCounterGroup(groupName) == null) {\r\n        CounterGroup cGrp = new CounterGroupPBImpl();\r\n        cGrp.setName(groupName);\r\n        cGrp.setDisplayName(groupName);\r\n        setCounterGroup(groupName, cGrp);\r\n    }\r\n    if (getCounterGroup(groupName).getCounter(key.name()) == null) {\r\n        Counter c = new CounterPBImpl();\r\n        c.setName(key.name());\r\n        c.setDisplayName(key.name());\r\n        c.setValue(0l);\r\n        getCounterGroup(groupName).setCounter(key.name(), c);\r\n    }\r\n    Counter counter = getCounterGroup(groupName).getCounter(key.name());\r\n    counter.setValue(counter.getValue() + amount);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "initCounterGroups",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initCounterGroups()\n{\r\n    if (this.counterGroups != null) {\r\n        return;\r\n    }\r\n    CountersProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<StringCounterGroupMapProto> list = p.getCounterGroupsList();\r\n    this.counterGroups = new HashMap<String, CounterGroup>();\r\n    for (StringCounterGroupMapProto c : list) {\r\n        this.counterGroups.put(c.getKey(), convertFromProtoFormat(c.getValue()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addAllCounterGroups",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllCounterGroups(final Map<String, CounterGroup> counterGroups)\n{\r\n    if (counterGroups == null)\r\n        return;\r\n    initCounterGroups();\r\n    this.counterGroups.putAll(counterGroups);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addCounterGroupsToProto",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void addCounterGroupsToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearCounterGroups();\r\n    if (counterGroups == null)\r\n        return;\r\n    Iterable<StringCounterGroupMapProto> iterable = new Iterable<StringCounterGroupMapProto>() {\r\n\r\n        @Override\r\n        public Iterator<StringCounterGroupMapProto> iterator() {\r\n            return new Iterator<StringCounterGroupMapProto>() {\r\n\r\n                Iterator<String> keyIter = counterGroups.keySet().iterator();\r\n\r\n                @Override\r\n                public void remove() {\r\n                    throw new UnsupportedOperationException();\r\n                }\r\n\r\n                @Override\r\n                public StringCounterGroupMapProto next() {\r\n                    String key = keyIter.next();\r\n                    return StringCounterGroupMapProto.newBuilder().setKey(key).setValue(convertToProtoFormat(counterGroups.get(key))).build();\r\n                }\r\n\r\n                @Override\r\n                public boolean hasNext() {\r\n                    return keyIter.hasNext();\r\n                }\r\n            };\r\n        }\r\n    };\r\n    builder.addAllCounterGroups(iterable);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setCounterGroup",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCounterGroup(String key, CounterGroup val)\n{\r\n    initCounterGroups();\r\n    this.counterGroups.put(key, val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "removeCounterGroup",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeCounterGroup(String key)\n{\r\n    initCounterGroups();\r\n    this.counterGroups.remove(key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "clearCounterGroups",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearCounterGroups()\n{\r\n    initCounterGroups();\r\n    this.counterGroups.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CounterGroupPBImpl convertFromProtoFormat(CounterGroupProto p)\n{\r\n    return new CounterGroupPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "CounterGroupProto convertToProtoFormat(CounterGroup t)\n{\r\n    return ((CounterGroupPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Token getDelegationToken()\n{\r\n    RenewDelegationTokenRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.token != null) {\r\n        return this.token;\r\n    }\r\n    this.token = convertFromProtoFormat(p.getToken());\r\n    return this.token;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setDelegationToken(Token token)\n{\r\n    maybeInitBuilder();\r\n    if (token == null)\r\n        builder.clearToken();\r\n    this.token = token;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "RenewDelegationTokenRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (token != null) {\r\n        builder.setToken(convertToProtoFormat(this.token));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = RenewDelegationTokenRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TokenPBImpl convertFromProtoFormat(TokenProto p)\n{\r\n    return new TokenPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TokenProto convertToProtoFormat(Token t)\n{\r\n    return ((TokenPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getProtocolVersion",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getProtocolVersion(String protocol, long clientVersion)\n{\r\n    return ClientProtocol.versionID;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getProtocolSignature",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ProtocolSignature getProtocolSignature(String protocol, long clientVersion, int clientMethodsHash) throws IOException\n{\r\n    return ProtocolSignature.getProtocolSignature(this, protocol, clientVersion, clientMethodsHash);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getNewJobID",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.JobID getNewJobID()\n{\r\n    return new org.apache.hadoop.mapreduce.JobID(\"local\" + randid, ++jobid);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "submitJob",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.JobStatus submitJob(org.apache.hadoop.mapreduce.JobID jobid, String jobSubmitDir, Credentials credentials) throws IOException\n{\r\n    Job job = new Job(JobID.downgrade(jobid), jobSubmitDir);\r\n    job.job.setCredentials(credentials);\r\n    return job.status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killJob",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void killJob(org.apache.hadoop.mapreduce.JobID id)\n{\r\n    jobs.get(JobID.downgrade(id)).killed = true;\r\n    jobs.get(JobID.downgrade(id)).interrupt();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setJobPriority",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setJobPriority(org.apache.hadoop.mapreduce.JobID id, String jp) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"Changing job priority \" + \"in LocalJobRunner is not supported.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "killTask",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean killTask(org.apache.hadoop.mapreduce.TaskAttemptID taskId, boolean shouldFail) throws IOException\n{\r\n    throw new UnsupportedOperationException(\"Killing tasks in \" + \"LocalJobRunner is not supported\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskReports",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.TaskReport[] getTaskReports(org.apache.hadoop.mapreduce.JobID id, TaskType type)\n{\r\n    return new org.apache.hadoop.mapreduce.TaskReport[0];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobStatus",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.JobStatus getJobStatus(org.apache.hadoop.mapreduce.JobID id)\n{\r\n    Job job = jobs.get(JobID.downgrade(id));\r\n    if (job != null)\r\n        return job.status;\r\n    else\r\n        return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.Counters getJobCounters(org.apache.hadoop.mapreduce.JobID id)\n{\r\n    Job job = jobs.get(JobID.downgrade(id));\r\n    return new org.apache.hadoop.mapreduce.Counters(job.getCurrentCounters());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getFilesystemName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getFilesystemName() throws IOException\n{\r\n    return fs.getUri().toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getClusterMetrics",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "ClusterMetrics getClusterMetrics()\n{\r\n    int numMapTasks = map_tasks.get();\r\n    int numReduceTasks = reduce_tasks.get();\r\n    return new ClusterMetrics(numMapTasks, numReduceTasks, numMapTasks, numReduceTasks, 0, 0, 1, 1, jobs.size(), 1, 0, 0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobTrackerStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobTrackerStatus getJobTrackerStatus()\n{\r\n    return JobTrackerStatus.RUNNING;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskTrackerExpiryInterval",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getTaskTrackerExpiryInterval() throws IOException, InterruptedException\n{\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getActiveTrackers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskTrackerInfo[] getActiveTrackers() throws IOException, InterruptedException\n{\r\n    return new TaskTrackerInfo[0];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getBlacklistedTrackers",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskTrackerInfo[] getBlacklistedTrackers() throws IOException, InterruptedException\n{\r\n    return new TaskTrackerInfo[0];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskCompletionEvent[] getTaskCompletionEvents(org.apache.hadoop.mapreduce.JobID jobid, int fromEventId, int maxEvents) throws IOException\n{\r\n    return TaskCompletionEvent.EMPTY_ARRAY;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getAllJobs",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.JobStatus[] getAllJobs()\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getTaskDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String[] getTaskDiagnostics(org.apache.hadoop.mapreduce.TaskAttemptID taskid) throws IOException\n{\r\n    return new String[0];\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getSystemDir",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getSystemDir()\n{\r\n    Path sysDir = new Path(conf.get(JTConfig.JT_SYSTEM_DIR, \"/tmp/hadoop/mapred/system\"));\r\n    return fs.makeQualified(sysDir).toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueAdmins",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AccessControlList getQueueAdmins(String queueName) throws IOException\n{\r\n    return new AccessControlList(\" \");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getStagingAreaDir",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String getStagingAreaDir() throws IOException\n{\r\n    Path stagingRootDir = new Path(conf.get(JTConfig.JT_STAGING_AREA_ROOT, \"/tmp/hadoop/mapred/staging\"));\r\n    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\r\n    String user;\r\n    randid = rand.nextInt(Integer.MAX_VALUE);\r\n    if (ugi != null) {\r\n        user = ugi.getShortUserName() + randid;\r\n    } else {\r\n        user = \"dummy\" + randid;\r\n    }\r\n    return fs.makeQualified(new Path(stagingRootDir, user + \"/.staging\")).toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getJobHistoryDir",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getJobHistoryDir()\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getChildQueues",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "QueueInfo[] getChildQueues(String queueName) throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getRootQueues",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "QueueInfo[] getRootQueues() throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueues",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "QueueInfo[] getQueues() throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "QueueInfo getQueue(String queue) throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getQueueAclsForCurrentUser",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.QueueAclsInfo[] getQueueAclsForCurrentUser() throws IOException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setLocalMaxRunningMaps",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setLocalMaxRunningMaps(org.apache.hadoop.mapreduce.JobContext job, int maxMaps)\n{\r\n    job.getConfiguration().setInt(LOCAL_MAX_MAPS, maxMaps);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLocalMaxRunningMaps",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getLocalMaxRunningMaps(org.apache.hadoop.mapreduce.JobContext job)\n{\r\n    return job.getConfiguration().getInt(LOCAL_MAX_MAPS, 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setLocalMaxRunningReduces",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setLocalMaxRunningReduces(org.apache.hadoop.mapreduce.JobContext job, int maxReduces)\n{\r\n    job.getConfiguration().setInt(LOCAL_MAX_REDUCES, maxReduces);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLocalMaxRunningReduces",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getLocalMaxRunningReduces(org.apache.hadoop.mapreduce.JobContext job)\n{\r\n    return job.getConfiguration().getInt(LOCAL_MAX_REDUCES, 1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "cancelDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void cancelDelegationToken(Token<DelegationTokenIdentifier> token) throws IOException, InterruptedException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Token<DelegationTokenIdentifier> getDelegationToken(Text renewer) throws IOException, InterruptedException\n{\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "renewDelegationToken",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long renewDelegationToken(Token<DelegationTokenIdentifier> token) throws IOException, InterruptedException\n{\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLogFileParams",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "LogParams getLogFileParams(org.apache.hadoop.mapreduce.JobID jobID, org.apache.hadoop.mapreduce.TaskAttemptID taskAttemptID) throws IOException, InterruptedException\n{\r\n    throw new UnsupportedOperationException(\"Not supported\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "setupChildMapredLocalDirs",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void setupChildMapredLocalDirs(Task t, JobConf conf)\n{\r\n    String[] localDirs = conf.getTrimmedStrings(MRConfig.LOCAL_DIR);\r\n    String jobId = t.getJobID().toString();\r\n    String taskId = t.getTaskID().toString();\r\n    boolean isCleanup = t.isTaskCleanupTask();\r\n    String user = t.getUser();\r\n    StringBuffer childMapredLocalDir = new StringBuffer(localDirs[0] + Path.SEPARATOR + getLocalTaskDir(user, jobId, taskId, isCleanup));\r\n    for (int i = 1; i < localDirs.length; i++) {\r\n        childMapredLocalDir.append(\",\" + localDirs[i] + Path.SEPARATOR + getLocalTaskDir(user, jobId, taskId, isCleanup));\r\n    }\r\n    LOG.debug(MRConfig.LOCAL_DIR + \" for child : \" + childMapredLocalDir);\r\n    conf.set(MRConfig.LOCAL_DIR, childMapredLocalDir.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "getLocalTaskDir",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getLocalTaskDir(String user, String jobid, String taskid, boolean isCleanupAttempt)\n{\r\n    String taskDir = jobDir + Path.SEPARATOR + user + Path.SEPARATOR + JOBCACHE + Path.SEPARATOR + jobid + Path.SEPARATOR + taskid;\r\n    if (isCleanupAttempt) {\r\n        taskDir = taskDir + TASK_CLEANUP_SUFFIX;\r\n    }\r\n    return taskDir;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CancelDelegationTokenResponseProto getProto()\n{\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security",
  "methodName" : "handleKind",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean handleKind(Text kind)\n{\r\n    return MRDelegationTokenIdentifier.KIND_NAME.equals(kind);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security",
  "methodName" : "renew",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "long renew(Token<?> token, Configuration conf) throws IOException, InterruptedException\n{\r\n    org.apache.hadoop.yarn.api.records.Token dToken = org.apache.hadoop.yarn.api.records.Token.newInstance(token.getIdentifier(), token.getKind().toString(), token.getPassword(), token.getService().toString());\r\n    MRClientProtocol histProxy = instantiateHistoryProxy(conf, SecurityUtil.getTokenServiceAddr(token));\r\n    try {\r\n        RenewDelegationTokenRequest request = Records.newRecord(RenewDelegationTokenRequest.class);\r\n        request.setDelegationToken(dToken);\r\n        return histProxy.renewDelegationToken(request).getNextExpirationTime();\r\n    } finally {\r\n        stopHistoryProxy(histProxy);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security",
  "methodName" : "cancel",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void cancel(Token<?> token, Configuration conf) throws IOException, InterruptedException\n{\r\n    org.apache.hadoop.yarn.api.records.Token dToken = org.apache.hadoop.yarn.api.records.Token.newInstance(token.getIdentifier(), token.getKind().toString(), token.getPassword(), token.getService().toString());\r\n    MRClientProtocol histProxy = instantiateHistoryProxy(conf, SecurityUtil.getTokenServiceAddr(token));\r\n    try {\r\n        CancelDelegationTokenRequest request = Records.newRecord(CancelDelegationTokenRequest.class);\r\n        request.setDelegationToken(dToken);\r\n        histProxy.cancelDelegationToken(request);\r\n    } finally {\r\n        stopHistoryProxy(histProxy);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security",
  "methodName" : "isManaged",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isManaged(Token<?> token) throws IOException\n{\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security",
  "methodName" : "stopHistoryProxy",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void stopHistoryProxy(MRClientProtocol proxy)\n{\r\n    RPC.stopProxy(proxy);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security",
  "methodName" : "instantiateHistoryProxy",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "MRClientProtocol instantiateHistoryProxy(final Configuration conf, final InetSocketAddress hsAddress) throws IOException\n{\r\n    if (LOG.isDebugEnabled()) {\r\n        LOG.debug(\"Connecting to MRHistoryServer at: \" + hsAddress);\r\n    }\r\n    final YarnRPC rpc = YarnRPC.create(conf);\r\n    UserGroupInformation currentUser = UserGroupInformation.getCurrentUser();\r\n    return currentUser.doAs(new PrivilegedAction<MRClientProtocol>() {\r\n\r\n        @Override\r\n        public MRClientProtocol run() {\r\n            return (MRClientProtocol) rpc.getProxy(HSClientProtocol.class, hsAddress, conf);\r\n        }\r\n    });\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "KillTaskAttemptRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskAttemptId != null) {\r\n        builder.setTaskAttemptId(convertToProtoFormat(this.taskAttemptId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = KillTaskAttemptRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getTaskAttemptId()\n{\r\n    KillTaskAttemptRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskAttemptId != null) {\r\n        return this.taskAttemptId;\r\n    }\r\n    if (!p.hasTaskAttemptId()) {\r\n        return null;\r\n    }\r\n    this.taskAttemptId = convertFromProtoFormat(p.getTaskAttemptId());\r\n    return this.taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskAttemptId(TaskAttemptId taskAttemptId)\n{\r\n    maybeInitBuilder();\r\n    if (taskAttemptId == null)\r\n        builder.clearTaskAttemptId();\r\n    this.taskAttemptId = taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "FailTaskAttemptResponseProto getProto()\n{\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = FailTaskAttemptResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobReportProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.jobId != null) {\r\n        builder.setJobId(convertToProtoFormat(this.jobId));\r\n    }\r\n    if (this.amInfos != null) {\r\n        addAMInfosToProto();\r\n    }\r\n    if (this.jobPriority != null) {\r\n        builder.setJobPriority(convertToProtoFormat(this.jobPriority));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = JobReportProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobId getJobId()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobId != null) {\r\n        return this.jobId;\r\n    }\r\n    if (!p.hasJobId()) {\r\n        return null;\r\n    }\r\n    this.jobId = convertFromProtoFormat(p.getJobId());\r\n    return this.jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setJobId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobId(JobId jobId)\n{\r\n    maybeInitBuilder();\r\n    if (jobId == null)\r\n        builder.clearJobId();\r\n    this.jobId = jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getJobState",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "JobState getJobState()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasJobState()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getJobState());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setJobState",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setJobState(JobState jobState)\n{\r\n    maybeInitBuilder();\r\n    if (jobState == null) {\r\n        builder.clearJobState();\r\n        return;\r\n    }\r\n    builder.setJobState(convertToProtoFormat(jobState));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getMapProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getMapProgress()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getMapProgress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setMapProgress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setMapProgress(float mapProgress)\n{\r\n    maybeInitBuilder();\r\n    builder.setMapProgress((mapProgress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getReduceProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getReduceProgress()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getReduceProgress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setReduceProgress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setReduceProgress(float reduceProgress)\n{\r\n    maybeInitBuilder();\r\n    builder.setReduceProgress((reduceProgress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getCleanupProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getCleanupProgress()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getCleanupProgress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setCleanupProgress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCleanupProgress(float cleanupProgress)\n{\r\n    maybeInitBuilder();\r\n    builder.setCleanupProgress((cleanupProgress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getSetupProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getSetupProgress()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getSetupProgress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setSetupProgress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setSetupProgress(float setupProgress)\n{\r\n    maybeInitBuilder();\r\n    builder.setSetupProgress((setupProgress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getSubmitTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getSubmitTime()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getSubmitTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setSubmitTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setSubmitTime(long submitTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setSubmitTime((submitTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStartTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getStartTime()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getStartTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStartTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setStartTime(long startTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setStartTime((startTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getFinishTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getFinishTime()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getFinishTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setFinishTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setFinishTime(long finishTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setFinishTime((finishTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getUser",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getUser()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getUser());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setUser",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setUser(String user)\n{\r\n    maybeInitBuilder();\r\n    builder.setUser((user));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getJobName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJobName()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getJobName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setJobName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobName(String jobName)\n{\r\n    maybeInitBuilder();\r\n    builder.setJobName((jobName));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTrackingUrl",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getTrackingUrl()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getTrackingUrl());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTrackingUrl",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTrackingUrl(String trackingUrl)\n{\r\n    maybeInitBuilder();\r\n    builder.setTrackingUrl(trackingUrl);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getDiagnostics()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return p.getDiagnostics();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setDiagnostics(String diagnostics)\n{\r\n    maybeInitBuilder();\r\n    builder.setDiagnostics(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getJobFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJobFile()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return p.getJobFile();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setJobFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobFile(String jobFile)\n{\r\n    maybeInitBuilder();\r\n    builder.setJobFile(jobFile);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAMInfos",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<AMInfo> getAMInfos()\n{\r\n    initAMInfos();\r\n    return this.amInfos;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setAMInfos",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void setAMInfos(List<AMInfo> amInfos)\n{\r\n    maybeInitBuilder();\r\n    if (amInfos == null) {\r\n        this.builder.clearAmInfos();\r\n        this.amInfos = null;\r\n        return;\r\n    }\r\n    initAMInfos();\r\n    this.amInfos.clear();\r\n    this.amInfos.addAll(amInfos);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "initAMInfos",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initAMInfos()\n{\r\n    if (this.amInfos != null) {\r\n        return;\r\n    }\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<AMInfoProto> list = p.getAmInfosList();\r\n    this.amInfos = new ArrayList<AMInfo>();\r\n    for (AMInfoProto amInfoProto : list) {\r\n        this.amInfos.add(convertFromProtoFormat(amInfoProto));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addAMInfosToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addAMInfosToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearAmInfos();\r\n    if (this.amInfos == null)\r\n        return;\r\n    for (AMInfo amInfo : this.amInfos) {\r\n        builder.addAmInfos(convertToProtoFormat(amInfo));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AMInfoPBImpl convertFromProtoFormat(AMInfoProto p)\n{\r\n    return new AMInfoPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "AMInfoProto convertToProtoFormat(AMInfo t)\n{\r\n    return ((AMInfoPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobIdPBImpl convertFromProtoFormat(JobIdProto p)\n{\r\n    return new JobIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobIdProto convertToProtoFormat(JobId t)\n{\r\n    return ((JobIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobStateProto convertToProtoFormat(JobState e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobState convertFromProtoFormat(JobStateProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "PriorityPBImpl convertFromProtoFormat(PriorityProto p)\n{\r\n    return new PriorityPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "PriorityProto convertToProtoFormat(Priority t)\n{\r\n    return ((PriorityPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "isUber",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isUber()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return p.getIsUber();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setIsUber",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setIsUber(boolean isUber)\n{\r\n    maybeInitBuilder();\r\n    builder.setIsUber(isUber);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getJobPriority",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Priority getJobPriority()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.jobPriority != null) {\r\n        return this.jobPriority;\r\n    }\r\n    if (!p.hasJobPriority()) {\r\n        return null;\r\n    }\r\n    this.jobPriority = convertFromProtoFormat(p.getJobPriority());\r\n    return this.jobPriority;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setJobPriority",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJobPriority(Priority priority)\n{\r\n    maybeInitBuilder();\r\n    if (priority == null) {\r\n        builder.clearJobPriority();\r\n    }\r\n    this.jobPriority = priority;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getHistoryFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getHistoryFile()\n{\r\n    JobReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return p.getHistoryFile();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setHistoryFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setHistoryFile(String historyFile)\n{\r\n    maybeInitBuilder();\r\n    builder.setHistoryFile(historyFile);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getTaskId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskId getTaskId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "getId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getId()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setTaskId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setTaskId(TaskId taskId)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "setId",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setId(int id)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int hashCode()\n{\r\n    final int prime = 31;\r\n    int result = 1;\r\n    result = prime * result + getId();\r\n    result = prime * result + ((getTaskId() == null) ? 0 : getTaskId().hashCode());\r\n    return result;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean equals(Object obj)\n{\r\n    if (this == obj)\r\n        return true;\r\n    if (obj == null)\r\n        return false;\r\n    if (getClass() != obj.getClass())\r\n        return false;\r\n    TaskAttemptId other = (TaskAttemptId) obj;\r\n    if (getId() != other.getId())\r\n        return false;\r\n    if (!getTaskId().equals(other.getTaskId()))\r\n        return false;\r\n    return true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "String toString()\n{\r\n    StringBuilder builder = new StringBuilder(TASKATTEMPT);\r\n    TaskId taskId = getTaskId();\r\n    builder.append(\"_\").append(taskId.getJobId().getAppId().getClusterTimestamp());\r\n    builder.append(\"_\").append(JobId.jobIdFormat.get().format(getTaskId().getJobId().getAppId().getId()));\r\n    builder.append(\"_\");\r\n    builder.append(taskId.getTaskType() == TaskType.MAP ? \"m\" : \"r\");\r\n    builder.append(\"_\").append(TaskId.taskIdFormat.get().format(taskId.getId()));\r\n    builder.append(\"_\");\r\n    builder.append(getId());\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "int compareTo(TaskAttemptId other)\n{\r\n    int taskIdComp = this.getTaskId().compareTo(other.getTaskId());\r\n    if (taskIdComp == 0) {\r\n        return this.getId() - other.getId();\r\n    } else {\r\n        return taskIdComp;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskReportProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskId != null) {\r\n        builder.setTaskId(convertToProtoFormat(this.taskId));\r\n    }\r\n    convertRawCountersToCounters();\r\n    if (this.counters != null) {\r\n        builder.setCounters(convertToProtoFormat(this.counters));\r\n    }\r\n    if (this.runningAttempts != null) {\r\n        addRunningAttemptsToProto();\r\n    }\r\n    if (this.successfulAttemptId != null) {\r\n        builder.setSuccessfulAttempt(convertToProtoFormat(this.successfulAttemptId));\r\n    }\r\n    if (this.diagnostics != null) {\r\n        addDiagnosticsToProto();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = TaskReportProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getCounters",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "Counters getCounters()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    convertRawCountersToCounters();\r\n    if (this.counters != null) {\r\n        return this.counters;\r\n    }\r\n    if (!p.hasCounters()) {\r\n        return null;\r\n    }\r\n    this.counters = convertFromProtoFormat(p.getCounters());\r\n    return this.counters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCounters(Counters counters)\n{\r\n    maybeInitBuilder();\r\n    if (counters == null) {\r\n        builder.clearCounters();\r\n    }\r\n    this.counters = counters;\r\n    this.rawCounters = null;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getRawCounters",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.Counters getRawCounters()\n{\r\n    return this.rawCounters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setRawCounters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setRawCounters(org.apache.hadoop.mapreduce.Counters rCounters)\n{\r\n    setCounters(null);\r\n    this.rawCounters = rCounters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertRawCountersToCounters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void convertRawCountersToCounters()\n{\r\n    if (this.counters == null && this.rawCounters != null) {\r\n        this.counters = TypeConverter.toYarn(rawCounters);\r\n        this.rawCounters = null;\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStartTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getStartTime()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getStartTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStartTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setStartTime(long startTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setStartTime((startTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getFinishTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getFinishTime()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getFinishTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setFinishTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setFinishTime(long finishTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setFinishTime((finishTime));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskId getTaskId()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskId != null) {\r\n        return this.taskId;\r\n    }\r\n    if (!p.hasTaskId()) {\r\n        return null;\r\n    }\r\n    this.taskId = convertFromProtoFormat(p.getTaskId());\r\n    return this.taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskId(TaskId taskId)\n{\r\n    maybeInitBuilder();\r\n    if (taskId == null)\r\n        builder.clearTaskId();\r\n    this.taskId = taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getProgress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getStatus()\n{\r\n    return status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setProgress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setProgress(float progress)\n{\r\n    maybeInitBuilder();\r\n    builder.setProgress((progress));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStatus",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void setStatus(String status)\n{\r\n    this.status = status;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getTaskState",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskState getTaskState()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasTaskState()) {\r\n        return null;\r\n    }\r\n    return convertFromProtoFormat(p.getTaskState());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setTaskState",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setTaskState(TaskState taskState)\n{\r\n    maybeInitBuilder();\r\n    if (taskState == null) {\r\n        builder.clearTaskState();\r\n        return;\r\n    }\r\n    builder.setTaskState(convertToProtoFormat(taskState));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getRunningAttemptsList",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<TaskAttemptId> getRunningAttemptsList()\n{\r\n    initRunningAttempts();\r\n    return this.runningAttempts;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getRunningAttempt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getRunningAttempt(int index)\n{\r\n    initRunningAttempts();\r\n    return this.runningAttempts.get(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getRunningAttemptsCount",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getRunningAttemptsCount()\n{\r\n    initRunningAttempts();\r\n    return this.runningAttempts.size();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "initRunningAttempts",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initRunningAttempts()\n{\r\n    if (this.runningAttempts != null) {\r\n        return;\r\n    }\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<TaskAttemptIdProto> list = p.getRunningAttemptsList();\r\n    this.runningAttempts = new ArrayList<TaskAttemptId>();\r\n    for (TaskAttemptIdProto c : list) {\r\n        this.runningAttempts.add(convertFromProtoFormat(c));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addAllRunningAttempts",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllRunningAttempts(final List<TaskAttemptId> runningAttempts)\n{\r\n    if (runningAttempts == null)\r\n        return;\r\n    initRunningAttempts();\r\n    this.runningAttempts.addAll(runningAttempts);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addRunningAttemptsToProto",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void addRunningAttemptsToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearRunningAttempts();\r\n    if (runningAttempts == null)\r\n        return;\r\n    Iterable<TaskAttemptIdProto> iterable = new Iterable<TaskAttemptIdProto>() {\r\n\r\n        @Override\r\n        public Iterator<TaskAttemptIdProto> iterator() {\r\n            return new Iterator<TaskAttemptIdProto>() {\r\n\r\n                Iterator<TaskAttemptId> iter = runningAttempts.iterator();\r\n\r\n                @Override\r\n                public boolean hasNext() {\r\n                    return iter.hasNext();\r\n                }\r\n\r\n                @Override\r\n                public TaskAttemptIdProto next() {\r\n                    return convertToProtoFormat(iter.next());\r\n                }\r\n\r\n                @Override\r\n                public void remove() {\r\n                    throw new UnsupportedOperationException();\r\n                }\r\n            };\r\n        }\r\n    };\r\n    builder.addAllRunningAttempts(iterable);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addRunningAttempt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addRunningAttempt(TaskAttemptId runningAttempts)\n{\r\n    initRunningAttempts();\r\n    this.runningAttempts.add(runningAttempts);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "removeRunningAttempt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeRunningAttempt(int index)\n{\r\n    initRunningAttempts();\r\n    this.runningAttempts.remove(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "clearRunningAttempts",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearRunningAttempts()\n{\r\n    initRunningAttempts();\r\n    this.runningAttempts.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getSuccessfulAttempt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptId getSuccessfulAttempt()\n{\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.successfulAttemptId != null) {\r\n        return this.successfulAttemptId;\r\n    }\r\n    if (!p.hasSuccessfulAttempt()) {\r\n        return null;\r\n    }\r\n    this.successfulAttemptId = convertFromProtoFormat(p.getSuccessfulAttempt());\r\n    return this.successfulAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setSuccessfulAttempt",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setSuccessfulAttempt(TaskAttemptId successfulAttempt)\n{\r\n    maybeInitBuilder();\r\n    if (successfulAttempt == null)\r\n        builder.clearSuccessfulAttempt();\r\n    this.successfulAttemptId = successfulAttempt;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDiagnosticsList",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> getDiagnosticsList()\n{\r\n    initDiagnostics();\r\n    return this.diagnostics;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getDiagnostics(int index)\n{\r\n    initDiagnostics();\r\n    return this.diagnostics.get(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDiagnosticsCount",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getDiagnosticsCount()\n{\r\n    initDiagnostics();\r\n    return this.diagnostics.size();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "initDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initDiagnostics()\n{\r\n    if (this.diagnostics != null) {\r\n        return;\r\n    }\r\n    TaskReportProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<String> list = p.getDiagnosticsList();\r\n    this.diagnostics = new ArrayList<String>();\r\n    for (String c : list) {\r\n        this.diagnostics.add(c);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addAllDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllDiagnostics(final List<String> diagnostics)\n{\r\n    if (diagnostics == null)\r\n        return;\r\n    initDiagnostics();\r\n    this.diagnostics.addAll(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addDiagnosticsToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void addDiagnosticsToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearDiagnostics();\r\n    if (diagnostics == null)\r\n        return;\r\n    builder.addAllDiagnostics(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addDiagnostics(String diagnostics)\n{\r\n    initDiagnostics();\r\n    this.diagnostics.add(diagnostics);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "removeDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeDiagnostics(int index)\n{\r\n    initDiagnostics();\r\n    this.diagnostics.remove(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "clearDiagnostics",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearDiagnostics()\n{\r\n    initDiagnostics();\r\n    this.diagnostics.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CountersPBImpl convertFromProtoFormat(CountersProto p)\n{\r\n    return new CountersPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "CountersProto convertToProtoFormat(Counters t)\n{\r\n    return ((CountersPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskIdPBImpl convertFromProtoFormat(TaskIdProto p)\n{\r\n    return new TaskIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskIdProto convertToProtoFormat(TaskId t)\n{\r\n    return ((TaskIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskStateProto convertToProtoFormat(TaskState e)\n{\r\n    return MRProtoUtils.convertToProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskState convertFromProtoFormat(TaskStateProto e)\n{\r\n    return MRProtoUtils.convertFromProtoFormat(e);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptIdPBImpl convertFromProtoFormat(TaskAttemptIdProto p)\n{\r\n    return new TaskAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptIdProto convertToProtoFormat(TaskAttemptId t)\n{\r\n    return ((TaskAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getConnectAddress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "InetSocketAddress getConnectAddress()\n{\r\n    return RPC.getServerAddress(proxy);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void close()\n{\r\n    if (this.proxy != null) {\r\n        RPC.stopProxy(this.proxy);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getJobReport",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetJobReportResponse getJobReport(GetJobReportRequest request) throws IOException\n{\r\n    GetJobReportRequestProto requestProto = ((GetJobReportRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetJobReportResponsePBImpl(proxy.getJobReport(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getTaskReport",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetTaskReportResponse getTaskReport(GetTaskReportRequest request) throws IOException\n{\r\n    GetTaskReportRequestProto requestProto = ((GetTaskReportRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetTaskReportResponsePBImpl(proxy.getTaskReport(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getTaskAttemptReport",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetTaskAttemptReportResponse getTaskAttemptReport(GetTaskAttemptReportRequest request) throws IOException\n{\r\n    GetTaskAttemptReportRequestProto requestProto = ((GetTaskAttemptReportRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetTaskAttemptReportResponsePBImpl(proxy.getTaskAttemptReport(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getCounters",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetCountersResponse getCounters(GetCountersRequest request) throws IOException\n{\r\n    GetCountersRequestProto requestProto = ((GetCountersRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetCountersResponsePBImpl(proxy.getCounters(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getTaskAttemptCompletionEvents",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetTaskAttemptCompletionEventsResponse getTaskAttemptCompletionEvents(GetTaskAttemptCompletionEventsRequest request) throws IOException\n{\r\n    GetTaskAttemptCompletionEventsRequestProto requestProto = ((GetTaskAttemptCompletionEventsRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetTaskAttemptCompletionEventsResponsePBImpl(proxy.getTaskAttemptCompletionEvents(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getTaskReports",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetTaskReportsResponse getTaskReports(GetTaskReportsRequest request) throws IOException\n{\r\n    GetTaskReportsRequestProto requestProto = ((GetTaskReportsRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetTaskReportsResponsePBImpl(proxy.getTaskReports(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getDiagnostics",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetDiagnosticsResponse getDiagnostics(GetDiagnosticsRequest request) throws IOException\n{\r\n    GetDiagnosticsRequestProto requestProto = ((GetDiagnosticsRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetDiagnosticsResponsePBImpl(proxy.getDiagnostics(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "getDelegationToken",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "GetDelegationTokenResponse getDelegationToken(GetDelegationTokenRequest request) throws IOException\n{\r\n    GetDelegationTokenRequestProto requestProto = ((GetDelegationTokenRequestPBImpl) request).getProto();\r\n    try {\r\n        return new GetDelegationTokenResponsePBImpl(proxy.getDelegationToken(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "killJob",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "KillJobResponse killJob(KillJobRequest request) throws IOException\n{\r\n    KillJobRequestProto requestProto = ((KillJobRequestPBImpl) request).getProto();\r\n    try {\r\n        return new KillJobResponsePBImpl(proxy.killJob(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "killTask",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "KillTaskResponse killTask(KillTaskRequest request) throws IOException\n{\r\n    KillTaskRequestProto requestProto = ((KillTaskRequestPBImpl) request).getProto();\r\n    try {\r\n        return new KillTaskResponsePBImpl(proxy.killTask(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "killTaskAttempt",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "KillTaskAttemptResponse killTaskAttempt(KillTaskAttemptRequest request) throws IOException\n{\r\n    KillTaskAttemptRequestProto requestProto = ((KillTaskAttemptRequestPBImpl) request).getProto();\r\n    try {\r\n        return new KillTaskAttemptResponsePBImpl(proxy.killTaskAttempt(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "failTaskAttempt",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "FailTaskAttemptResponse failTaskAttempt(FailTaskAttemptRequest request) throws IOException\n{\r\n    FailTaskAttemptRequestProto requestProto = ((FailTaskAttemptRequestPBImpl) request).getProto();\r\n    try {\r\n        return new FailTaskAttemptResponsePBImpl(proxy.failTaskAttempt(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "renewDelegationToken",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "RenewDelegationTokenResponse renewDelegationToken(RenewDelegationTokenRequest request) throws IOException\n{\r\n    RenewDelegationTokenRequestProto requestProto = ((RenewDelegationTokenRequestPBImpl) request).getProto();\r\n    try {\r\n        return new RenewDelegationTokenResponsePBImpl(proxy.renewDelegationToken(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "cancelDelegationToken",
  "errType" : [ "ServiceException" ],
  "containingMethodsNum" : 3,
  "sourceCodeText" : "CancelDelegationTokenResponse cancelDelegationToken(CancelDelegationTokenRequest request) throws IOException\n{\r\n    CancelDelegationTokenRequestProto requestProto = ((CancelDelegationTokenRequestPBImpl) request).getProto();\r\n    try {\r\n        return new CancelDelegationTokenResponsePBImpl(proxy.cancelDelegationToken(null, requestProto));\r\n    } catch (ServiceException e) {\r\n        throw unwrapAndThrowException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\impl\\pb\\client",
  "methodName" : "unwrapAndThrowException",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "IOException unwrapAndThrowException(ServiceException se)\n{\r\n    if (se.getCause() instanceof RemoteException) {\r\n        return ((RemoteException) se.getCause()).unwrapRemoteException();\r\n    } else if (se.getCause() instanceof IOException) {\r\n        return (IOException) se.getCause();\r\n    } else {\r\n        throw new UndeclaredThrowableException(se.getCause());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "create",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "LocalJobRunnerMetrics create()\n{\r\n    MetricsSystem ms = DefaultMetricsSystem.initialize(\"JobTracker\");\r\n    return ms.register(\"LocalJobRunnerMetrics-\" + ThreadLocalRandom.current().nextInt(), null, new LocalJobRunnerMetrics());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "launchMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void launchMap(TaskAttemptID taskAttemptID)\n{\r\n    numMapTasksLaunched.incr();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "completeMap",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void completeMap(TaskAttemptID taskAttemptID)\n{\r\n    numMapTasksCompleted.incr();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "launchReduce",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void launchReduce(TaskAttemptID taskAttemptID)\n{\r\n    numReduceTasksLaunched.incr();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapred",
  "methodName" : "completeReduce",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void completeReduce(TaskAttemptID taskAttemptID)\n{\r\n    numReduceTasksCompleted.incr();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "AMInfoProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.appAttemptId != null && !((ApplicationAttemptIdPBImpl) this.appAttemptId).getProto().equals(builder.getApplicationAttemptId())) {\r\n        builder.setApplicationAttemptId(convertToProtoFormat(this.appAttemptId));\r\n    }\r\n    if (this.getContainerId() != null && !((ContainerIdPBImpl) this.containerId).getProto().equals(builder.getContainerId())) {\r\n        builder.setContainerId(convertToProtoFormat(this.containerId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = AMInfoProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAppAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ApplicationAttemptId getAppAttemptId()\n{\r\n    AMInfoProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (appAttemptId != null) {\r\n        return appAttemptId;\r\n    }\r\n    if (!p.hasApplicationAttemptId()) {\r\n        return null;\r\n    }\r\n    appAttemptId = convertFromProtoFormat(p.getApplicationAttemptId());\r\n    return appAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setAppAttemptId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setAppAttemptId(ApplicationAttemptId appAttemptId)\n{\r\n    maybeInitBuilder();\r\n    if (appAttemptId == null) {\r\n        builder.clearApplicationAttemptId();\r\n    }\r\n    this.appAttemptId = appAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getStartTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getStartTime()\n{\r\n    AMInfoProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getStartTime());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setStartTime",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setStartTime(long startTime)\n{\r\n    maybeInitBuilder();\r\n    builder.setStartTime(startTime);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getContainerId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ContainerId getContainerId()\n{\r\n    AMInfoProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (containerId != null) {\r\n        return containerId;\r\n    }\r\n    if (!p.hasContainerId()) {\r\n        return null;\r\n    }\r\n    containerId = convertFromProtoFormat(p.getContainerId());\r\n    return containerId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setContainerId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setContainerId(ContainerId containerId)\n{\r\n    maybeInitBuilder();\r\n    if (containerId == null) {\r\n        builder.clearContainerId();\r\n    }\r\n    this.containerId = containerId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getNodeManagerHost",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getNodeManagerHost()\n{\r\n    AMInfoProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasNodeManagerHost()) {\r\n        return null;\r\n    }\r\n    return p.getNodeManagerHost();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setNodeManagerHost",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setNodeManagerHost(String nmHost)\n{\r\n    maybeInitBuilder();\r\n    if (nmHost == null) {\r\n        builder.clearNodeManagerHost();\r\n        return;\r\n    }\r\n    builder.setNodeManagerHost(nmHost);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getNodeManagerPort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getNodeManagerPort()\n{\r\n    AMInfoProtoOrBuilder p = viaProto ? proto : builder;\r\n    return (p.getNodeManagerPort());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setNodeManagerPort",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setNodeManagerPort(int nmPort)\n{\r\n    maybeInitBuilder();\r\n    builder.setNodeManagerPort(nmPort);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getNodeManagerHttpPort",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int getNodeManagerHttpPort()\n{\r\n    AMInfoProtoOrBuilder p = viaProto ? proto : builder;\r\n    return p.getNodeManagerHttpPort();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setNodeManagerHttpPort",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setNodeManagerHttpPort(int httpPort)\n{\r\n    maybeInitBuilder();\r\n    builder.setNodeManagerHttpPort(httpPort);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ApplicationAttemptIdPBImpl convertFromProtoFormat(ApplicationAttemptIdProto p)\n{\r\n    return new ApplicationAttemptIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "ContainerIdPBImpl convertFromProtoFormat(ContainerIdProto p)\n{\r\n    return new ContainerIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ApplicationAttemptIdProto convertToProtoFormat(ApplicationAttemptId t)\n{\r\n    return ((ApplicationAttemptIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "ContainerIdProto convertToProtoFormat(ContainerId t)\n{\r\n    return ((ContainerIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskAttemptCompletionEventsResponseProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.completionEvents != null) {\r\n        addCompletionEventsToProto();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskAttemptCompletionEventsResponseProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getCompletionEventList",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<TaskAttemptCompletionEvent> getCompletionEventList()\n{\r\n    initCompletionEvents();\r\n    return this.completionEvents;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getCompletionEvent",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskAttemptCompletionEvent getCompletionEvent(int index)\n{\r\n    initCompletionEvents();\r\n    return this.completionEvents.get(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getCompletionEventCount",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "int getCompletionEventCount()\n{\r\n    initCompletionEvents();\r\n    return this.completionEvents.size();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "initCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initCompletionEvents()\n{\r\n    if (this.completionEvents != null) {\r\n        return;\r\n    }\r\n    GetTaskAttemptCompletionEventsResponseProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<TaskAttemptCompletionEventProto> list = p.getCompletionEventsList();\r\n    this.completionEvents = new ArrayList<TaskAttemptCompletionEvent>();\r\n    for (TaskAttemptCompletionEventProto c : list) {\r\n        this.completionEvents.add(convertFromProtoFormat(c));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addAllCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllCompletionEvents(final List<TaskAttemptCompletionEvent> completionEvents)\n{\r\n    if (completionEvents == null)\r\n        return;\r\n    initCompletionEvents();\r\n    this.completionEvents.addAll(completionEvents);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addCompletionEventsToProto",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void addCompletionEventsToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearCompletionEvents();\r\n    if (completionEvents == null)\r\n        return;\r\n    Iterable<TaskAttemptCompletionEventProto> iterable = new Iterable<TaskAttemptCompletionEventProto>() {\r\n\r\n        @Override\r\n        public Iterator<TaskAttemptCompletionEventProto> iterator() {\r\n            return new Iterator<TaskAttemptCompletionEventProto>() {\r\n\r\n                Iterator<TaskAttemptCompletionEvent> iter = completionEvents.iterator();\r\n\r\n                @Override\r\n                public boolean hasNext() {\r\n                    return iter.hasNext();\r\n                }\r\n\r\n                @Override\r\n                public TaskAttemptCompletionEventProto next() {\r\n                    return convertToProtoFormat(iter.next());\r\n                }\r\n\r\n                @Override\r\n                public void remove() {\r\n                    throw new UnsupportedOperationException();\r\n                }\r\n            };\r\n        }\r\n    };\r\n    builder.addAllCompletionEvents(iterable);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "addCompletionEvent",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addCompletionEvent(TaskAttemptCompletionEvent completionEvents)\n{\r\n    initCompletionEvents();\r\n    this.completionEvents.add(completionEvents);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "removeCompletionEvent",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeCompletionEvent(int index)\n{\r\n    initCompletionEvents();\r\n    this.completionEvents.remove(index);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "clearCompletionEvents",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearCompletionEvents()\n{\r\n    initCompletionEvents();\r\n    this.completionEvents.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptCompletionEventPBImpl convertFromProtoFormat(TaskAttemptCompletionEventProto p)\n{\r\n    return new TaskAttemptCompletionEventPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptCompletionEventProto convertToProtoFormat(TaskAttemptCompletionEvent t)\n{\r\n    return ((TaskAttemptCompletionEventPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "CounterGroupProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.counters != null) {\r\n        addContersToProto();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = CounterGroupProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getName()\n{\r\n    CounterGroupProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasName()) {\r\n        return null;\r\n    }\r\n    return (p.getName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setName",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setName(String name)\n{\r\n    maybeInitBuilder();\r\n    if (name == null) {\r\n        builder.clearName();\r\n        return;\r\n    }\r\n    builder.setName((name));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getDisplayName",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getDisplayName()\n{\r\n    CounterGroupProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (!p.hasDisplayName()) {\r\n        return null;\r\n    }\r\n    return (p.getDisplayName());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setDisplayName",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setDisplayName(String displayName)\n{\r\n    maybeInitBuilder();\r\n    if (displayName == null) {\r\n        builder.clearDisplayName();\r\n        return;\r\n    }\r\n    builder.setDisplayName((displayName));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getAllCounters",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Map<String, Counter> getAllCounters()\n{\r\n    initCounters();\r\n    return this.counters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "getCounter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Counter getCounter(String key)\n{\r\n    initCounters();\r\n    return this.counters.get(key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "initCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initCounters()\n{\r\n    if (this.counters != null) {\r\n        return;\r\n    }\r\n    CounterGroupProtoOrBuilder p = viaProto ? proto : builder;\r\n    List<StringCounterMapProto> list = p.getCountersList();\r\n    this.counters = new HashMap<String, Counter>();\r\n    for (StringCounterMapProto c : list) {\r\n        this.counters.put(c.getKey(), convertFromProtoFormat(c.getValue()));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addAllCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addAllCounters(final Map<String, Counter> counters)\n{\r\n    if (counters == null)\r\n        return;\r\n    initCounters();\r\n    this.counters.putAll(counters);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "addContersToProto",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void addContersToProto()\n{\r\n    maybeInitBuilder();\r\n    builder.clearCounters();\r\n    if (counters == null)\r\n        return;\r\n    Iterable<StringCounterMapProto> iterable = new Iterable<StringCounterMapProto>() {\r\n\r\n        @Override\r\n        public Iterator<StringCounterMapProto> iterator() {\r\n            return new Iterator<StringCounterMapProto>() {\r\n\r\n                Iterator<String> keyIter = counters.keySet().iterator();\r\n\r\n                @Override\r\n                public void remove() {\r\n                    throw new UnsupportedOperationException();\r\n                }\r\n\r\n                @Override\r\n                public StringCounterMapProto next() {\r\n                    String key = keyIter.next();\r\n                    return StringCounterMapProto.newBuilder().setKey(key).setValue(convertToProtoFormat(counters.get(key))).build();\r\n                }\r\n\r\n                @Override\r\n                public boolean hasNext() {\r\n                    return keyIter.hasNext();\r\n                }\r\n            };\r\n        }\r\n    };\r\n    builder.addAllCounters(iterable);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "setCounter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setCounter(String key, Counter val)\n{\r\n    initCounters();\r\n    this.counters.put(key, val);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "removeCounter",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void removeCounter(String key)\n{\r\n    initCounters();\r\n    this.counters.remove(key);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "clearCounters",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void clearCounters()\n{\r\n    initCounters();\r\n    this.counters.clear();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "CounterPBImpl convertFromProtoFormat(CounterProto p)\n{\r\n    return new CounterPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\records\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "CounterProto convertToProtoFormat(Counter t)\n{\r\n    return ((CounterPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "isValidJobHistoryFileName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean isValidJobHistoryFileName(String pathString)\n{\r\n    return pathString.endsWith(JOB_HISTORY_FILE_EXTENSION);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getJobIDFromHistoryFilePath",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "JobID getJobIDFromHistoryFilePath(String pathString) throws IOException\n{\r\n    String[] parts = pathString.split(Path.SEPARATOR);\r\n    String fileNamePart = parts[parts.length - 1];\r\n    JobIndexInfo jobIndexInfo = FileNameIndexUtils.getIndexInfo(fileNamePart);\r\n    return TypeConverter.fromYarn(jobIndexInfo.getJobId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getConfFileFilter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "PathFilter getConfFileFilter()\n{\r\n    return CONF_FILTER;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getHistoryFileFilter",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "PathFilter getHistoryFileFilter()\n{\r\n    return JOB_HISTORY_FILE_FILTER;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getConfiguredHistoryStagingDirPrefix",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String getConfiguredHistoryStagingDirPrefix(Configuration conf, String jobId) throws IOException\n{\r\n    String user = UserGroupInformation.getCurrentUser().getShortUserName();\r\n    Path stagingPath = MRApps.getStagingAreaDir(conf, user);\r\n    Path path = new Path(stagingPath, jobId);\r\n    String logDir = path.toString();\r\n    return ensurePathInDefaultFileSystem(logDir, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getConfiguredHistoryIntermediateDoneDirPrefix",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getConfiguredHistoryIntermediateDoneDirPrefix(Configuration conf)\n{\r\n    String doneDirPrefix = conf.get(JHAdminConfig.MR_HISTORY_INTERMEDIATE_DONE_DIR);\r\n    if (doneDirPrefix == null) {\r\n        doneDirPrefix = conf.get(MRJobConfig.MR_AM_STAGING_DIR, MRJobConfig.DEFAULT_MR_AM_STAGING_DIR) + \"/history/done_intermediate\";\r\n    }\r\n    return ensurePathInDefaultFileSystem(doneDirPrefix, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getConfiguredHistoryIntermediateUserDoneDirPermissions",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "FsPermission getConfiguredHistoryIntermediateUserDoneDirPermissions(Configuration conf)\n{\r\n    String userDoneDirPermissions = conf.get(JHAdminConfig.MR_HISTORY_INTERMEDIATE_USER_DONE_DIR_PERMISSIONS);\r\n    if (userDoneDirPermissions == null) {\r\n        return new FsPermission(JHAdminConfig.DEFAULT_MR_HISTORY_INTERMEDIATE_USER_DONE_DIR_PERMISSIONS);\r\n    }\r\n    FsPermission permission = new FsPermission(userDoneDirPermissions);\r\n    if (permission.getUserAction() != FsAction.ALL || permission.getGroupAction() != FsAction.ALL) {\r\n        permission = new FsPermission(FsAction.ALL, FsAction.ALL, permission.getOtherAction(), permission.getStickyBit());\r\n        LOG.warn(\"Unsupported permission configured in \" + JHAdminConfig.MR_HISTORY_INTERMEDIATE_USER_DONE_DIR_PERMISSIONS + \", the user and the group permission must be 7 (rwx). \" + \"The permission was set to \" + permission.toString());\r\n    }\r\n    return permission;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getConfiguredHistoryServerDoneDirPrefix",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getConfiguredHistoryServerDoneDirPrefix(Configuration conf)\n{\r\n    String doneDirPrefix = conf.get(JHAdminConfig.MR_HISTORY_DONE_DIR);\r\n    if (doneDirPrefix == null) {\r\n        doneDirPrefix = conf.get(MRJobConfig.MR_AM_STAGING_DIR, MRJobConfig.DEFAULT_MR_AM_STAGING_DIR) + \"/history/done\";\r\n    }\r\n    return ensurePathInDefaultFileSystem(doneDirPrefix, conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getDefaultFileContext",
  "errType" : [ "UnsupportedFileSystemException" ],
  "containingMethodsNum" : 6,
  "sourceCodeText" : "FileContext getDefaultFileContext()\n{\r\n    FileContext fc = null;\r\n    Configuration defaultConf = new Configuration();\r\n    String[] sources;\r\n    sources = defaultConf.getPropertySources(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY);\r\n    if (sources != null && (!Arrays.asList(sources).contains(\"core-default.xml\") || sources.length > 1)) {\r\n        try {\r\n            fc = FileContext.getFileContext(defaultConf);\r\n            LOG.info(\"Default file system [\" + fc.getDefaultFileSystem().getUri() + \"]\");\r\n        } catch (UnsupportedFileSystemException e) {\r\n            LOG.error(\"Unable to create default file context [\" + defaultConf.get(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY) + \"]\", e);\r\n        }\r\n    } else {\r\n        LOG.info(\"Default file system is set solely \" + \"by core-default.xml therefore -  ignoring\");\r\n    }\r\n    return fc;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "ensurePathInDefaultFileSystem",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String ensurePathInDefaultFileSystem(String sourcePath, Configuration conf)\n{\r\n    Path path = new Path(sourcePath);\r\n    FileContext fc = getDefaultFileContext();\r\n    if (fc == null || fc.getDefaultFileSystem().getUri().toString().equals(conf.getTrimmed(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY, \"\")) || path.toUri().getAuthority() != null || path.toUri().getScheme() != null) {\r\n        return sourcePath;\r\n    }\r\n    return fc.makeQualified(path).toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getHistoryIntermediateDoneDirForUser",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getHistoryIntermediateDoneDirForUser(Configuration conf) throws IOException\n{\r\n    return new Path(getConfiguredHistoryIntermediateDoneDirPrefix(conf), UserGroupInformation.getCurrentUser().getShortUserName()).toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "shouldCreateNonUserDirectory",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "boolean shouldCreateNonUserDirectory(Configuration conf)\n{\r\n    return conf.getBoolean(MRJobConfig.MR_AM_CREATE_JH_INTERMEDIATE_BASE_DIR, true);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getStagingJobHistoryFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path getStagingJobHistoryFile(Path dir, JobId jobId, int attempt)\n{\r\n    return getStagingJobHistoryFile(dir, TypeConverter.fromYarn(jobId).toString(), attempt);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getStagingJobHistoryFile",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Path getStagingJobHistoryFile(Path dir, String jobId, int attempt)\n{\r\n    return new Path(dir, jobId + \"_\" + attempt + JOB_HISTORY_FILE_EXTENSION);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getIntermediateConfFileName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getIntermediateConfFileName(JobId jobId)\n{\r\n    return TypeConverter.fromYarn(jobId).toString() + CONF_FILE_NAME_SUFFIX;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getIntermediateSummaryFileName",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getIntermediateSummaryFileName(JobId jobId)\n{\r\n    return TypeConverter.fromYarn(jobId).toString() + SUMMARY_FILE_NAME_SUFFIX;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getStagingConfFile",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path getStagingConfFile(Path logDir, JobId jobId, int attempt)\n{\r\n    Path jobFilePath = null;\r\n    if (logDir != null) {\r\n        jobFilePath = new Path(logDir, TypeConverter.fromYarn(jobId).toString() + \"_\" + attempt + CONF_FILE_NAME_SUFFIX);\r\n    }\r\n    return jobFilePath;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "serialNumberDirectoryComponent",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String serialNumberDirectoryComponent(JobId id, String serialNumberFormat)\n{\r\n    return String.format(serialNumberFormat, Integer.valueOf(jobSerialNumber(id))).substring(0, SERIAL_NUMBER_DIRECTORY_DIGITS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getTimestampPartFromPath",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String getTimestampPartFromPath(String path)\n{\r\n    Matcher matcher = TIMESTAMP_DIR_PATTERN.matcher(path);\r\n    if (matcher.find()) {\r\n        String matched = matcher.group();\r\n        String ret = matched.intern();\r\n        return ret;\r\n    } else {\r\n        return null;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "historyLogSubdirectory",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String historyLogSubdirectory(JobId id, String timestampComponent, String serialNumberFormat)\n{\r\n    String result = \"\";\r\n    String serialNumberDirectory = serialNumberDirectoryComponent(id, serialNumberFormat);\r\n    result = result + timestampComponent + File.separator + serialNumberDirectory + File.separator;\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "timestampDirectoryComponent",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String timestampDirectoryComponent(long millisecondTime)\n{\r\n    Calendar timestamp = Calendar.getInstance();\r\n    timestamp.setTimeInMillis(millisecondTime);\r\n    String dateString = null;\r\n    dateString = String.format(TIMESTAMP_DIR_FORMAT, timestamp.get(Calendar.YEAR), timestamp.get(Calendar.MONTH) + 1, timestamp.get(Calendar.DAY_OF_MONTH));\r\n    dateString = dateString.intern();\r\n    return dateString;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "doneSubdirsBeforeSerialTail",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String doneSubdirsBeforeSerialTail()\n{\r\n    String result = \"/*/*/*\";\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "jobSerialNumber",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int jobSerialNumber(JobId id)\n{\r\n    return id.getId();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "localGlobber",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<FileStatus> localGlobber(FileContext fc, Path root, String tail) throws IOException\n{\r\n    return localGlobber(fc, root, tail, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "localGlobber",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<FileStatus> localGlobber(FileContext fc, Path root, String tail, PathFilter filter) throws IOException\n{\r\n    return localGlobber(fc, root, tail, filter, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "localGlobber",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "List<FileStatus> localGlobber(FileContext fc, Path root, String tail, PathFilter filter, AtomicBoolean hasFlatFiles) throws IOException\n{\r\n    if (tail.equals(\"\")) {\r\n        return (listFilteredStatus(fc, root, filter));\r\n    }\r\n    if (tail.startsWith(\"/*\")) {\r\n        Path[] subdirs = filteredStat2Paths(remoteIterToList(fc.listStatus(root)), true, hasFlatFiles);\r\n        List<List<FileStatus>> subsubdirs = new LinkedList<List<FileStatus>>();\r\n        int subsubdirCount = 0;\r\n        if (subdirs.length == 0) {\r\n            return new LinkedList<FileStatus>();\r\n        }\r\n        String newTail = tail.substring(2);\r\n        for (int i = 0; i < subdirs.length; ++i) {\r\n            subsubdirs.add(localGlobber(fc, subdirs[i], newTail, filter, null));\r\n            subsubdirCount += subsubdirs.get(i).size();\r\n        }\r\n        List<FileStatus> result = new LinkedList<FileStatus>();\r\n        for (int i = 0; i < subsubdirs.size(); ++i) {\r\n            result.addAll(subsubdirs.get(i));\r\n        }\r\n        return result;\r\n    }\r\n    if (tail.startsWith(\"/\")) {\r\n        int split = tail.indexOf('/', 1);\r\n        if (split < 0) {\r\n            return listFilteredStatus(fc, new Path(root, tail.substring(1)), filter);\r\n        } else {\r\n            String thisSegment = tail.substring(1, split);\r\n            String newTail = tail.substring(split);\r\n            return localGlobber(fc, new Path(root, thisSegment), newTail, filter, hasFlatFiles);\r\n        }\r\n    }\r\n    IOException e = new IOException(\"localGlobber: bad tail\");\r\n    throw e;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "listFilteredStatus",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "List<FileStatus> listFilteredStatus(FileContext fc, Path root, PathFilter filter) throws IOException\n{\r\n    List<FileStatus> fsList = remoteIterToList(fc.listStatus(root));\r\n    if (filter == null) {\r\n        return fsList;\r\n    } else {\r\n        List<FileStatus> filteredList = new LinkedList<FileStatus>();\r\n        for (FileStatus fs : fsList) {\r\n            if (filter.accept(fs.getPath())) {\r\n                filteredList.add(fs);\r\n            }\r\n        }\r\n        return filteredList;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "remoteIterToList",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "List<FileStatus> remoteIterToList(RemoteIterator<FileStatus> rIter) throws IOException\n{\r\n    List<FileStatus> fsList = new LinkedList<FileStatus>();\r\n    if (rIter == null)\r\n        return fsList;\r\n    while (rIter.hasNext()) {\r\n        fsList.add(rIter.next());\r\n    }\r\n    return fsList;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "filteredStat2Paths",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Path[] filteredStat2Paths(List<FileStatus> stats, boolean dirs, AtomicBoolean hasMismatches)\n{\r\n    int resultCount = 0;\r\n    if (hasMismatches == null) {\r\n        hasMismatches = new AtomicBoolean(false);\r\n    }\r\n    for (int i = 0; i < stats.size(); ++i) {\r\n        if (stats.get(i).isDirectory() == dirs) {\r\n            stats.set(resultCount++, stats.get(i));\r\n        } else {\r\n            hasMismatches.set(true);\r\n        }\r\n    }\r\n    Path[] result = new Path[resultCount];\r\n    for (int i = 0; i < resultCount; i++) {\r\n        result[i] = stats.get(i).getPath();\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getPreviousJobHistoryPath",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Path getPreviousJobHistoryPath(Configuration conf, ApplicationAttemptId applicationAttemptId) throws IOException\n{\r\n    String jobId = TypeConverter.fromYarn(applicationAttemptId.getApplicationId()).toString();\r\n    String jobhistoryDir = JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(conf, jobId);\r\n    Path histDirPath = FileContext.getFileContext(conf).makeQualified(new Path(jobhistoryDir));\r\n    FileContext fc = FileContext.getFileContext(histDirPath.toUri(), conf);\r\n    return fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath, jobId, (applicationAttemptId.getAttemptId() - 1)));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\jobhistory",
  "methodName" : "getHistoryDirsForCleaning",
  "errType" : [ "NumberFormatException", "NumberFormatException", "NumberFormatException" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "List<FileStatus> getHistoryDirsForCleaning(FileContext fc, Path root, long cutoff) throws IOException\n{\r\n    List<FileStatus> fsList = new ArrayList<FileStatus>();\r\n    Calendar cCal = Calendar.getInstance();\r\n    cCal.setTimeInMillis(cutoff);\r\n    int cYear = cCal.get(Calendar.YEAR);\r\n    int cMonth = cCal.get(Calendar.MONTH) + 1;\r\n    int cDate = cCal.get(Calendar.DATE);\r\n    RemoteIterator<FileStatus> yearDirIt = fc.listStatus(root);\r\n    while (yearDirIt.hasNext()) {\r\n        FileStatus yearDir = yearDirIt.next();\r\n        try {\r\n            int year = Integer.parseInt(yearDir.getPath().getName());\r\n            if (year <= cYear) {\r\n                RemoteIterator<FileStatus> monthDirIt = fc.listStatus(yearDir.getPath());\r\n                while (monthDirIt.hasNext()) {\r\n                    FileStatus monthDir = monthDirIt.next();\r\n                    try {\r\n                        int month = Integer.parseInt(monthDir.getPath().getName());\r\n                        if (year < cYear || month <= cMonth) {\r\n                            RemoteIterator<FileStatus> dateDirIt = fc.listStatus(monthDir.getPath());\r\n                            while (dateDirIt.hasNext()) {\r\n                                FileStatus dateDir = dateDirIt.next();\r\n                                try {\r\n                                    int date = Integer.parseInt(dateDir.getPath().getName());\r\n                                    if (year < cYear || month < cMonth || date <= cDate) {\r\n                                        fsList.addAll(remoteIterToList(fc.listStatus(dateDir.getPath())));\r\n                                    }\r\n                                } catch (NumberFormatException nfe) {\r\n                                }\r\n                            }\r\n                        }\r\n                    } catch (NumberFormatException nfe) {\r\n                    }\r\n                }\r\n            }\r\n        } catch (NumberFormatException nfe) {\r\n        }\r\n    }\r\n    return fsList;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\security\\client",
  "methodName" : "selectToken",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Token<MRDelegationTokenIdentifier> selectToken(Text service, Collection<Token<? extends TokenIdentifier>> tokens)\n{\r\n    if (service == null) {\r\n        return null;\r\n    }\r\n    LOG.debug(\"Looking for a token with service \" + service.toString());\r\n    for (Token<? extends TokenIdentifier> token : tokens) {\r\n        if (LOG.isDebugEnabled()) {\r\n            LOG.debug(\"Token kind is \" + token.getKind().toString() + \" and the token's service name is \" + token.getService());\r\n        }\r\n        if (MRDelegationTokenIdentifier.KIND_NAME.equals(token.getKind()) && service.equals(token.getService())) {\r\n            return (Token<MRDelegationTokenIdentifier>) token;\r\n        }\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getProto",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "GetTaskReportRequestProto getProto()\n{\r\n    mergeLocalToProto();\r\n    proto = viaProto ? proto : builder.build();\r\n    viaProto = true;\r\n    return proto;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void mergeLocalToBuilder()\n{\r\n    if (this.taskId != null) {\r\n        builder.setTaskId(convertToProtoFormat(this.taskId));\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "mergeLocalToProto",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void mergeLocalToProto()\n{\r\n    if (viaProto)\r\n        maybeInitBuilder();\r\n    mergeLocalToBuilder();\r\n    proto = builder.build();\r\n    viaProto = true;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "maybeInitBuilder",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void maybeInitBuilder()\n{\r\n    if (viaProto || builder == null) {\r\n        builder = GetTaskReportRequestProto.newBuilder(proto);\r\n    }\r\n    viaProto = false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "getTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskId getTaskId()\n{\r\n    GetTaskReportRequestProtoOrBuilder p = viaProto ? proto : builder;\r\n    if (this.taskId != null) {\r\n        return this.taskId;\r\n    }\r\n    if (!p.hasTaskId()) {\r\n        return null;\r\n    }\r\n    this.taskId = convertFromProtoFormat(p.getTaskId());\r\n    return this.taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "setTaskId",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setTaskId(TaskId taskId)\n{\r\n    maybeInitBuilder();\r\n    if (taskId == null)\r\n        builder.clearTaskId();\r\n    this.taskId = taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertFromProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskIdPBImpl convertFromProtoFormat(TaskIdProto p)\n{\r\n    return new TaskIdPBImpl(p);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\api\\protocolrecords\\impl\\pb",
  "methodName" : "convertToProtoFormat",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskIdProto convertToProtoFormat(TaskId t)\n{\r\n    return ((TaskIdPBImpl) t).getProto();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "org.apache.hadoop.mapred.JobID fromYarn(JobId id)\n{\r\n    String identifier = fromClusterTimeStamp(id.getAppId().getClusterTimestamp());\r\n    return new org.apache.hadoop.mapred.JobID(identifier, id.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.JobID fromYarn(ApplicationId appID)\n{\r\n    String identifier = fromClusterTimeStamp(appID.getClusterTimestamp());\r\n    return new org.apache.hadoop.mapred.JobID(identifier, appID.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "JobId toYarn(org.apache.hadoop.mapreduce.JobID id)\n{\r\n    JobId jobId = recordFactory.newRecordInstance(JobId.class);\r\n    jobId.setId(id.getId());\r\n    ApplicationId appId = ApplicationId.newInstance(toClusterTimeStamp(id.getJtIdentifier()), id.getId());\r\n    jobId.setAppId(appId);\r\n    return jobId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarnApplicationPriority",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int toYarnApplicationPriority(String priority)\n{\r\n    JobPriority jobPriority = JobPriority.valueOf(priority);\r\n    switch(jobPriority) {\r\n        case VERY_HIGH:\r\n            return 5;\r\n        case HIGH:\r\n            return 4;\r\n        case NORMAL:\r\n            return 3;\r\n        case LOW:\r\n            return 2;\r\n        case VERY_LOW:\r\n            return 1;\r\n        case DEFAULT:\r\n            return 0;\r\n    }\r\n    throw new IllegalArgumentException(\"Unrecognized priority: \" + priority);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromClusterTimeStamp",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String fromClusterTimeStamp(long clusterTimeStamp)\n{\r\n    return Long.toString(clusterTimeStamp);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toClusterTimeStamp",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long toClusterTimeStamp(String identifier)\n{\r\n    return Long.parseLong(identifier);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.TaskType fromYarn(TaskType taskType)\n{\r\n    switch(taskType) {\r\n        case MAP:\r\n            return org.apache.hadoop.mapreduce.TaskType.MAP;\r\n        case REDUCE:\r\n            return org.apache.hadoop.mapreduce.TaskType.REDUCE;\r\n        default:\r\n            throw new YarnRuntimeException(\"Unrecognized task type: \" + taskType);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskType toYarn(org.apache.hadoop.mapreduce.TaskType taskType)\n{\r\n    switch(taskType) {\r\n        case MAP:\r\n            return TaskType.MAP;\r\n        case REDUCE:\r\n            return TaskType.REDUCE;\r\n        default:\r\n            throw new YarnRuntimeException(\"Unrecognized task type: \" + taskType);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "org.apache.hadoop.mapred.TaskID fromYarn(TaskId id)\n{\r\n    return new org.apache.hadoop.mapred.TaskID(fromYarn(id.getJobId()), fromYarn(id.getTaskType()), id.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "TaskId toYarn(org.apache.hadoop.mapreduce.TaskID id)\n{\r\n    TaskId taskId = recordFactory.newRecordInstance(TaskId.class);\r\n    taskId.setId(id.getId());\r\n    taskId.setTaskType(toYarn(id.getTaskType()));\r\n    taskId.setJobId(toYarn(id.getJobID()));\r\n    return taskId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskAttemptState toYarn(org.apache.hadoop.mapred.TaskStatus.State state)\n{\r\n    switch(state) {\r\n        case COMMIT_PENDING:\r\n            return TaskAttemptState.COMMIT_PENDING;\r\n        case FAILED:\r\n        case FAILED_UNCLEAN:\r\n            return TaskAttemptState.FAILED;\r\n        case KILLED:\r\n        case KILLED_UNCLEAN:\r\n            return TaskAttemptState.KILLED;\r\n        case RUNNING:\r\n            return TaskAttemptState.RUNNING;\r\n        case SUCCEEDED:\r\n            return TaskAttemptState.SUCCEEDED;\r\n        case UNASSIGNED:\r\n            return TaskAttemptState.STARTING;\r\n        default:\r\n            throw new YarnRuntimeException(\"Unrecognized State: \" + state);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Phase toYarn(org.apache.hadoop.mapred.TaskStatus.Phase phase)\n{\r\n    switch(phase) {\r\n        case STARTING:\r\n            return Phase.STARTING;\r\n        case MAP:\r\n            return Phase.MAP;\r\n        case SHUFFLE:\r\n            return Phase.SHUFFLE;\r\n        case SORT:\r\n            return Phase.SORT;\r\n        case REDUCE:\r\n            return Phase.REDUCE;\r\n        case CLEANUP:\r\n            return Phase.CLEANUP;\r\n        default:\r\n            break;\r\n    }\r\n    throw new YarnRuntimeException(\"Unrecognized Phase: \" + phase);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskCompletionEvent[] fromYarn(TaskAttemptCompletionEvent[] newEvents)\n{\r\n    TaskCompletionEvent[] oldEvents = new TaskCompletionEvent[newEvents.length];\r\n    int i = 0;\r\n    for (TaskAttemptCompletionEvent newEvent : newEvents) {\r\n        oldEvents[i++] = fromYarn(newEvent);\r\n    }\r\n    return oldEvents;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "TaskCompletionEvent fromYarn(TaskAttemptCompletionEvent newEvent)\n{\r\n    return new TaskCompletionEvent(newEvent.getEventId(), fromYarn(newEvent.getAttemptId()), newEvent.getAttemptId().getId(), newEvent.getAttemptId().getTaskId().getTaskType().equals(TaskType.MAP), fromYarn(newEvent.getStatus()), newEvent.getMapOutputServerAddress());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "TaskCompletionEvent.Status fromYarn(TaskAttemptCompletionEventStatus newStatus)\n{\r\n    switch(newStatus) {\r\n        case FAILED:\r\n            return TaskCompletionEvent.Status.FAILED;\r\n        case KILLED:\r\n            return TaskCompletionEvent.Status.KILLED;\r\n        case OBSOLETE:\r\n            return TaskCompletionEvent.Status.OBSOLETE;\r\n        case SUCCEEDED:\r\n            return TaskCompletionEvent.Status.SUCCEEDED;\r\n        case TIPFAILED:\r\n            return TaskCompletionEvent.Status.TIPFAILED;\r\n    }\r\n    throw new YarnRuntimeException(\"Unrecognized status: \" + newStatus);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "org.apache.hadoop.mapred.TaskAttemptID fromYarn(TaskAttemptId id)\n{\r\n    return new org.apache.hadoop.mapred.TaskAttemptID(fromYarn(id.getTaskId()), id.getId());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TaskAttemptId toYarn(org.apache.hadoop.mapred.TaskAttemptID id)\n{\r\n    TaskAttemptId taskAttemptId = recordFactory.newRecordInstance(TaskAttemptId.class);\r\n    taskAttemptId.setTaskId(toYarn(id.getTaskID()));\r\n    taskAttemptId.setId(id.getId());\r\n    return taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "TaskAttemptId toYarn(org.apache.hadoop.mapreduce.TaskAttemptID id)\n{\r\n    TaskAttemptId taskAttemptId = recordFactory.newRecordInstance(TaskAttemptId.class);\r\n    taskAttemptId.setTaskId(toYarn(id.getTaskID()));\r\n    taskAttemptId.setId(id.getId());\r\n    return taskAttemptId;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.Counters fromYarn(Counters yCntrs)\n{\r\n    if (yCntrs == null) {\r\n        return null;\r\n    }\r\n    org.apache.hadoop.mapreduce.Counters counters = new org.apache.hadoop.mapreduce.Counters();\r\n    for (CounterGroup yGrp : yCntrs.getAllCounterGroups().values()) {\r\n        counters.addGroup(yGrp.getName(), yGrp.getDisplayName());\r\n        for (Counter yCntr : yGrp.getAllCounters().values()) {\r\n            org.apache.hadoop.mapreduce.Counter c = counters.findCounter(yGrp.getName(), yCntr.getName());\r\n            if (c != null) {\r\n                c.setValue(yCntr.getValue());\r\n            }\r\n        }\r\n    }\r\n    return counters;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "Counters toYarn(org.apache.hadoop.mapred.Counters counters)\n{\r\n    if (counters == null) {\r\n        return null;\r\n    }\r\n    Counters yCntrs = recordFactory.newRecordInstance(Counters.class);\r\n    yCntrs.addAllCounterGroups(new HashMap<String, CounterGroup>());\r\n    for (org.apache.hadoop.mapred.Counters.Group grp : counters) {\r\n        CounterGroup yGrp = recordFactory.newRecordInstance(CounterGroup.class);\r\n        yGrp.setName(grp.getName());\r\n        yGrp.setDisplayName(grp.getDisplayName());\r\n        yGrp.addAllCounters(new HashMap<String, Counter>());\r\n        for (org.apache.hadoop.mapred.Counters.Counter cntr : grp) {\r\n            Counter yCntr = recordFactory.newRecordInstance(Counter.class);\r\n            yCntr.setName(cntr.getName());\r\n            yCntr.setDisplayName(cntr.getDisplayName());\r\n            yCntr.setValue(cntr.getValue());\r\n            yGrp.setCounter(yCntr.getName(), yCntr);\r\n        }\r\n        yCntrs.setCounterGroup(yGrp.getName(), yGrp);\r\n    }\r\n    return yCntrs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "toYarn",
  "errType" : null,
  "containingMethodsNum" : 12,
  "sourceCodeText" : "Counters toYarn(org.apache.hadoop.mapreduce.Counters counters)\n{\r\n    if (counters == null) {\r\n        return null;\r\n    }\r\n    Counters yCntrs = recordFactory.newRecordInstance(Counters.class);\r\n    yCntrs.addAllCounterGroups(new HashMap<String, CounterGroup>());\r\n    for (org.apache.hadoop.mapreduce.CounterGroup grp : counters) {\r\n        CounterGroup yGrp = recordFactory.newRecordInstance(CounterGroup.class);\r\n        yGrp.setName(grp.getName());\r\n        yGrp.setDisplayName(grp.getDisplayName());\r\n        yGrp.addAllCounters(new HashMap<String, Counter>());\r\n        for (org.apache.hadoop.mapreduce.Counter cntr : grp) {\r\n            Counter yCntr = recordFactory.newRecordInstance(Counter.class);\r\n            yCntr.setName(cntr.getName());\r\n            yCntr.setDisplayName(cntr.getDisplayName());\r\n            yCntr.setValue(cntr.getValue());\r\n            yGrp.setCounter(yCntr.getName(), yCntr);\r\n        }\r\n        yCntrs.setCounterGroup(yGrp.getName(), yGrp);\r\n    }\r\n    return yCntrs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "JobStatus fromYarn(JobReport jobreport, String trackingUrl)\n{\r\n    JobPriority jobPriority = (jobreport.getJobPriority() == null) ? JobPriority.DEFAULT : fromYarnPriority(jobreport.getJobPriority().getPriority());\r\n    JobStatus jobStatus = new org.apache.hadoop.mapred.JobStatus(fromYarn(jobreport.getJobId()), jobreport.getSetupProgress(), jobreport.getMapProgress(), jobreport.getReduceProgress(), jobreport.getCleanupProgress(), fromYarn(jobreport.getJobState()), jobPriority, jobreport.getUser(), jobreport.getJobName(), jobreport.getJobFile(), trackingUrl, jobreport.isUber(), jobreport.getHistoryFile());\r\n    jobStatus.setStartTime(jobreport.getStartTime());\r\n    jobStatus.setFinishTime(jobreport.getFinishTime());\r\n    jobStatus.setFailureInfo(jobreport.getDiagnostics());\r\n    return jobStatus;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarnPriority",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "JobPriority fromYarnPriority(int priority)\n{\r\n    switch(priority) {\r\n        case 5:\r\n            return JobPriority.VERY_HIGH;\r\n        case 4:\r\n            return JobPriority.HIGH;\r\n        case 3:\r\n            return JobPriority.NORMAL;\r\n        case 2:\r\n            return JobPriority.LOW;\r\n        case 1:\r\n            return JobPriority.VERY_LOW;\r\n        case 0:\r\n            return JobPriority.DEFAULT;\r\n        default:\r\n            break;\r\n    }\r\n    return JobPriority.UNDEFINED_PRIORITY;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarnApplicationPriority",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.JobPriority fromYarnApplicationPriority(int priority)\n{\r\n    switch(priority) {\r\n        case 5:\r\n            return org.apache.hadoop.mapreduce.JobPriority.VERY_HIGH;\r\n        case 4:\r\n            return org.apache.hadoop.mapreduce.JobPriority.HIGH;\r\n        case 3:\r\n            return org.apache.hadoop.mapreduce.JobPriority.NORMAL;\r\n        case 2:\r\n            return org.apache.hadoop.mapreduce.JobPriority.LOW;\r\n        case 1:\r\n            return org.apache.hadoop.mapreduce.JobPriority.VERY_LOW;\r\n        case 0:\r\n            return org.apache.hadoop.mapreduce.JobPriority.DEFAULT;\r\n        default:\r\n            break;\r\n    }\r\n    return org.apache.hadoop.mapreduce.JobPriority.UNDEFINED_PRIORITY;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "org.apache.hadoop.mapreduce.QueueState fromYarn(QueueState state)\n{\r\n    org.apache.hadoop.mapreduce.QueueState qState = org.apache.hadoop.mapreduce.QueueState.getState(StringUtils.toLowerCase(state.toString()));\r\n    return qState;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int fromYarn(JobState state)\n{\r\n    switch(state) {\r\n        case NEW:\r\n        case INITED:\r\n            return org.apache.hadoop.mapred.JobStatus.PREP;\r\n        case RUNNING:\r\n            return org.apache.hadoop.mapred.JobStatus.RUNNING;\r\n        case KILLED:\r\n            return org.apache.hadoop.mapred.JobStatus.KILLED;\r\n        case SUCCEEDED:\r\n            return org.apache.hadoop.mapred.JobStatus.SUCCEEDED;\r\n        case FAILED:\r\n        case ERROR:\r\n            return org.apache.hadoop.mapred.JobStatus.FAILED;\r\n    }\r\n    throw new YarnRuntimeException(\"Unrecognized job state: \" + state);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "org.apache.hadoop.mapred.TIPStatus fromYarn(TaskState state)\n{\r\n    switch(state) {\r\n        case NEW:\r\n        case SCHEDULED:\r\n            return org.apache.hadoop.mapred.TIPStatus.PENDING;\r\n        case RUNNING:\r\n            return org.apache.hadoop.mapred.TIPStatus.RUNNING;\r\n        case KILLED:\r\n            return org.apache.hadoop.mapred.TIPStatus.KILLED;\r\n        case SUCCEEDED:\r\n            return org.apache.hadoop.mapred.TIPStatus.COMPLETE;\r\n        case FAILED:\r\n            return org.apache.hadoop.mapred.TIPStatus.FAILED;\r\n    }\r\n    throw new YarnRuntimeException(\"Unrecognized task state: \" + state);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 16,
  "sourceCodeText" : "TaskReport fromYarn(org.apache.hadoop.mapreduce.v2.api.records.TaskReport report)\n{\r\n    String[] diagnostics = null;\r\n    if (report.getDiagnosticsList() != null) {\r\n        diagnostics = new String[report.getDiagnosticsCount()];\r\n        int i = 0;\r\n        for (String cs : report.getDiagnosticsList()) {\r\n            diagnostics[i++] = cs.toString();\r\n        }\r\n    } else {\r\n        diagnostics = new String[0];\r\n    }\r\n    TaskReport rep = new TaskReport(fromYarn(report.getTaskId()), report.getProgress(), report.getTaskState().toString(), diagnostics, fromYarn(report.getTaskState()), report.getStartTime(), report.getFinishTime(), fromYarn(report.getCounters()));\r\n    List<org.apache.hadoop.mapreduce.TaskAttemptID> runningAtts = new ArrayList<org.apache.hadoop.mapreduce.TaskAttemptID>();\r\n    for (org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId id : report.getRunningAttemptsList()) {\r\n        runningAtts.add(fromYarn(id));\r\n    }\r\n    rep.setRunningTaskAttemptIds(runningAtts);\r\n    if (report.getSuccessfulAttempt() != null) {\r\n        rep.setSuccessfulAttemptId(fromYarn(report.getSuccessfulAttempt()));\r\n    }\r\n    return rep;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<TaskReport> fromYarn(List<org.apache.hadoop.mapreduce.v2.api.records.TaskReport> taskReports)\n{\r\n    List<TaskReport> reports = new ArrayList<TaskReport>();\r\n    for (org.apache.hadoop.mapreduce.v2.api.records.TaskReport r : taskReports) {\r\n        reports.add(fromYarn(r));\r\n    }\r\n    return reports;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "State fromYarn(YarnApplicationState yarnApplicationState, FinalApplicationStatus finalApplicationStatus)\n{\r\n    switch(yarnApplicationState) {\r\n        case NEW:\r\n        case NEW_SAVING:\r\n        case SUBMITTED:\r\n        case ACCEPTED:\r\n            return State.PREP;\r\n        case RUNNING:\r\n            return State.RUNNING;\r\n        case FINISHED:\r\n            if (finalApplicationStatus == FinalApplicationStatus.SUCCEEDED) {\r\n                return State.SUCCEEDED;\r\n            } else if (finalApplicationStatus == FinalApplicationStatus.KILLED) {\r\n                return State.KILLED;\r\n            }\r\n        case FAILED:\r\n            return State.FAILED;\r\n        case KILLED:\r\n            return State.KILLED;\r\n    }\r\n    throw new YarnRuntimeException(\"Unrecognized application state: \" + yarnApplicationState);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskTrackerInfo fromYarn(NodeReport node)\n{\r\n    TaskTrackerInfo taskTracker = new TaskTrackerInfo(TT_NAME_PREFIX + node.getNodeId().toString());\r\n    return taskTracker;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarnNodes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskTrackerInfo[] fromYarnNodes(List<NodeReport> nodes)\n{\r\n    List<TaskTrackerInfo> taskTrackers = new ArrayList<TaskTrackerInfo>();\r\n    for (NodeReport node : nodes) {\r\n        taskTrackers.add(fromYarn(node));\r\n    }\r\n    return taskTrackers.toArray(new TaskTrackerInfo[nodes.size()]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "JobStatus fromYarn(ApplicationReport application, String jobFile)\n{\r\n    String trackingUrl = application.getTrackingUrl();\r\n    trackingUrl = trackingUrl == null ? \"\" : trackingUrl;\r\n    JobStatus jobStatus = new JobStatus(TypeConverter.fromYarn(application.getApplicationId()), 0.0f, 0.0f, 0.0f, 0.0f, TypeConverter.fromYarn(application.getYarnApplicationState(), application.getFinalApplicationStatus()), fromYarnApplicationPriority((application.getPriority() == null) ? 0 : application.getPriority().getPriority()), application.getUser(), application.getName(), application.getQueue(), jobFile, trackingUrl, false);\r\n    jobStatus.setSchedulingInfo(trackingUrl);\r\n    jobStatus.setStartTime(application.getStartTime());\r\n    jobStatus.setFinishTime(application.getFinishTime());\r\n    jobStatus.setFailureInfo(application.getDiagnostics());\r\n    ApplicationResourceUsageReport resourceUsageReport = application.getApplicationResourceUsageReport();\r\n    if (resourceUsageReport != null) {\r\n        jobStatus.setNeededMem((int) resourceUsageReport.getNeededResources().getMemorySize());\r\n        jobStatus.setNumReservedSlots(resourceUsageReport.getNumReservedContainers());\r\n        jobStatus.setNumUsedSlots(resourceUsageReport.getNumUsedContainers());\r\n        jobStatus.setReservedMem((int) resourceUsageReport.getReservedResources().getMemorySize());\r\n        jobStatus.setUsedMem((int) resourceUsageReport.getUsedResources().getMemorySize());\r\n    }\r\n    return jobStatus;\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarnApps",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "JobStatus[] fromYarnApps(List<ApplicationReport> applications, Configuration conf)\n{\r\n    List<JobStatus> jobStatuses = new ArrayList<JobStatus>();\r\n    for (ApplicationReport application : applications) {\r\n        org.apache.hadoop.mapreduce.JobID jobId = TypeConverter.fromYarn(application.getApplicationId());\r\n        jobStatuses.add(TypeConverter.fromYarn(application, MRApps.getJobFile(conf, application.getUser(), jobId)));\r\n    }\r\n    return jobStatuses.toArray(new JobStatus[jobStatuses.size()]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarn",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "QueueInfo fromYarn(org.apache.hadoop.yarn.api.records.QueueInfo queueInfo, Configuration conf)\n{\r\n    QueueInfo toReturn = new QueueInfo(queueInfo.getQueueName(), \"Capacity: \" + queueInfo.getCapacity() * 100 + \", MaximumCapacity: \" + (queueInfo.getMaximumCapacity() < 0 ? \"UNDEFINED\" : queueInfo.getMaximumCapacity() * 100) + \", CurrentCapacity: \" + queueInfo.getCurrentCapacity() * 100, fromYarn(queueInfo.getQueueState()), TypeConverter.fromYarnApps(queueInfo.getApplications(), conf));\r\n    List<QueueInfo> childQueues = new ArrayList<QueueInfo>();\r\n    for (org.apache.hadoop.yarn.api.records.QueueInfo childQueue : queueInfo.getChildQueues()) {\r\n        childQueues.add(fromYarn(childQueue, conf));\r\n    }\r\n    toReturn.setQueueChildren(childQueues);\r\n    return toReturn;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarnQueueInfo",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "QueueInfo[] fromYarnQueueInfo(List<org.apache.hadoop.yarn.api.records.QueueInfo> queues, Configuration conf)\n{\r\n    List<QueueInfo> queueInfos = new ArrayList<QueueInfo>(queues.size());\r\n    for (org.apache.hadoop.yarn.api.records.QueueInfo queue : queues) {\r\n        queueInfos.add(TypeConverter.fromYarn(queue, conf));\r\n    }\r\n    return queueInfos.toArray(new QueueInfo[queueInfos.size()]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce",
  "methodName" : "fromYarnQueueUserAclsInfo",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "QueueAclsInfo[] fromYarnQueueUserAclsInfo(List<QueueUserACLInfo> userAcls)\n{\r\n    List<QueueAclsInfo> acls = new ArrayList<QueueAclsInfo>();\r\n    for (QueueUserACLInfo aclInfo : userAcls) {\r\n        List<String> operations = new ArrayList<String>();\r\n        for (QueueACL qAcl : aclInfo.getUserAcls()) {\r\n            operations.add(qAcl.toString());\r\n        }\r\n        QueueAclsInfo acl = new QueueAclsInfo(aclInfo.getQueueName(), operations.toArray(new String[operations.size()]));\r\n        acls.add(acl);\r\n    }\r\n    return acls.toArray(new QueueAclsInfo[acls.size()]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void initialize(Configuration conf)\n{\r\n    setHttpPolicyInYARN(conf.get(YarnConfiguration.YARN_HTTP_POLICY_KEY, YarnConfiguration.YARN_HTTP_POLICY_DEFAULT));\r\n    setHttpPolicyInJHS(conf.get(JHAdminConfig.MR_HS_HTTP_POLICY, JHAdminConfig.DEFAULT_MR_HS_HTTP_POLICY));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setHttpPolicyInJHS",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setHttpPolicyInJHS(String policy)\n{\r\n    MRWebAppUtil.httpPolicyInJHS = Policy.fromString(policy);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setHttpPolicyInYARN",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setHttpPolicyInYARN(String policy)\n{\r\n    MRWebAppUtil.httpPolicyInYarn = Policy.fromString(policy);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getJHSHttpPolicy",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Policy getJHSHttpPolicy()\n{\r\n    return MRWebAppUtil.httpPolicyInJHS;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getYARNHttpPolicy",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Policy getYARNHttpPolicy()\n{\r\n    return MRWebAppUtil.httpPolicyInYarn;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getYARNWebappScheme",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getYARNWebappScheme()\n{\r\n    return httpPolicyInYarn == HttpConfig.Policy.HTTPS_ONLY ? \"https://\" : \"http://\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getJHSWebappScheme",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getJHSWebappScheme(Configuration conf)\n{\r\n    setHttpPolicyInJHS(conf.get(JHAdminConfig.MR_HS_HTTP_POLICY, JHAdminConfig.DEFAULT_MR_HS_HTTP_POLICY));\r\n    return httpPolicyInJHS == HttpConfig.Policy.HTTPS_ONLY ? \"https://\" : \"http://\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setJHSWebappURLWithoutScheme",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setJHSWebappURLWithoutScheme(Configuration conf, String hostAddress)\n{\r\n    if (httpPolicyInJHS == Policy.HTTPS_ONLY) {\r\n        conf.set(JHAdminConfig.MR_HISTORY_WEBAPP_HTTPS_ADDRESS, hostAddress);\r\n    } else {\r\n        conf.set(JHAdminConfig.MR_HISTORY_WEBAPP_ADDRESS, hostAddress);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getJHSWebappURLWithoutScheme",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getJHSWebappURLWithoutScheme(Configuration conf)\n{\r\n    if (httpPolicyInJHS == Policy.HTTPS_ONLY) {\r\n        return conf.get(JHAdminConfig.MR_HISTORY_WEBAPP_HTTPS_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_HTTPS_ADDRESS);\r\n    } else {\r\n        return conf.get(JHAdminConfig.MR_HISTORY_WEBAPP_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_ADDRESS);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getJHSWebappURLWithScheme",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getJHSWebappURLWithScheme(Configuration conf)\n{\r\n    return getJHSWebappScheme(conf) + getJHSWebappURLWithoutScheme(conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getJHSWebBindAddress",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "InetSocketAddress getJHSWebBindAddress(Configuration conf)\n{\r\n    if (httpPolicyInJHS == Policy.HTTPS_ONLY) {\r\n        return conf.getSocketAddr(JHAdminConfig.MR_HISTORY_BIND_HOST, JHAdminConfig.MR_HISTORY_WEBAPP_HTTPS_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_HTTPS_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_HTTPS_PORT);\r\n    } else {\r\n        return conf.getSocketAddr(JHAdminConfig.MR_HISTORY_BIND_HOST, JHAdminConfig.MR_HISTORY_WEBAPP_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_PORT);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getApplicationWebURLOnJHSWithoutScheme",
  "errType" : [ "NoSuchElementException" ],
  "containingMethodsNum" : 18,
  "sourceCodeText" : "String getApplicationWebURLOnJHSWithoutScheme(Configuration conf, ApplicationId appId) throws UnknownHostException\n{\r\n    String addr = getJHSWebappURLWithoutScheme(conf);\r\n    String port;\r\n    try {\r\n        Iterator<String> it = ADDR_SPLITTER.split(addr).iterator();\r\n        it.next();\r\n        port = it.next();\r\n    } catch (NoSuchElementException e) {\r\n        throw new IllegalArgumentException(\"MapReduce JobHistory WebApp Address\" + \" does not contain a valid host:port authority: \" + addr);\r\n    }\r\n    addr = conf.get(JHAdminConfig.MR_HISTORY_ADDRESS, JHAdminConfig.DEFAULT_MR_HISTORY_ADDRESS);\r\n    String host = ADDR_SPLITTER.split(addr).iterator().next();\r\n    String hsAddress = JOINER.join(host, \":\", port);\r\n    InetSocketAddress address = NetUtils.createSocketAddr(hsAddress, getDefaultJHSWebappPort(), getDefaultJHSWebappURLWithoutScheme());\r\n    StringBuffer sb = new StringBuffer();\r\n    if (address.getAddress() != null && (address.getAddress().isAnyLocalAddress() || address.getAddress().isLoopbackAddress())) {\r\n        sb.append(InetAddress.getLocalHost().getCanonicalHostName());\r\n    } else {\r\n        sb.append(address.getHostName());\r\n    }\r\n    sb.append(\":\").append(address.getPort());\r\n    sb.append(\"/jobhistory/job/\");\r\n    JobID jobId = TypeConverter.fromYarn(appId);\r\n    sb.append(jobId.toString());\r\n    return sb.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getApplicationWebURLOnJHSWithScheme",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getApplicationWebURLOnJHSWithScheme(Configuration conf, ApplicationId appId) throws UnknownHostException\n{\r\n    return getJHSWebappScheme(conf) + getApplicationWebURLOnJHSWithoutScheme(conf, appId);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getDefaultJHSWebappPort",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "int getDefaultJHSWebappPort()\n{\r\n    return httpPolicyInJHS == Policy.HTTPS_ONLY ? JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_HTTPS_PORT : JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_PORT;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getDefaultJHSWebappURLWithoutScheme",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getDefaultJHSWebappURLWithoutScheme()\n{\r\n    return httpPolicyInJHS == Policy.HTTPS_ONLY ? JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_HTTPS_ADDRESS : JHAdminConfig.DEFAULT_MR_HISTORY_WEBAPP_ADDRESS;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getAMWebappScheme",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getAMWebappScheme(Configuration conf)\n{\r\n    return conf.getBoolean(MRJobConfig.MR_AM_WEBAPP_HTTPS_ENABLED, MRJobConfig.DEFAULT_MR_AM_WEBAPP_HTTPS_ENABLED) ? \"https://\" : \"http://\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toString(JobId jid)\n{\r\n    return jid.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "toJobID",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "JobId toJobID(String jid)\n{\r\n    return TypeConverter.toYarn(JobID.forName(jid));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toString(TaskId tid)\n{\r\n    return tid.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "toTaskID",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskId toTaskID(String tid)\n{\r\n    return TypeConverter.toYarn(TaskID.forName(tid));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toString(TaskAttemptId taid)\n{\r\n    return taid.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "toTaskAttemptID",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptId toTaskAttemptID(String taid)\n{\r\n    return TypeConverter.toYarn(TaskAttemptID.forName(taid));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "taskSymbol",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String taskSymbol(TaskType type)\n{\r\n    switch(type) {\r\n        case MAP:\r\n            return \"m\";\r\n        case REDUCE:\r\n            return \"r\";\r\n    }\r\n    throw new YarnRuntimeException(\"Unknown task type: \" + type.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "taskType",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "TaskType taskType(String symbol)\n{\r\n    if (symbol.equals(\"m\"))\r\n        return TaskType.MAP;\r\n    if (symbol.equals(\"r\"))\r\n        return TaskType.REDUCE;\r\n    throw new YarnRuntimeException(\"Unknown task symbol: \" + symbol);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "taskAttemptState",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskAttemptStateUI taskAttemptState(String attemptStateStr)\n{\r\n    return TaskAttemptStateUI.valueOf(attemptStateStr);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "taskState",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "TaskStateUI taskState(String taskStateStr)\n{\r\n    return TaskStateUI.valueOf(taskStateStr);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getMRFrameworkName",
  "errType" : [ "URISyntaxException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "String getMRFrameworkName(Configuration conf)\n{\r\n    String frameworkName = null;\r\n    String framework = conf.get(MRJobConfig.MAPREDUCE_APPLICATION_FRAMEWORK_PATH, \"\");\r\n    if (!framework.isEmpty()) {\r\n        URI uri;\r\n        try {\r\n            uri = new URI(framework);\r\n        } catch (URISyntaxException e) {\r\n            throw new IllegalArgumentException(\"Unable to parse '\" + framework + \"' as a URI, check the setting for \" + MRJobConfig.MAPREDUCE_APPLICATION_FRAMEWORK_PATH, e);\r\n        }\r\n        frameworkName = uri.getFragment();\r\n        if (frameworkName == null) {\r\n            frameworkName = new Path(uri).getName();\r\n        }\r\n    }\r\n    return frameworkName;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setMRFrameworkClasspath",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void setMRFrameworkClasspath(Map<String, String> environment, Configuration conf) throws IOException\n{\r\n    if (conf.getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false)) {\r\n        MRApps.addToEnvironment(environment, Environment.CLASSPATH.name(), System.getProperty(\"java.class.path\"), conf);\r\n    }\r\n    boolean crossPlatform = conf.getBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM, MRConfig.DEFAULT_MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM);\r\n    String frameworkName = getMRFrameworkName(conf);\r\n    if (frameworkName == null) {\r\n        for (String c : conf.getStrings(YarnConfiguration.YARN_APPLICATION_CLASSPATH, crossPlatform ? YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH : YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH)) {\r\n            MRApps.addToEnvironment(environment, Environment.CLASSPATH.name(), c.trim(), conf);\r\n        }\r\n    }\r\n    boolean foundFrameworkInClasspath = (frameworkName == null);\r\n    for (String c : conf.getStrings(MRJobConfig.MAPREDUCE_APPLICATION_CLASSPATH, crossPlatform ? StringUtils.getStrings(MRJobConfig.DEFAULT_MAPREDUCE_CROSS_PLATFORM_APPLICATION_CLASSPATH) : StringUtils.getStrings(MRJobConfig.DEFAULT_MAPREDUCE_APPLICATION_CLASSPATH))) {\r\n        MRApps.addToEnvironment(environment, Environment.CLASSPATH.name(), c.trim(), conf);\r\n        if (!foundFrameworkInClasspath) {\r\n            foundFrameworkInClasspath = c.contains(frameworkName);\r\n        }\r\n    }\r\n    if (!foundFrameworkInClasspath) {\r\n        throw new IllegalArgumentException(\"Could not locate MapReduce framework name '\" + frameworkName + \"' in \" + MRJobConfig.MAPREDUCE_APPLICATION_CLASSPATH);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setClasspath",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void setClasspath(Map<String, String> environment, Configuration conf) throws IOException\n{\r\n    boolean userClassesTakesPrecedence = conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_USER_CLASSPATH_FIRST, false);\r\n    String classpathEnvVar = conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_CLASSLOADER, false) ? Environment.APP_CLASSPATH.name() : Environment.CLASSPATH.name();\r\n    MRApps.addToEnvironment(environment, classpathEnvVar, crossPlatformifyMREnv(conf, Environment.PWD), conf);\r\n    if (!userClassesTakesPrecedence) {\r\n        MRApps.setMRFrameworkClasspath(environment, conf);\r\n    }\r\n    MRApps.addToEnvironment(environment, classpathEnvVar, MRJobConfig.JOB_JAR + Path.SEPARATOR + \"*\", conf);\r\n    MRApps.addToEnvironment(environment, classpathEnvVar, MRJobConfig.JOB_JAR + Path.SEPARATOR + \"classes\" + Path.SEPARATOR, conf);\r\n    MRApps.addToEnvironment(environment, classpathEnvVar, MRJobConfig.JOB_JAR + Path.SEPARATOR + \"lib\" + Path.SEPARATOR + \"*\", conf);\r\n    MRApps.addToEnvironment(environment, classpathEnvVar, crossPlatformifyMREnv(conf, Environment.PWD) + Path.SEPARATOR + \"*\", conf);\r\n    addToClasspathIfNotJar(JobContextImpl.getFileClassPaths(conf), JobContextImpl.getCacheFiles(conf), conf, environment, classpathEnvVar);\r\n    addToClasspathIfNotJar(JobContextImpl.getArchiveClassPaths(conf), JobContextImpl.getCacheArchives(conf), conf, environment, classpathEnvVar);\r\n    if (userClassesTakesPrecedence) {\r\n        MRApps.setMRFrameworkClasspath(environment, conf);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "addToClasspathIfNotJar",
  "errType" : null,
  "containingMethodsNum" : 19,
  "sourceCodeText" : "void addToClasspathIfNotJar(Path[] paths, URI[] withLinks, Configuration conf, Map<String, String> environment, String classpathEnvVar) throws IOException\n{\r\n    if (paths != null) {\r\n        HashMap<Path, String> linkLookup = new HashMap<Path, String>();\r\n        if (withLinks != null) {\r\n            for (URI u : withLinks) {\r\n                Path p = new Path(u);\r\n                FileSystem remoteFS = p.getFileSystem(conf);\r\n                String name = p.getName();\r\n                String wildcard = null;\r\n                if (name.equals(DistributedCache.WILDCARD)) {\r\n                    wildcard = name;\r\n                    p = p.getParent();\r\n                }\r\n                p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory()));\r\n                if ((wildcard != null) && (u.getFragment() != null)) {\r\n                    throw new IOException(\"Invalid path URI: \" + p + \" - cannot \" + \"contain both a URI fragment and a wildcard\");\r\n                } else if (wildcard != null) {\r\n                    name = p.getName() + Path.SEPARATOR + wildcard;\r\n                } else if (u.getFragment() != null) {\r\n                    name = u.getFragment();\r\n                }\r\n                if (!StringUtils.toLowerCase(name).endsWith(\".jar\")) {\r\n                    String old = linkLookup.put(p, name);\r\n                    if ((old != null) && !name.equals(old)) {\r\n                        LOG.warn(\"The same path is included more than once \" + \"with different links or wildcards: \" + p + \" [\" + name + \", \" + old + \"]\");\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        for (Path p : paths) {\r\n            FileSystem remoteFS = p.getFileSystem(conf);\r\n            p = remoteFS.resolvePath(p.makeQualified(remoteFS.getUri(), remoteFS.getWorkingDirectory()));\r\n            String name = linkLookup.get(p);\r\n            if (name == null) {\r\n                name = p.getName();\r\n            }\r\n            if (!StringUtils.toLowerCase(name).endsWith(\".jar\")) {\r\n                MRApps.addToEnvironment(environment, classpathEnvVar, crossPlatformifyMREnv(conf, Environment.PWD) + Path.SEPARATOR + name, conf);\r\n            }\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setJobClassLoader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setJobClassLoader(Configuration conf) throws IOException\n{\r\n    setClassLoader(createJobClassLoader(conf), conf);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "createJobClassLoader",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "ClassLoader createJobClassLoader(Configuration conf) throws IOException\n{\r\n    ClassLoader jobClassLoader = null;\r\n    if (conf.getBoolean(MRJobConfig.MAPREDUCE_JOB_CLASSLOADER, false)) {\r\n        String appClasspath = System.getenv(Environment.APP_CLASSPATH.key());\r\n        if (appClasspath == null) {\r\n            LOG.warn(\"Not creating job classloader since APP_CLASSPATH is not set.\");\r\n        } else {\r\n            LOG.info(\"Creating job classloader\");\r\n            if (LOG.isDebugEnabled()) {\r\n                LOG.debug(\"APP_CLASSPATH=\" + appClasspath);\r\n            }\r\n            String[] systemClasses = getSystemClasses(conf);\r\n            jobClassLoader = createJobClassLoader(appClasspath, systemClasses);\r\n        }\r\n    }\r\n    return jobClassLoader;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setClassLoader",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void setClassLoader(ClassLoader classLoader, Configuration conf)\n{\r\n    if (classLoader != null) {\r\n        LOG.info(\"Setting classloader \" + classLoader + \" on the configuration and as the thread context classloader\");\r\n        conf.setClassLoader(classLoader);\r\n        Thread.currentThread().setContextClassLoader(classLoader);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getSystemClasses",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String[] getSystemClasses(Configuration conf)\n{\r\n    return conf.getTrimmedStrings(MRJobConfig.MAPREDUCE_JOB_CLASSLOADER_SYSTEM_CLASSES);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "createJobClassLoader",
  "errType" : [ "PrivilegedActionException" ],
  "containingMethodsNum" : 2,
  "sourceCodeText" : "ClassLoader createJobClassLoader(final String appClasspath, final String[] systemClasses) throws IOException\n{\r\n    try {\r\n        return AccessController.doPrivileged(new PrivilegedExceptionAction<ClassLoader>() {\r\n\r\n            @Override\r\n            public ClassLoader run() throws MalformedURLException {\r\n                return new ApplicationClassLoader(appClasspath, MRApps.class.getClassLoader(), Arrays.asList(systemClasses));\r\n            }\r\n        });\r\n    } catch (PrivilegedActionException e) {\r\n        Throwable t = e.getCause();\r\n        if (t instanceof MalformedURLException) {\r\n            throw (MalformedURLException) t;\r\n        }\r\n        throw new IOException(e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getStagingAreaDir",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "Path getStagingAreaDir(Configuration conf, String user)\n{\r\n    return new Path(conf.get(MRJobConfig.MR_AM_STAGING_DIR, MRJobConfig.DEFAULT_MR_AM_STAGING_DIR) + Path.SEPARATOR + user + Path.SEPARATOR + STAGING_CONSTANT);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getJobFile",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String getJobFile(Configuration conf, String user, org.apache.hadoop.mapreduce.JobID jobId)\n{\r\n    Path jobFile = new Path(MRApps.getStagingAreaDir(conf, user), jobId.toString() + Path.SEPARATOR + MRJobConfig.JOB_CONF_FILE);\r\n    return jobFile.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getEndJobCommitSuccessFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Path getEndJobCommitSuccessFile(Configuration conf, String user, JobId jobId)\n{\r\n    Path endCommitFile = new Path(MRApps.getStagingAreaDir(conf, user), jobId.toString() + Path.SEPARATOR + \"COMMIT_SUCCESS\");\r\n    return endCommitFile;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getEndJobCommitFailureFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Path getEndJobCommitFailureFile(Configuration conf, String user, JobId jobId)\n{\r\n    Path endCommitFile = new Path(MRApps.getStagingAreaDir(conf, user), jobId.toString() + Path.SEPARATOR + \"COMMIT_FAIL\");\r\n    return endCommitFile;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getStartJobCommitFile",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "Path getStartJobCommitFile(Configuration conf, String user, JobId jobId)\n{\r\n    Path startCommitFile = new Path(MRApps.getStagingAreaDir(conf, user), jobId.toString() + Path.SEPARATOR + \"COMMIT_STARTED\");\r\n    return startCommitFile;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setupDistributedCache",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void setupDistributedCache(Configuration conf, Map<String, LocalResource> localResources) throws IOException\n{\r\n    LocalResourceBuilder lrb = new LocalResourceBuilder();\r\n    lrb.setConf(conf);\r\n    lrb.setType(LocalResourceType.ARCHIVE);\r\n    lrb.setUris(JobContextImpl.getCacheArchives(conf));\r\n    lrb.setTimestamps(JobContextImpl.getArchiveTimestamps(conf));\r\n    lrb.setSizes(getFileSizes(conf, MRJobConfig.CACHE_ARCHIVES_SIZES));\r\n    lrb.setVisibilities(DistributedCache.getArchiveVisibilities(conf));\r\n    lrb.setSharedCacheUploadPolicies(Job.getArchiveSharedCacheUploadPolicies(conf));\r\n    lrb.createLocalResources(localResources);\r\n    lrb.setType(LocalResourceType.FILE);\r\n    lrb.setUris(JobContextImpl.getCacheFiles(conf));\r\n    lrb.setTimestamps(JobContextImpl.getFileTimestamps(conf));\r\n    lrb.setSizes(getFileSizes(conf, MRJobConfig.CACHE_FILES_SIZES));\r\n    lrb.setVisibilities(DistributedCache.getFileVisibilities(conf));\r\n    lrb.setSharedCacheUploadPolicies(Job.getFileSharedCacheUploadPolicies(conf));\r\n    lrb.createLocalResources(localResources);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setupDistributedCacheLocal",
  "errType" : null,
  "containingMethodsNum" : 17,
  "sourceCodeText" : "void setupDistributedCacheLocal(Configuration conf) throws IOException\n{\r\n    String localWorkDir = System.getenv(\"PWD\");\r\n    URI[] cacheArchives = JobContextImpl.getCacheArchives(conf);\r\n    if (cacheArchives != null) {\r\n        List<String> localArchives = new ArrayList<String>();\r\n        for (int i = 0; i < cacheArchives.length; ++i) {\r\n            URI u = cacheArchives[i];\r\n            Path p = new Path(u);\r\n            Path name = new Path((null == u.getFragment()) ? p.getName() : u.getFragment());\r\n            String linkName = name.toUri().getPath();\r\n            localArchives.add(new Path(localWorkDir, linkName).toUri().getPath());\r\n        }\r\n        if (!localArchives.isEmpty()) {\r\n            conf.set(MRJobConfig.CACHE_LOCALARCHIVES, StringUtils.arrayToString(localArchives.toArray(new String[localArchives.size()])));\r\n        }\r\n    }\r\n    URI[] cacheFiles = JobContextImpl.getCacheFiles(conf);\r\n    if (cacheFiles != null) {\r\n        List<String> localFiles = new ArrayList<String>();\r\n        for (int i = 0; i < cacheFiles.length; ++i) {\r\n            URI u = cacheFiles[i];\r\n            Path p = new Path(u);\r\n            Path name = new Path((null == u.getFragment()) ? p.getName() : u.getFragment());\r\n            String linkName = name.toUri().getPath();\r\n            localFiles.add(new Path(localWorkDir, linkName).toUri().getPath());\r\n        }\r\n        if (!localFiles.isEmpty()) {\r\n            conf.set(MRJobConfig.CACHE_LOCALFILES, StringUtils.arrayToString(localFiles.toArray(new String[localFiles.size()])));\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getFileSizes",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "long[] getFileSizes(Configuration conf, String key)\n{\r\n    String[] strs = conf.getStrings(key);\r\n    if (strs == null) {\r\n        return null;\r\n    }\r\n    long[] result = new long[strs.length];\r\n    for (int i = 0; i < strs.length; ++i) {\r\n        result[i] = Long.parseLong(strs[i]);\r\n    }\r\n    return result;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getChildLogLevel",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String getChildLogLevel(Configuration conf, boolean isMap)\n{\r\n    if (isMap) {\r\n        return conf.get(MRJobConfig.MAP_LOG_LEVEL, JobConf.DEFAULT_LOG_LEVEL);\r\n    } else {\r\n        return conf.get(MRJobConfig.REDUCE_LOG_LEVEL, JobConf.DEFAULT_LOG_LEVEL);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "addLog4jSystemProperties",
  "errType" : [ "URISyntaxException" ],
  "containingMethodsNum" : 24,
  "sourceCodeText" : "void addLog4jSystemProperties(Task task, List<String> vargs, Configuration conf)\n{\r\n    String log4jPropertyFile = conf.get(MRJobConfig.MAPREDUCE_JOB_LOG4J_PROPERTIES_FILE, \"\");\r\n    if (log4jPropertyFile.isEmpty()) {\r\n        vargs.add(\"-Dlog4j.configuration=container-log4j.properties\");\r\n    } else {\r\n        URI log4jURI = null;\r\n        try {\r\n            log4jURI = new URI(log4jPropertyFile);\r\n        } catch (URISyntaxException e) {\r\n            throw new IllegalArgumentException(e);\r\n        }\r\n        Path log4jPath = new Path(log4jURI);\r\n        vargs.add(\"-Dlog4j.configuration=\" + log4jPath.getName());\r\n    }\r\n    long logSize;\r\n    String logLevel;\r\n    int numBackups;\r\n    if (task == null) {\r\n        logSize = conf.getLong(MRJobConfig.MR_AM_LOG_KB, MRJobConfig.DEFAULT_MR_AM_LOG_KB) << 10;\r\n        logLevel = conf.get(MRJobConfig.MR_AM_LOG_LEVEL, MRJobConfig.DEFAULT_MR_AM_LOG_LEVEL);\r\n        numBackups = conf.getInt(MRJobConfig.MR_AM_LOG_BACKUPS, MRJobConfig.DEFAULT_MR_AM_LOG_BACKUPS);\r\n    } else {\r\n        logSize = TaskLog.getTaskLogLimitBytes(conf);\r\n        logLevel = getChildLogLevel(conf, task.isMapTask());\r\n        numBackups = conf.getInt(MRJobConfig.TASK_LOG_BACKUPS, MRJobConfig.DEFAULT_TASK_LOG_BACKUPS);\r\n    }\r\n    vargs.add(\"-D\" + YarnConfiguration.YARN_APP_CONTAINER_LOG_DIR + \"=\" + ApplicationConstants.LOG_DIR_EXPANSION_VAR);\r\n    vargs.add(\"-D\" + YarnConfiguration.YARN_APP_CONTAINER_LOG_SIZE + \"=\" + logSize);\r\n    if (logSize > 0L && numBackups > 0) {\r\n        vargs.add(\"-D\" + YarnConfiguration.YARN_APP_CONTAINER_LOG_BACKUPS + \"=\" + numBackups);\r\n        vargs.add(\"-Dhadoop.root.logger=\" + logLevel + \",CRLA\");\r\n    } else {\r\n        vargs.add(\"-Dhadoop.root.logger=\" + logLevel + \",CLA\");\r\n    }\r\n    vargs.add(\"-Dhadoop.root.logfile=\" + TaskLog.LogName.SYSLOG);\r\n    if (task != null && !task.isMapTask() && conf.getBoolean(MRJobConfig.REDUCE_SEPARATE_SHUFFLE_LOG, MRJobConfig.DEFAULT_REDUCE_SEPARATE_SHUFFLE_LOG)) {\r\n        final int numShuffleBackups = conf.getInt(MRJobConfig.SHUFFLE_LOG_BACKUPS, MRJobConfig.DEFAULT_SHUFFLE_LOG_BACKUPS);\r\n        final long shuffleLogSize = conf.getLong(MRJobConfig.SHUFFLE_LOG_KB, MRJobConfig.DEFAULT_SHUFFLE_LOG_KB) << 10;\r\n        final String shuffleLogger = logLevel + (shuffleLogSize > 0L && numShuffleBackups > 0 ? \",shuffleCRLA\" : \",shuffleCLA\");\r\n        vargs.add(\"-D\" + MRJobConfig.MR_PREFIX + \"shuffle.logger=\" + shuffleLogger);\r\n        vargs.add(\"-D\" + MRJobConfig.MR_PREFIX + \"shuffle.logfile=\" + TaskLog.LogName.SYSLOG + \".shuffle\");\r\n        vargs.add(\"-D\" + MRJobConfig.MR_PREFIX + \"shuffle.log.filesize=\" + shuffleLogSize);\r\n        vargs.add(\"-D\" + MRJobConfig.MR_PREFIX + \"shuffle.log.backups=\" + numShuffleBackups);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "getSystemPropertiesToLog",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "String getSystemPropertiesToLog(Configuration conf)\n{\r\n    String key = conf.get(MRJobConfig.MAPREDUCE_JVM_SYSTEM_PROPERTIES_TO_LOG, MRJobConfig.DEFAULT_MAPREDUCE_JVM_SYSTEM_PROPERTIES_TO_LOG);\r\n    if (key != null) {\r\n        key = key.trim();\r\n        if (!key.isEmpty()) {\r\n            String[] props = key.split(\",\");\r\n            if (props.length > 0) {\r\n                StringBuilder sb = new StringBuilder();\r\n                sb.append(\"\\n/************************************************************\\n\");\r\n                sb.append(\"[system properties]\\n\");\r\n                for (String prop : props) {\r\n                    prop = prop.trim();\r\n                    if (!prop.isEmpty()) {\r\n                        sb.append(prop).append(\": \").append(System.getProperty(prop)).append('\\n');\r\n                    }\r\n                }\r\n                sb.append(\"************************************************************/\");\r\n                return sb.toString();\r\n            }\r\n        }\r\n    }\r\n    return null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setEnvFromInputString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setEnvFromInputString(Map<String, String> env, String envString, Configuration conf)\n{\r\n    String classPathSeparator = conf.getBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM, MRConfig.DEFAULT_MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM) ? ApplicationConstants.CLASS_PATH_SEPARATOR : File.pathSeparator;\r\n    Apps.setEnvFromInputString(env, envString, classPathSeparator);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "setEnvFromInputProperty",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void setEnvFromInputProperty(Map<String, String> env, String propName, String defaultPropValue, Configuration conf)\n{\r\n    String classPathSeparator = conf.getBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM, MRConfig.DEFAULT_MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM) ? ApplicationConstants.CLASS_PATH_SEPARATOR : File.pathSeparator;\r\n    Apps.setEnvFromInputProperty(env, propName, defaultPropValue, conf, classPathSeparator);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "addToEnvironment",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void addToEnvironment(Map<String, String> environment, String variable, String value, Configuration conf)\n{\r\n    String classPathSeparator = conf.getBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM, MRConfig.DEFAULT_MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM) ? ApplicationConstants.CLASS_PATH_SEPARATOR : File.pathSeparator;\r\n    Apps.addToEnvironment(environment, variable, value, classPathSeparator);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-mapreduce-project\\hadoop-mapreduce-client\\hadoop-mapreduce-client-common\\src\\main\\java\\org\\apache\\hadoop\\mapreduce\\v2\\util",
  "methodName" : "crossPlatformifyMREnv",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String crossPlatformifyMREnv(Configuration conf, Environment env)\n{\r\n    boolean crossPlatform = conf.getBoolean(MRConfig.MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM, MRConfig.DEFAULT_MAPREDUCE_APP_SUBMISSION_CROSS_PLATFORM);\r\n    return crossPlatform ? env.$$() : env.$();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]