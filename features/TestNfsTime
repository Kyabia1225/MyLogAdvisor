[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testConstructor",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testConstructor()\n{\r\n    NfsTime nfstime = new NfsTime(1001);\r\n    Assert.assertEquals(1, nfstime.getSeconds());\r\n    Assert.assertEquals(1000000, nfstime.getNseconds());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testSerializeDeserialize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testSerializeDeserialize()\n{\r\n    NfsTime t1 = new NfsTime(1001);\r\n    XDR xdr = new XDR();\r\n    t1.serialize(xdr);\r\n    NfsTime t2 = NfsTime.deserialize(xdr.asReadOnlyWrap());\r\n    Assert.assertEquals(t1, t2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testWildcardRW",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testWildcardRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"* rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testWildcardRO",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testWildcardRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"* ro\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testExactAddressRW",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testExactAddressRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, address1 + \" rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertFalse(AccessPrivilege.READ_WRITE == matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testExactAddressRO",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testExactAddressRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, address1);\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testExactHostRW",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testExactHostRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, hostname1 + \" rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testExactHostRO",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testExactHostRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, hostname1);\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testCidrShortRW",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testCidrShortRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.0/22 rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testCidrShortRO",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testCidrShortRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.0/22\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testCidrLongRW",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testCidrLongRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.0/255.255.252.0 rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testCidrLongRO",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testCidrLongRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.0/255.255.252.0\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testRegexIPRW",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testRegexIPRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.[0-9]+ rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testRegexIPRO",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testRegexIPRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.[0-9]+\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.NONE, matcher.getAccessPrivilege(address2, hostname1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testRegexHostRW",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testRegexHostRW()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"[a-z]+.b.com rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address1, hostname2));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testRegexHostRO",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testRegexHostRO()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"[a-z]+.b.com\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname2));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testRegexGrouping",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testRegexGrouping()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"192.168.0.(12|34)\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname2));\r\n    matcher = new NfsExports(CacheSize, ExpirationPeriod, \"\\\\w*.a.b.com\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(\"1.2.3.4\", \"web.a.b.com\"));\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(\"1.2.3.4\", \"email.a.b.org\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testMultiMatchers",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testMultiMatchers() throws Exception\n{\r\n    long shortExpirationPeriod = 1 * 1000 * 1000 * 1000;\r\n    NfsExports matcher = new NfsExports(CacheSize, shortExpirationPeriod, \"192.168.0.[0-9]+;[a-z]+.b.com rw\");\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname2));\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, address1));\r\n    Assert.assertEquals(AccessPrivilege.READ_ONLY, matcher.getAccessPrivilege(address1, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address2, hostname1));\r\n    Assert.assertEquals(AccessPrivilege.READ_WRITE, matcher.getAccessPrivilege(address2, hostname2));\r\n    Thread.sleep(1000);\r\n    AccessPrivilege ap;\r\n    long startNanos = System.nanoTime();\r\n    do {\r\n        ap = matcher.getAccessPrivilege(address2, address2);\r\n        if (ap == AccessPrivilege.NONE) {\r\n            break;\r\n        }\r\n        Thread.sleep(500);\r\n    } while ((System.nanoTime() - startNanos) / NanosPerMillis < 5000);\r\n    Assert.assertEquals(AccessPrivilege.NONE, ap);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testInvalidHost",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void testInvalidHost()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"foo#bar\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs",
  "methodName" : "testInvalidSeparator",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void testInvalidSeparator()\n{\r\n    NfsExports matcher = new NfsExports(CacheSize, ExpirationPeriod, \"foo ro : bar rw\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc\\security",
  "methodName" : "testReadWrite",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testReadWrite()\n{\r\n    CredentialsSys credential = new CredentialsSys();\r\n    credential.setUID(0);\r\n    credential.setGID(1);\r\n    credential.setStamp(1234);\r\n    XDR xdr = new XDR();\r\n    credential.write(xdr);\r\n    CredentialsSys newCredential = new CredentialsSys();\r\n    newCredential.read(xdr.asReadOnlyWrap());\r\n    assertEquals(0, newCredential.getUID());\r\n    assertEquals(1, newCredential.getGID());\r\n    assertEquals(1234, newCredential.getStamp());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc\\security",
  "methodName" : "testHostNameNotMultipleOf4",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testHostNameNotMultipleOf4()\n{\r\n    CredentialsSys credential = new CredentialsSys();\r\n    credential.setUID(0);\r\n    credential.setGID(1);\r\n    credential.setStamp(1234);\r\n    credential.setHostName(\"hadoop-nfs\");\r\n    XDR xdr = new XDR();\r\n    credential.write(xdr);\r\n    CredentialsSys newCredential = new CredentialsSys();\r\n    newCredential.read(xdr.asReadOnlyWrap());\r\n    assertEquals(0, newCredential.getUID());\r\n    assertEquals(1, newCredential.getGID());\r\n    assertEquals(1234, newCredential.getStamp());\r\n    assertEquals(32, newCredential.getCredentialLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc\\security",
  "methodName" : "testHostNameMultipleOf4",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void testHostNameMultipleOf4()\n{\r\n    CredentialsSys credential = new CredentialsSys();\r\n    credential.setUID(0);\r\n    credential.setGID(1);\r\n    credential.setStamp(1234);\r\n    credential.setHostName(\"apachehadoop\");\r\n    XDR xdr = new XDR();\r\n    credential.write(xdr);\r\n    CredentialsSys newCredential = new CredentialsSys();\r\n    newCredential.read(xdr.asReadOnlyWrap());\r\n    assertEquals(0, newCredential.getUID());\r\n    assertEquals(1, newCredential.getGID());\r\n    assertEquals(1234, newCredential.getStamp());\r\n    assertEquals(32, newCredential.getCredentialLength());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testReplyStateFromValue",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testReplyStateFromValue()\n{\r\n    Assert.assertEquals(ReplyState.MSG_ACCEPTED, ReplyState.fromValue(0));\r\n    Assert.assertEquals(ReplyState.MSG_DENIED, ReplyState.fromValue(1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testReplyStateFromInvalidValue1",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testReplyStateFromInvalidValue1()\n{\r\n    ReplyState.fromValue(2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRpcReply",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRpcReply()\n{\r\n    RpcReply reply = new RpcReply(0, ReplyState.MSG_ACCEPTED, new VerifierNone()) {\r\n\r\n        @Override\r\n        public XDR write(XDR xdr) {\r\n            return null;\r\n        }\r\n    };\r\n    Assert.assertEquals(0, reply.getXid());\r\n    Assert.assertEquals(RpcMessage.Type.RPC_REPLY, reply.getMessageType());\r\n    Assert.assertEquals(ReplyState.MSG_ACCEPTED, reply.getState());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRpcCallCacheConstructorIllegalArgument0",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void testRpcCallCacheConstructorIllegalArgument0()\n{\r\n    new RpcCallCache(\"test\", 0);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRpcCallCacheConstructorIllegalArgumentNegative",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void testRpcCallCacheConstructorIllegalArgumentNegative()\n{\r\n    new RpcCallCache(\"test\", -1);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRpcCallCacheConstructor",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRpcCallCacheConstructor()\n{\r\n    RpcCallCache cache = new RpcCallCache(\"test\", 100);\r\n    assertEquals(\"test\", cache.getProgram());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testAddRemoveEntries",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "void testAddRemoveEntries() throws UnknownHostException\n{\r\n    RpcCallCache cache = new RpcCallCache(\"test\", 100);\r\n    InetAddress clientIp = InetAddress.getByName(\"1.1.1.1\");\r\n    int xid = 100;\r\n    CacheEntry e = cache.checkOrAddToCache(clientIp, xid);\r\n    assertNull(e);\r\n    e = cache.checkOrAddToCache(clientIp, xid);\r\n    validateInprogressCacheEntry(e);\r\n    RpcResponse response = mock(RpcResponse.class);\r\n    cache.callCompleted(clientIp, xid, response);\r\n    e = cache.checkOrAddToCache(clientIp, xid);\r\n    validateCompletedCacheEntry(e, response);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "validateInprogressCacheEntry",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void validateInprogressCacheEntry(CacheEntry c)\n{\r\n    assertTrue(c.isInProgress());\r\n    assertFalse(c.isCompleted());\r\n    assertNull(c.getResponse());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "validateCompletedCacheEntry",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void validateCompletedCacheEntry(CacheEntry c, RpcResponse response)\n{\r\n    assertFalse(c.isInProgress());\r\n    assertTrue(c.isCompleted());\r\n    assertEquals(response, c.getResponse());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testCacheEntry",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testCacheEntry()\n{\r\n    CacheEntry c = new CacheEntry();\r\n    validateInprogressCacheEntry(c);\r\n    assertTrue(c.isInProgress());\r\n    assertFalse(c.isCompleted());\r\n    assertNull(c.getResponse());\r\n    RpcResponse response = mock(RpcResponse.class);\r\n    c.setResponse(response);\r\n    validateCompletedCacheEntry(c, response);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testCacheFunctionality",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testCacheFunctionality() throws UnknownHostException\n{\r\n    RpcCallCache cache = new RpcCallCache(\"Test\", 10);\r\n    int size = 0;\r\n    for (int clientId = 0; clientId < 20; clientId++) {\r\n        InetAddress clientIp = InetAddress.getByName(\"1.1.1.\" + clientId);\r\n        System.out.println(\"Adding \" + clientIp);\r\n        cache.checkOrAddToCache(clientIp, 0);\r\n        size = Math.min(++size, 10);\r\n        System.out.println(\"Cache size \" + cache.size());\r\n        assertEquals(size, cache.size());\r\n        int startEntry = Math.max(clientId - 10 + 1, 0);\r\n        Iterator<Entry<ClientRequest, CacheEntry>> iterator = cache.iterator();\r\n        for (int i = 0; i < size; i++) {\r\n            ClientRequest key = iterator.next().getKey();\r\n            System.out.println(\"Entry \" + key.getClientId());\r\n            assertEquals(InetAddress.getByName(\"1.1.1.\" + (startEntry + i)), key.getClientId());\r\n        }\r\n        for (int i = 0; i < size; i++) {\r\n            CacheEntry e = cache.checkOrAddToCache(InetAddress.getByName(\"1.1.1.\" + (startEntry + i)), 0);\r\n            assertNotNull(e);\r\n            assertTrue(e.isInProgress());\r\n            assertFalse(e.isCompleted());\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc\\security",
  "methodName" : "testAuthFlavor",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testAuthFlavor()\n{\r\n    assertEquals(AuthFlavor.AUTH_NONE, AuthFlavor.fromValue(0));\r\n    assertEquals(AuthFlavor.AUTH_SYS, AuthFlavor.fromValue(1));\r\n    assertEquals(AuthFlavor.AUTH_SHORT, AuthFlavor.fromValue(2));\r\n    assertEquals(AuthFlavor.AUTH_DH, AuthFlavor.fromValue(3));\r\n    assertEquals(AuthFlavor.RPCSEC_GSS, AuthFlavor.fromValue(6));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc\\security",
  "methodName" : "testInvalidAuthFlavor",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testInvalidAuthFlavor()\n{\r\n    assertEquals(AuthFlavor.AUTH_NONE, AuthFlavor.fromValue(4));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRequest",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRequest(XDR request, int serverPort)\n{\r\n    resultSize = 0;\r\n    SimpleTcpClient tcpClient = new SimpleTcpClient(\"localhost\", serverPort, request, true);\r\n    tcpClient.run();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testSingleFrame",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testSingleFrame()\n{\r\n    RpcFrameDecoder decoder = new RpcFrameDecoder();\r\n    ByteBuf buf = Unpooled.directBuffer(1);\r\n    List<Object> outputBufs = new ArrayList<>();\r\n    decoder.decode(Mockito.mock(ChannelHandlerContext.class), buf, outputBufs);\r\n    assertTrue(outputBufs.isEmpty());\r\n    decoder = new RpcFrameDecoder();\r\n    byte[] fragment = new byte[4 + 9];\r\n    fragment[0] = (byte) (1 << 7);\r\n    fragment[1] = 0;\r\n    fragment[2] = 0;\r\n    fragment[3] = (byte) 10;\r\n    assertTrue(XDR.isLastFragment(fragment));\r\n    assertTrue(XDR.fragmentSize(fragment) == 10);\r\n    buf.release();\r\n    buf = Unpooled.directBuffer(4 + 9);\r\n    buf.writeBytes(fragment);\r\n    outputBufs = new ArrayList<>();\r\n    decoder.decode(Mockito.mock(ChannelHandlerContext.class), buf, outputBufs);\r\n    assertTrue(decoder.isLast());\r\n    buf.release();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testMultipleFrames",
  "errType" : null,
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void testMultipleFrames()\n{\r\n    RpcFrameDecoder decoder = new RpcFrameDecoder();\r\n    byte[] fragment1 = new byte[4 + 10];\r\n    fragment1[0] = 0;\r\n    fragment1[1] = 0;\r\n    fragment1[2] = 0;\r\n    fragment1[3] = (byte) 10;\r\n    assertFalse(XDR.isLastFragment(fragment1));\r\n    assertTrue(XDR.fragmentSize(fragment1) == 10);\r\n    List<Object> outputBufs = new ArrayList<>();\r\n    ByteBuf buf = Unpooled.directBuffer(4 + 10, 4 + 10);\r\n    buf.writeBytes(fragment1);\r\n    decoder.decode(Mockito.mock(ChannelHandlerContext.class), buf, outputBufs);\r\n    byte[] fragment2 = new byte[4 + 10];\r\n    fragment2[0] = (byte) (1 << 7);\r\n    fragment2[1] = 0;\r\n    fragment2[2] = 0;\r\n    fragment2[3] = (byte) 10;\r\n    assertTrue(XDR.isLastFragment(fragment2));\r\n    assertTrue(XDR.fragmentSize(fragment2) == 10);\r\n    buf.release();\r\n    buf = Unpooled.directBuffer(4 + 10, 4 + 10);\r\n    buf.writeBytes(fragment2);\r\n    decoder.decode(Mockito.mock(ChannelHandlerContext.class), buf, outputBufs);\r\n    decoder.isLast();\r\n    assertEquals(2, outputBufs.size());\r\n    outputBufs.forEach(b -> assertEquals(((ByteBuf) b).readableBytes(), 10));\r\n    buf.release();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testFrames",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testFrames() throws InterruptedException\n{\r\n    int serverPort = startRpcServer(true);\r\n    XDR xdrOut = createGetportMount();\r\n    int headerSize = xdrOut.size();\r\n    int bufsize = 2 * 1024 * 1024;\r\n    byte[] buffer = new byte[bufsize];\r\n    xdrOut.writeFixedOpaque(buffer);\r\n    int requestSize = xdrOut.size() - headerSize;\r\n    testRequest(xdrOut, serverPort);\r\n    assertEquals(requestSize, resultSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testUnprivilegedPort",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "void testUnprivilegedPort() throws InterruptedException\n{\r\n    int serverPort = startRpcServer(false);\r\n    XDR xdrOut = createGetportMount();\r\n    int bufsize = 2 * 1024 * 1024;\r\n    byte[] buffer = new byte[bufsize];\r\n    xdrOut.writeFixedOpaque(buffer);\r\n    testRequest(xdrOut, serverPort);\r\n    assertEquals(0, resultSize);\r\n    xdrOut = new XDR();\r\n    createPortmapXDRheader(xdrOut, 0);\r\n    int headerSize = xdrOut.size();\r\n    buffer = new byte[bufsize];\r\n    xdrOut.writeFixedOpaque(buffer);\r\n    int requestSize = xdrOut.size() - headerSize;\r\n    testRequest(xdrOut, serverPort);\r\n    assertEquals(requestSize, resultSize);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "startRpcServer",
  "errType" : [ "InterruptedException|ChannelException" ],
  "containingMethodsNum" : 4,
  "sourceCodeText" : "int startRpcServer(boolean allowInsecurePorts) throws InterruptedException\n{\r\n    Random rand = new Random();\r\n    int serverPort = 30000 + rand.nextInt(10000);\r\n    int retries = 10;\r\n    while (true) {\r\n        SimpleTcpServer tcpServer = null;\r\n        try {\r\n            RpcProgram program = new TestFrameDecoder.TestRpcProgram(\"TestRpcProgram\", \"localhost\", serverPort, 100000, 1, 2, allowInsecurePorts);\r\n            tcpServer = new SimpleTcpServer(serverPort, program, 1);\r\n            tcpServer.run();\r\n            break;\r\n        } catch (InterruptedException | ChannelException e) {\r\n            if (tcpServer != null) {\r\n                tcpServer.shutdown();\r\n            }\r\n            if (retries-- > 0) {\r\n                serverPort += rand.nextInt(20);\r\n            } else {\r\n                throw e;\r\n            }\r\n        }\r\n    }\r\n    return serverPort;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "createPortmapXDRheader",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void createPortmapXDRheader(XDR xdr_out, int procedure)\n{\r\n    RpcCall.getInstance(0, 100000, 2, procedure, new CredentialsNone(), new VerifierNone()).write(xdr_out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "createGetportMount",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "XDR createGetportMount()\n{\r\n    XDR xdr_out = new XDR();\r\n    createPortmapXDRheader(xdr_out, 3);\r\n    return xdr_out;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRejectStateFromValue",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testRejectStateFromValue()\n{\r\n    Assert.assertEquals(RejectState.RPC_MISMATCH, RejectState.fromValue(0));\r\n    Assert.assertEquals(RejectState.AUTH_ERROR, RejectState.fromValue(1));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRejectStateFromInvalidValue1",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testRejectStateFromInvalidValue1()\n{\r\n    RejectState.fromValue(2);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testConstructor",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testConstructor()\n{\r\n    RpcDeniedReply reply = new RpcDeniedReply(0, ReplyState.MSG_ACCEPTED, RejectState.AUTH_ERROR, new VerifierNone());\r\n    Assert.assertEquals(0, reply.getXid());\r\n    Assert.assertEquals(RpcMessage.Type.RPC_REPLY, reply.getMessageType());\r\n    Assert.assertEquals(ReplyState.MSG_ACCEPTED, reply.getState());\r\n    Assert.assertEquals(RejectState.AUTH_ERROR, reply.getRejectState());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\portmap",
  "methodName" : "setup",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setup() throws InterruptedException\n{\r\n    pm.start(SHORT_TIMEOUT_MILLISECONDS, new InetSocketAddress(\"localhost\", 0), new InetSocketAddress(\"localhost\", 0));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\portmap",
  "methodName" : "tearDown",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void tearDown()\n{\r\n    pm.shutdown();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\portmap",
  "methodName" : "testIdle",
  "errType" : null,
  "containingMethodsNum" : 7,
  "sourceCodeText" : "void testIdle() throws InterruptedException, IOException\n{\r\n    Socket s = new Socket();\r\n    try {\r\n        s.connect(pm.getTcpServerLocalAddress());\r\n        int i = 0;\r\n        while (!s.isConnected() && i < RETRY_TIMES) {\r\n            ++i;\r\n            Thread.sleep(SHORT_TIMEOUT_MILLISECONDS);\r\n        }\r\n        Assert.assertTrue(\"Failed to connect to the server\", s.isConnected() && i < RETRY_TIMES);\r\n        int b = s.getInputStream().read();\r\n        Assert.assertTrue(\"The server failed to disconnect\", b == -1);\r\n    } finally {\r\n        s.close();\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\portmap",
  "methodName" : "testRegistration",
  "errType" : null,
  "containingMethodsNum" : 13,
  "sourceCodeText" : "void testRegistration() throws IOException, InterruptedException\n{\r\n    XDR req = new XDR();\r\n    RpcCall.getInstance(++xid, RpcProgramPortmap.PROGRAM, RpcProgramPortmap.VERSION, RpcProgramPortmap.PMAPPROC_SET, new CredentialsNone(), new VerifierNone()).write(req);\r\n    PortmapMapping sent = new PortmapMapping(90000, 1, PortmapMapping.TRANSPORT_TCP, 1234);\r\n    sent.serialize(req);\r\n    byte[] reqBuf = req.getBytes();\r\n    DatagramSocket s = new DatagramSocket();\r\n    DatagramPacket p = new DatagramPacket(reqBuf, reqBuf.length, pm.getUdpServerLoAddress());\r\n    try {\r\n        s.send(p);\r\n    } finally {\r\n        s.close();\r\n    }\r\n    Thread.sleep(100);\r\n    boolean found = false;\r\n    @SuppressWarnings(\"unchecked\")\r\n    Map<String, PortmapMapping> map = (Map<String, PortmapMapping>) Whitebox.getInternalState(pm.getHandler(), \"map\");\r\n    for (PortmapMapping m : map.values()) {\r\n        if (m.getPort() == sent.getPort() && PortmapMapping.key(m).equals(PortmapMapping.key(sent))) {\r\n            found = true;\r\n            break;\r\n        }\r\n    }\r\n    Assert.assertTrue(\"Registration failed\", found);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testAcceptState",
  "errType" : null,
  "containingMethodsNum" : 6,
  "sourceCodeText" : "void testAcceptState()\n{\r\n    assertEquals(AcceptState.SUCCESS, AcceptState.fromValue(0));\r\n    assertEquals(AcceptState.PROG_UNAVAIL, AcceptState.fromValue(1));\r\n    assertEquals(AcceptState.PROG_MISMATCH, AcceptState.fromValue(2));\r\n    assertEquals(AcceptState.PROC_UNAVAIL, AcceptState.fromValue(3));\r\n    assertEquals(AcceptState.GARBAGE_ARGS, AcceptState.fromValue(4));\r\n    assertEquals(AcceptState.SYSTEM_ERR, AcceptState.fromValue(5));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testAcceptStateFromInvalidValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void testAcceptStateFromInvalidValue()\n{\r\n    AcceptState.fromValue(6);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testConstructor",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void testConstructor()\n{\r\n    Verifier verifier = new VerifierNone();\r\n    RpcAcceptedReply reply = new RpcAcceptedReply(0, ReplyState.MSG_ACCEPTED, verifier, AcceptState.SUCCESS);\r\n    assertEquals(0, reply.getXid());\r\n    assertEquals(RpcMessage.Type.RPC_REPLY, reply.getMessageType());\r\n    assertEquals(ReplyState.MSG_ACCEPTED, reply.getState());\r\n    assertEquals(verifier, reply.getVerifier());\r\n    assertEquals(AcceptState.SUCCESS, reply.getAcceptState());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testConstructor",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void testConstructor()\n{\r\n    Credentials credential = new CredentialsNone();\r\n    Verifier verifier = new VerifierNone();\r\n    int rpcVersion = RpcCall.RPC_VERSION;\r\n    int program = 2;\r\n    int version = 3;\r\n    int procedure = 4;\r\n    RpcCall call = new RpcCall(0, RpcMessage.Type.RPC_CALL, rpcVersion, program, version, procedure, credential, verifier);\r\n    assertEquals(0, call.getXid());\r\n    assertEquals(RpcMessage.Type.RPC_CALL, call.getMessageType());\r\n    assertEquals(rpcVersion, call.getRpcVersion());\r\n    assertEquals(program, call.getProgram());\r\n    assertEquals(version, call.getVersion());\r\n    assertEquals(procedure, call.getProcedure());\r\n    assertEquals(credential, call.getCredential());\r\n    assertEquals(verifier, call.getVerifier());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testInvalidRpcVersion",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void testInvalidRpcVersion()\n{\r\n    int invalidRpcVersion = 3;\r\n    new RpcCall(0, RpcMessage.Type.RPC_CALL, invalidRpcVersion, 2, 3, 4, null, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testInvalidRpcMessageType",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void testInvalidRpcMessageType()\n{\r\n    RpcMessage.Type invalidMessageType = RpcMessage.Type.RPC_REPLY;\r\n    new RpcCall(0, invalidMessageType, RpcCall.RPC_VERSION, 2, 3, 4, null, null);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "serializeInt",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void serializeInt(int times)\n{\r\n    XDR w = new XDR();\r\n    for (int i = 0; i < times; ++i) w.writeInt(WRITE_VALUE);\r\n    XDR r = w.asReadOnlyWrap();\r\n    for (int i = 0; i < times; ++i) Assert.assertEquals(WRITE_VALUE, r.readInt());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "serializeLong",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void serializeLong(int times)\n{\r\n    XDR w = new XDR();\r\n    for (int i = 0; i < times; ++i) w.writeLongAsHyper(WRITE_VALUE);\r\n    XDR r = w.asReadOnlyWrap();\r\n    for (int i = 0; i < times; ++i) Assert.assertEquals(WRITE_VALUE, r.readHyper());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testPerformance",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testPerformance()\n{\r\n    final int TEST_TIMES = 8 << 20;\r\n    serializeInt(TEST_TIMES);\r\n    serializeLong(TEST_TIMES);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "getRpcMessage",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "RpcMessage getRpcMessage(int xid, RpcMessage.Type msgType)\n{\r\n    return new RpcMessage(xid, msgType) {\r\n\r\n        @Override\r\n        public XDR write(XDR xdr) {\r\n            return null;\r\n        }\r\n    };\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testRpcMessage",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void testRpcMessage()\n{\r\n    RpcMessage msg = getRpcMessage(0, RpcMessage.Type.RPC_CALL);\r\n    Assert.assertEquals(0, msg.getXid());\r\n    Assert.assertEquals(RpcMessage.Type.RPC_CALL, msg.getMessageType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testValidateMessage",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testValidateMessage()\n{\r\n    RpcMessage msg = getRpcMessage(0, RpcMessage.Type.RPC_CALL);\r\n    msg.validateMessageType(RpcMessage.Type.RPC_CALL);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\oncrpc",
  "methodName" : "testValidateMessageException",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void testValidateMessageException()\n{\r\n    RpcMessage msg = getRpcMessage(0, RpcMessage.Type.RPC_CALL);\r\n    msg.validateMessageType(RpcMessage.Type.RPC_REPLY);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-common-project\\hadoop-nfs\\src\\test\\java\\org\\apache\\hadoop\\nfs\\nfs3",
  "methodName" : "testConstructor",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void testConstructor()\n{\r\n    FileHandle handle = new FileHandle(1024);\r\n    XDR xdr = new XDR();\r\n    handle.serialize(xdr);\r\n    assertThat(handle.getFileId()).isEqualTo(1024);\r\n    FileHandle handle2 = new FileHandle();\r\n    handle2.deserialize(xdr.asReadOnlyWrap());\r\n    assertThat(handle.getFileId()).withFailMessage(\"Failed: Assert 1024 is id \").isEqualTo(1024);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]