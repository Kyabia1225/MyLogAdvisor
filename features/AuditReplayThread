[ {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "drainCounters",
  "errType" : null,
  "containingMethodsNum" : 4,
  "sourceCodeText" : "void drainCounters(Mapper.Context context)\n{\r\n    for (Map.Entry<REPLAYCOUNTERS, Counter> ent : replayCountersMap.entrySet()) {\r\n        context.getCounter(ent.getKey()).increment(ent.getValue().getValue());\r\n    }\r\n    for (Map.Entry<String, Counter> ent : individualCommandsMap.entrySet()) {\r\n        context.getCounter(INDIVIDUAL_COMMANDS_COUNTER_GROUP, ent.getKey()).increment(ent.getValue().getValue());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "drainCommandLatencies",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void drainCommandLatencies(Mapper.Context context) throws InterruptedException, IOException\n{\r\n    for (Map.Entry<UserCommandKey, CountTimeWritable> ent : commandLatencyMap.entrySet()) {\r\n        context.write(ent.getKey(), ent.getValue());\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "addToQueue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void addToQueue(AuditReplayCommand cmd)\n{\r\n    commandQueue.put(cmd);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getException",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "Exception getException()\n{\r\n    return exception;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "run",
  "errType" : [ "InterruptedException", "Exception" ],
  "containingMethodsNum" : 15,
  "sourceCodeText" : "void run()\n{\r\n    long currentEpoch = System.currentTimeMillis();\r\n    long delay = startTimestampMs - currentEpoch;\r\n    try {\r\n        if (delay > 0) {\r\n            LOG.info(\"Sleeping for \" + delay + \" ms\");\r\n            Thread.sleep(delay);\r\n        } else {\r\n            LOG.warn(\"Starting late by \" + (-1 * delay) + \" ms\");\r\n        }\r\n        AuditReplayCommand cmd = commandQueue.take();\r\n        while (!cmd.isPoison()) {\r\n            replayCountersMap.get(REPLAYCOUNTERS.TOTALCOMMANDS).increment(1);\r\n            delay = cmd.getDelay(TimeUnit.MILLISECONDS);\r\n            if (delay < -5) {\r\n                replayCountersMap.get(REPLAYCOUNTERS.LATECOMMANDS).increment(1);\r\n                replayCountersMap.get(REPLAYCOUNTERS.LATECOMMANDSTOTALTIME).increment(-1 * delay);\r\n            }\r\n            if (!replayLog(cmd)) {\r\n                replayCountersMap.get(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).increment(1);\r\n            }\r\n            cmd = commandQueue.take();\r\n        }\r\n    } catch (InterruptedException e) {\r\n        LOG.error(\"Interrupted; exiting from thread.\", e);\r\n    } catch (Exception e) {\r\n        exception = e;\r\n        LOG.error(\"ReplayThread encountered exception; exiting.\", e);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "replayLog",
  "errType" : [ "IOException", "IllegalArgumentException", "IOException" ],
  "containingMethodsNum" : 48,
  "sourceCodeText" : "boolean replayLog(final AuditReplayCommand command)\n{\r\n    final String src = command.getSrc();\r\n    final String dst = command.getDest();\r\n    FileSystem proxyFs = fsCache.get(command.getSimpleUgi());\r\n    if (proxyFs == null) {\r\n        UserGroupInformation ugi = UserGroupInformation.createProxyUser(command.getSimpleUgi(), loginUser);\r\n        proxyFs = ugi.doAs((PrivilegedAction<FileSystem>) () -> {\r\n            try {\r\n                FileSystem fs = new DistributedFileSystem();\r\n                fs.initialize(namenodeUri, mapperConf);\r\n                return fs;\r\n            } catch (IOException ioe) {\r\n                throw new RuntimeException(ioe);\r\n            }\r\n        });\r\n        fsCache.put(command.getSimpleUgi(), proxyFs);\r\n    }\r\n    final FileSystem fs = proxyFs;\r\n    ReplayCommand replayCommand;\r\n    try {\r\n        replayCommand = ReplayCommand.valueOf(command.getCommand().split(\" \")[0].toUpperCase());\r\n    } catch (IllegalArgumentException iae) {\r\n        LOG.warn(\"Unsupported/invalid command: \" + command);\r\n        replayCountersMap.get(REPLAYCOUNTERS.TOTALUNSUPPORTEDCOMMANDS).increment(1);\r\n        return false;\r\n    }\r\n    try {\r\n        long startTime = System.currentTimeMillis();\r\n        switch(replayCommand) {\r\n            case CREATE:\r\n                FSDataOutputStream fsDos = fs.create(new Path(src));\r\n                if (createBlocks) {\r\n                    fsDos.writeByte(0);\r\n                }\r\n                fsDos.close();\r\n                break;\r\n            case GETFILEINFO:\r\n                fs.getFileStatus(new Path(src));\r\n                break;\r\n            case CONTENTSUMMARY:\r\n                fs.getContentSummary(new Path(src));\r\n                break;\r\n            case MKDIRS:\r\n                fs.mkdirs(new Path(src));\r\n                break;\r\n            case RENAME:\r\n                fs.rename(new Path(src), new Path(dst));\r\n                break;\r\n            case LISTSTATUS:\r\n                ((DistributedFileSystem) fs).getClient().listPaths(src, HdfsFileStatus.EMPTY_NAME);\r\n                break;\r\n            case APPEND:\r\n                fs.append(new Path(src));\r\n                return true;\r\n            case DELETE:\r\n                fs.delete(new Path(src), true);\r\n                break;\r\n            case OPEN:\r\n                fs.open(new Path(src)).close();\r\n                break;\r\n            case SETPERMISSION:\r\n                fs.setPermission(new Path(src), FsPermission.getDefault());\r\n                break;\r\n            case SETOWNER:\r\n                fs.setOwner(new Path(src), UserGroupInformation.getCurrentUser().getShortUserName(), UserGroupInformation.getCurrentUser().getPrimaryGroupName());\r\n                break;\r\n            case SETTIMES:\r\n                fs.setTimes(new Path(src), System.currentTimeMillis(), System.currentTimeMillis());\r\n                break;\r\n            case SETREPLICATION:\r\n                fs.setReplication(new Path(src), (short) 1);\r\n                break;\r\n            case CONCAT:\r\n                String bareDist = dst.length() < 2 ? \"\" : dst.substring(1, dst.length() - 1).trim();\r\n                List<Path> dsts = new ArrayList<>();\r\n                for (String s : Splitter.on(\",\").omitEmptyStrings().trimResults().split(bareDist)) {\r\n                    dsts.add(new Path(s));\r\n                }\r\n                fs.concat(new Path(src), dsts.toArray(new Path[] {}));\r\n                break;\r\n            default:\r\n                throw new RuntimeException(\"Unexpected command: \" + replayCommand);\r\n        }\r\n        long latency = System.currentTimeMillis() - startTime;\r\n        UserCommandKey userCommandKey = new UserCommandKey(command.getSimpleUgi(), replayCommand.toString(), replayCommand.getType().toString());\r\n        commandLatencyMap.putIfAbsent(userCommandKey, new CountTimeWritable());\r\n        CountTimeWritable latencyWritable = commandLatencyMap.get(userCommandKey);\r\n        latencyWritable.setCount(latencyWritable.getCount() + 1);\r\n        latencyWritable.setTime(latencyWritable.getTime() + latency);\r\n        switch(replayCommand.getType()) {\r\n            case WRITE:\r\n                replayCountersMap.get(REPLAYCOUNTERS.TOTALWRITECOMMANDLATENCY).increment(latency);\r\n                replayCountersMap.get(REPLAYCOUNTERS.TOTALWRITECOMMANDS).increment(1);\r\n                break;\r\n            case READ:\r\n                replayCountersMap.get(REPLAYCOUNTERS.TOTALREADCOMMANDLATENCY).increment(latency);\r\n                replayCountersMap.get(REPLAYCOUNTERS.TOTALREADCOMMANDS).increment(1);\r\n                break;\r\n            default:\r\n                throw new RuntimeException(\"Unexpected command type: \" + replayCommand.getType());\r\n        }\r\n        individualCommandsMap.get(replayCommand + INDIVIDUAL_COMMANDS_LATENCY_SUFFIX).increment(latency);\r\n        individualCommandsMap.get(replayCommand + INDIVIDUAL_COMMANDS_COUNT_SUFFIX).increment(1);\r\n        return true;\r\n    } catch (IOException e) {\r\n        LOG.debug(\"IOException: \" + e.getLocalizedMessage());\r\n        individualCommandsMap.get(replayCommand + INDIVIDUAL_COMMANDS_INVALID_SUFFIX).increment(1);\r\n        return false;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 3,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getSplits",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "List<InputSplit> getSplits(JobContext job) throws IOException\n{\r\n    Configuration conf = job.getConfiguration();\r\n    int numMappers = conf.getInt(CreateFileMapper.NUM_MAPPERS_KEY, -1);\r\n    if (numMappers == -1) {\r\n        throw new IOException(\"Number of mappers should be provided as input\");\r\n    }\r\n    List<InputSplit> splits = new ArrayList<InputSplit>(numMappers);\r\n    for (int i = 0; i < numMappers; i++) {\r\n        splits.add(new VirtualInputSplit());\r\n    }\r\n    return splits;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "createRecordReader",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "RecordReader<K, V> createRecordReader(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException\n{\r\n    return new VirtualRecordReader<>();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getDescription",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getDescription()\n{\r\n    return \"This mapper replays audit log files.\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getConfigDescriptions",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> getConfigDescriptions()\n{\r\n    return Lists.newArrayList(INPUT_PATH_KEY + \" (required): Path to directory containing input files.\", OUTPUT_PATH_KEY + \" (required): Path to destination for output files.\", NUM_THREADS_KEY + \" (default \" + NUM_THREADS_DEFAULT + \"): Number of threads to use per mapper for replay.\", CREATE_BLOCKS_KEY + \" (default \" + CREATE_BLOCKS_DEFAULT + \"): Whether or not to create 1-byte blocks when \" + \"performing `create` commands.\", RATE_FACTOR_KEY + \" (default \" + RATE_FACTOR_DEFAULT + \"): Multiplicative speed at which to replay the audit \" + \"log; e.g. a value of 2.0 would make the replay occur at \" + \"twice the original speed. This can be useful \" + \"to induce heavier loads.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "verifyConfigurations",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean verifyConfigurations(Configuration conf)\n{\r\n    return conf.get(INPUT_PATH_KEY) != null && conf.get(OUTPUT_PATH_KEY) != null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "setup",
  "errType" : [ "NoSuchMethodException|InstantiationException|IllegalAccessException|InvocationTargetException" ],
  "containingMethodsNum" : 12,
  "sourceCodeText" : "void setup(final Mapper.Context context) throws IOException\n{\r\n    Configuration conf = context.getConfiguration();\r\n    startTimestampMs = conf.getLong(WorkloadDriver.START_TIMESTAMP_MS, -1);\r\n    numThreads = conf.getInt(NUM_THREADS_KEY, NUM_THREADS_DEFAULT);\r\n    rateFactor = conf.getDouble(RATE_FACTOR_KEY, RATE_FACTOR_DEFAULT);\r\n    try {\r\n        commandParser = conf.getClass(COMMAND_PARSER_KEY, COMMAND_PARSER_DEFAULT, AuditCommandParser.class).getConstructor().newInstance();\r\n    } catch (NoSuchMethodException | InstantiationException | IllegalAccessException | InvocationTargetException e) {\r\n        throw new IOException(\"Exception encountered while instantiating the command parser\", e);\r\n    }\r\n    commandParser.initialize(conf);\r\n    relativeToAbsoluteTimestamp = (input) -> startTimestampMs + Math.round(input / rateFactor);\r\n    LOG.info(\"Starting \" + numThreads + \" threads\");\r\n    progressExecutor = new ScheduledThreadPoolExecutor(1);\r\n    long progressFrequencyMs = conf.getLong(MRJobConfig.TASK_TIMEOUT, 2 * 60 * 1000) / 2;\r\n    progressExecutor.scheduleAtFixedRate(context::progress, progressFrequencyMs, progressFrequencyMs, TimeUnit.MILLISECONDS);\r\n    threads = new ArrayList<>();\r\n    ConcurrentMap<String, FileSystem> fsCache = new ConcurrentHashMap<>();\r\n    commandQueue = new DelayQueue<>();\r\n    for (int i = 0; i < numThreads; i++) {\r\n        AuditReplayThread thread = new AuditReplayThread(context, commandQueue, fsCache);\r\n        threads.add(thread);\r\n        thread.start();\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "map",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void map(LongWritable lineNum, Text inputLine, Mapper.Context context) throws IOException, InterruptedException\n{\r\n    AuditReplayCommand cmd = commandParser.parse(inputLine, relativeToAbsoluteTimestamp);\r\n    long delay = cmd.getDelay(TimeUnit.MILLISECONDS);\r\n    if (delay > MAX_READAHEAD_MS) {\r\n        Thread.sleep(delay - (MAX_READAHEAD_MS / 2));\r\n    }\r\n    commandQueue.put(cmd);\r\n    highestTimestamp = cmd.getAbsoluteTimestamp();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "cleanup",
  "errType" : null,
  "containingMethodsNum" : 14,
  "sourceCodeText" : "void cleanup(Mapper.Context context) throws InterruptedException, IOException\n{\r\n    for (AuditReplayThread t : threads) {\r\n        t.addToQueue(AuditReplayCommand.getPoisonPill(highestTimestamp + 1));\r\n    }\r\n    Optional<Exception> threadException = Optional.empty();\r\n    for (AuditReplayThread t : threads) {\r\n        t.join();\r\n        t.drainCounters(context);\r\n        t.drainCommandLatencies(context);\r\n        if (t.getException() != null) {\r\n            threadException = Optional.of(t.getException());\r\n        }\r\n    }\r\n    progressExecutor.shutdown();\r\n    if (threadException.isPresent()) {\r\n        throw new RuntimeException(\"Exception in AuditReplayThread\", threadException.get());\r\n    }\r\n    LOG.info(\"Time taken to replay the logs in ms: \" + (System.currentTimeMillis() - startTimestampMs));\r\n    long totalCommands = context.getCounter(REPLAYCOUNTERS.TOTALCOMMANDS).getValue();\r\n    if (totalCommands != 0) {\r\n        double percentageOfInvalidOps = context.getCounter(REPLAYCOUNTERS.TOTALINVALIDCOMMANDS).getValue() * 100.0 / totalCommands;\r\n        LOG.info(\"Percentage of invalid ops: \" + percentageOfInvalidOps);\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "configureJob",
  "errType" : null,
  "containingMethodsNum" : 10,
  "sourceCodeText" : "void configureJob(Job job)\n{\r\n    job.setMapOutputKeyClass(UserCommandKey.class);\r\n    job.setMapOutputValueClass(CountTimeWritable.class);\r\n    job.setInputFormatClass(NoSplitTextInputFormat.class);\r\n    job.setNumReduceTasks(1);\r\n    job.setReducerClass(AuditReplayReducer.class);\r\n    job.setOutputKeyClass(UserCommandKey.class);\r\n    job.setOutputValueClass(CountTimeWritable.class);\r\n    job.setOutputFormatClass(TextOutputFormat.class);\r\n    TextOutputFormat.setOutputPath(job, new Path(job.getConfiguration().get(OUTPUT_PATH_KEY)));\r\n    job.getConfiguration().set(TextOutputFormat.SEPARATOR, \",\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getCount",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getCount()\n{\r\n    return count.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getTime()\n{\r\n    return time.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "setCount",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setCount(long count)\n{\r\n    this.count.set(count);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "setTime",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void setTime(long time)\n{\r\n    this.time.set(time);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n    count.write(out);\r\n    time.write(out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n    count.readFields(in);\r\n    time.readFields(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "String toString()\n{\r\n    return getCount() + \",\" + getTime();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "run",
  "errType" : null,
  "containingMethodsNum" : 28,
  "sourceCodeText" : "int run(String[] args) throws Exception\n{\r\n    Option helpOption = new Option(\"h\", \"help\", false, \"Shows this message. Additionally specify the \" + MAPPER_CLASS_NAME + \" argument to show help for a specific mapper class.\");\r\n    Options options = new Options();\r\n    options.addOption(helpOption);\r\n    options.addOption(OptionBuilder.withArgName(\"NN URI\").hasArg().withDescription(\"URI of the NameNode under test\").isRequired().create(NN_URI));\r\n    OptionGroup startTimeOptions = new OptionGroup();\r\n    startTimeOptions.addOption(OptionBuilder.withArgName(\"Start Timestamp\").hasArg().withDescription(\"Mapper start UTC timestamp in ms\").create(START_TIMESTAMP_MS));\r\n    startTimeOptions.addOption(OptionBuilder.withArgName(\"Start Time Offset\").hasArg().withDescription(\"Mapper start time as an offset from current \" + \"time. Human-readable formats accepted, e.g. 10m (default \" + START_TIME_OFFSET_DEFAULT + \").\").create(START_TIME_OFFSET));\r\n    options.addOptionGroup(startTimeOptions);\r\n    Option mapperClassOption = OptionBuilder.withArgName(\"Mapper ClassName\").hasArg().withDescription(\"Class name of the mapper; must be a WorkloadMapper \" + \"subclass. Mappers supported currently: \\n\" + \"1. AuditReplayMapper \\n\" + \"2. CreateFileMapper \\n\" + \"Fully specified class names are also supported.\").isRequired().create(MAPPER_CLASS_NAME);\r\n    options.addOption(mapperClassOption);\r\n    Options helpOptions = new Options();\r\n    helpOptions.addOption(helpOption);\r\n    Option mapperClassNotRequiredOption = (Option) mapperClassOption.clone();\r\n    mapperClassNotRequiredOption.setRequired(false);\r\n    helpOptions.addOption(mapperClassNotRequiredOption);\r\n    CommandLineParser parser = new PosixParser();\r\n    CommandLine cli = parser.parse(helpOptions, args, true);\r\n    if (cli.hasOption(\"h\")) {\r\n        String footer = null;\r\n        if (cli.hasOption(MAPPER_CLASS_NAME)) {\r\n            footer = getMapperUsageInfo(cli.getOptionValue(MAPPER_CLASS_NAME));\r\n        }\r\n        HelpFormatter formatter = new HelpFormatter();\r\n        formatter.printHelp(200, \"./start-workload [options]\", null, options, footer);\r\n        return 1;\r\n    }\r\n    cli = parser.parse(options, args);\r\n    String nnURI = cli.getOptionValue(NN_URI);\r\n    long startTimestampMs;\r\n    if (cli.hasOption(START_TIMESTAMP_MS)) {\r\n        startTimestampMs = Long.parseLong(cli.getOptionValue(START_TIMESTAMP_MS));\r\n    } else {\r\n        String tmpConfKey = \"___temp_config_property___\";\r\n        Configuration tmpConf = new Configuration();\r\n        tmpConf.set(tmpConfKey, cli.getOptionValue(START_TIME_OFFSET, START_TIME_OFFSET_DEFAULT));\r\n        startTimestampMs = tmpConf.getTimeDuration(tmpConfKey, 0, TimeUnit.MILLISECONDS) + System.currentTimeMillis();\r\n    }\r\n    Class<? extends WorkloadMapper<?, ?, ?, ?>> mapperClass = getMapperClass(cli.getOptionValue(MAPPER_CLASS_NAME));\r\n    if (!mapperClass.newInstance().verifyConfigurations(getConf())) {\r\n        System.err.println(getMapperUsageInfo(cli.getOptionValue(MAPPER_CLASS_NAME)));\r\n        return 1;\r\n    }\r\n    Job job = getJobForSubmission(getConf(), nnURI, startTimestampMs, mapperClass);\r\n    boolean success = job.waitForCompletion(true);\r\n    return success ? 0 : 1;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getJobForSubmission",
  "errType" : null,
  "containingMethodsNum" : 9,
  "sourceCodeText" : "Job getJobForSubmission(Configuration baseConf, String nnURI, long startTimestampMs, Class<? extends WorkloadMapper<?, ?, ?, ?>> mapperClass) throws IOException, InstantiationException, IllegalAccessException\n{\r\n    Configuration conf = new Configuration(baseConf);\r\n    conf.set(NN_URI, nnURI);\r\n    conf.setBoolean(MRJobConfig.MAP_SPECULATIVE, false);\r\n    String startTimeString = new SimpleDateFormat(\"yyyy/MM/dd HH:mm:ss z\").format(new Date(startTimestampMs));\r\n    LOG.info(\"The workload will start at \" + startTimestampMs + \" ms (\" + startTimeString + \")\");\r\n    conf.setLong(START_TIMESTAMP_MS, startTimestampMs);\r\n    Job job = Job.getInstance(conf, \"Dynamometer Workload Driver\");\r\n    job.setJarByClass(mapperClass);\r\n    job.setMapperClass(mapperClass);\r\n    mapperClass.newInstance().configureJob(job);\r\n    return job;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "main",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "void main(String[] args) throws Exception\n{\r\n    WorkloadDriver driver = new WorkloadDriver();\r\n    System.exit(ToolRunner.run(driver, args));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getMapperClass",
  "errType" : [ "ClassNotFoundException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "Class<? extends WorkloadMapper<?, ?, ?, ?>> getMapperClass(String className)\n{\r\n    String[] potentialQualifiedClassNames = { WorkloadDriver.class.getPackage().getName() + \".\" + className, AuditReplayMapper.class.getPackage().getName() + \".\" + className, className };\r\n    for (String qualifiedClassName : potentialQualifiedClassNames) {\r\n        Class<?> mapperClass;\r\n        try {\r\n            mapperClass = getConf().getClassByName(qualifiedClassName);\r\n        } catch (ClassNotFoundException cnfe) {\r\n            continue;\r\n        }\r\n        if (!WorkloadMapper.class.isAssignableFrom(mapperClass)) {\r\n            throw new IllegalArgumentException(className + \" is not a subclass of \" + WorkloadMapper.class.getCanonicalName());\r\n        }\r\n        return (Class<? extends WorkloadMapper<?, ?, ?, ?>>) mapperClass;\r\n    }\r\n    throw new IllegalArgumentException(\"Unable to find workload mapper class: \" + className);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getMapperUsageInfo",
  "errType" : null,
  "containingMethodsNum" : 11,
  "sourceCodeText" : "String getMapperUsageInfo(String mapperClassName) throws ClassNotFoundException, InstantiationException, IllegalAccessException\n{\r\n    WorkloadMapper<?, ?, ?, ?> mapper = getMapperClass(mapperClassName).newInstance();\r\n    StringBuilder builder = new StringBuilder(\"Usage for \");\r\n    builder.append(mapper.getClass().getSimpleName());\r\n    builder.append(\":\\n\");\r\n    builder.append(mapper.getDescription());\r\n    for (String configDescription : mapper.getConfigDescriptions()) {\r\n        builder.append(\"\\n    \");\r\n        builder.append(configDescription);\r\n    }\r\n    builder.append(\"\\nConfiguration parameters can be set at the \");\r\n    builder.append(\"_start_ of the argument list like:\\n\");\r\n    builder.append(\"  -Dconfiguration.key=configurationValue\");\r\n    return builder.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getLength",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getLength() throws IOException, InterruptedException\n{\r\n    return 0;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getLocations",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String[] getLocations() throws IOException, InterruptedException\n{\r\n    return new String[] {};\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void initialize(InputSplit split, TaskAttemptContext context) throws IOException, InterruptedException\n{\r\n    Configuration conf = context.getConfiguration();\r\n    durationMs = conf.getInt(CreateFileMapper.DURATION_MIN_KEY, 0) * 60 * 1000;\r\n    startTimestampInMs = conf.getInt(WorkloadDriver.START_TIMESTAMP_MS, 0);\r\n    endTimestampInMs = startTimestampInMs + durationMs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "nextKeyValue",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean nextKeyValue() throws IOException, InterruptedException\n{\r\n    if (numRows > 0) {\r\n        numRows--;\r\n        return true;\r\n    } else {\r\n        return false;\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getCurrentKey",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "K getCurrentKey() throws IOException, InterruptedException\n{\r\n    return (K) NullWritable.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getCurrentValue",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "V getCurrentValue() throws IOException, InterruptedException\n{\r\n    return (V) NullWritable.get();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getProgress",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "float getProgress() throws IOException, InterruptedException\n{\r\n    long remainingMs = endTimestampInMs - System.currentTimeMillis();\r\n    return (remainingMs * 100.0f) / durationMs;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "close",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void close() throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "listStatus",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "List<FileStatus> listStatus(JobContext context) throws IOException\n{\r\n    context.getConfiguration().set(FileInputFormat.INPUT_DIR, context.getConfiguration().get(AuditReplayMapper.INPUT_PATH_KEY));\r\n    return super.listStatus(context);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "isSplitable",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isSplitable(JobContext context, Path file)\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "reduce",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void reduce(UserCommandKey key, Iterable<CountTimeWritable> values, Context context) throws IOException, InterruptedException\n{\r\n    long countSum = 0;\r\n    long timeSum = 0;\r\n    for (CountTimeWritable v : values) {\r\n        countSum += v.getCount();\r\n        timeSum += v.getTime();\r\n    }\r\n    context.write(key, new CountTimeWritable(countSum, timeSum));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getDescription",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getDescription()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getConfigDescriptions",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "List<String> getConfigDescriptions()",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "verifyConfigurations",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean verifyConfigurations(Configuration conf)",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "configureJob",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "void configureJob(Job job)\n{\r\n    job.setInputFormatClass(VirtualInputFormat.class);\r\n    job.setNumReduceTasks(0);\r\n    job.setOutputKeyClass(NullWritable.class);\r\n    job.setOutputValueClass(NullWritable.class);\r\n    job.setOutputFormatClass(NullOutputFormat.class);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getDescription",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getDescription()\n{\r\n    return \"This mapper creates 1-byte files for the specified duration.\";\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "getConfigDescriptions",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "List<String> getConfigDescriptions()\n{\r\n    return Lists.newArrayList(NUM_MAPPERS_KEY + \" (required): Number of mappers to launch.\", DURATION_MIN_KEY + \" (required): Number of minutes to induce workload for.\", SHOULD_DELETE_KEY + \" (default: \" + SHOULD_DELETE_DEFAULT + \"): If true, delete the files after creating \" + \"them. This can be useful for generating constant load without \" + \"increasing the number of file objects.\", FILE_PARENT_PATH_KEY + \" (default: \" + FILE_PARENT_PATH_DEFAULT + \"): The root directory in which to create files.\");\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "verifyConfigurations",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "boolean verifyConfigurations(Configuration confToVerify)\n{\r\n    return confToVerify.get(NUM_MAPPERS_KEY) != null && confToVerify.get(DURATION_MIN_KEY) != null;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : true,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator",
  "methodName" : "map",
  "errType" : null,
  "containingMethodsNum" : 22,
  "sourceCodeText" : "void map(NullWritable key, NullWritable value, Mapper.Context mapperContext) throws IOException, InterruptedException\n{\r\n    taskID = mapperContext.getTaskAttemptID().getTaskID().getId();\r\n    conf = mapperContext.getConfiguration();\r\n    String namenodeURI = conf.get(WorkloadDriver.NN_URI);\r\n    startTimestampMs = conf.getLong(WorkloadDriver.START_TIMESTAMP_MS, -1);\r\n    fileParentPath = conf.get(FILE_PARENT_PATH_KEY, FILE_PARENT_PATH_DEFAULT);\r\n    shouldDelete = conf.getBoolean(SHOULD_DELETE_KEY, SHOULD_DELETE_DEFAULT);\r\n    int durationMin = conf.getInt(DURATION_MIN_KEY, -1);\r\n    if (durationMin < 0) {\r\n        throw new IOException(\"Duration must be positive; got: \" + durationMin);\r\n    }\r\n    endTimeStampMs = startTimestampMs + TimeUnit.MILLISECONDS.convert(durationMin, TimeUnit.MINUTES);\r\n    fs = FileSystem.get(URI.create(namenodeURI), conf);\r\n    System.out.println(\"Start timestamp: \" + startTimestampMs);\r\n    long currentEpoch = System.currentTimeMillis();\r\n    long delay = startTimestampMs - currentEpoch;\r\n    if (delay > 0) {\r\n        System.out.println(\"Sleeping for \" + delay + \" ms\");\r\n        Thread.sleep(delay);\r\n    }\r\n    String mapperSpecifcPathPrefix = fileParentPath + \"/mapper\" + taskID;\r\n    System.out.println(\"Mapper path prefix: \" + mapperSpecifcPathPrefix);\r\n    long numFilesCreated = 0;\r\n    Path path;\r\n    final byte[] content = { 0x0 };\r\n    while (System.currentTimeMillis() < endTimeStampMs) {\r\n        path = new Path(mapperSpecifcPathPrefix + \"/file\" + numFilesCreated);\r\n        OutputStream out = fs.create(path);\r\n        out.write(content);\r\n        out.close();\r\n        numFilesCreated++;\r\n        mapperContext.getCounter(CREATEFILECOUNTERS.NUMFILESCREATED).increment(1L);\r\n        if (numFilesCreated % 1000 == 0) {\r\n            mapperContext.progress();\r\n            System.out.println(\"Number of files created: \" + numFilesCreated);\r\n        }\r\n        if (shouldDelete) {\r\n            fs.delete(path, true);\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 8,
  "sourceCodeText" : "void initialize(Configuration conf) throws IOException\n{\r\n    startTimestamp = conf.getLong(AUDIT_START_TIMESTAMP_KEY, -1);\r\n    if (startTimestamp < 0) {\r\n        throw new IOException(\"Invalid or missing audit start timestamp: \" + startTimestamp);\r\n    }\r\n    dateFormat = new SimpleDateFormat(conf.get(AUDIT_LOG_DATE_FORMAT_KEY, AUDIT_LOG_DATE_FORMAT_DEFAULT));\r\n    String timeZoneString = conf.get(AUDIT_LOG_DATE_TIME_ZONE_KEY, AUDIT_LOG_DATE_TIME_ZONE_DEFAULT);\r\n    dateFormat.setTimeZone(TimeZone.getTimeZone(timeZoneString));\r\n    String logLineParseRegexString = conf.get(AUDIT_LOG_PARSE_REGEX_KEY, AUDIT_LOG_PARSE_REGEX_DEFAULT);\r\n    if (!logLineParseRegexString.contains(\"(?<timestamp>\") && logLineParseRegexString.contains(\"(?<message>\")) {\r\n        throw new IllegalArgumentException(\"Must configure regex with named \" + \"capture groups 'timestamp' and 'message'\");\r\n    }\r\n    logLineParseRegex = Pattern.compile(logLineParseRegexString);\r\n}\n",
  "settingFlag" : true,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "parse",
  "errType" : [ "ParseException", "ArrayIndexOutOfBoundsException" ],
  "containingMethodsNum" : 13,
  "sourceCodeText" : "AuditReplayCommand parse(Text inputLine, Function<Long, Long> relativeToAbsolute) throws IOException\n{\r\n    Matcher m = logLineParseRegex.matcher(inputLine.toString());\r\n    if (!m.find()) {\r\n        throw new IOException(\"Unable to find valid message pattern from audit log line: `\" + inputLine + \"` using regex `\" + logLineParseRegex + \"`\");\r\n    }\r\n    long relativeTimestamp;\r\n    try {\r\n        relativeTimestamp = dateFormat.parse(m.group(\"timestamp\")).getTime() - startTimestamp;\r\n    } catch (ParseException p) {\r\n        throw new IOException(\"Exception while parsing timestamp from audit log line: `\" + inputLine + \"`\", p);\r\n    }\r\n    String auditMessageSanitized = m.group(\"message\").replace(\"(options=\", \"(options:\");\r\n    Map<String, String> parameterMap = new HashMap<String, String>();\r\n    String[] auditMessageSanitizedList = auditMessageSanitized.split(\"\\t\");\r\n    for (String auditMessage : auditMessageSanitizedList) {\r\n        String[] splitMessage = auditMessage.split(\"=\", 2);\r\n        try {\r\n            parameterMap.put(splitMessage[0], splitMessage[1]);\r\n        } catch (ArrayIndexOutOfBoundsException e) {\r\n            throw new IOException(\"Exception while parsing a message from audit log line: `\" + inputLine + \"`\", e);\r\n        }\r\n    }\r\n    return new AuditReplayCommand(relativeToAbsolute.apply(relativeTimestamp), SPACE_SPLITTER.split(parameterMap.get(\"ugi\")).iterator().next(), parameterMap.get(\"cmd\").replace(\"(options:\", \"(options=\"), parameterMap.get(\"src\"), parameterMap.get(\"dst\"), parameterMap.get(\"ip\"));\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 2,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getAbsoluteTimestamp",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "long getAbsoluteTimestamp()\n{\r\n    return absoluteTimestamp;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getSimpleUgi",
  "errType" : [ "IOException" ],
  "containingMethodsNum" : 5,
  "sourceCodeText" : "String getSimpleUgi()\n{\r\n    Matcher m = SIMPLE_UGI_PATTERN.matcher(ugi);\r\n    if (m.matches()) {\r\n        return m.group(1);\r\n    } else {\r\n        LOG.error(\"Error parsing simple UGI <{}>; falling back to current user\", ugi);\r\n        try {\r\n            return UserGroupInformation.getCurrentUser().getShortUserName();\r\n        } catch (IOException ioe) {\r\n            return \"\";\r\n        }\r\n    }\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 1,
  "logged" : true
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getCommand",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getCommand()\n{\r\n    return command;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getSrc",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getSrc()\n{\r\n    return src;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getDest",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getDest()\n{\r\n    return dest;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getSourceIP",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "String getSourceIP()\n{\r\n    return sourceIP;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getDelay",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "long getDelay(TimeUnit unit)\n{\r\n    return unit.convert(absoluteTimestamp - System.currentTimeMillis(), TimeUnit.MILLISECONDS);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int compareTo(Delayed o)\n{\r\n    return Long.compare(absoluteTimestamp, ((AuditReplayCommand) o).absoluteTimestamp);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "isPoison",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "boolean isPoison()\n{\r\n    return false;\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getPoisonPill",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "AuditReplayCommand getPoisonPill(long relativeTimestamp)\n{\r\n    return new PoisonPillCommand(relativeTimestamp);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean equals(Object other)\n{\r\n    if (!(other instanceof AuditReplayCommand)) {\r\n        return false;\r\n    }\r\n    AuditReplayCommand o = (AuditReplayCommand) other;\r\n    return absoluteTimestamp == o.absoluteTimestamp && ugi.equals(o.ugi) && command.equals(o.command) && src.equals(o.src) && dest.equals(o.dest) && sourceIP.equals(o.sourceIP);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    return Objects.hash(absoluteTimestamp, ugi, command, src, dest, sourceIP);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String toString()\n{\r\n    return String.format(\"AuditReplayCommand(absoluteTimestamp=%d, ugi=%s, \" + \"command=%s, src=%s, dest=%s, sourceIP=%s\", absoluteTimestamp, ugi, command, src, dest, sourceIP);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "initialize",
  "errType" : null,
  "containingMethodsNum" : 0,
  "sourceCodeText" : "void initialize(Configuration conf) throws IOException\n{\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "parse",
  "errType" : null,
  "containingMethodsNum" : 2,
  "sourceCodeText" : "AuditReplayCommand parse(Text inputLine, Function<Long, Long> relativeToAbsolute) throws IOException\n{\r\n    String[] fields = inputLine.toString().split(FIELD_SEPARATOR);\r\n    long absoluteTimestamp = relativeToAbsolute.apply(Long.parseLong(fields[0]));\r\n    return new AuditReplayCommand(absoluteTimestamp, fields[1], fields[2], fields[3], fields[4], fields[5]);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getUser",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getUser()\n{\r\n    return user.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getCommand",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getCommand()\n{\r\n    return command.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "getType",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "String getType()\n{\r\n    return type.toString();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "write",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void write(DataOutput out) throws IOException\n{\r\n    user.write(out);\r\n    command.write(out);\r\n    type.write(out);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "readFields",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "void readFields(DataInput in) throws IOException\n{\r\n    user.readFields(in);\r\n    command.readFields(in);\r\n    type.readFields(in);\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : true,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "compareTo",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int compareTo(@Nonnull Object o)\n{\r\n    return toString().compareTo(o.toString());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "toString",
  "errType" : null,
  "containingMethodsNum" : 3,
  "sourceCodeText" : "String toString()\n{\r\n    return getUser() + \",\" + getType() + \",\" + getCommand();\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "equals",
  "errType" : null,
  "containingMethodsNum" : 5,
  "sourceCodeText" : "boolean equals(Object o)\n{\r\n    if (this == o) {\r\n        return true;\r\n    }\r\n    if (o == null || getClass() != o.getClass()) {\r\n        return false;\r\n    }\r\n    UserCommandKey that = (UserCommandKey) o;\r\n    return getUser().equals(that.getUser()) && getCommand().equals(that.getCommand()) && getType().equals(that.getType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
}, {
  "directory" : "E:\\MyPaper\\hadoop\\hadoop-tools\\hadoop-dynamometer\\hadoop-dynamometer-workload\\src\\main\\java\\org\\apache\\hadoop\\tools\\dynamometer\\workloadgenerator\\audit",
  "methodName" : "hashCode",
  "errType" : null,
  "containingMethodsNum" : 1,
  "sourceCodeText" : "int hashCode()\n{\r\n    return Objects.hash(getUser(), getCommand(), getType());\r\n}\n",
  "settingFlag" : false,
  "hasThrow" : false,
  "returnSpecialValue" : false,
  "tryCatchBlockNum" : 0,
  "logged" : false
} ]